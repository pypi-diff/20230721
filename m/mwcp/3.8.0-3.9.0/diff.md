# Comparing `tmp/mwcp-3.8.0.tar.gz` & `tmp/mwcp-3.9.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "mwcp-3.8.0.tar", last modified: Fri Sep 16 12:27:50 2022, max compression
+gzip compressed data, was "mwcp-3.9.0.tar", last modified: Thu Dec  8 23:23:48 2022, max compression
```

## Comparing `mwcp-3.8.0.tar` & `mwcp-3.9.0.tar`

### file list

```diff
@@ -1,153 +1,166 @@
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.315907 mwcp-3.8.0/
--rw-rw-rw-   0        0        0    30252 2022-09-16 12:20:03.000000 mwcp-3.8.0/CHANGELOG.md
--rw-rw-rw-   0        0        0     1343 2022-06-28 15:51:32.000000 mwcp-3.8.0/LICENSE.txt
--rw-rw-rw-   0        0        0      330 2022-06-28 15:51:32.000000 mwcp-3.8.0/MANIFEST.in
--rw-rw-rw-   0        0        0    26193 2022-09-16 12:27:50.491850 mwcp-3.8.0/PKG-INFO
--rw-rw-rw-   0        0        0    21018 2022-06-28 15:51:32.000000 mwcp-3.8.0/README.md
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.361904 mwcp-3.8.0/mwcp/
--rw-rw-rw-   0        0        0      893 2022-09-16 12:20:03.000000 mwcp-3.8.0/mwcp/__init__.py
--rw-rw-rw-   0        0        0    30369 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/cli.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.320907 mwcp-3.8.0/mwcp/config/
--rw-rw-rw-   0        0        0     3192 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/config/__init__.py
--rw-rw-rw-   0        0        0     1360 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/config/config.yml
--rw-rw-rw-   0        0        0    14742 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/config/fields.json
--rw-rw-rw-   0        0        0     5579 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/config/fields.txt
--rw-rw-rw-   0        0        0     1126 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/config/log_config.yml
--rw-rw-rw-   0        0        0    59987 2022-09-16 12:20:03.000000 mwcp-3.8.0/mwcp/config/schema.json
--rw-rw-rw-   0        0        0     3411 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/core.py
--rw-rw-rw-   0        0        0    15155 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/dispatcher.py
--rw-rw-rw-   0        0        0      575 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/exceptions.py
--rw-rw-rw-   0        0        0    19643 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/file_object.py
--rw-rw-rw-   0        0        0    85223 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/metadata.py
--rw-rw-rw-   0        0        0     6010 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/parser.py
--rw-rw-rw-   0        0        0      263 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/parser_config.yml
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.323905 mwcp-3.8.0/mwcp/parsers/
--rw-rw-rw-   0        0        0      848 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/parsers/TA.py
--rw-rw-rw-   0        0        0      187 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/parsers/__init__.py
--rw-rw-rw-   0        0        0     3742 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/parsers/bar.py
--rw-rw-rw-   0        0        0     1713 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/parsers/foo.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.326915 mwcp-3.8.0/mwcp/parsers/tests/
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.328901 mwcp-3.8.0/mwcp/parsers/tests/foo/
--rw-rw-rw-   0        0        0     2285 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/parsers/tests/foo/f144899b86766688991c5d0d10902f4a.json
--rw-rw-rw-   0        0        0    17453 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/registry.py
--rw-rw-rw-   0        0        0    38173 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/report.py
--rw-rw-rw-   0        0        0    14018 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/report_writers.py
--rw-rw-rw-   0        0        0     1021 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/reporter.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.330904 mwcp-3.8.0/mwcp/resources/
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.333905 mwcp-3.8.0/mwcp/resources/RATDecoders/
--rw-rw-rw-   0        0        0        0 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/resources/RATDecoders/PLACE_PARSERS_HERE
--rw-rw-rw-   0        0        0        0 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/resources/RATDecoders/__init__.py
--rw-rw-rw-   0        0        0        0 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/resources/__init__.py
--rw-rw-rw-   0        0        0    18099 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/resources/techanarchy_bridge.py
--rw-rw-rw-   0        0        0    11807 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/runner.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.335905 mwcp-3.8.0/mwcp/stix/
--rw-rw-rw-   0        0        0        0 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/stix/__init__.py
--rw-rw-rw-   0        0        0     5001 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/stix/extensions.py
--rw-rw-rw-   0        0        0     1799 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/stix/objects.py
--rw-rw-rw-   0        0        0     5939 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/stix/report_writer.py
--rw-rw-rw-   0        0        0    26892 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tester.py
--rw-rw-rw-   0        0        0    13179 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/testing.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.356902 mwcp-3.8.0/mwcp/tests/
--rw-rw-rw-   0        0        0        0 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/__init__.py
--rw-rw-rw-   0        0        0     7995 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/conftest.py
--rw-rw-rw-   0        0        0    21939 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/construct_html.html
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.340908 mwcp-3.8.0/mwcp/tests/test_cli/
--rw-rw-rw-   0        0        0     1903 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_cli/csv_cli.csv
--rw-rw-rw-   0        0        0      302 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_cli/csv_legacy.csv
--rw-rw-rw-   0        0        0     2375 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_cli/fb843efb2ffec987db12e72ca75c9ea2.json
--rw-rw-rw-   0        0        0     2556 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_cli/parse.json
--rw-rw-rw-   0        0        0     1407 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_cli/parse.txt
--rw-rw-rw-   0        0        0    11260 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_cli.py
--rw-rw-rw-   0        0        0     3514 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_construct.py
--rw-rw-rw-   0        0        0      917 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_custombase64.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.343910 mwcp-3.8.0/mwcp/tests/test_disassembly/
--rw-rw-rw-   0        0        0     2306 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_disassembly/Sample.py
--rw-rw-rw-   0        0        0     2533 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_disassembly/strings.c
--rwxrwxrwx   0        0        0    49152 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_disassembly/strings.exe
--rw-rw-rw-   0        0        0    11878 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_disassembly/strings.json
--rw-rw-rw-   0        0        0     2301 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_disassembly.py
--rw-rw-rw-   0        0        0     7119 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_dispatcher.py
--rw-rw-rw-   0        0        0     4702 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_issues.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.346903 mwcp-3.8.0/mwcp/tests/test_legacy_reporter/
--rw-rw-rw-   0        0        0      858 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_legacy_reporter/report.txt
--rw-rw-rw-   0        0        0     5729 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_legacy_reporter.py
--rw-rw-rw-   0        0        0     5036 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_metadata.py
--rw-rw-rw-   0        0        0    10721 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_parsers.py
--rw-rw-rw-   0        0        0     2860 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_pecon.py
--rw-rw-rw-   0        0        0      232 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_poshdeob.py
--rw-rw-rw-   0        0        0    10395 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_registry.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.348905 mwcp-3.8.0/mwcp/tests/test_report/
--rw-rw-rw-   0        0        0    12181 2022-09-16 12:20:03.000000 mwcp-3.8.0/mwcp/tests/test_report/report.json
--rw-rw-rw-   0        0        0    11304 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_report/report.py
--rw-rw-rw-   0        0        0     2738 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_report/split_report.py
--rw-rw-rw-   0        0        0     4135 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_report.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.351903 mwcp-3.8.0/mwcp/tests/test_report_writer/
--rw-rw-rw-   0        0        0    10233 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_report_writer/report.html
--rw-rw-rw-   0        0        0     8002 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_report_writer/report.md
--rw-rw-rw-   0        0        0     5721 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_report_writer/report.txt
--rw-rw-rw-   0        0        0     2017 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_report_writer/report_foreign.html
--rw-rw-rw-   0        0        0     1627 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_report_writer/report_foreign.md
--rw-rw-rw-   0        0        0      958 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_report_writer/report_foreign.txt
--rw-rw-rw-   0        0        0     4413 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_report_writer/report_wordwrap.html
--rw-rw-rw-   0        0        0     9881 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_report_writer/report_wordwrap.md
--rw-rw-rw-   0        0        0     3686 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_report_writer/report_wordwrap.txt
--rw-rw-rw-   0        0        0     3083 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_report_writer.py
--rw-rw-rw-   0        0        0      248 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_runner.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.353905 mwcp-3.8.0/mwcp/tests/test_server/
--rw-rw-rw-   0        0        0      445 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_server/DecodedStringTestParser.py
--rw-rw-rw-   0        0        0    15394 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_server.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.356902 mwcp-3.8.0/mwcp/tests/test_stix/
--rw-rw-rw-   0        0        0    22882 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_stix/report.json
--rw-rw-rw-   0        0        0     1997 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_stix.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.358908 mwcp-3.8.0/mwcp/tests/test_string_report/
--rw-rw-rw-   0        0        0     1088 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_string_report/strings.json
--rw-rw-rw-   0        0        0       12 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_string_report/strings.txt
--rw-rw-rw-   0        0        0      994 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tests/test_string_report.py
--rw-rw-rw-   0        0        0     1916 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tests/test_testing.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.361904 mwcp-3.8.0/mwcp/tools/
--rw-rw-rw-   0        0        0        0 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tools/__init__.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.366903 mwcp-3.8.0/mwcp/tools/server/
--rw-rw-rw-   0        0        0      706 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tools/server/__init__.py
--rw-rw-rw-   0        0        0    15092 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/tools/server/server.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.366903 mwcp-3.8.0/mwcp/tools/server/static/
--rw-rw-rw-   0        0        0    14107 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tools/server/static/style.css
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.368904 mwcp-3.8.0/mwcp/tools/server/templates/
--rw-rw-rw-   0        0        0     1021 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tools/server/templates/base.html
--rw-rw-rw-   0        0        0      509 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tools/server/templates/parsers.html
--rw-rw-rw-   0        0        0       90 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tools/server/templates/results.html
--rw-rw-rw-   0        0        0     1411 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tools/server/templates/upload.html
--rw-rw-rw-   0        0        0     6900 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tools/update_legacy_tests.py
--rw-rw-rw-   0        0        0      353 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/tools/update_schema.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.371906 mwcp-3.8.0/mwcp/utils/
--rw-rw-rw-   0        0        0       85 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/__init__.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.374902 mwcp-3.8.0/mwcp/utils/construct/
--rw-rw-rw-   0        0        0     6020 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/ARM.py
--rw-rw-rw-   0        0        0     2249 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/MIPS.py
--rw-rw-rw-   0        0        0      430 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/__init__.py
--rw-rw-rw-   0        0        0    16259 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/construct_html.py
--rw-rw-rw-   0        0        0     5584 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/construct_template.html
--rw-rw-rw-   0        0        0     1941 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/datetime_.py
--rw-rw-rw-   0        0        0     3719 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/dotnet.py
--rw-rw-rw-   0        0        0    47121 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/helpers.py
--rw-rw-rw-   0        0        0     1179 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/network.py
--rw-rw-rw-   0        0        0    26087 2022-09-16 12:20:02.000000 mwcp-3.8.0/mwcp/utils/construct/version28.py
--rw-rw-rw-   0        0        0     5701 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/windows_constants.py
--rw-rw-rw-   0        0        0     4961 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/windows_enums.py
--rw-rw-rw-   0        0        0    14468 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/construct/windows_structures.py
--rw-rw-rw-   0        0        0     5968 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/custombase64.py
--rw-rw-rw-   0        0        0     3718 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/elffileutils.py
--rw-rw-rw-   0        0        0     6846 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/logutil.py
--rw-rw-rw-   0        0        0     1774 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/multi_proc.py
--rw-rw-rw-   0        0        0    17520 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/pecon.py
--rw-rw-rw-   0        0        0    25094 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/pefileutils.py
--rw-rw-rw-   0        0        0    10454 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/poshdeob.py
--rw-rw-rw-   0        0        0      812 2022-06-28 15:51:33.000000 mwcp-3.8.0/mwcp/utils/stringutils.py
-drwxrwxrwx   0        0        0        0 2022-09-16 12:27:49.318905 mwcp-3.8.0/mwcp.egg-info/
--rw-rw-rw-   0        0        0    26193 2022-09-16 12:27:48.000000 mwcp-3.8.0/mwcp.egg-info/PKG-INFO
--rw-rw-rw-   0        0        0     3753 2022-09-16 12:27:49.000000 mwcp-3.8.0/mwcp.egg-info/SOURCES.txt
--rw-rw-rw-   0        0        0        1 2022-09-16 12:27:48.000000 mwcp-3.8.0/mwcp.egg-info/dependency_links.txt
--rw-rw-rw-   0        0        0      175 2022-09-16 12:27:48.000000 mwcp-3.8.0/mwcp.egg-info/entry_points.txt
--rw-rw-rw-   0        0        0      423 2022-09-16 12:27:48.000000 mwcp-3.8.0/mwcp.egg-info/requires.txt
--rw-rw-rw-   0        0        0        5 2022-09-16 12:27:48.000000 mwcp-3.8.0/mwcp.egg-info/top_level.txt
--rw-rw-rw-   0        0        0      418 2022-09-16 12:27:50.496850 mwcp-3.8.0/setup.cfg
--rw-rw-rw-   0        0        0     2019 2022-09-16 12:20:03.000000 mwcp-3.8.0/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.178854 mwcp-3.9.0/
+-rw-r--r--   0 runner    (1001) docker     (123)    31099 2022-12-08 23:23:34.000000 mwcp-3.9.0/CHANGELOG.md
+-rw-r--r--   0 runner    (1001) docker     (123)     1338 2022-12-08 23:23:34.000000 mwcp-3.9.0/LICENSE.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      321 2022-12-08 23:23:34.000000 mwcp-3.9.0/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (123)    23503 2022-12-08 23:23:48.178854 mwcp-3.9.0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    22872 2022-12-08 23:23:34.000000 mwcp-3.9.0/README.md
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.118854 mwcp-3.9.0/mwcp/
+-rw-r--r--   0 runner    (1001) docker     (123)      816 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    30134 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/cli.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.122854 mwcp-3.9.0/mwcp/config/
+-rw-r--r--   0 runner    (1001) docker     (123)     3093 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1220 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/config/config.yml
+-rw-r--r--   0 runner    (1001) docker     (123)    14279 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/config/fields.json
+-rw-r--r--   0 runner    (1001) docker     (123)     5429 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/config/fields.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     1082 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/config/log_config.yml
+-rw-r--r--   0 runner    (1001) docker     (123)    58597 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/config/schema.json
+-rw-r--r--   0 runner    (1001) docker     (123)     4109 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14809 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/dispatcher.py
+-rw-r--r--   0 runner    (1001) docker     (123)      550 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19961 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/file_object.py
+-rw-r--r--   0 runner    (1001) docker     (123)    82768 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/metadata.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5850 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1018 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parser_config.yml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.126854 mwcp-3.9.0/mwcp/parsers/
+-rw-r--r--   0 runner    (1001) docker     (123)     2058 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/Archive.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1819 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/Decoy.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1489 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/GenericDropper.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1292 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/ISO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1824 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/PDF.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1883 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/PowerShell.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4100 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/Python.py
+-rw-r--r--   0 runner    (1001) docker     (123)    44620 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/Quarantined.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5848 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/RSA.py
+-rw-r--r--   0 runner    (1001) docker     (123)      820 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/TA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4910 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/VisualBasic.py
+-rw-r--r--   0 runner    (1001) docker     (123)      182 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1663 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/foo.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.098854 mwcp-3.9.0/mwcp/parsers/tests/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.126854 mwcp-3.9.0/mwcp/parsers/tests/foo/
+-rw-r--r--   0 runner    (1001) docker     (123)     2216 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/parsers/tests/foo/f144899b86766688991c5d0d10902f4a.json
+-rw-r--r--   0 runner    (1001) docker     (123)    16946 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/registry.py
+-rw-r--r--   0 runner    (1001) docker     (123)    37492 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13642 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/report_writers.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.126854 mwcp-3.9.0/mwcp/resources/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.130854 mwcp-3.9.0/mwcp/resources/RATDecoders/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/resources/RATDecoders/PLACE_PARSERS_HERE
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/resources/RATDecoders/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/resources/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17805 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/resources/techanarchy_bridge.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9247 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/runner.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.130854 mwcp-3.9.0/mwcp/stix/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/stix/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4880 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/stix/extensions.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1755 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/stix/objects.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5788 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/stix/report_writer.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26264 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tester.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12901 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/testing.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.146854 mwcp-3.9.0/mwcp/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7752 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21566 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/construct_html.html
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.146854 mwcp-3.9.0/mwcp/tests/test_cli/
+-rw-r--r--   0 runner    (1001) docker     (123)     1870 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_cli/csv_cli.csv
+-rw-r--r--   0 runner    (1001) docker     (123)      293 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_cli/csv_legacy.csv
+-rw-r--r--   0 runner    (1001) docker     (123)     2304 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_cli/fb843efb2ffec987db12e72ca75c9ea2.json
+-rw-r--r--   0 runner    (1001) docker     (123)     2483 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_cli/parse.json
+-rw-r--r--   0 runner    (1001) docker     (123)     1368 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_cli/parse.txt
+-rw-r--r--   0 runner    (1001) docker     (123)    10941 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3414 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_construct.py
+-rw-r--r--   0 runner    (1001) docker     (123)      896 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_custombase64.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.146854 mwcp-3.9.0/mwcp/tests/test_disassembly/
+-rw-r--r--   0 runner    (1001) docker     (123)     2245 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_disassembly/Sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2457 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_disassembly/strings.c
+-rw-r--r--   0 runner    (1001) docker     (123)    49152 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_disassembly/strings.exe
+-rw-r--r--   0 runner    (1001) docker     (123)    11463 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_disassembly/strings.json
+-rw-r--r--   0 runner    (1001) docker     (123)     2234 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_disassembly.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6929 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_dispatcher.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4567 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_issues.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.146854 mwcp-3.9.0/mwcp/tests/test_legacy_reporter/
+-rw-r--r--   0 runner    (1001) docker     (123)      832 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_legacy_reporter/report.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     5234 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_legacy_reporter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4877 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_metadata.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10502 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_parsers.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2801 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_pecon.py
+-rw-r--r--   0 runner    (1001) docker     (123)      219 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_poshdeob.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10076 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_registry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.150854 mwcp-3.9.0/mwcp/tests/test_report/
+-rw-r--r--   0 runner    (1001) docker     (123)    11736 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report/report.json
+-rw-r--r--   0 runner    (1001) docker     (123)    10936 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2650 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report/split_report.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4005 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.150854 mwcp-3.9.0/mwcp/tests/test_report_writer/
+-rw-r--r--   0 runner    (1001) docker     (123)     9915 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report_writer/report.html
+-rw-r--r--   0 runner    (1001) docker     (123)     7834 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report_writer/report.md
+-rw-r--r--   0 runner    (1001) docker     (123)     5537 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report_writer/report.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     1977 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report_writer/report_foreign.html
+-rw-r--r--   0 runner    (1001) docker     (123)     1597 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report_writer/report_foreign.md
+-rw-r--r--   0 runner    (1001) docker     (123)      930 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report_writer/report_foreign.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     4302 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report_writer/report_wordwrap.html
+-rw-r--r--   0 runner    (1001) docker     (123)     9849 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report_writer/report_wordwrap.md
+-rw-r--r--   0 runner    (1001) docker     (123)     3599 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report_writer/report_wordwrap.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     3009 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_report_writer.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.150854 mwcp-3.9.0/mwcp/tests/test_runner/
+-rw-r--r--   0 runner    (1001) docker     (123)      430 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_runner/Sample.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.150854 mwcp-3.9.0/mwcp/tests/test_runner/yara_repo/
+-rw-r--r--   0 runner    (1001) docker     (123)      227 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_runner/yara_repo/rule_a.yara
+-rw-r--r--   0 runner    (1001) docker     (123)      258 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_runner/yara_repo/rule_b.yara
+-rw-r--r--   0 runner    (1001) docker     (123)     1628 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_runner.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.154854 mwcp-3.9.0/mwcp/tests/test_server/
+-rw-r--r--   0 runner    (1001) docker     (123)      428 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_server/DecodedStringTestParser.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14473 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_server.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.154854 mwcp-3.9.0/mwcp/tests/test_stix/
+-rw-r--r--   0 runner    (1001) docker     (123)    22308 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_stix/report.json
+-rw-r--r--   0 runner    (1001) docker     (123)     1927 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_stix.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.154854 mwcp-3.9.0/mwcp/tests/test_string_report/
+-rw-r--r--   0 runner    (1001) docker     (123)     1050 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_string_report/strings.json
+-rw-r--r--   0 runner    (1001) docker     (123)       11 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_string_report/strings.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      970 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_string_report.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1865 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tests/test_testing.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.154854 mwcp-3.9.0/mwcp/tools/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tools/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.154854 mwcp-3.9.0/mwcp/tools/server/
+-rw-r--r--   0 runner    (1001) docker     (123)      676 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tools/server/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14859 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tools/server/server.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.154854 mwcp-3.9.0/mwcp/tools/server/static/
+-rw-r--r--   0 runner    (1001) docker     (123)    13312 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tools/server/static/style.css
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.158854 mwcp-3.9.0/mwcp/tools/server/templates/
+-rw-r--r--   0 runner    (1001) docker     (123)      985 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tools/server/templates/base.html
+-rw-r--r--   0 runner    (1001) docker     (123)      488 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tools/server/templates/parsers.html
+-rw-r--r--   0 runner    (1001) docker     (123)       86 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tools/server/templates/results.html
+-rw-r--r--   0 runner    (1001) docker     (123)     1370 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tools/server/templates/upload.html
+-rw-r--r--   0 runner    (1001) docker     (123)     6701 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tools/update_legacy_tests.py
+-rw-r--r--   0 runner    (1001) docker     (123)      335 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/tools/update_schema.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.166854 mwcp-3.9.0/mwcp/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)       84 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.178854 mwcp-3.9.0/mwcp/utils/construct/
+-rw-r--r--   0 runner    (1001) docker     (123)     5880 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/ARM.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2194 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/MIPS.py
+-rw-r--r--   0 runner    (1001) docker     (123)      413 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15869 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/construct_html.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5428 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/construct_template.html
+-rw-r--r--   0 runner    (1001) docker     (123)     1880 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/datetime_.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3604 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/dotnet.py
+-rw-r--r--   0 runner    (1001) docker     (123)    45896 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1133 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/network.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25429 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/version28.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5569 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/windows_constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4785 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/windows_enums.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14102 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/construct/windows_structures.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5783 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/custombase64.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3590 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/elffileutils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6643 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/logutil.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1720 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/multi_proc.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17025 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/pecon.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24352 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/pefileutils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10141 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/poshdeob.py
+-rw-r--r--   0 runner    (1001) docker     (123)      786 2022-12-08 23:23:34.000000 mwcp-3.9.0/mwcp/utils/stringutils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2022-12-08 23:23:48.118854 mwcp-3.9.0/mwcp.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)    23503 2022-12-08 23:23:48.000000 mwcp-3.9.0/mwcp.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     4082 2022-12-08 23:23:48.000000 mwcp-3.9.0/mwcp.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2022-12-08 23:23:48.000000 mwcp-3.9.0/mwcp.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      173 2022-12-08 23:23:48.000000 mwcp-3.9.0/mwcp.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      466 2022-12-08 23:23:48.000000 mwcp-3.9.0/mwcp.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        5 2022-12-08 23:23:48.000000 mwcp-3.9.0/mwcp.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      399 2022-12-08 23:23:48.178854 mwcp-3.9.0/setup.cfg
+-rwxr-xr-x   0 runner    (1001) docker     (123)     2075 2022-12-08 23:23:34.000000 mwcp-3.9.0/setup.py
```

### Comparing `mwcp-3.8.0/CHANGELOG.md` & `mwcp-3.9.0/CHANGELOG.md`

 * *Files 10% similar despite different names*

```diff
@@ -1,557 +1,590 @@
-# Changelog
-All notable changes to this project will be documented in this file.
-
-## [3.8.0] - 2022-09-14
-
-### Added
-- Added `Report.strings()` convenience function for obtaining reported decoded strings.
-- Added option to produce external string reports for decoded strings instead of being included in the main report.
-  -  Reports will be added as supplemental files with original name suffixed with `_strings.json` and `_strings.txt`.
-  - Use the `--string-report` flag to enable this in the CLI tool.
-  - Use the `external_strings` field to enable this in the server.
-
-### Changed
-- `DecodedString` metadata is now included in legacy report output.
-
-### Fixed
-- Fixed issue with `Path2.from_segments()` ignoring previous segments when another segment starts with a slash.
-- Fixed issue with throwing of `UnableToParse` sometimes causing the residual file not to be reported.
-- Files for which a parser throws an `UnableToParse` and end up not getting identified by any other parsers will
-  now appropriately be identified as "Unidentified file". (NOTE: This change may cause previous test cases to fail.)
-- Fixed bug with `Report.get()` and `Report.iter()` returning elements that don't match requested type.
-- Fixed bug in STIX output when a parser added a tag to a piece of metadata that translated to an observed-string.
-
-
-## [3.7.0] - 2022-06-28
-
-### Added
-- STIX 2.1 output format that includes three SCO extensions and one property extension.  This generates a STIX package containing the results of the full analysis.
-  - SCO Extensions
-    - observed-string
-    - crypto-currency-address
-    - symmetric-encryption
-  - Property Extensions
-    - extension-definition--b84c95f5-d48d-4e4a-b723-7d209a02deb9 -- RSA Private key extension for x509-certificate
-- Added `Path2` metadata element which simplifies fields from `Path` and better supports non-Windows paths.
-  - `name` and `directory_path` are removed in favor of just having a `path` element.
-  - Added `posix` field to indicated if path is Posix or Windows based.
-  - Added `.from_segments()` and `.from_pathlib_path()` constructors.
-- Added `derivation` field to `FileObject` object and `File` metadata element.
-- Added `FileObject.disassembly()` function for obtaining Dragodis dissassembler.
-
-### Fixed
-- AttributeError that can occur during testing if a Registry without a path was reported.
-- Disables skipping recursive files to avoid a breaking bug with greedy parsers.
-  - This is temporary until a proper fix can be implemented.
-- Fixed issue with process stalling when integer is provided in a bytes metadata field.
-
-### Deprecated
-- `Path` is deprecated in favor of `Path2`.
-  - NOTE: Once deprecations are removed, `Path2` will be renamed back to `Path`.
-
-
-## [3.6.2] - 2022-04-04
-
-### Fixed
-- config.load now accepts file_path as a string on pathlib.Path (@rhartig-ct)
-  - In 3.6.1 config.load was updated to take pathlib.Path, but mwcp.tools.server still used string
-
-## [3.6.1] - 2022-03-28
-
-### Fixed
-- AttributeError that can occur during testing if a Registry without a path was reported.
-- Disables skipping recursive files to avoid a breaking bug with greedy parsers.
-  - This is temporary until a proper fix can be implemented.
-
-
-## [3.6.0] - 2022-03-23
-
-### Added
-- `Command` metadata element.
-- `CryptoAddress` metadata element.
-- `Report.add_tag()` which allows adding tags to the report itself.
-- Added ability to include `TAGS` attribute in `Parser` classes.
-- Added ability to include direct aliases in parser config by simply providing the name. (e.g. `FooAlias: Foo`)
-- Added `.from_PEM()`, `.from_DER()`, `.from_BLOB()`, and `.from_XML()` construction methods for `RSAPublicKey` and `RSAPrivateKey` metadata elements.
-- Added `Registry2` metadata element which includes the following changes from `Registry`:
-  - `path` attribute has been removed.
-  - `key` attribute has been renamed to `subkey` and no longer includes the root hive key.
-  - `hive` attribute has been added which is casted to a `metadata.RegistryHive` enum type. `hive` will automatically be extracted if not provided but included in `subkey`.
-  - `data_type` attribute has been added, which is a `metadata.RegistryDataType` enum type. `data_type` will automatically be inferred from the data type of `data` if not provided.
-  - Added a `.from_path()` constructor to generate an entry from a full path.
-- Added `mwcp download` CLI command to download sample files from the malware repo.
-  - Includes `--last-failed` flag to download samples from previously failed tests.
-
-### Changed
-- Enable construct Adapters for `EpochTime`, `SystemTime`, and `FileTime` to accept a timezone, and add default helpers for UTC. (@ddash-ct)
-- Renamed `Dispatcher.add_to_queue()` to `Dispatcher.add()`.
-- Added full parameters to `C2URL` metadata function to match `URL`.
-- Updated `mwcp test` CLI command:
-  - Condensed diff and removed extraneous information for failed test reports.
-  - Added `--full-diff` flag to get the full diff. 
-  - Added `--last-failed` flag to rerun only previously failed test cases.
-    - Can also be combined with `--update` flag to update only previously failed tests.
-
-### Fixed
-- Fixed issue with `Version` table in text report stripping off 0's
-- Added detection of recursive loop parsing the same file.
-  - Duplicate files will automatically be tagged with `duplicate` and not be parsed.
-- If a parser dispatches the file it is currently processing, it will now be ignored.
-
-### Deprecated
-- `Dispacher.add_to_queue()` is deprecated in favor of `Dispatcher.add()`.
-- `Registry` is deprecated in favor of `Registry2`. 
-  - NOTE: Once deprecations are removed, `Registry2` will be renamed back to `Registry`.
-
-
-## [3.5.0] - 2022-01-11
-
-### Added
-- Added `--command` flag to `mwcp test`. This flag will provide the user with a printout of the pytest 
-command that would be run given the other options provided in the command line.
-
-### Changed
-- The `--no-legacy` flag is now set by default for `mwcp parse` and `mwcp test` commands. 
-  - **If you still need to use legacy testing or parse results, you must now explicitly include the `--legacy` flag.**
-  - *This does not affect the web service tool. For now, legacy mode is still set as default.*
-- Updated the `Other` metadata element to accept string, bytes, integers, or booleans as values.
-  - Also, added new field `value_format` to show the data type of the value. This helps to avoid any ambiguities in json results.
-- The "Tags" column in the generated report won't be shown if there are no tags in the table.
-
-### Fixed
-- Fixed UnicodeDecodeError that can occur when printing a report with nested metadata elements. ([\#31](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/issues/31))
-- Include missing "Mode" column from EncryptionKey report tables.
-- Fixed rendering for values with line breaks in the HTML report output.
-- Removed obfuscated powershell examples from poshdeob causing a VT hit. ([\#32](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/issues/32))
-
-
-## [3.4.0] - 2021-10-06
-
-### Added
-- Added a formal schema for (non-legacy) JSON report output which can be found in [schema.json](/mwcp/config/schema.json)
-- Added `mwcp schema` CLI command to generate the current schema.
-- Added [documentation](/README.md#schema) on how to create your own custom reportable metadata element.
-
-### Changed
-- Updated server dependencies.
-- The `input_file` and `residual_file` metadata types are now both referred to as `file`.
-- Legacy versions of `uuid` and `interval` metadata types are now typed as `uuid_legacy` and `interval_legacy`
-  respectively. This was done to ensure a proper schema can be generated.
-- Updated testing utility to ensure test cases older than 3.3.3 handle changes accordingly.
-- Updated the regular expression in the `URL` metadata object allowing it to succeed with optional schema
-- `URL` metadata object no longer defaults the network protocol to `tcp` for embedded `socket`
-
-### Fixed
-- Fixed `EncryptionKey` report formatting to display text representation when key is printable (not just ascii).
-- The `--testcase-dir` flag when running `mwcp test` in non-legacy mode will now handle any directory structure.
-
-
-## [3.3.2] - 2021-07-19
-
-### Added
-- Added `mode` attribute for EncryptionKey to report on block cipher mode.
-  - Updated testing utility to ensure test cases older than 3.3.2 ignore this new property.
-
-### Changed
-- Added word wrap for long fields in a generated report.
-- Switched "html" report output format to be consistent with "simple" and "markdown" formats.
-- Improved display formatting for EncryptionKey, RSAPrivateKey, and RSAPublicKey.
-
-### Fixed
-- Fixed test case path for `foo` parser, changed to a path which will always exist since input file is irrelevant. (@ddash-ct)
-- Fixed issue with results in the new metadata style not being dedupped across file sources.
-- Split report results are now correctly ordered by processing order.
-- Fixed issue with running `mwcp test -u` command to update all legacy parser tests.
-- Fixed bug with differently ordered tags causing test cases to fail.
-
-### Removed
-- Removed unused `split` argument in `Report` initialization.
-
-
-## [3.3.1] - 2021-06-28
-
-### Added
-- Added support for providing a custom logging filter when running a parser.
-
-### Changed
-- Updated `poshdeob` utility to work with the latest version of pyparsing.
-  - Removed version pinning for pyparsing dependency.
-
-### Fixed
-- Fixed "can't set attribute" error occurring when using web server.
-
-
-## [3.3.0] - 2021-06-10
-
-*NOTE: This release may require updating setuptools to successfully install.*
-
-### Added
-- Added `mwcp.run()` as a shortcut for running a parser and getting back its results. (See [documentation](/README.md#python-api))
-- Added ability to provide a `mwcp.Parser` class directly to `mwcp.run()`.
-  This is helpful for quick one-off scripting.
-- Added `--split` option within the `mwcp parse` command, which changes the report to display
-  metadata split by originating file instead of all being consolidating with the initial input file.
-  (This option is only available when `--no-legacy` is enabled.)
-- The `Report` class now includes the following output options for programmatically rendering results in different formats:
-  - `.as_text()` - Renders sectioned tables of results in a simple text format (this is the default format when using the command line).
-  - `.as_markdown()` - Renders sectioned tables of results in markdown.
-  - `.as_html()` - Renders a flat table of results in html.
-  - `.as_csv()` - Renders a flat table of results in csv.
-  - `.as_dataframe()` - Produces a flat table of results in a pandas dataframe.
-  - `.file_tree()` - Renders an ascii tree representing the hierarchy of residual files.
-- Added ability to add tags to metadata elements. (See [documentation](/docs/ParserComponents.md#tagging))
-- Added DecodedString metadata element.
-- Added `.compile_time` attribute to `FileObject`.
-- Added `.architecture` attribute to `FileObject`.
-- Added ability to pass results from `Parser.identify()` into the `Parser.run()` function. (See [documentation](/docs/ParserDevelopment.md#passing-identify-results))
-
-
-### Changed
-- MWCP version can now be accessed from `mwcp.__version__`
-- Updated metadata mechanism to an objected-oriented approach. (See [documentation](/docs/ParserComponents.md#report))
-- `mwcp.Reporter` has been replaced with `mwcp.Runner`. (However, using `mwcp.run()` is now recommended.)
-- Updated json and text report output.
-  - NOTE: To keep backwards compatibility, the schema for the original json output is provided by default.
-  To enable the new schema, you must provide the `--no-legacy` in the command line.
-- `FileObject.data` (and `FileObject.file_data`) has been set to a read-only attribute. 
-- Updated parser testing to support the new metadata schema. To use, provide the `--no-legacy` flag to
-the `mwcp test` command.
-  - Created a new command line tool `mwcp_update_legacy_tests` to update your existing test cases to use the new metadata schema. (See [documentation](/docs/ParserTesting.md#updating-legacy-test-cases))
-  - New parser test cases now use pytest.
-- Updated text report display and added markdown and html formats.
-  - Also added file tree display at the end of the report (for some formats).
-- Updated csv output.
-- Results from `Parser.identify()` are now cached to prevent repeated processing of the same file.
-
-
-### Deprecated
-- `FileObject.file_path` is planned to be changed to only be a non-None value if the `FileObject` 
-instance is backed by a real file on the file system.
-    - The creation of a temporary file path has been moved to `.temp_path()`.
-- Adding metadata is now done using objects found in `mwcp.metadata`. The key/value approach is deprecated
-  and support will be removed in a future major release.
-- `mwcp.Reporter` object is deprecated in favor of using either `mwcp.Runner` or `mwcp.run()`.
-- The `self.reporter` attribute in a parser has been renamed to `self.report` and is now a `mwcp.Report` object.
-  - Interface is currently the same as `mwcp.Reporter`, so your code shouldn't break except for in extreme corner cases.
-- The `.metadata` attribute in `mwcp.Reporter` (now called `mwcp.Report`) is deprecated in favor of using `.as_dict()`.
-    - WARNING: A best attempt was done to keep the results of the `.metadata` attribute the same. However, due to new validation and type coercion mechanisms, you may run into corner cases where the results are slightly different, causing your parser test to fail. 
-- The json schema as described in [fields.txt](mwcp/config/fields.txt) is deprecated in favor
-of the schema described in [`mwcp.metadata`](mwcp/metadata.py).
-- Providing a "reporter" argument to `FileObject.__init__()` is deprecated.
-- `FileObject.output()` and `Reporter.output_file()` is deprecated in favor of adding a `mwcp.metadata.ResidualFile` object to `Report.add()`.
-- Using `FileObject.file_path` to get a temporary file path is deprecated in favor of using `.temp_path()`, which is now a context manager.
-    - (This change is to ensure we have more guaranteed cleanup of temporary files.)
-- `Reporter.managed_tempdir` is deprecated. Instead, the developer should properly create and destroy a temporary directory themselves using Python's builtin library. However, it is best to use `FileObject.temp_path()` or reevaluate if there is a way parsing can be accomplished without writing out a file to the file system if possible.
-- The `-i` flag is no longer supported. Input file information will now always be provided (with the exception of legacy JSON output).
-- Using a `FileObject` instance in a `with` statement directly to get a file stream is now deprecated. Please use `FileObject.open()` instead.
-- `FileObject.file_data` is deprecated in favor of `FileObject.data`.
-- `FileObject.file_name` is deprecated in favor of `FileObject.name`.
-
-
-## [3.2.1] - 2020-11-03
-- Added source argument to Dispatcher initialization to comply with new method signature
-
-## [3.2.0] - 2020-10-30
-
-### Changed
-- Updated `IMAGE_OPTIONAL_HEADER` to support 64-bit and added missing `DllCharacteristics` Flags. (@ddash-ct)
-- Updated `IMAGE_FILE_HEADER.SizeOfOptionalHeader` to enable leveraging `sizeof()`. (@ddash-ct)
-- Changed log messages for file identification and misidentification to update phrasing for parsing groups vs parsing components. (@ddash-ct)
-- Added support for importing external parser components/groups within a parser configuration. (See [documentation](docs/ParserInstallation.md#grouping-parsers))
-- Added support for providing run configuration options to `FileObject.run_kordesii_decoder()` which will be passed 
-    along to `kordesii.run_ida()` when calling IDA. (This allows you to provide the new `is_64bit` option if necessary.)
-
-### Fixed
-- Fixed glob pattern in Techanarchy wrapper. (@cccs-aa)
-- Fixed misspelling of "Characteristics" in `IMAGE_IMPORT_DESCRIPTOR`. (@ddash-ct)
-- Fixed infinite loop that can be caused due to a sub-parser throwing an `UnableToParse` exception. (@ddash-ct)
-- Fixed bug in construct.Base64 adapter for build with unicode encoding types. (@ddash-ct)
-- General fixes to improve support when running under Linux.
-    - Changed log configuration usage of `%LOCALAPPDATA%` for the log directory reported by `appdirs`.
-- Fixed build issue in `pecon` and added option for setting architecture to 64 bit.
-
-## [3.1.0] - 2020-06-05
-
-### Added
-- Added `children` and `siblings` attributes to `FileObject` class.
-- Added `--prefix/--no-prefix` command line flag allowing the removal of the first 5
-    characters of the md5 prefixed on output files.
-    - WARNING: If disabled, unique files with the same file name will be overwritten.
-    
-
-### Removed
-- Removed deprecated `requirements.txt` file.
-
-
-## [3.0.1] - 2020-05-01
-
-### Changed
-- Setup fixes for PyPi deployment
-- Remove deprecated `decoderdir` variable from `file_object.run_kordesii_decoder()` and add `kordesii.register_entry_points()`
-
-
-## [3.0.0] - 2020-02-20
-
-### Changed
-- Dropped support for Python 2
-
-### Removed
-- Removed previously deprecated components:
-    - Support for reading configuration from enviromnent variables:
-        - `MWCP_PARSER_DIR`, `MWCP_PARSER_CONFIG`, `MWCP_PARSER_SOURCE`, `MWCP_TESTCASE_DIR`, `MWCP_MALWARE_REPO`
-    - `report_tempfile()` in `Reporter` class
-    - `mwcp-tool`, `mwcp-client`, `mwcp-server`, and `mwcp-test` command line tools
-    
-
-## [2.2.0] - 2020-01-15
-
-**NOTE: This is the last version to support Python 2. 
-The next release will only support Python 3.**
-
-### Added
-- Added `--force` flag to `Tester` for adding or updating testcases to ignore errors if set. (@ddash-ct)
-- Added `embedded` option that can be set in the parser configuration. (See [documentation](docs/ParserInstallation.md#parser-group-options))
-
-### Fixed
-- `pefileutils.obtain_export_list` would contain a `null` entry as the last item in the list for any file
-- Errors that occur while importing a parser are no longer silenced.
-- Recursive loops in the parser configuration are now detected and cause an error.
-
-
-## [2.1.0] - 2019-09-10
-
-### Added
-- Simple HTML interface with mwcp server. 
-
-### Changed
-- The `outputfiles` attribute in `mwcp.Reporter` has been removed. 
-Instead, the output file path will be returned by `output_file()`.
-- All output filenames now include the first 5 digits of its MD5 and are
-converted to file system safe names.
-- Configuration is now set using a yaml file located within the user's profile directory.
-    - This file can be modified by running `mwcp config`.
-- Input file paths in test cases now support environment variable expansion. 
-- Input file paths in test cases can include `{MALWARE_REPO}` which will be replaced
-by the currently set malware repository path.
-- Using `mwcp test Foo --add=...` to a add file that already exists in the test cases will no
-longer cause the test case to be updated. This must be explicitly allowed by also adding the `--update` flag.
-- Added `mwcp serve` command to run mwcp server.
-- mwcp server is now implemented with Flask instead of Bottle.
-    - If using the server as a WSGI app, the app instance must be created with
-      the factory function `mwcp.tools.server.create_app()`.
-
-### Deprecated
-- Setting configuration using environment variables is deprecated. Please use the configuration file instead.
-
-### Removed
-- Removed support for adding a prefix to output files.
-
-
-## [2.0.3] - 2019-06-20
-
-### Fixed
-- Updated pefileutils to support pefile version 2018.4.18
-- Pinned pyparsing dependency to 2.3.0 to avoid breaking poshdeob.
-
-
-## [2.0.2] - 2019-04-10
-### Changed
-- Moved output files to a folder named '{input filename}_mwcp_output' when running `mwcp parse`
-  - This prevents output files from being overwritten when running multiple input files.
-
-### Fixed
-- Pinned kordesii dependency to 1.4.0 or greater.
-- Fixed bug with using old "enableidalog" parameter when running kordesii parsers.
-- Fixed tuple error when attempting to use the `--add-filelist` option in `mwcp test`.
-
-### Deprecated
-- `Reporter.report_tempfile()` is deprecated. Use `FileObject.output()` instead.
-
-
-## [2.0.1] - 2019-03-15
-### Added
-- Added caching of kordesii results.
-
-### Changed
-- `mwcp test` can now accept more than one parser.
-
-### Fixed
-- Fixed up dispatcher logic to properly work with sub parser groups.
-- Fixed missing dispatcher issue when running a single parser directly from command line.
-- Fixed up unicode string handling in Reporter.
-- Fixed handling of optional capture groups for `Regex` construct helper.
-
-
-## [2.0.0] - 2019-02-11
-### Added
-- `sha1` and `sha256` attributes in FileObject class.
-- Created a new command line tool called `mwcp` which encompasses parsing and testing in one tool.
-    - This tool simplifies and cleans up the old CLI flags and uses subcommands for better organization.
-- `--parser-config` flag to specify location of a parser configuration file for a custom parser directory.
-- Ability to set a parser source with `--parser-source` flag.
-- Streamlined the wrapper for [TechAnarchy](http://techanarchy.net/2014/04/rat-decoders/) parsers.
-    - Parsers can be run using the naming scheme `TA.{decoder_filename}` after placing the parsers 
-      in the `mwcp/resources/RATDecoders` directory.
-- `pecon` PE file reconstruction utility.
-- `poshdeob` Powershell deobfuscator utility.
-- Support for relative input paths in test cases.
-
-### Changed
-- Parsers are now declared using a YAML configuration file.
-    - Please see the [Parser Installation](docs/ParserInstallation.md) and [Parser Developemnt](docs/ParserDevelopment.md) documentation for more info.
-- `FileObject.md5` now produces a hex string instead of raw bytes.
-- Rearranged the location of some modules (imports do not change however).
-- "parserstests" folder has been moved to within the "parsers" folder and renamed "tests".
-- Changed `Reporter.managed_tempdir` to a property.
-- Updated `construct` helpers to support construct version **2.9.45**.
-    - Please see their [transision to 2.9](https://construct.readthedocs.io/en/latest/transision29.html) to see what has changed.
-- Reintroduced back some construct 2.8 features that were removed from 2.8, such as `[:]` syntax and default encodings
-for String constructs. 
-    - These changes will be patched in when using `mwcp.utils.construct` instead of `construct` by itself.
-    - Please see the docstring found in [version28.py](mwcp/utils/construct/version28.py) for a full list of changes.
-- Added/Updated new `construct` helpers:
-    - `ELFPointer` support for ARM. See `mwcp.utils.construct.ARM.ELFPointer`
-    - Expanded windows structures.
-    - Added support for supplying a callable instead of a dictionary for `Iter`.
-
-### Deprecated
-- The `mwcp-tool` and `mwcp-test` tools are deprecated in exchange for using the new `mwcp` tool and
-    will be removed in a future version.
-    - *NOTE: Some flags will no longer work due to removed features (see Removed section).*
-- The `-t` flag is no longer necessary when running tests with `mwcp-test`. 
-It is assumed if you are not updating/adding tests.
-
-### Removed
-- Removed previously deprecated components:
-    - `data`, `filename()`, `pe`, `handle`, `resourcedir`, `parserdir`, `debug()`, `error()` from Reporter class.
-    - `mwcp.malwareconfigparser`, `mwcp.malwareconfigreporter`
-    - `TerminatedString` in `construct` helpers.
-- Removed unused/unpopular Reporter options: 
-    - `disablemodulesearch`
-    - `disablevaluededup`
-    - `disableautosubfieldparsing`
-    
-### Fixed
-- Add ability to set decoder directory from the `run_kordesii_decoder()` function by @ddash-ct ([\#8](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/issues/8))
-
-
-## [1.4.1] - 2018-10-15
-### Changed
-- Parsers are now imported on-demand to save initial startup time.
-- Small tweaks to logging level.
-- Refactored testing utility and force a failed test if a test case or parser is missing.
-
-### Fixed
-- Fixed bug where new parsers in the default directory were not getting registered. ([\#6](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/issues/6))
-
-
-## [1.4.0] - 2018-08-07
-### Added
-- `elffileutils` helper utility that works similar to `pefileutils`, but for ELF files.
-- Timing statistics in `mwcp-test`
-- New `construct` helpers: `EpochTime`, `ELFPointer`, `FocusLast`
-
-### Changed
-- Logging is now performed using Python's builtin `logging` module.
-    - Please see the [README](README.md#logging) for more information.
-- Removed "_malwareconfigparser" suffix from example parsers.
-- Updated `custombase64` to also support standard alphabet.
-    - (Making it suitable as a drop-in replacement of `base64`)
-- Updated `construct` helpers: `Delimited`, `Backwards`
-
-### Deprecated
-- Deprecated the use of `debug()` and `error()` functions in the Reporter class.
-    - Parsers should use the ComponentParser's `logger` or create one at the top of your module.
-- Deprecated `TerminatedString` in `construct` helpers. (Please use Padded with CString instead.)
-
-### Fixed
-- Reporter will now modify the output filename on a name collision.
-- Fixed bug with incorrect csv output formatting when input is a directory.
-
-
-## [1.3.0] - 2018-05-15
-### Added
-- Added unit testing using tox and pytest.
-
-### Changed
-- Added new standard metadata fields
-- Cleaned up mwcp tool
-- Updated and added documentation for developing/testing parsers.
-- Set DC3-Kordesii as an optional dependency.
-
-### Fixed
-- Fixed "unorderable types" error when outputting to csv
-- Fixed bugs found in  unit tests.
-
-
-## [1.2.0] - 2018-04-17
-### Added
-- Support for multiprocessing in tester.
-- Helper function for running [kordesii](https://github.com/Defense-Cyber-Crime-Center/kordesii) decoders in FileObject class.
-- Enhancements to Dispatcher.
-    - Added option to not output unidentified files.
-    - Added option to force overwriting descriptions.
-
-### Changed
-- bugfixes and code reformatting
-- Pinned construct version to avoid errors that occur with newer versions.
-
-### Removed
-- Removed `enstructured` library.
-
-
-## [1.1.0] - 2018-01-09
-### Added
-- Initial support for Python 3 from @mlaferrera
-- `pefileutils` helper utility
-- `custombase64` helper utility
-- Dispatcher model, which allows you to split up a parser by their components (Dropper, Implant, etc). (See [documentation](docs/DispatcherParserDevelopment.md) for more information.)
-- Support for using setuptool's entry_points to allow for formal python packaging of parsers. (See [documentation](docs/ParserDevelopment.md#formal-parser-packaging) for more information.)
-- Added ability to merge results from multiple parsers with the same name but different sources.
-
-### Changed
-- Replaced `enstructured` with a `construct` helper utility (See [migration guide](docs/construct.ipynb) for more information.)
-- Updated setup.py to install scripts using setuptool's entry_points.
-- Renamed "malwareconfigreporter" to "Reporter" and "malwareconfigparser" to "Parser".
-    - Old names have been aliased for backwards compatibility but are deprecated.
-
-### Deprecated
-- Deprecated use of resourcedir in Reporter.
-    - Parser should modify sys.path themselves or properly install the library if it has a dependency.
-
-
-## 1.0.0 - 2017-04-18
-### Added
-- Initial contribution.
-
-### Fixed
-- Fixed broken markdown headings from @bryant1410
-
-
-[Unreleased]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.8.0...HEAD
-[3.8.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.7.0...3.8.0
-[3.7.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.6.2...3.7.0
-[3.6.2]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.6.1...3.6.2
-[3.6.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.6.0...3.6.1
-[3.6.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.5.0...3.6.0
-[3.5.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.4.0...3.5.0
-[3.4.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.3.2...3.4.0
-[3.3.2]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.3.1...3.3.2
-[3.3.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.3.0...3.3.1
-[3.3.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.2.1...3.3.0
-[3.2.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.2.0...3.2.1
-[3.2.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.1.0...3.2.0
-[3.1.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.0.1...3.1.0
-[3.0.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.0.0...3.0.1
-[3.0.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.2.0...3.0.0
-[2.2.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.2.0...2.2.0
-[2.1.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.0.3...2.1.0
-[2.0.3]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.0.2...2.0.3
-[2.0.2]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.0.1...2.0.2
-[2.0.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.0.0...2.0.1
-[2.0.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.4.1...2.0.0
-[1.4.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.4.0...1.4.1
-[1.4.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.3.0...1.4.0
-[1.3.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.2.0...1.3.0
-[1.2.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.1.0...1.2.0
-[1.1.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.0.0...1.1.0
+# Changelog
+All notable changes to this project will be documented in this file.
+
+
+## [3.9.0] - 2022-11-22
+### Added
+- Added `FileObject.ext` property for getting and setting the file's extension.
+- Added builtin parsers.
+- Added YARA matching capability to automatically determine which parser(s) to run. (see [documentation](README.md#yara-matching)) 
+
+### Changed
+- Improved aliasing in parser configuration file.
+  - Aliases can now be used for pointing to individual parser components. (e.g. `PDF: .Document`) This helps to avoid the need to create parser groups just for pointing to a single parser component.
+  - External pointers are no longer limited to just inside parser groups. Aliases can now also point to external parsers (e.g. `DecoyDOC: dc3:Decoy.DOC`) 
+
+### Removed
+- Removed legacy `mwcp.Reporter` object.  
+- Removed `cleanup_temp_files` option from `mwcp.Runner` object.
+- Removed `temp_directory` option from `mwcp.Runner` object.
+- Removed deprecated components from `mwcp.Runner` (these components should be pulled from the generated Report object instead):
+  - `.managed_tempdir`
+  - `.add_metadata()`
+  - `.input_file`
+  - `.metadata`
+  - `.output_file()`
+  - `.errors`
+  - `.run_parser()`
+  - `.print_report()`
+  - `.print_report()`
+  - `.get_output_text()`
+  - `.fields`
+- Removed deprecated `.managed_tempdir` from `mwcp.Report` object.
+- Removed `--cleanup` CLI flag.
+
+
+## [3.8.0] - 2022-09-14
+
+### Added
+- Added `Report.strings()` convenience function for obtaining reported decoded strings.
+- Added option to produce external string reports for decoded strings instead of being included in the main report.
+  -  Reports will be added as supplemental files with original name suffixed with `_strings.json` and `_strings.txt`.
+  - Use the `--string-report` flag to enable this in the CLI tool.
+  - Use the `external_strings` field to enable this in the server.
+
+### Changed
+- `DecodedString` metadata is now included in legacy report output.
+
+### Fixed
+- Fixed issue with `Path2.from_segments()` ignoring previous segments when another segment starts with a slash.
+- Fixed issue with throwing of `UnableToParse` sometimes causing the residual file not to be reported.
+- Files for which a parser throws an `UnableToParse` and end up not getting identified by any other parsers will
+  now appropriately be identified as "Unidentified file". (NOTE: This change may cause previous test cases to fail.)
+- Fixed bug with `Report.get()` and `Report.iter()` returning elements that don't match requested type.
+- Fixed bug in STIX output when a parser added a tag to a piece of metadata that translated to an observed-string.
+
+
+## [3.7.0] - 2022-06-28
+
+### Added
+- STIX 2.1 output format that includes three SCO extensions and one property extension.  This generates a STIX package containing the results of the full analysis.
+  - SCO Extensions
+    - observed-string
+    - crypto-currency-address
+    - symmetric-encryption
+  - Property Extensions
+    - extension-definition--b84c95f5-d48d-4e4a-b723-7d209a02deb9 -- RSA Private key extension for x509-certificate
+- Added `Path2` metadata element which simplifies fields from `Path` and better supports non-Windows paths.
+  - `name` and `directory_path` are removed in favor of just having a `path` element.
+  - Added `posix` field to indicated if path is Posix or Windows based.
+  - Added `.from_segments()` and `.from_pathlib_path()` constructors.
+- Added `derivation` field to `FileObject` object and `File` metadata element.
+- Added `FileObject.disassembly()` function for obtaining Dragodis dissassembler.
+
+### Fixed
+- AttributeError that can occur during testing if a Registry without a path was reported.
+- Disables skipping recursive files to avoid a breaking bug with greedy parsers.
+  - This is temporary until a proper fix can be implemented.
+- Fixed issue with process stalling when integer is provided in a bytes metadata field.
+
+### Deprecated
+- `Path` is deprecated in favor of `Path2`.
+  - NOTE: Once deprecations are removed, `Path2` will be renamed back to `Path`.
+
+
+## [3.6.2] - 2022-04-04
+
+### Fixed
+- config.load now accepts file_path as a string on pathlib.Path (@rhartig-ct)
+  - In 3.6.1 config.load was updated to take pathlib.Path, but mwcp.tools.server still used string
+
+## [3.6.1] - 2022-03-28
+
+### Fixed
+- AttributeError that can occur during testing if a Registry without a path was reported.
+- Disables skipping recursive files to avoid a breaking bug with greedy parsers.
+  - This is temporary until a proper fix can be implemented.
+
+
+## [3.6.0] - 2022-03-23
+
+### Added
+- `Command` metadata element.
+- `CryptoAddress` metadata element.
+- `Report.add_tag()` which allows adding tags to the report itself.
+- Added ability to include `TAGS` attribute in `Parser` classes.
+- Added ability to include direct aliases in parser config by simply providing the name. (e.g. `FooAlias: Foo`)
+- Added `.from_PEM()`, `.from_DER()`, `.from_BLOB()`, and `.from_XML()` construction methods for `RSAPublicKey` and `RSAPrivateKey` metadata elements.
+- Added `Registry2` metadata element which includes the following changes from `Registry`:
+  - `path` attribute has been removed.
+  - `key` attribute has been renamed to `subkey` and no longer includes the root hive key.
+  - `hive` attribute has been added which is casted to a `metadata.RegistryHive` enum type. `hive` will automatically be extracted if not provided but included in `subkey`.
+  - `data_type` attribute has been added, which is a `metadata.RegistryDataType` enum type. `data_type` will automatically be inferred from the data type of `data` if not provided.
+  - Added a `.from_path()` constructor to generate an entry from a full path.
+- Added `mwcp download` CLI command to download sample files from the malware repo.
+  - Includes `--last-failed` flag to download samples from previously failed tests.
+
+### Changed
+- Enable construct Adapters for `EpochTime`, `SystemTime`, and `FileTime` to accept a timezone, and add default helpers for UTC. (@ddash-ct)
+- Renamed `Dispatcher.add_to_queue()` to `Dispatcher.add()`.
+- Added full parameters to `C2URL` metadata function to match `URL`.
+- Updated `mwcp test` CLI command:
+  - Condensed diff and removed extraneous information for failed test reports.
+  - Added `--full-diff` flag to get the full diff. 
+  - Added `--last-failed` flag to rerun only previously failed test cases.
+    - Can also be combined with `--update` flag to update only previously failed tests.
+
+### Fixed
+- Fixed issue with `Version` table in text report stripping off 0's
+- Added detection of recursive loop parsing the same file.
+  - Duplicate files will automatically be tagged with `duplicate` and not be parsed.
+- If a parser dispatches the file it is currently processing, it will now be ignored.
+
+### Deprecated
+- `Dispacher.add_to_queue()` is deprecated in favor of `Dispatcher.add()`.
+- `Registry` is deprecated in favor of `Registry2`. 
+  - NOTE: Once deprecations are removed, `Registry2` will be renamed back to `Registry`.
+
+
+## [3.5.0] - 2022-01-11
+
+### Added
+- Added `--command` flag to `mwcp test`. This flag will provide the user with a printout of the pytest 
+command that would be run given the other options provided in the command line.
+
+### Changed
+- The `--no-legacy` flag is now set by default for `mwcp parse` and `mwcp test` commands. 
+  - **If you still need to use legacy testing or parse results, you must now explicitly include the `--legacy` flag.**
+  - *This does not affect the web service tool. For now, legacy mode is still set as default.*
+- Updated the `Other` metadata element to accept string, bytes, integers, or booleans as values.
+  - Also, added new field `value_format` to show the data type of the value. This helps to avoid any ambiguities in json results.
+- The "Tags" column in the generated report won't be shown if there are no tags in the table.
+
+### Fixed
+- Fixed UnicodeDecodeError that can occur when printing a report with nested metadata elements. ([\#31](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/issues/31))
+- Include missing "Mode" column from EncryptionKey report tables.
+- Fixed rendering for values with line breaks in the HTML report output.
+- Removed obfuscated powershell examples from poshdeob causing a VT hit. ([\#32](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/issues/32))
+
+
+## [3.4.0] - 2021-10-06
+
+### Added
+- Added a formal schema for (non-legacy) JSON report output which can be found in [schema.json](/mwcp/config/schema.json)
+- Added `mwcp schema` CLI command to generate the current schema.
+- Added [documentation](/README.md#schema) on how to create your own custom reportable metadata element.
+
+### Changed
+- Updated server dependencies.
+- The `input_file` and `residual_file` metadata types are now both referred to as `file`.
+- Legacy versions of `uuid` and `interval` metadata types are now typed as `uuid_legacy` and `interval_legacy`
+  respectively. This was done to ensure a proper schema can be generated.
+- Updated testing utility to ensure test cases older than 3.3.3 handle changes accordingly.
+- Updated the regular expression in the `URL` metadata object allowing it to succeed with optional schema
+- `URL` metadata object no longer defaults the network protocol to `tcp` for embedded `socket`
+
+### Fixed
+- Fixed `EncryptionKey` report formatting to display text representation when key is printable (not just ascii).
+- The `--testcase-dir` flag when running `mwcp test` in non-legacy mode will now handle any directory structure.
+
+
+## [3.3.2] - 2021-07-19
+
+### Added
+- Added `mode` attribute for EncryptionKey to report on block cipher mode.
+  - Updated testing utility to ensure test cases older than 3.3.2 ignore this new property.
+
+### Changed
+- Added word wrap for long fields in a generated report.
+- Switched "html" report output format to be consistent with "simple" and "markdown" formats.
+- Improved display formatting for EncryptionKey, RSAPrivateKey, and RSAPublicKey.
+
+### Fixed
+- Fixed test case path for `foo` parser, changed to a path which will always exist since input file is irrelevant. (@ddash-ct)
+- Fixed issue with results in the new metadata style not being dedupped across file sources.
+- Split report results are now correctly ordered by processing order.
+- Fixed issue with running `mwcp test -u` command to update all legacy parser tests.
+- Fixed bug with differently ordered tags causing test cases to fail.
+
+### Removed
+- Removed unused `split` argument in `Report` initialization.
+
+
+## [3.3.1] - 2021-06-28
+
+### Added
+- Added support for providing a custom logging filter when running a parser.
+
+### Changed
+- Updated `poshdeob` utility to work with the latest version of pyparsing.
+  - Removed version pinning for pyparsing dependency.
+
+### Fixed
+- Fixed "can't set attribute" error occurring when using web server.
+
+
+## [3.3.0] - 2021-06-10
+
+*NOTE: This release may require updating setuptools to successfully install.*
+
+### Added
+- Added `mwcp.run()` as a shortcut for running a parser and getting back its results. (See [documentation](/README.md#python-api))
+- Added ability to provide a `mwcp.Parser` class directly to `mwcp.run()`.
+  This is helpful for quick one-off scripting.
+- Added `--split` option within the `mwcp parse` command, which changes the report to display
+  metadata split by originating file instead of all being consolidating with the initial input file.
+  (This option is only available when `--no-legacy` is enabled.)
+- The `Report` class now includes the following output options for programmatically rendering results in different formats:
+  - `.as_text()` - Renders sectioned tables of results in a simple text format (this is the default format when using the command line).
+  - `.as_markdown()` - Renders sectioned tables of results in markdown.
+  - `.as_html()` - Renders a flat table of results in html.
+  - `.as_csv()` - Renders a flat table of results in csv.
+  - `.as_dataframe()` - Produces a flat table of results in a pandas dataframe.
+  - `.file_tree()` - Renders an ascii tree representing the hierarchy of residual files.
+- Added ability to add tags to metadata elements. (See [documentation](/docs/ParserComponents.md#tagging))
+- Added DecodedString metadata element.
+- Added `.compile_time` attribute to `FileObject`.
+- Added `.architecture` attribute to `FileObject`.
+- Added ability to pass results from `Parser.identify()` into the `Parser.run()` function. (See [documentation](/docs/ParserDevelopment.md#passing-identify-results))
+
+
+### Changed
+- MWCP version can now be accessed from `mwcp.__version__`
+- Updated metadata mechanism to an objected-oriented approach. (See [documentation](/docs/ParserComponents.md#report))
+- `mwcp.Reporter` has been replaced with `mwcp.Runner`. (However, using `mwcp.run()` is now recommended.)
+- Updated json and text report output.
+  - NOTE: To keep backwards compatibility, the schema for the original json output is provided by default.
+  To enable the new schema, you must provide the `--no-legacy` in the command line.
+- `FileObject.data` (and `FileObject.file_data`) has been set to a read-only attribute. 
+- Updated parser testing to support the new metadata schema. To use, provide the `--no-legacy` flag to
+the `mwcp test` command.
+  - Created a new command line tool `mwcp_update_legacy_tests` to update your existing test cases to use the new metadata schema. (See [documentation](/docs/ParserTesting.md#updating-legacy-test-cases))
+  - New parser test cases now use pytest.
+- Updated text report display and added markdown and html formats.
+  - Also added file tree display at the end of the report (for some formats).
+- Updated csv output.
+- Results from `Parser.identify()` are now cached to prevent repeated processing of the same file.
+
+
+### Deprecated
+- `FileObject.file_path` is planned to be changed to only be a non-None value if the `FileObject` 
+instance is backed by a real file on the file system.
+    - The creation of a temporary file path has been moved to `.temp_path()`.
+- Adding metadata is now done using objects found in `mwcp.metadata`. The key/value approach is deprecated
+  and support will be removed in a future major release.
+- `mwcp.Reporter` object is deprecated in favor of using either `mwcp.Runner` or `mwcp.run()`.
+- The `self.reporter` attribute in a parser has been renamed to `self.report` and is now a `mwcp.Report` object.
+  - Interface is currently the same as `mwcp.Reporter`, so your code shouldn't break except for in extreme corner cases.
+- The `.metadata` attribute in `mwcp.Reporter` (now called `mwcp.Report`) is deprecated in favor of using `.as_dict()`.
+    - WARNING: A best attempt was done to keep the results of the `.metadata` attribute the same. However, due to new validation and type coercion mechanisms, you may run into corner cases where the results are slightly different, causing your parser test to fail. 
+- The json schema as described in [fields.txt](mwcp/config/fields.txt) is deprecated in favor
+of the schema described in [`mwcp.metadata`](mwcp/metadata.py).
+- Providing a "reporter" argument to `FileObject.__init__()` is deprecated.
+- `FileObject.output()` and `Reporter.output_file()` is deprecated in favor of adding a `mwcp.metadata.ResidualFile` object to `Report.add()`.
+- Using `FileObject.file_path` to get a temporary file path is deprecated in favor of using `.temp_path()`, which is now a context manager.
+    - (This change is to ensure we have more guaranteed cleanup of temporary files.)
+- `Reporter.managed_tempdir` is deprecated. Instead, the developer should properly create and destroy a temporary directory themselves using Python's builtin library. However, it is best to use `FileObject.temp_path()` or reevaluate if there is a way parsing can be accomplished without writing out a file to the file system if possible.
+- The `-i` flag is no longer supported. Input file information will now always be provided (with the exception of legacy JSON output).
+- Using a `FileObject` instance in a `with` statement directly to get a file stream is now deprecated. Please use `FileObject.open()` instead.
+- `FileObject.file_data` is deprecated in favor of `FileObject.data`.
+- `FileObject.file_name` is deprecated in favor of `FileObject.name`.
+
+
+## [3.2.1] - 2020-11-03
+- Added source argument to Dispatcher initialization to comply with new method signature
+
+## [3.2.0] - 2020-10-30
+
+### Changed
+- Updated `IMAGE_OPTIONAL_HEADER` to support 64-bit and added missing `DllCharacteristics` Flags. (@ddash-ct)
+- Updated `IMAGE_FILE_HEADER.SizeOfOptionalHeader` to enable leveraging `sizeof()`. (@ddash-ct)
+- Changed log messages for file identification and misidentification to update phrasing for parsing groups vs parsing components. (@ddash-ct)
+- Added support for importing external parser components/groups within a parser configuration. (See [documentation](docs/ParserInstallation.md#grouping-parsers))
+- Added support for providing run configuration options to `FileObject.run_kordesii_decoder()` which will be passed 
+    along to `kordesii.run_ida()` when calling IDA. (This allows you to provide the new `is_64bit` option if necessary.)
+
+### Fixed
+- Fixed glob pattern in Techanarchy wrapper. (@cccs-aa)
+- Fixed misspelling of "Characteristics" in `IMAGE_IMPORT_DESCRIPTOR`. (@ddash-ct)
+- Fixed infinite loop that can be caused due to a sub-parser throwing an `UnableToParse` exception. (@ddash-ct)
+- Fixed bug in construct.Base64 adapter for build with unicode encoding types. (@ddash-ct)
+- General fixes to improve support when running under Linux.
+    - Changed log configuration usage of `%LOCALAPPDATA%` for the log directory reported by `appdirs`.
+- Fixed build issue in `pecon` and added option for setting architecture to 64 bit.
+
+## [3.1.0] - 2020-06-05
+
+### Added
+- Added `children` and `siblings` attributes to `FileObject` class.
+- Added `--prefix/--no-prefix` command line flag allowing the removal of the first 5
+    characters of the md5 prefixed on output files.
+    - WARNING: If disabled, unique files with the same file name will be overwritten.
+    
+
+### Removed
+- Removed deprecated `requirements.txt` file.
+
+
+## [3.0.1] - 2020-05-01
+
+### Changed
+- Setup fixes for PyPi deployment
+- Remove deprecated `decoderdir` variable from `file_object.run_kordesii_decoder()` and add `kordesii.register_entry_points()`
+
+
+## [3.0.0] - 2020-02-20
+
+### Changed
+- Dropped support for Python 2
+
+### Removed
+- Removed previously deprecated components:
+    - Support for reading configuration from enviromnent variables:
+        - `MWCP_PARSER_DIR`, `MWCP_PARSER_CONFIG`, `MWCP_PARSER_SOURCE`, `MWCP_TESTCASE_DIR`, `MWCP_MALWARE_REPO`
+    - `report_tempfile()` in `Reporter` class
+    - `mwcp-tool`, `mwcp-client`, `mwcp-server`, and `mwcp-test` command line tools
+    
+
+## [2.2.0] - 2020-01-15
+
+**NOTE: This is the last version to support Python 2. 
+The next release will only support Python 3.**
+
+### Added
+- Added `--force` flag to `Tester` for adding or updating testcases to ignore errors if set. (@ddash-ct)
+- Added `embedded` option that can be set in the parser configuration. (See [documentation](docs/ParserInstallation.md#parser-group-options))
+
+### Fixed
+- `pefileutils.obtain_export_list` would contain a `null` entry as the last item in the list for any file
+- Errors that occur while importing a parser are no longer silenced.
+- Recursive loops in the parser configuration are now detected and cause an error.
+
+
+## [2.1.0] - 2019-09-10
+
+### Added
+- Simple HTML interface with mwcp server. 
+
+### Changed
+- The `outputfiles` attribute in `mwcp.Reporter` has been removed. 
+Instead, the output file path will be returned by `output_file()`.
+- All output filenames now include the first 5 digits of its MD5 and are
+converted to file system safe names.
+- Configuration is now set using a yaml file located within the user's profile directory.
+    - This file can be modified by running `mwcp config`.
+- Input file paths in test cases now support environment variable expansion. 
+- Input file paths in test cases can include `{MALWARE_REPO}` which will be replaced
+by the currently set malware repository path.
+- Using `mwcp test Foo --add=...` to a add file that already exists in the test cases will no
+longer cause the test case to be updated. This must be explicitly allowed by also adding the `--update` flag.
+- Added `mwcp serve` command to run mwcp server.
+- mwcp server is now implemented with Flask instead of Bottle.
+    - If using the server as a WSGI app, the app instance must be created with
+      the factory function `mwcp.tools.server.create_app()`.
+
+### Deprecated
+- Setting configuration using environment variables is deprecated. Please use the configuration file instead.
+
+### Removed
+- Removed support for adding a prefix to output files.
+
+
+## [2.0.3] - 2019-06-20
+
+### Fixed
+- Updated pefileutils to support pefile version 2018.4.18
+- Pinned pyparsing dependency to 2.3.0 to avoid breaking poshdeob.
+
+
+## [2.0.2] - 2019-04-10
+### Changed
+- Moved output files to a folder named '{input filename}_mwcp_output' when running `mwcp parse`
+  - This prevents output files from being overwritten when running multiple input files.
+
+### Fixed
+- Pinned kordesii dependency to 1.4.0 or greater.
+- Fixed bug with using old "enableidalog" parameter when running kordesii parsers.
+- Fixed tuple error when attempting to use the `--add-filelist` option in `mwcp test`.
+
+### Deprecated
+- `Reporter.report_tempfile()` is deprecated. Use `FileObject.output()` instead.
+
+
+## [2.0.1] - 2019-03-15
+### Added
+- Added caching of kordesii results.
+
+### Changed
+- `mwcp test` can now accept more than one parser.
+
+### Fixed
+- Fixed up dispatcher logic to properly work with sub parser groups.
+- Fixed missing dispatcher issue when running a single parser directly from command line.
+- Fixed up unicode string handling in Reporter.
+- Fixed handling of optional capture groups for `Regex` construct helper.
+
+
+## [2.0.0] - 2019-02-11
+### Added
+- `sha1` and `sha256` attributes in FileObject class.
+- Created a new command line tool called `mwcp` which encompasses parsing and testing in one tool.
+    - This tool simplifies and cleans up the old CLI flags and uses subcommands for better organization.
+- `--parser-config` flag to specify location of a parser configuration file for a custom parser directory.
+- Ability to set a parser source with `--parser-source` flag.
+- Streamlined the wrapper for [TechAnarchy](http://techanarchy.net/2014/04/rat-decoders/) parsers.
+    - Parsers can be run using the naming scheme `TA.{decoder_filename}` after placing the parsers 
+      in the `mwcp/resources/RATDecoders` directory.
+- `pecon` PE file reconstruction utility.
+- `poshdeob` Powershell deobfuscator utility.
+- Support for relative input paths in test cases.
+
+### Changed
+- Parsers are now declared using a YAML configuration file.
+    - Please see the [Parser Installation](docs/ParserInstallation.md) and [Parser Developemnt](docs/ParserDevelopment.md) documentation for more info.
+- `FileObject.md5` now produces a hex string instead of raw bytes.
+- Rearranged the location of some modules (imports do not change however).
+- "parserstests" folder has been moved to within the "parsers" folder and renamed "tests".
+- Changed `Reporter.managed_tempdir` to a property.
+- Updated `construct` helpers to support construct version **2.9.45**.
+    - Please see their [transision to 2.9](https://construct.readthedocs.io/en/latest/transision29.html) to see what has changed.
+- Reintroduced back some construct 2.8 features that were removed from 2.8, such as `[:]` syntax and default encodings
+for String constructs. 
+    - These changes will be patched in when using `mwcp.utils.construct` instead of `construct` by itself.
+    - Please see the docstring found in [version28.py](mwcp/utils/construct/version28.py) for a full list of changes.
+- Added/Updated new `construct` helpers:
+    - `ELFPointer` support for ARM. See `mwcp.utils.construct.ARM.ELFPointer`
+    - Expanded windows structures.
+    - Added support for supplying a callable instead of a dictionary for `Iter`.
+
+### Deprecated
+- The `mwcp-tool` and `mwcp-test` tools are deprecated in exchange for using the new `mwcp` tool and
+    will be removed in a future version.
+    - *NOTE: Some flags will no longer work due to removed features (see Removed section).*
+- The `-t` flag is no longer necessary when running tests with `mwcp-test`. 
+It is assumed if you are not updating/adding tests.
+
+### Removed
+- Removed previously deprecated components:
+    - `data`, `filename()`, `pe`, `handle`, `resourcedir`, `parserdir`, `debug()`, `error()` from Reporter class.
+    - `mwcp.malwareconfigparser`, `mwcp.malwareconfigreporter`
+    - `TerminatedString` in `construct` helpers.
+- Removed unused/unpopular Reporter options: 
+    - `disablemodulesearch`
+    - `disablevaluededup`
+    - `disableautosubfieldparsing`
+    
+### Fixed
+- Add ability to set decoder directory from the `run_kordesii_decoder()` function by @ddash-ct ([\#8](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/issues/8))
+
+
+## [1.4.1] - 2018-10-15
+### Changed
+- Parsers are now imported on-demand to save initial startup time.
+- Small tweaks to logging level.
+- Refactored testing utility and force a failed test if a test case or parser is missing.
+
+### Fixed
+- Fixed bug where new parsers in the default directory were not getting registered. ([\#6](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/issues/6))
+
+
+## [1.4.0] - 2018-08-07
+### Added
+- `elffileutils` helper utility that works similar to `pefileutils`, but for ELF files.
+- Timing statistics in `mwcp-test`
+- New `construct` helpers: `EpochTime`, `ELFPointer`, `FocusLast`
+
+### Changed
+- Logging is now performed using Python's builtin `logging` module.
+    - Please see the [README](README.md#logging) for more information.
+- Removed "_malwareconfigparser" suffix from example parsers.
+- Updated `custombase64` to also support standard alphabet.
+    - (Making it suitable as a drop-in replacement of `base64`)
+- Updated `construct` helpers: `Delimited`, `Backwards`
+
+### Deprecated
+- Deprecated the use of `debug()` and `error()` functions in the Reporter class.
+    - Parsers should use the ComponentParser's `logger` or create one at the top of your module.
+- Deprecated `TerminatedString` in `construct` helpers. (Please use Padded with CString instead.)
+
+### Fixed
+- Reporter will now modify the output filename on a name collision.
+- Fixed bug with incorrect csv output formatting when input is a directory.
+
+
+## [1.3.0] - 2018-05-15
+### Added
+- Added unit testing using tox and pytest.
+
+### Changed
+- Added new standard metadata fields
+- Cleaned up mwcp tool
+- Updated and added documentation for developing/testing parsers.
+- Set DC3-Kordesii as an optional dependency.
+
+### Fixed
+- Fixed "unorderable types" error when outputting to csv
+- Fixed bugs found in  unit tests.
+
+
+## [1.2.0] - 2018-04-17
+### Added
+- Support for multiprocessing in tester.
+- Helper function for running [kordesii](https://github.com/Defense-Cyber-Crime-Center/kordesii) decoders in FileObject class.
+- Enhancements to Dispatcher.
+    - Added option to not output unidentified files.
+    - Added option to force overwriting descriptions.
+
+### Changed
+- bugfixes and code reformatting
+- Pinned construct version to avoid errors that occur with newer versions.
+
+### Removed
+- Removed `enstructured` library.
+
+
+## [1.1.0] - 2018-01-09
+### Added
+- Initial support for Python 3 from @mlaferrera
+- `pefileutils` helper utility
+- `custombase64` helper utility
+- Dispatcher model, which allows you to split up a parser by their components (Dropper, Implant, etc). (See [documentation](docs/DispatcherParserDevelopment.md) for more information.)
+- Support for using setuptool's entry_points to allow for formal python packaging of parsers. (See [documentation](docs/ParserDevelopment.md#formal-parser-packaging) for more information.)
+- Added ability to merge results from multiple parsers with the same name but different sources.
+
+### Changed
+- Replaced `enstructured` with a `construct` helper utility (See [migration guide](docs/construct.ipynb) for more information.)
+- Updated setup.py to install scripts using setuptool's entry_points.
+- Renamed "malwareconfigreporter" to "Reporter" and "malwareconfigparser" to "Parser".
+    - Old names have been aliased for backwards compatibility but are deprecated.
+
+### Deprecated
+- Deprecated use of resourcedir in Reporter.
+    - Parser should modify sys.path themselves or properly install the library if it has a dependency.
+
+
+## 1.0.0 - 2017-04-18
+### Added
+- Initial contribution.
+
+### Fixed
+- Fixed broken markdown headings from @bryant1410
+
+
+[Unreleased]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.9.0...HEAD
+[3.9.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.8.0...3.9.0
+[3.8.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.7.0...3.8.0
+[3.7.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.6.2...3.7.0
+[3.6.2]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.6.1...3.6.2
+[3.6.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.6.0...3.6.1
+[3.6.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.5.0...3.6.0
+[3.5.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.4.0...3.5.0
+[3.4.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.3.2...3.4.0
+[3.3.2]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.3.1...3.3.2
+[3.3.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.3.0...3.3.1
+[3.3.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.2.1...3.3.0
+[3.2.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.2.0...3.2.1
+[3.2.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.1.0...3.2.0
+[3.1.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.0.1...3.1.0
+[3.0.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/3.0.0...3.0.1
+[3.0.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.2.0...3.0.0
+[2.2.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.2.0...2.2.0
+[2.1.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.0.3...2.1.0
+[2.0.3]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.0.2...2.0.3
+[2.0.2]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.0.1...2.0.2
+[2.0.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/2.0.0...2.0.1
+[2.0.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.4.1...2.0.0
+[1.4.1]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.4.0...1.4.1
+[1.4.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.3.0...1.4.0
+[1.3.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.2.0...1.3.0
+[1.2.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.1.0...1.2.0
+[1.1.0]: https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/compare/1.0.0...1.1.0
```

### Comparing `mwcp-3.8.0/LICENSE.txt` & `mwcp-3.9.0/LICENSE.txt`

 * *Ordering differences only*

 * *Files 3% similar despite different names*

```diff
@@ -1,5 +1,5 @@
-This project constitutes a work of the United States Government and is not subject to domestic copyright protection under 17 USC  105.
-
-However, because the project utilizes code licensed from contributors and other third parties, it therefore is licensed under the MIT License. http://opensource.org/licenses/mit-license.php. Under that license, permission is granted free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the conditions that any appropriate copyright notices and this permission notice are included in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+This project constitutes a work of the United States Government and is not subject to domestic copyright protection under 17 USC  105.
+
+However, because the project utilizes code licensed from contributors and other third parties, it therefore is licensed under the MIT License. http://opensource.org/licenses/mit-license.php. Under that license, permission is granted free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the conditions that any appropriate copyright notices and this permission notice are included in all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
```

### Comparing `mwcp-3.8.0/PKG-INFO` & `mwcp-3.9.0/PKG-INFO`

 * *Files 20% similar despite different names*

```diff
@@ -1,585 +1,658 @@
-Metadata-Version: 2.1
-Name: mwcp
-Version: 3.8.0
-Summary: A framework for malware configuration parsers.
-Home-page: http://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/
-Author: DC3
-Author-email: dcci@dc3.mil
-License: MIT
-Description: # DC3-MWCP
-        [Changelog](CHANGELOG.md) | [Releases](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/releases)
-        
-        DC3 Malware Configuration Parser (DC3-MWCP) is a framework for parsing configuration information from malware.
-        The information extracted from malware includes items such as addresses, passwords, filenames, and
-        mutex names. A parser module is usually created per malware family.
-        DC3-MWCP is designed to help ensure consistency in parser function and output, ease parser development,
-        and facilitate parser sharing. DC3-MWCP supports both analyst directed analysis and
-        large-scale automated execution, utilizing either the native python API, a REST API, or a provided
-        command line tool. DC3-MWCP is authored by the Defense Cyber Crime Center (DC3).
-        
-        - [Install](#install)
-        - [Dragodis Support](#dragodis-support)
-        - [DC3-Kordesii Support](#dc3-kordesii-support)
-        - [Usage](#usage)
-            - [CLI Tool](#cli-tool)
-            - [REST API](#rest-api)
-            - [Python API](#python-api)
-        - [Schema](#schema)
-        - [STIX Output](#stix-output)
-        - [Helper Utilities](#helper-utilities)
-        
-        ### Guides
-        - [Parser Development](docs/ParserDevelopment.md)
-        - [Parser Components](docs/ParserComponents.md)
-        - [Parser Installation](docs/ParserInstallation.md)
-        - [Parser Testing](docs/ParserTesting.md)
-        - [Python Style Guide](docs/PythonStyleGuide.md)
-        - [Construct Tutorial](docs/construct.ipynb)
-        - [Style Guide](docs/PythonStyleGuide.md)
-        - [Testing](docs/Testing.md)
-        
-        
-        ## Install
-        ```console
-        > pip install mwcp
-        ```
-        
-        Alternatively you can clone this repo and install locally.
-        ```console
-        > git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
-        > pip install ./DC3-MWCP
-        ```
-        
-        For a development mode use the `-e` flag to install in editable mode:
-        
-        ```console
-        > git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
-        > pip install -e ./DC3-MWCP
-        ```
-        
-        ## Dragodis Support
-        DC3-MWCP optionally supports [Dragodis](https://github.com/Defense-Cyber-Crime-Center/Dragodis)
-        if it is installed. This allows you to obtain a disassembler agnostic interface for parsing
-        the file's disassembly from the `mwcp.FileObject` object with the `.disassembly()` function.
-        
-        You can install Dragodis along with DC3-MWCP by adding `[dragodis]` to your appropriate install command:
-        ```
-        pip install mwcp[dragodis]
-        pip install ./DC3-MWCP[dragodis]
-        pip install -e ./DC3-MWCP[dragodis]
-        ```
-        
-        After installation make sure to follow Dragodis's [installation instructions](https://github.com/Defense-Cyber-Crime-Center/Dragodis/blob/master/docs/install.rst) to setup
-        a backend disassembler.
-        
-        *It is recommended to also install [Rugosa](https://github.com/Defense-Cyber-Crime-Center/rugosa) 
-        for emulation and regex/yara matching capabilities using Dragodis.*
-        
-        
-        ## DC3-Kordesii Support
-        DC3-MWCP optionally supports [DC3-Kordesii](https://github.com/Defense-Cyber-Crime-Center/kordesii)
-        if it is installed. This will allow you to run any DC3-Kordesii decoder from the
-        `mwcp.FileObject` object with the `run_kordesii_decoder` function.
-        
-        You can install DC3-Kordesii along with DC3-MWCP by adding `[kordesii]` to your appropriate install command:
-        ```
-        pip install mwcp[kordesii]
-        pip install ./DC3-MWCP[kordesii]
-        pip install -e ./DC3-MWCP[kordesii]
-        ```
-        
-        
-        ## Usage
-        DC3-MWCP is designed to allow easy development and use of malware config parsers. DC3-MWCP is also designed to ensure
-        that these parsers are scalable and that DC3-MWCP can be integrated in other systems.
-        
-        Most automated processing systems will use a condition, such as a yara signature match, to trigger execution
-        of an DC3-MWCP parser.
-        
-        There are 3 options for integration of DC3-MWCP:
-        - CLI: `mwcp`
-        - REST API: `mwcp serve`
-        - Python API
-        
-        DC3-MWCP also includes a utility for test case generation and execution.
-        
-        ### CLI tool
-        
-        DC3-MWCP can be used directly from the command line using the `mwcp` command.
-        
-        ```console
-        > mwcp parse foo ./README.md
-        ----- File: README.md -----
-        Field         Value
-        ------------  ----------------------------------------------------------------
-        Parser        foo
-        File Path     README.md
-        Description   Foo
-        Architecture
-        MD5           b21df2332fe87c0fae95bdda00b5a3c0
-        SHA1          8841a1fff55687ccddc587935b62667173b14bcd
-        SHA256        0097c13a3541a440d64155a7f4443d76597409e0f40ce3ae67f73f51f59f1930
-        Compile Time
-        Tags
-        
-        ---- Socket ----
-        Tags    Address    Network Protocol
-        ------  ---------  ------------------
-                127.0.0.1  tcp
-        
-        ---- URL ----
-        Tags    Url               Address    Network Protocol    Application Protocol
-        ------  ----------------  ---------  ------------------  ----------------------
-                http://127.0.0.1  127.0.0.1  tcp                 http
-        
-        ---- Residual Files ----
-        Tags    Filename           Description          MD5                               Arch    Compile Time
-        ------  -----------------  -------------------  --------------------------------  ------  --------------
-                fooconfigtest.txt  example output file  5eb63bbbe01eeed093cb22bb8f5acdc3
-        
-        ---- Logs ----
-        [+] File README.md identified as Foo.
-        [+] size of inputfile is 15560 bytes
-        [+] README.md dispatched residual file: fooconfigtest.txt
-        [+] File fooconfigtest.txt described as example output file
-        [+] operating on inputfile README.md
-        
-        ----- File Tree -----
-        <README.md (b21df2332fe87c0fae95bdda00b5a3c0) : Foo>
-         <fooconfigtest.txt (5eb63bbbe01eeed093cb22bb8f5acdc3) : example output file>
-        ```
-        
-        see ```mwcp parse -h``` for full set of options
-        
-        
-        ### REST API
-        
-        DC3-MWCP can be used as a web service. The web service provides a web application as
-        well as a REST API for some commonly used functions:
-        
-        * ```/run_parser/<parser>``` -- executes a parser on uploaded file
-        * ```/descriptions``` -- provides list of available parsers
-        * ```/schema.json``` -- provides the [schema](#schema) for report output
-        
-        To use, first start the server by running:
-        ```console
-        > mwcp serve
-        ```
-        
-        Then you can either use an HTTP client to create REST requests.
-        
-        Using cURL:
-        ```console
-        # Get JSON for processing README.md with foo parser
-        > curl --form data=@README.md http://localhost:8080/run_parser/foo
-        # Get STIX 2.1 JSON for processing README.md with foo parser
-        > curl --form data=@README.md --form output=stix http://localhost:8080/run_parser/foo
-        # Get STIX 2.1 JSON  without artifacts for processing README.md with foo parser
-        > curl --form data=@README.md --form output=stix --form no_file_data=1 http://localhost:8080/run_parser/foo
-        ```
-        
-        Using Python requests:
-        ```python
-        import requests
-        req = requests.post("http://localhost:8080/run_parser/foo", files={'data': open("README.md", 'rb')})
-        req.json()
-        ```
-        
-        Output:
-        ```json
-        {
-            "url": [
-                "http://127.0.0.1"
-            ],
-            "address": [
-                "127.0.0.1"
-            ],
-            "debug": [
-                "size of inputfile is 7128 bytes",
-                "outputfile: fooconfigtest.txt",
-                "operating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfile-n4mw7uw3"
-            ],
-            "outputfile": [
-                [
-                    "fooconfigtest.txt",
-                    "example output file",
-                    "5eb63bbbe01eeed093cb22bb8f5acdc3",
-                    "aGVsbG8gd29ybGQ="
-                ]
-            ],
-            "output_text": "\n----Standard Metadata----\n\nurl                  http://127.0.0.1\naddress              127.0.0.1\n\n----Debug----\n\nsize of inputfile
-        is 7128 bytes\noutputfile: fooconfigtest.txt\noperating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfi
-        le-n4mw7uw3\n\n----Output Files----\n\nfooconfigtest.txt    example output file\n                     5eb63bbbe01eeed093cb22bb8f5acdc3\n"
-        }
-        ```
-        
-        By default, the original legacy json schema will be provided upon request.
-        To use the new schema, you must set the `legacy` option in the query section to `False`.
-        
-        Eventually this new schema will replace the old one entirely. It is recommended to start using this flag
-        to help transition your automation platform to use the new schema.
-        
-        
-        ```console
-        > curl --form data=@README.md http://localhost:8080/run_parser/foo?legacy=False
-        ```
-        
-        ```json
-        [
-            {
-                "type": "report",
-                "tags": [],
-                "input_file": {
-                    "type": "input_file",
-                    "tags": [],
-                    "name": "README.md",
-                    "description": "Foo",
-                    "md5": "80a3d9b88c956c960d1fea265db0882e",
-                    "sha1": "994aa37fd26dd88272b8e661631eec8a5f425920",
-                    "sha256": "3bef8d5dc4cd94c0ee92c9b6d7ee47a4794e550d287ee1affde84c2b7bcdf3cb",
-                    "architecture": null,
-                    "compile_time": null,
-                    "file_path": "README.md",
-                    "data": null
-                },
-                "parser": "foo",
-                "errors": [],
-                "logs": [
-                    "[+] File README.md identified as Foo.",
-                    "[+] size of inputfile is 15887 bytes",
-                    "[+] README.md dispatched residual file: fooconfigtest.txt",
-                    "[+] File fooconfigtest.txt described as example output file",
-                    "[+] operating on inputfile README.md"
-                ],
-                "metadata": [
-                    {
-                        "type": "url",
-                        "tags": [],
-                        "url": "http://127.0.0.1",
-                        "socket": {
-                            "type": "socket",
-                            "tags": [],
-                            "address": "127.0.0.1",
-                            "port": null,
-                            "network_protocol": "tcp",
-                            "c2": null,
-                            "listen": null
-                        },
-                        "path": null,
-                        "query": "",
-                        "application_protocol": "http",
-                        "credential": null
-                    },
-                    {
-                        "type": "socket",
-                        "tags": [],
-                        "address": "127.0.0.1",
-                        "port": null,
-                        "network_protocol": "tcp",
-                        "c2": null,
-                        "listen": null
-                    },
-                    {
-                        "type": "residual_file",
-                        "tags": [],
-                        "name": "fooconfigtest.txt",
-                        "description": "example output file",
-                        "md5": "5eb63bbbe01eeed093cb22bb8f5acdc3",
-                        "sha1": "2aae6c35c94fcfb415dbe95f408b9ce91ee846ed",
-                        "sha256": "b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9",
-                        "architecture": null,
-                        "compile_time": null,
-                        "file_path": "README.md_mwcp_output\\5eb63_fooconfigtest.txt",
-                        "data": null
-                    }
-                ]
-            }
-        ]
-        ```
-        
-        A simple HTML interface is also available at the same address. By default this
-        is `http://localhost:8080/`. Individual samples can be submitted and results
-        saved as JSON, plain text, or ZIP archives.
-        
-        
-        ### Python API
-        DC3-MWCP can be run directly from Python.
-        
-        ```python
-        #!/usr/bin/env python
-        """
-        Simple example to demonstrate use of the API provided by DC3-MWCP framework.
-        """
-        
-        # first, import mwcp
-        import mwcp
-        
-        # register the builtin MWCP parsers and any other parser packages installed on the system
-        mwcp.register_entry_points()
-        
-        # register a directory containing parsers
-        mwcp.register_parser_directory(r'C:\my_parsers')
-        
-        # view all available parsers
-        print(mwcp.get_parser_descriptions(config_only=False))
-        
-        # call the run() function to to generate a mwcp.Report object.
-        report = mwcp.run("FooParser", "C:\\README.md")
-        # alternate, run on provided buffer:
-        report = mwcp.run("FooParser", data=b"lorem ipsum")
-        
-        # Display report results in a variety of formats:
-        print(report.as_dict())
-        print(report.as_json())
-        print(report.as_text())
-        
-        # The metadata schema has changed recently. To get the legacy format use the following:
-        print(report.as_dict_legacy())
-        print(report.as_json_legacy())
-        
-        # You can also programmatically view results of report:
-        from mwcp import metadata
-        
-        # display errors that may occur
-        for log in report.errors:
-          print(log)
-        
-        # display data about original input file
-        print(report.input_file)
-        
-        # get all url's using ftp protocol or has a query
-        for url in report.get(metadata.URL):
-          if url.application_protocol == "ftp" or url.query:
-            print(url.url)
-        
-        # get residual files
-        for residual_file in report.get(metadata.File):
-          print(residual_file.name)
-          print(residual_file.description)
-          print(residual_file.md5)
-        
-        # iterate through all metadata elements
-        for element in report:
-          print(element)
-        
-        ```
-        
-        ## Configuration
-        DC3-MWCP uses a configuration file which is located within the user's 
-        profile directory. (`%APPDATA%\Local\mwcp\config.yml` for Windows or `~/.config/mwcp/config.yml` for Linux)
-        
-        This configuration file is used to manage configurable parameters, such as the location
-        of the malware repository used for testing or the default parser source.
-        
-        To configure this file, run `mwcp config` to open up the file in your default text
-        editor.
-        
-        An alternative configuration file can also be temporarily set using the `--config` parameter.
-        ```console
-        > mwcp --config='new_config.yml' test Foo
-        ```
-        
-        Individual configuration parameters can be overwritten on the command line using the respective parameter.
-        
-        
-        ## Logging
-        DC3-MWCP uses Python's builtin in `logging` module to log all messages.
-        By default, logging is configured using the [log_config.yml](mwcp/config/log_config.yml) configuration
-        file. Which is currently set to log all messages to the console and error messages to `%LOCALAPPDATA%/mwcp/errors.log`. 
-        
-        You can provide your own custom log configuration file by adding the path
-        to the configuration parameter `LOG_CONFIG_PATH`. 
-        (Please see [Python's documentation](http://docs.python.org/dev/library/logging.config.html) for more information on how to write your own configuration file.)
-        
-        You may also use the `--verbose` or `--debug` flags to adjust the logging level when using the `mwcp` tool.
-        
-        
-        ## Schema
-        
-        One of the major goals of DC3-MWCP is to standardize output for malware configuration parsers, making the data
-        from one parser comparable with that of other parsers. This is achieved by establishing a schema of
-        standardized metadata elements that represent the common malware configuration items seen across malware families.
-        
-        A formal [JSON Schema](https://json-schema.org) can be found at [schema.json](/mwcp/config/schema.json), by calling `mwcp schema` in the command line, or programmatically by calling `mwcp.schema()`. 
-        This schema is versioned the same as DC3-MWCP. A change in the version may not necessarily
-        reflect a change in the actual schema. However, any major or minor changes to the schema will
-        be reflected in an appropriate change to the version and will be noted in the [changelog](/CHANGELOG.md).
-        Please ensure you pin DC3-MWCP appropriately.
-        
-        It is acknowledged that a set of generic elements will often not be adequate to capture the nuances of
-        individual malware families. To ensure that malware family specific attributes are appropriately captured
-        in parser output, the schema includes an "Other" element which supports arbitrary key-value pairs.
-        The keys and values are arbitrary to permit flexibility in describing the peculiarities of individual malware families.
-        Information
-        not captured in the abstract standardized elements is captured through this mechanism.
-        
-        The use of [tags](/docs/ParserComponents.md#tagging) is encouraged to provide additional context for the configuration items.
-        For example, if a specific url is used to download a second stage component, a tag of "download"
-        could be added to the reported URL element. Alternatively, if the URL is used for a proxy, 
-        a tag of "proxy" could be included.
-        There is no standard on what tags are available or when they should be included.
-        This should be determined by your organization.
-        
-        
-        ### Extending the Schema
-        
-        It is possible to extend the schema to include your own custom metadata elements.
-        This can be accomplished by creating a class that inherits from `mwcp.metadata.Metadata`. 
-        This class must be decorated with [attr](https://attrs.org) using the custom configuration `mwcp.metadata.config`. 
-        
-        *NOTE: The class name must be unique from other metadata elements.*
-        
-        ```python
-        from typing import List
-        
-        import attr
-        
-        import mwcp
-        from mwcp import metadata
-        
-        
-        @attr.s(**metadata.config)
-        class MyCustom(metadata.Metadata):
-            """
-            This is my custom metadata item.
-            """
-            field_a: str
-            field_b: int
-            field_c: List[str] = attr.ib(factory=list)
-        
-            
-        item = MyCustom(field_a="hello", field_b=42, field_c=["a", "b"])
-        
-        print(item)
-        print(item.as_dict())
-        
-        # Custom items can be included in the report like normal.
-        # MWCP will automatically format and display the custom element in the report.
-        report = mwcp.Report()
-        with report:
-            report.add(item)
-        
-        print(report.as_text())
-        ```
-        
-        ```
-        MyCustom(tags=set(), field_a='hello', field_b=42, field_c=['a', 'b'])
-        {'type': 'my_custom', 'tags': [], 'field_a': 'hello', 'field_b': 42, 'field_c': ['a', 'b']}
-        ---- My Custom ----
-        Tags    Field A      Field B  Field C
-        ------  ---------  ---------  ----------
-                hello             42  a, b
-        ```
-        
-        
-        Please note, that extending the schema will obviously cause the [schema.json](/mwcp/config/schema.json) file to be incorrect.
-        To regenerate the schema to also include the custom element run `mwcp.schema()` afterwards.
-        
-        ```python
-        import json
-        import mwcp
-        
-        with open("schema.json", "w") as fo:
-            json.dump(mwcp.schema(id="https://acme.org/0.1/schema.json"), fo, indent=4)
-        ```
-        
-        
-        ## STIX Output
-        
-        MWCP can generate a [STIX 2.1](https://www.oasis-open.org/standard/stix-version-2-1/) JSON output that is suitable for integration into many
-        systems that support the STIX standard. This output format makes use of three SCO 
-        extensions and one property extension in addition to the currently defined STIX
-        objects order to accurately convey MWCP's scan results.
-        
-        Some tools may not support these extensions yet which can result in the following data
-        being omitted when ingesting MWCP's STIX output.  The following provides a list of STIX
-        objects and extensions are used and what MWCP classes these are associated with:
-        
-        1. artifact (SCO)
-            1. File -- only used if the original binary is requested
-        2. crypto-currency-address (SCO Extension)
-            1. CryptoAddress
-        3. directory (SCO)
-            1. File
-            2. Path
-            3. Service
-        4. domain-name (SCO)
-            1. Socket
-            2. URL
-        5. email-address (SCO)
-            1. EmailAddress
-        6. file (SCO)
-            1. File
-            2. Path
-            3. Service
-        7. ipv4-address (SCO)
-            1. Socket
-            2. URL
-        8. ipv6-address (SCO)
-            1. Socket
-            2. URL
-        9. malware-analysis (SDO)
-            1. MWCP's scan results are tied together via a malware-analysis object showing the input object and the outputs
-        10. mutex (SCO)
-            1. Mutex
-        11. network-traffic (SCO)
-            1. Socket
-            2. URL
-        12. note (SDO)
-            1. Boolean and Integer values for Other.  These are added to the description of the Note.
-            2. Descriptions and other narrative text tied to SCOs
-            3. Tags for SCOs excluding files
-        13. observed-string (SCO Extension)
-            1. DecodedString
-            2. MissionID
-            3. Other
-            4. Pipe
-            5. User Agent
-            6. UUID
-        14. process (SCO)
-            1. Command
-            2. Service
-        15. relationship (SRO)
-            1. DecodedString
-            2. URL
-        16. RSA Private Key (Property Extension for x509-certificate)
-            1. RSAPrivateKey
-        17. symmetric-encryption (SCO)
-            1. EncryptionKey
-        18. user-account (SCO)
-            1. Credential
-        19. url (SCO)
-            1. URL
-        20. x509-certificate (SCO)
-            1. RSAPrivateKey
-            2. RSAPublicKey
-            3. SSLCertSHA1
-        21. windows-registry-key (SCO)
-            1. Registry2
-        
-        
-        ## Helper Utilities
-        MWCP comes with a few helper utilities (located in `mwcp.utils`) that may become useful for parsing malware files.
-        
-        - `pefileutils` - Provides helper functions for common routines done with the `pefile` library. (obtaining or checking for exports, imports, resources, sections, etc.)
-        - `elffileutils` - Provides helper functions for common routines done with the `elftools` library. Provides a consistent interface similar to `pefileutils`.
-        - `custombase64` - Provides functions for base64 encoding/decoding data with a custom alphabet.
-        - `construct` - Provides extended functionality to the [construct](https://construct.readthedocs.io) library and brings
-        back some lost features from version 2.8 into 2.9.
-            - This library has replaced the `enstructured` library originally found in the resources directory.
-            - Please follow [this tutorial](docs/construct.ipynb) for migrating from `enstructured` to `construct`.
-        - `pecon` - PE file reconstruction utility.
-            - Please see docstring in [pecon.py](mwcp/utils/pecon.py) for more information.
-        - `poshdeob` - An experimental powershell deobfuscator utility used to statically deobfuscate code and extract strings.
-         
-Keywords: malware
-Platform: UNKNOWN
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Intended Audience :: Developers
-Classifier: License :: OSI Approved :: MIT License
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.8
-Description-Content-Type: text/markdown
-Provides-Extra: dragodis
-Provides-Extra: kordesii
-Provides-Extra: testing
+Metadata-Version: 2.1
+Name: mwcp
+Version: 3.9.0
+Summary: A framework for malware configuration parsers.
+Home-page: http://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/
+Author: DC3
+Author-email: dcci@dc3.mil
+License: MIT
+Keywords: malware
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.8
+Description-Content-Type: text/markdown
+Provides-Extra: dragodis
+Provides-Extra: kordesii
+Provides-Extra: testing
+License-File: LICENSE.txt
+
+# DC3-MWCP
+[Changelog](CHANGELOG.md) | [Releases](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/releases)
+
+DC3 Malware Configuration Parser (DC3-MWCP) is a framework for parsing configuration information from malware.
+The information extracted from malware includes items such as addresses, passwords, filenames, and
+mutex names. A parser module is usually created per malware family.
+DC3-MWCP is designed to help ensure consistency in parser function and output, ease parser development,
+and facilitate parser sharing. DC3-MWCP supports both analyst directed analysis and
+large-scale automated execution, utilizing either the native python API, a REST API, or a provided
+command line tool. DC3-MWCP is authored by the Defense Cyber Crime Center (DC3).
+
+- [Install](#install)
+- [Builtin Parsers](#builtin-parsers)
+- [Dragodis Support](#dragodis-support)
+- [DC3-Kordesii Support](#dc3-kordesii-support)
+- [Usage](#usage)
+    - [CLI Tool](#cli-tool)
+    - [REST API](#rest-api)
+    - [Python API](#python-api)
+- [Schema](#schema)
+- [STIX Output](#stix-output)
+- [YARA Matching](#yara-matching)
+- [Helper Utilities](#helper-utilities)
+
+### Guides
+- [Parser Development](docs/ParserDevelopment.md)
+- [Parser Components](docs/ParserComponents.md)
+- [Parser Installation](docs/ParserInstallation.md)
+- [Parser Testing](docs/ParserTesting.md)
+- [Python Style Guide](docs/PythonStyleGuide.md)
+- [Construct Tutorial](docs/construct.ipynb)
+- [Style Guide](docs/PythonStyleGuide.md)
+- [Testing](docs/Testing.md)
+
+
+## Install
+```console
+> pip install mwcp
+```
+
+Alternatively you can clone this repo and install locally.
+```console
+> git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
+> pip install ./DC3-MWCP
+```
+
+For a development mode use the `-e` flag to install in editable mode:
+
+```console
+> git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
+> pip install -e ./DC3-MWCP
+```
+
+## Builtin Parsers
+DC3-MWCP includes a handful of builtin [parsers](./mwcp/parsers) to get you started.
+These can be used as-is, subclassed, or included in your own parser groups.
+
+To view the available parsers:
+```bash
+$ mwcp list
+```
+
+Parsers are installed under the `dc3` source name. To include them in a group simply add them with
+the `dc3:` prefix.
+
+```yml
+SuperMalware:
+    description: SuperMalware component
+    author: acme
+    parsers:
+      - dc3:Archive.Zip
+      - .Dropper
+      - .Implant
+      - dc3:Decoy
+```
+
+
+## Dragodis Support
+DC3-MWCP optionally supports [Dragodis](https://github.com/Defense-Cyber-Crime-Center/Dragodis)
+if it is installed. This allows you to obtain a disassembler agnostic interface for parsing
+the file's disassembly from the `mwcp.FileObject` object with the `.disassembly()` function.
+
+You can install Dragodis along with DC3-MWCP by adding `[dragodis]` to your appropriate install command:
+```
+pip install mwcp[dragodis]
+pip install ./DC3-MWCP[dragodis]
+pip install -e ./DC3-MWCP[dragodis]
+```
+
+After installation make sure to follow Dragodis's [installation instructions](https://github.com/Defense-Cyber-Crime-Center/Dragodis/blob/master/docs/install.rst) to setup
+a backend disassembler.
+
+*It is recommended to also install [Rugosa](https://github.com/Defense-Cyber-Crime-Center/rugosa) 
+for emulation and regex/yara matching capabilities using Dragodis.*
+
+
+## DC3-Kordesii Support
+DC3-MWCP optionally supports [DC3-Kordesii](https://github.com/Defense-Cyber-Crime-Center/kordesii)
+if it is installed. This will allow you to run any DC3-Kordesii decoder from the
+`mwcp.FileObject` object with the `run_kordesii_decoder` function.
+
+You can install DC3-Kordesii along with DC3-MWCP by adding `[kordesii]` to your appropriate install command:
+```
+pip install mwcp[kordesii]
+pip install ./DC3-MWCP[kordesii]
+pip install -e ./DC3-MWCP[kordesii]
+```
+
+
+## Usage
+DC3-MWCP is designed to allow easy development and use of malware config parsers. DC3-MWCP is also designed to ensure
+that these parsers are scalable and that DC3-MWCP can be integrated in other systems.
+
+Most automated processing systems will use a condition, such as a yara signature match, to trigger execution
+of an DC3-MWCP parser.
+
+There are 3 options for integration of DC3-MWCP:
+- CLI: `mwcp`
+- REST API: `mwcp serve`
+- Python API
+
+DC3-MWCP also includes a utility for test case generation and execution.
+
+### CLI tool
+
+DC3-MWCP can be used directly from the command line using the `mwcp` command.
+
+```console
+> mwcp parse foo ./README.md
+----- File: README.md -----
+Field         Value
+------------  ----------------------------------------------------------------
+Parser        foo
+File Path     README.md
+Description   Foo
+Architecture
+MD5           b21df2332fe87c0fae95bdda00b5a3c0
+SHA1          8841a1fff55687ccddc587935b62667173b14bcd
+SHA256        0097c13a3541a440d64155a7f4443d76597409e0f40ce3ae67f73f51f59f1930
+Compile Time
+Tags
+
+---- Socket ----
+Tags    Address    Network Protocol
+------  ---------  ------------------
+        127.0.0.1  tcp
+
+---- URL ----
+Tags    Url               Address    Network Protocol    Application Protocol
+------  ----------------  ---------  ------------------  ----------------------
+        http://127.0.0.1  127.0.0.1  tcp                 http
+
+---- Residual Files ----
+Tags    Filename           Description          MD5                               Arch    Compile Time
+------  -----------------  -------------------  --------------------------------  ------  --------------
+        fooconfigtest.txt  example output file  5eb63bbbe01eeed093cb22bb8f5acdc3
+
+---- Logs ----
+[+] File README.md identified as Foo.
+[+] size of inputfile is 15560 bytes
+[+] README.md dispatched residual file: fooconfigtest.txt
+[+] File fooconfigtest.txt described as example output file
+[+] operating on inputfile README.md
+
+----- File Tree -----
+<README.md (b21df2332fe87c0fae95bdda00b5a3c0) : Foo>
+ <fooconfigtest.txt (5eb63bbbe01eeed093cb22bb8f5acdc3) : example output file>
+```
+
+see ```mwcp parse -h``` for full set of options
+
+
+### REST API
+
+DC3-MWCP can be used as a web service. The web service provides a web application as
+well as a REST API for some commonly used functions:
+
+* ```/run_parser/<parser>``` -- executes a parser on uploaded file
+* ```/descriptions``` -- provides list of available parsers
+* ```/schema.json``` -- provides the [schema](#schema) for report output
+
+To use, first start the server by running:
+```console
+> mwcp serve
+```
+
+Then you can either use an HTTP client to create REST requests.
+
+Using cURL:
+```console
+# Get JSON for processing README.md with foo parser
+> curl --form data=@README.md http://localhost:8080/run_parser/foo
+# Get STIX 2.1 JSON for processing README.md with foo parser
+> curl --form data=@README.md --form output=stix http://localhost:8080/run_parser/foo
+# Get STIX 2.1 JSON  without artifacts for processing README.md with foo parser
+> curl --form data=@README.md --form output=stix --form no_file_data=1 http://localhost:8080/run_parser/foo
+```
+
+Using Python requests:
+```python
+import requests
+req = requests.post("http://localhost:8080/run_parser/foo", files={'data': open("README.md", 'rb')})
+req.json()
+```
+
+Output:
+```json
+{
+    "url": [
+        "http://127.0.0.1"
+    ],
+    "address": [
+        "127.0.0.1"
+    ],
+    "debug": [
+        "size of inputfile is 7128 bytes",
+        "outputfile: fooconfigtest.txt",
+        "operating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfile-n4mw7uw3"
+    ],
+    "outputfile": [
+        [
+            "fooconfigtest.txt",
+            "example output file",
+            "5eb63bbbe01eeed093cb22bb8f5acdc3",
+            "aGVsbG8gd29ybGQ="
+        ]
+    ],
+    "output_text": "\n----Standard Metadata----\n\nurl                  http://127.0.0.1\naddress              127.0.0.1\n\n----Debug----\n\nsize of inputfile is 7128 bytes\noutputfile: fooconfigtest.txt\noperating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfile-n4mw7uw3\n\n----Output Files----\n\nfooconfigtest.txt    example output file\n                     5eb63bbbe01eeed093cb22bb8f5acdc3\n"
+}
+```
+
+By default, the original legacy json schema will be provided upon request.
+To use the new schema, you must set the `legacy` option in the query section to `False`.
+
+Eventually this new schema will replace the old one entirely. It is recommended to start using this flag
+to help transition your automation platform to use the new schema.
+
+
+```console
+> curl --form data=@README.md http://localhost:8080/run_parser/foo?legacy=False
+```
+
+```json
+[
+    {
+        "type": "report",
+        "tags": [],
+        "input_file": {
+            "type": "input_file",
+            "tags": [],
+            "name": "README.md",
+            "description": "Foo",
+            "md5": "80a3d9b88c956c960d1fea265db0882e",
+            "sha1": "994aa37fd26dd88272b8e661631eec8a5f425920",
+            "sha256": "3bef8d5dc4cd94c0ee92c9b6d7ee47a4794e550d287ee1affde84c2b7bcdf3cb",
+            "architecture": null,
+            "compile_time": null,
+            "file_path": "README.md",
+            "data": null
+        },
+        "parser": "foo",
+        "errors": [],
+        "logs": [
+            "[+] File README.md identified as Foo.",
+            "[+] size of inputfile is 15887 bytes",
+            "[+] README.md dispatched residual file: fooconfigtest.txt",
+            "[+] File fooconfigtest.txt described as example output file",
+            "[+] operating on inputfile README.md"
+        ],
+        "metadata": [
+            {
+                "type": "url",
+                "tags": [],
+                "url": "http://127.0.0.1",
+                "socket": {
+                    "type": "socket",
+                    "tags": [],
+                    "address": "127.0.0.1",
+                    "port": null,
+                    "network_protocol": "tcp",
+                    "c2": null,
+                    "listen": null
+                },
+                "path": null,
+                "query": "",
+                "application_protocol": "http",
+                "credential": null
+            },
+            {
+                "type": "socket",
+                "tags": [],
+                "address": "127.0.0.1",
+                "port": null,
+                "network_protocol": "tcp",
+                "c2": null,
+                "listen": null
+            },
+            {
+                "type": "residual_file",
+                "tags": [],
+                "name": "fooconfigtest.txt",
+                "description": "example output file",
+                "md5": "5eb63bbbe01eeed093cb22bb8f5acdc3",
+                "sha1": "2aae6c35c94fcfb415dbe95f408b9ce91ee846ed",
+                "sha256": "b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9",
+                "architecture": null,
+                "compile_time": null,
+                "file_path": "README.md_mwcp_output\\5eb63_fooconfigtest.txt",
+                "data": null
+            }
+        ]
+    }
+]
+```
+
+A simple HTML interface is also available at the same address. By default this
+is `http://localhost:8080/`. Individual samples can be submitted and results
+saved as JSON, plain text, or ZIP archives.
+
+
+### Python API
+DC3-MWCP can be run directly from Python.
+
+```python
+#!/usr/bin/env python
+"""
+Simple example to demonstrate use of the API provided by DC3-MWCP framework.
+"""
+
+# first, import mwcp
+import mwcp
+
+# register the builtin MWCP parsers and any other parser packages installed on the system
+mwcp.register_entry_points()
+
+# register a directory containing parsers
+mwcp.register_parser_directory(r'C:\my_parsers')
+
+# view all available parsers
+print(mwcp.get_parser_descriptions(config_only=False))
+
+# call the run() function to to generate a mwcp.Report object.
+report = mwcp.run("FooParser", "C:\\README.md")
+# alternate, run on provided buffer:
+report = mwcp.run("FooParser", data=b"lorem ipsum")
+
+# Display report results in a variety of formats:
+print(report.as_dict())
+print(report.as_json())
+print(report.as_text())
+
+# The metadata schema has changed recently. To get the legacy format use the following:
+print(report.as_dict_legacy())
+print(report.as_json_legacy())
+
+# You can also programmatically view results of report:
+from mwcp import metadata
+
+# display errors that may occur
+for log in report.errors:
+  print(log)
+
+# display data about original input file
+print(report.input_file)
+
+# get all url's using ftp protocol or has a query
+for url in report.get(metadata.URL):
+  if url.application_protocol == "ftp" or url.query:
+    print(url.url)
+
+# get residual files
+for residual_file in report.get(metadata.File):
+  print(residual_file.name)
+  print(residual_file.description)
+  print(residual_file.md5)
+
+# iterate through all metadata elements
+for element in report:
+  print(element)
+
+```
+
+## Configuration
+DC3-MWCP uses a configuration file which is located within the user's 
+profile directory. (`%APPDATA%\Local\mwcp\config.yml` for Windows or `~/.config/mwcp/config.yml` for Linux)
+
+This configuration file is used to manage configurable parameters, such as the location
+of the malware repository used for testing or the default parser source.
+
+To configure this file, run `mwcp config` to open up the file in your default text
+editor.
+
+An alternative configuration file can also be temporarily set using the `--config` parameter.
+```console
+> mwcp --config='new_config.yml' test Foo
+```
+
+Individual configuration parameters can be overwritten on the command line using the respective parameter.
+
+
+## Logging
+DC3-MWCP uses Python's builtin in `logging` module to log all messages.
+By default, logging is configured using the [log_config.yml](mwcp/config/log_config.yml) configuration
+file. Which is currently set to log all messages to the console and error messages to `%LOCALAPPDATA%/mwcp/errors.log`. 
+
+You can provide your own custom log configuration file by adding the path
+to the configuration parameter `LOG_CONFIG_PATH`. 
+(Please see [Python's documentation](http://docs.python.org/dev/library/logging.config.html) for more information on how to write your own configuration file.)
+
+You may also use the `--verbose` or `--debug` flags to adjust the logging level when using the `mwcp` tool.
+
+
+## Schema
+
+One of the major goals of DC3-MWCP is to standardize output for malware configuration parsers, making the data
+from one parser comparable with that of other parsers. This is achieved by establishing a schema of
+standardized metadata elements that represent the common malware configuration items seen across malware families.
+
+A formal [JSON Schema](https://json-schema.org) can be found at [schema.json](/mwcp/config/schema.json), by calling `mwcp schema` in the command line, or programmatically by calling `mwcp.schema()`. 
+This schema is versioned the same as DC3-MWCP. A change in the version may not necessarily
+reflect a change in the actual schema. However, any major or minor changes to the schema will
+be reflected in an appropriate change to the version and will be noted in the [changelog](/CHANGELOG.md).
+Please ensure you pin DC3-MWCP appropriately.
+
+It is acknowledged that a set of generic elements will often not be adequate to capture the nuances of
+individual malware families. To ensure that malware family specific attributes are appropriately captured
+in parser output, the schema includes an "Other" element which supports arbitrary key-value pairs.
+The keys and values are arbitrary to permit flexibility in describing the peculiarities of individual malware families.
+Information
+not captured in the abstract standardized elements is captured through this mechanism.
+
+The use of [tags](/docs/ParserComponents.md#tagging) is encouraged to provide additional context for the configuration items.
+For example, if a specific url is used to download a second stage component, a tag of "download"
+could be added to the reported URL element. Alternatively, if the URL is used for a proxy, 
+a tag of "proxy" could be included.
+There is no standard on what tags are available or when they should be included.
+This should be determined by your organization.
+
+
+### Extending the Schema
+
+It is possible to extend the schema to include your own custom metadata elements.
+This can be accomplished by creating a class that inherits from `mwcp.metadata.Metadata`. 
+This class must be decorated with [attr](https://attrs.org) using the custom configuration `mwcp.metadata.config`. 
+
+*NOTE: The class name must be unique from other metadata elements.*
+
+```python
+from typing import List
+
+import attr
+
+import mwcp
+from mwcp import metadata
+
+
+@attr.s(**metadata.config)
+class MyCustom(metadata.Metadata):
+    """
+    This is my custom metadata item.
+    """
+    field_a: str
+    field_b: int
+    field_c: List[str] = attr.ib(factory=list)
+
+    
+item = MyCustom(field_a="hello", field_b=42, field_c=["a", "b"])
+
+print(item)
+print(item.as_dict())
+
+# Custom items can be included in the report like normal.
+# MWCP will automatically format and display the custom element in the report.
+report = mwcp.Report()
+with report:
+    report.add(item)
+
+print(report.as_text())
+```
+
+```
+MyCustom(tags=set(), field_a='hello', field_b=42, field_c=['a', 'b'])
+{'type': 'my_custom', 'tags': [], 'field_a': 'hello', 'field_b': 42, 'field_c': ['a', 'b']}
+---- My Custom ----
+Tags    Field A      Field B  Field C
+------  ---------  ---------  ----------
+        hello             42  a, b
+```
+
+
+Please note, that extending the schema will obviously cause the [schema.json](/mwcp/config/schema.json) file to be incorrect.
+To regenerate the schema to also include the custom element run `mwcp.schema()` afterwards.
+
+```python
+import json
+import mwcp
+
+with open("schema.json", "w") as fo:
+    json.dump(mwcp.schema(id="https://acme.org/0.1/schema.json"), fo, indent=4)
+```
+
+
+## STIX Output
+
+MWCP can generate a [STIX 2.1](https://www.oasis-open.org/standard/stix-version-2-1/) JSON output that is suitable for integration into many
+systems that support the STIX standard. This output format makes use of three SCO 
+extensions and one property extension in addition to the currently defined STIX
+objects order to accurately convey MWCP's scan results.
+
+Some tools may not support these extensions yet which can result in the following data
+being omitted when ingesting MWCP's STIX output.  The following provides a list of STIX
+objects and extensions are used and what MWCP classes these are associated with:
+
+1. artifact (SCO)
+    1. File -- only used if the original binary is requested
+2. crypto-currency-address (SCO Extension)
+    1. CryptoAddress
+3. directory (SCO)
+    1. File
+    2. Path
+    3. Service
+4. domain-name (SCO)
+    1. Socket
+    2. URL
+5. email-address (SCO)
+    1. EmailAddress
+6. file (SCO)
+    1. File
+    2. Path
+    3. Service
+7. ipv4-address (SCO)
+    1. Socket
+    2. URL
+8. ipv6-address (SCO)
+    1. Socket
+    2. URL
+9. malware-analysis (SDO)
+    1. MWCP's scan results are tied together via a malware-analysis object showing the input object and the outputs
+10. mutex (SCO)
+    1. Mutex
+11. network-traffic (SCO)
+    1. Socket
+    2. URL
+12. note (SDO)
+    1. Boolean and Integer values for Other.  These are added to the description of the Note.
+    2. Descriptions and other narrative text tied to SCOs
+    3. Tags for SCOs excluding files
+13. observed-string (SCO Extension)
+    1. DecodedString
+    2. MissionID
+    3. Other
+    4. Pipe
+    5. User Agent
+    6. UUID
+14. process (SCO)
+    1. Command
+    2. Service
+15. relationship (SRO)
+    1. DecodedString
+    2. URL
+16. RSA Private Key (Property Extension for x509-certificate)
+    1. RSAPrivateKey
+17. symmetric-encryption (SCO)
+    1. EncryptionKey
+18. user-account (SCO)
+    1. Credential
+19. url (SCO)
+    1. URL
+20. x509-certificate (SCO)
+    1. RSAPrivateKey
+    2. RSAPublicKey
+    3. SSLCertSHA1
+21. windows-registry-key (SCO)
+    1. Registry2
+
+
+## YARA Matching
+
+MWCP includes a runner that can use YARA match results to determine which parser(s) to run on a given file.
+
+This will be used whenever you use `-` instead of specifying a parser on the command line,
+when a parser isn't specified in `mwcp.run()`, or when a parser isn't specified in a server request.
+
+```bash
+$ mwcp parse - input.exe
+$ curl --form data=@input.exe http://localhost:8080/run_parser
+```
+
+```python
+import mwcp 
+mwcp.register_entry_points()
+
+report = mwcp.run(data=b"file data")
+```
+
+As well, YARA matching will be recursively used on unidentified residual files.
+If you want to disable this, either set `--no-recursive` on the command line or set `recursive=False` on `mwcp.run()`.
+
+### Setup
+
+To enable YARA matching you'll need to specify a directory containing YARA signatures which use the `mwcp` 
+meta field to map a signature to a comma delimited list of parsers. Parsers can be specified in the same
+way as on the command line or Python API. That is, parser group names, `.` notation for specific parser components,
+and the use of `:` for specifying a parser source are all valid.
+
+Any signatures that don't have the `mwcp` meta field will be ignored.
+
+```yara
+rule SuperMalware {
+    meta:
+        mwcp = "SuperMalware"
+    ...
+}
+```
+
+To setup a YARA repo, set the `YARA_REPO` field to point to a directory containing YARA signatures (subdirectories allowed)
+in the configuration file that appears when you call `mwcp config`.
+If you have upgraded from an older version of MWCP, you may need to first backup and remove the original configuration file and
+then run `mwcp config` again to have MWCP recreate the file.
+
+Alternatively, the yara repo can be specified in the command line with `--yara-repo`. But the former method
+is necessary to use YARA matching with the server.
+
+
+## Helper Utilities
+MWCP comes with a few helper utilities (located in `mwcp.utils`) that may become useful for parsing malware files.
+
+- `pefileutils` - Provides helper functions for common routines done with the `pefile` library. (obtaining or checking for exports, imports, resources, sections, etc.)
+- `elffileutils` - Provides helper functions for common routines done with the `elftools` library. Provides a consistent interface similar to `pefileutils`.
+- `custombase64` - Provides functions for base64 encoding/decoding data with a custom alphabet.
+- `construct` - Provides extended functionality to the [construct](https://construct.readthedocs.io) library and brings
+back some lost features from version 2.8 into 2.9.
+    - This library has replaced the `enstructured` library originally found in the resources directory.
+    - Please follow [this tutorial](docs/construct.ipynb) for migrating from `enstructured` to `construct`.
+- `pecon` - PE file reconstruction utility.
+    - Please see docstring in [pecon.py](mwcp/utils/pecon.py) for more information.
+- `poshdeob` - An experimental powershell deobfuscator utility used to statically deobfuscate code and extract strings.
+
```

### Comparing `mwcp-3.8.0/README.md` & `mwcp-3.9.0/README.md`

 * *Files 17% similar despite different names*

```diff
@@ -1,566 +1,638 @@
-# DC3-MWCP
-[Changelog](CHANGELOG.md) | [Releases](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/releases)
-
-DC3 Malware Configuration Parser (DC3-MWCP) is a framework for parsing configuration information from malware.
-The information extracted from malware includes items such as addresses, passwords, filenames, and
-mutex names. A parser module is usually created per malware family.
-DC3-MWCP is designed to help ensure consistency in parser function and output, ease parser development,
-and facilitate parser sharing. DC3-MWCP supports both analyst directed analysis and
-large-scale automated execution, utilizing either the native python API, a REST API, or a provided
-command line tool. DC3-MWCP is authored by the Defense Cyber Crime Center (DC3).
-
-- [Install](#install)
-- [Dragodis Support](#dragodis-support)
-- [DC3-Kordesii Support](#dc3-kordesii-support)
-- [Usage](#usage)
-    - [CLI Tool](#cli-tool)
-    - [REST API](#rest-api)
-    - [Python API](#python-api)
-- [Schema](#schema)
-- [STIX Output](#stix-output)
-- [Helper Utilities](#helper-utilities)
-
-### Guides
-- [Parser Development](docs/ParserDevelopment.md)
-- [Parser Components](docs/ParserComponents.md)
-- [Parser Installation](docs/ParserInstallation.md)
-- [Parser Testing](docs/ParserTesting.md)
-- [Python Style Guide](docs/PythonStyleGuide.md)
-- [Construct Tutorial](docs/construct.ipynb)
-- [Style Guide](docs/PythonStyleGuide.md)
-- [Testing](docs/Testing.md)
-
-
-## Install
-```console
-> pip install mwcp
-```
-
-Alternatively you can clone this repo and install locally.
-```console
-> git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
-> pip install ./DC3-MWCP
-```
-
-For a development mode use the `-e` flag to install in editable mode:
-
-```console
-> git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
-> pip install -e ./DC3-MWCP
-```
-
-## Dragodis Support
-DC3-MWCP optionally supports [Dragodis](https://github.com/Defense-Cyber-Crime-Center/Dragodis)
-if it is installed. This allows you to obtain a disassembler agnostic interface for parsing
-the file's disassembly from the `mwcp.FileObject` object with the `.disassembly()` function.
-
-You can install Dragodis along with DC3-MWCP by adding `[dragodis]` to your appropriate install command:
-```
-pip install mwcp[dragodis]
-pip install ./DC3-MWCP[dragodis]
-pip install -e ./DC3-MWCP[dragodis]
-```
-
-After installation make sure to follow Dragodis's [installation instructions](https://github.com/Defense-Cyber-Crime-Center/Dragodis/blob/master/docs/install.rst) to setup
-a backend disassembler.
-
-*It is recommended to also install [Rugosa](https://github.com/Defense-Cyber-Crime-Center/rugosa) 
-for emulation and regex/yara matching capabilities using Dragodis.*
-
-
-## DC3-Kordesii Support
-DC3-MWCP optionally supports [DC3-Kordesii](https://github.com/Defense-Cyber-Crime-Center/kordesii)
-if it is installed. This will allow you to run any DC3-Kordesii decoder from the
-`mwcp.FileObject` object with the `run_kordesii_decoder` function.
-
-You can install DC3-Kordesii along with DC3-MWCP by adding `[kordesii]` to your appropriate install command:
-```
-pip install mwcp[kordesii]
-pip install ./DC3-MWCP[kordesii]
-pip install -e ./DC3-MWCP[kordesii]
-```
-
-
-## Usage
-DC3-MWCP is designed to allow easy development and use of malware config parsers. DC3-MWCP is also designed to ensure
-that these parsers are scalable and that DC3-MWCP can be integrated in other systems.
-
-Most automated processing systems will use a condition, such as a yara signature match, to trigger execution
-of an DC3-MWCP parser.
-
-There are 3 options for integration of DC3-MWCP:
-- CLI: `mwcp`
-- REST API: `mwcp serve`
-- Python API
-
-DC3-MWCP also includes a utility for test case generation and execution.
-
-### CLI tool
-
-DC3-MWCP can be used directly from the command line using the `mwcp` command.
-
-```console
-> mwcp parse foo ./README.md
------ File: README.md -----
-Field         Value
-------------  ----------------------------------------------------------------
-Parser        foo
-File Path     README.md
-Description   Foo
-Architecture
-MD5           b21df2332fe87c0fae95bdda00b5a3c0
-SHA1          8841a1fff55687ccddc587935b62667173b14bcd
-SHA256        0097c13a3541a440d64155a7f4443d76597409e0f40ce3ae67f73f51f59f1930
-Compile Time
-Tags
-
----- Socket ----
-Tags    Address    Network Protocol
-------  ---------  ------------------
-        127.0.0.1  tcp
-
----- URL ----
-Tags    Url               Address    Network Protocol    Application Protocol
-------  ----------------  ---------  ------------------  ----------------------
-        http://127.0.0.1  127.0.0.1  tcp                 http
-
----- Residual Files ----
-Tags    Filename           Description          MD5                               Arch    Compile Time
-------  -----------------  -------------------  --------------------------------  ------  --------------
-        fooconfigtest.txt  example output file  5eb63bbbe01eeed093cb22bb8f5acdc3
-
----- Logs ----
-[+] File README.md identified as Foo.
-[+] size of inputfile is 15560 bytes
-[+] README.md dispatched residual file: fooconfigtest.txt
-[+] File fooconfigtest.txt described as example output file
-[+] operating on inputfile README.md
-
------ File Tree -----
-<README.md (b21df2332fe87c0fae95bdda00b5a3c0) : Foo>
- <fooconfigtest.txt (5eb63bbbe01eeed093cb22bb8f5acdc3) : example output file>
-```
-
-see ```mwcp parse -h``` for full set of options
-
-
-### REST API
-
-DC3-MWCP can be used as a web service. The web service provides a web application as
-well as a REST API for some commonly used functions:
-
-* ```/run_parser/<parser>``` -- executes a parser on uploaded file
-* ```/descriptions``` -- provides list of available parsers
-* ```/schema.json``` -- provides the [schema](#schema) for report output
-
-To use, first start the server by running:
-```console
-> mwcp serve
-```
-
-Then you can either use an HTTP client to create REST requests.
-
-Using cURL:
-```console
-# Get JSON for processing README.md with foo parser
-> curl --form data=@README.md http://localhost:8080/run_parser/foo
-# Get STIX 2.1 JSON for processing README.md with foo parser
-> curl --form data=@README.md --form output=stix http://localhost:8080/run_parser/foo
-# Get STIX 2.1 JSON  without artifacts for processing README.md with foo parser
-> curl --form data=@README.md --form output=stix --form no_file_data=1 http://localhost:8080/run_parser/foo
-```
-
-Using Python requests:
-```python
-import requests
-req = requests.post("http://localhost:8080/run_parser/foo", files={'data': open("README.md", 'rb')})
-req.json()
-```
-
-Output:
-```json
-{
-    "url": [
-        "http://127.0.0.1"
-    ],
-    "address": [
-        "127.0.0.1"
-    ],
-    "debug": [
-        "size of inputfile is 7128 bytes",
-        "outputfile: fooconfigtest.txt",
-        "operating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfile-n4mw7uw3"
-    ],
-    "outputfile": [
-        [
-            "fooconfigtest.txt",
-            "example output file",
-            "5eb63bbbe01eeed093cb22bb8f5acdc3",
-            "aGVsbG8gd29ybGQ="
-        ]
-    ],
-    "output_text": "\n----Standard Metadata----\n\nurl                  http://127.0.0.1\naddress              127.0.0.1\n\n----Debug----\n\nsize of inputfile
-is 7128 bytes\noutputfile: fooconfigtest.txt\noperating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfi
-le-n4mw7uw3\n\n----Output Files----\n\nfooconfigtest.txt    example output file\n                     5eb63bbbe01eeed093cb22bb8f5acdc3\n"
-}
-```
-
-By default, the original legacy json schema will be provided upon request.
-To use the new schema, you must set the `legacy` option in the query section to `False`.
-
-Eventually this new schema will replace the old one entirely. It is recommended to start using this flag
-to help transition your automation platform to use the new schema.
-
-
-```console
-> curl --form data=@README.md http://localhost:8080/run_parser/foo?legacy=False
-```
-
-```json
-[
-    {
-        "type": "report",
-        "tags": [],
-        "input_file": {
-            "type": "input_file",
-            "tags": [],
-            "name": "README.md",
-            "description": "Foo",
-            "md5": "80a3d9b88c956c960d1fea265db0882e",
-            "sha1": "994aa37fd26dd88272b8e661631eec8a5f425920",
-            "sha256": "3bef8d5dc4cd94c0ee92c9b6d7ee47a4794e550d287ee1affde84c2b7bcdf3cb",
-            "architecture": null,
-            "compile_time": null,
-            "file_path": "README.md",
-            "data": null
-        },
-        "parser": "foo",
-        "errors": [],
-        "logs": [
-            "[+] File README.md identified as Foo.",
-            "[+] size of inputfile is 15887 bytes",
-            "[+] README.md dispatched residual file: fooconfigtest.txt",
-            "[+] File fooconfigtest.txt described as example output file",
-            "[+] operating on inputfile README.md"
-        ],
-        "metadata": [
-            {
-                "type": "url",
-                "tags": [],
-                "url": "http://127.0.0.1",
-                "socket": {
-                    "type": "socket",
-                    "tags": [],
-                    "address": "127.0.0.1",
-                    "port": null,
-                    "network_protocol": "tcp",
-                    "c2": null,
-                    "listen": null
-                },
-                "path": null,
-                "query": "",
-                "application_protocol": "http",
-                "credential": null
-            },
-            {
-                "type": "socket",
-                "tags": [],
-                "address": "127.0.0.1",
-                "port": null,
-                "network_protocol": "tcp",
-                "c2": null,
-                "listen": null
-            },
-            {
-                "type": "residual_file",
-                "tags": [],
-                "name": "fooconfigtest.txt",
-                "description": "example output file",
-                "md5": "5eb63bbbe01eeed093cb22bb8f5acdc3",
-                "sha1": "2aae6c35c94fcfb415dbe95f408b9ce91ee846ed",
-                "sha256": "b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9",
-                "architecture": null,
-                "compile_time": null,
-                "file_path": "README.md_mwcp_output\\5eb63_fooconfigtest.txt",
-                "data": null
-            }
-        ]
-    }
-]
-```
-
-A simple HTML interface is also available at the same address. By default this
-is `http://localhost:8080/`. Individual samples can be submitted and results
-saved as JSON, plain text, or ZIP archives.
-
-
-### Python API
-DC3-MWCP can be run directly from Python.
-
-```python
-#!/usr/bin/env python
-"""
-Simple example to demonstrate use of the API provided by DC3-MWCP framework.
-"""
-
-# first, import mwcp
-import mwcp
-
-# register the builtin MWCP parsers and any other parser packages installed on the system
-mwcp.register_entry_points()
-
-# register a directory containing parsers
-mwcp.register_parser_directory(r'C:\my_parsers')
-
-# view all available parsers
-print(mwcp.get_parser_descriptions(config_only=False))
-
-# call the run() function to to generate a mwcp.Report object.
-report = mwcp.run("FooParser", "C:\\README.md")
-# alternate, run on provided buffer:
-report = mwcp.run("FooParser", data=b"lorem ipsum")
-
-# Display report results in a variety of formats:
-print(report.as_dict())
-print(report.as_json())
-print(report.as_text())
-
-# The metadata schema has changed recently. To get the legacy format use the following:
-print(report.as_dict_legacy())
-print(report.as_json_legacy())
-
-# You can also programmatically view results of report:
-from mwcp import metadata
-
-# display errors that may occur
-for log in report.errors:
-  print(log)
-
-# display data about original input file
-print(report.input_file)
-
-# get all url's using ftp protocol or has a query
-for url in report.get(metadata.URL):
-  if url.application_protocol == "ftp" or url.query:
-    print(url.url)
-
-# get residual files
-for residual_file in report.get(metadata.File):
-  print(residual_file.name)
-  print(residual_file.description)
-  print(residual_file.md5)
-
-# iterate through all metadata elements
-for element in report:
-  print(element)
-
-```
-
-## Configuration
-DC3-MWCP uses a configuration file which is located within the user's 
-profile directory. (`%APPDATA%\Local\mwcp\config.yml` for Windows or `~/.config/mwcp/config.yml` for Linux)
-
-This configuration file is used to manage configurable parameters, such as the location
-of the malware repository used for testing or the default parser source.
-
-To configure this file, run `mwcp config` to open up the file in your default text
-editor.
-
-An alternative configuration file can also be temporarily set using the `--config` parameter.
-```console
-> mwcp --config='new_config.yml' test Foo
-```
-
-Individual configuration parameters can be overwritten on the command line using the respective parameter.
-
-
-## Logging
-DC3-MWCP uses Python's builtin in `logging` module to log all messages.
-By default, logging is configured using the [log_config.yml](mwcp/config/log_config.yml) configuration
-file. Which is currently set to log all messages to the console and error messages to `%LOCALAPPDATA%/mwcp/errors.log`. 
-
-You can provide your own custom log configuration file by adding the path
-to the configuration parameter `LOG_CONFIG_PATH`. 
-(Please see [Python's documentation](http://docs.python.org/dev/library/logging.config.html) for more information on how to write your own configuration file.)
-
-You may also use the `--verbose` or `--debug` flags to adjust the logging level when using the `mwcp` tool.
-
-
-## Schema
-
-One of the major goals of DC3-MWCP is to standardize output for malware configuration parsers, making the data
-from one parser comparable with that of other parsers. This is achieved by establishing a schema of
-standardized metadata elements that represent the common malware configuration items seen across malware families.
-
-A formal [JSON Schema](https://json-schema.org) can be found at [schema.json](/mwcp/config/schema.json), by calling `mwcp schema` in the command line, or programmatically by calling `mwcp.schema()`. 
-This schema is versioned the same as DC3-MWCP. A change in the version may not necessarily
-reflect a change in the actual schema. However, any major or minor changes to the schema will
-be reflected in an appropriate change to the version and will be noted in the [changelog](/CHANGELOG.md).
-Please ensure you pin DC3-MWCP appropriately.
-
-It is acknowledged that a set of generic elements will often not be adequate to capture the nuances of
-individual malware families. To ensure that malware family specific attributes are appropriately captured
-in parser output, the schema includes an "Other" element which supports arbitrary key-value pairs.
-The keys and values are arbitrary to permit flexibility in describing the peculiarities of individual malware families.
-Information
-not captured in the abstract standardized elements is captured through this mechanism.
-
-The use of [tags](/docs/ParserComponents.md#tagging) is encouraged to provide additional context for the configuration items.
-For example, if a specific url is used to download a second stage component, a tag of "download"
-could be added to the reported URL element. Alternatively, if the URL is used for a proxy, 
-a tag of "proxy" could be included.
-There is no standard on what tags are available or when they should be included.
-This should be determined by your organization.
-
-
-### Extending the Schema
-
-It is possible to extend the schema to include your own custom metadata elements.
-This can be accomplished by creating a class that inherits from `mwcp.metadata.Metadata`. 
-This class must be decorated with [attr](https://attrs.org) using the custom configuration `mwcp.metadata.config`. 
-
-*NOTE: The class name must be unique from other metadata elements.*
-
-```python
-from typing import List
-
-import attr
-
-import mwcp
-from mwcp import metadata
-
-
-@attr.s(**metadata.config)
-class MyCustom(metadata.Metadata):
-    """
-    This is my custom metadata item.
-    """
-    field_a: str
-    field_b: int
-    field_c: List[str] = attr.ib(factory=list)
-
-    
-item = MyCustom(field_a="hello", field_b=42, field_c=["a", "b"])
-
-print(item)
-print(item.as_dict())
-
-# Custom items can be included in the report like normal.
-# MWCP will automatically format and display the custom element in the report.
-report = mwcp.Report()
-with report:
-    report.add(item)
-
-print(report.as_text())
-```
-
-```
-MyCustom(tags=set(), field_a='hello', field_b=42, field_c=['a', 'b'])
-{'type': 'my_custom', 'tags': [], 'field_a': 'hello', 'field_b': 42, 'field_c': ['a', 'b']}
----- My Custom ----
-Tags    Field A      Field B  Field C
-------  ---------  ---------  ----------
-        hello             42  a, b
-```
-
-
-Please note, that extending the schema will obviously cause the [schema.json](/mwcp/config/schema.json) file to be incorrect.
-To regenerate the schema to also include the custom element run `mwcp.schema()` afterwards.
-
-```python
-import json
-import mwcp
-
-with open("schema.json", "w") as fo:
-    json.dump(mwcp.schema(id="https://acme.org/0.1/schema.json"), fo, indent=4)
-```
-
-
-## STIX Output
-
-MWCP can generate a [STIX 2.1](https://www.oasis-open.org/standard/stix-version-2-1/) JSON output that is suitable for integration into many
-systems that support the STIX standard. This output format makes use of three SCO 
-extensions and one property extension in addition to the currently defined STIX
-objects order to accurately convey MWCP's scan results.
-
-Some tools may not support these extensions yet which can result in the following data
-being omitted when ingesting MWCP's STIX output.  The following provides a list of STIX
-objects and extensions are used and what MWCP classes these are associated with:
-
-1. artifact (SCO)
-    1. File -- only used if the original binary is requested
-2. crypto-currency-address (SCO Extension)
-    1. CryptoAddress
-3. directory (SCO)
-    1. File
-    2. Path
-    3. Service
-4. domain-name (SCO)
-    1. Socket
-    2. URL
-5. email-address (SCO)
-    1. EmailAddress
-6. file (SCO)
-    1. File
-    2. Path
-    3. Service
-7. ipv4-address (SCO)
-    1. Socket
-    2. URL
-8. ipv6-address (SCO)
-    1. Socket
-    2. URL
-9. malware-analysis (SDO)
-    1. MWCP's scan results are tied together via a malware-analysis object showing the input object and the outputs
-10. mutex (SCO)
-    1. Mutex
-11. network-traffic (SCO)
-    1. Socket
-    2. URL
-12. note (SDO)
-    1. Boolean and Integer values for Other.  These are added to the description of the Note.
-    2. Descriptions and other narrative text tied to SCOs
-    3. Tags for SCOs excluding files
-13. observed-string (SCO Extension)
-    1. DecodedString
-    2. MissionID
-    3. Other
-    4. Pipe
-    5. User Agent
-    6. UUID
-14. process (SCO)
-    1. Command
-    2. Service
-15. relationship (SRO)
-    1. DecodedString
-    2. URL
-16. RSA Private Key (Property Extension for x509-certificate)
-    1. RSAPrivateKey
-17. symmetric-encryption (SCO)
-    1. EncryptionKey
-18. user-account (SCO)
-    1. Credential
-19. url (SCO)
-    1. URL
-20. x509-certificate (SCO)
-    1. RSAPrivateKey
-    2. RSAPublicKey
-    3. SSLCertSHA1
-21. windows-registry-key (SCO)
-    1. Registry2
-
-
-## Helper Utilities
-MWCP comes with a few helper utilities (located in `mwcp.utils`) that may become useful for parsing malware files.
-
-- `pefileutils` - Provides helper functions for common routines done with the `pefile` library. (obtaining or checking for exports, imports, resources, sections, etc.)
-- `elffileutils` - Provides helper functions for common routines done with the `elftools` library. Provides a consistent interface similar to `pefileutils`.
-- `custombase64` - Provides functions for base64 encoding/decoding data with a custom alphabet.
-- `construct` - Provides extended functionality to the [construct](https://construct.readthedocs.io) library and brings
-back some lost features from version 2.8 into 2.9.
-    - This library has replaced the `enstructured` library originally found in the resources directory.
-    - Please follow [this tutorial](docs/construct.ipynb) for migrating from `enstructured` to `construct`.
-- `pecon` - PE file reconstruction utility.
-    - Please see docstring in [pecon.py](mwcp/utils/pecon.py) for more information.
-- `poshdeob` - An experimental powershell deobfuscator utility used to statically deobfuscate code and extract strings.
+# DC3-MWCP
+[Changelog](CHANGELOG.md) | [Releases](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/releases)
+
+DC3 Malware Configuration Parser (DC3-MWCP) is a framework for parsing configuration information from malware.
+The information extracted from malware includes items such as addresses, passwords, filenames, and
+mutex names. A parser module is usually created per malware family.
+DC3-MWCP is designed to help ensure consistency in parser function and output, ease parser development,
+and facilitate parser sharing. DC3-MWCP supports both analyst directed analysis and
+large-scale automated execution, utilizing either the native python API, a REST API, or a provided
+command line tool. DC3-MWCP is authored by the Defense Cyber Crime Center (DC3).
+
+- [Install](#install)
+- [Builtin Parsers](#builtin-parsers)
+- [Dragodis Support](#dragodis-support)
+- [DC3-Kordesii Support](#dc3-kordesii-support)
+- [Usage](#usage)
+    - [CLI Tool](#cli-tool)
+    - [REST API](#rest-api)
+    - [Python API](#python-api)
+- [Schema](#schema)
+- [STIX Output](#stix-output)
+- [YARA Matching](#yara-matching)
+- [Helper Utilities](#helper-utilities)
+
+### Guides
+- [Parser Development](docs/ParserDevelopment.md)
+- [Parser Components](docs/ParserComponents.md)
+- [Parser Installation](docs/ParserInstallation.md)
+- [Parser Testing](docs/ParserTesting.md)
+- [Python Style Guide](docs/PythonStyleGuide.md)
+- [Construct Tutorial](docs/construct.ipynb)
+- [Style Guide](docs/PythonStyleGuide.md)
+- [Testing](docs/Testing.md)
+
+
+## Install
+```console
+> pip install mwcp
+```
+
+Alternatively you can clone this repo and install locally.
+```console
+> git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
+> pip install ./DC3-MWCP
+```
+
+For a development mode use the `-e` flag to install in editable mode:
+
+```console
+> git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
+> pip install -e ./DC3-MWCP
+```
+
+## Builtin Parsers
+DC3-MWCP includes a handful of builtin [parsers](./mwcp/parsers) to get you started.
+These can be used as-is, subclassed, or included in your own parser groups.
+
+To view the available parsers:
+```bash
+$ mwcp list
+```
+
+Parsers are installed under the `dc3` source name. To include them in a group simply add them with
+the `dc3:` prefix.
+
+```yml
+SuperMalware:
+    description: SuperMalware component
+    author: acme
+    parsers:
+      - dc3:Archive.Zip
+      - .Dropper
+      - .Implant
+      - dc3:Decoy
+```
+
+
+## Dragodis Support
+DC3-MWCP optionally supports [Dragodis](https://github.com/Defense-Cyber-Crime-Center/Dragodis)
+if it is installed. This allows you to obtain a disassembler agnostic interface for parsing
+the file's disassembly from the `mwcp.FileObject` object with the `.disassembly()` function.
+
+You can install Dragodis along with DC3-MWCP by adding `[dragodis]` to your appropriate install command:
+```
+pip install mwcp[dragodis]
+pip install ./DC3-MWCP[dragodis]
+pip install -e ./DC3-MWCP[dragodis]
+```
+
+After installation make sure to follow Dragodis's [installation instructions](https://github.com/Defense-Cyber-Crime-Center/Dragodis/blob/master/docs/install.rst) to setup
+a backend disassembler.
+
+*It is recommended to also install [Rugosa](https://github.com/Defense-Cyber-Crime-Center/rugosa) 
+for emulation and regex/yara matching capabilities using Dragodis.*
+
+
+## DC3-Kordesii Support
+DC3-MWCP optionally supports [DC3-Kordesii](https://github.com/Defense-Cyber-Crime-Center/kordesii)
+if it is installed. This will allow you to run any DC3-Kordesii decoder from the
+`mwcp.FileObject` object with the `run_kordesii_decoder` function.
+
+You can install DC3-Kordesii along with DC3-MWCP by adding `[kordesii]` to your appropriate install command:
+```
+pip install mwcp[kordesii]
+pip install ./DC3-MWCP[kordesii]
+pip install -e ./DC3-MWCP[kordesii]
+```
+
+
+## Usage
+DC3-MWCP is designed to allow easy development and use of malware config parsers. DC3-MWCP is also designed to ensure
+that these parsers are scalable and that DC3-MWCP can be integrated in other systems.
+
+Most automated processing systems will use a condition, such as a yara signature match, to trigger execution
+of an DC3-MWCP parser.
+
+There are 3 options for integration of DC3-MWCP:
+- CLI: `mwcp`
+- REST API: `mwcp serve`
+- Python API
+
+DC3-MWCP also includes a utility for test case generation and execution.
+
+### CLI tool
+
+DC3-MWCP can be used directly from the command line using the `mwcp` command.
+
+```console
+> mwcp parse foo ./README.md
+----- File: README.md -----
+Field         Value
+------------  ----------------------------------------------------------------
+Parser        foo
+File Path     README.md
+Description   Foo
+Architecture
+MD5           b21df2332fe87c0fae95bdda00b5a3c0
+SHA1          8841a1fff55687ccddc587935b62667173b14bcd
+SHA256        0097c13a3541a440d64155a7f4443d76597409e0f40ce3ae67f73f51f59f1930
+Compile Time
+Tags
+
+---- Socket ----
+Tags    Address    Network Protocol
+------  ---------  ------------------
+        127.0.0.1  tcp
+
+---- URL ----
+Tags    Url               Address    Network Protocol    Application Protocol
+------  ----------------  ---------  ------------------  ----------------------
+        http://127.0.0.1  127.0.0.1  tcp                 http
+
+---- Residual Files ----
+Tags    Filename           Description          MD5                               Arch    Compile Time
+------  -----------------  -------------------  --------------------------------  ------  --------------
+        fooconfigtest.txt  example output file  5eb63bbbe01eeed093cb22bb8f5acdc3
+
+---- Logs ----
+[+] File README.md identified as Foo.
+[+] size of inputfile is 15560 bytes
+[+] README.md dispatched residual file: fooconfigtest.txt
+[+] File fooconfigtest.txt described as example output file
+[+] operating on inputfile README.md
+
+----- File Tree -----
+<README.md (b21df2332fe87c0fae95bdda00b5a3c0) : Foo>
+ <fooconfigtest.txt (5eb63bbbe01eeed093cb22bb8f5acdc3) : example output file>
+```
+
+see ```mwcp parse -h``` for full set of options
+
+
+### REST API
+
+DC3-MWCP can be used as a web service. The web service provides a web application as
+well as a REST API for some commonly used functions:
+
+* ```/run_parser/<parser>``` -- executes a parser on uploaded file
+* ```/descriptions``` -- provides list of available parsers
+* ```/schema.json``` -- provides the [schema](#schema) for report output
+
+To use, first start the server by running:
+```console
+> mwcp serve
+```
+
+Then you can either use an HTTP client to create REST requests.
+
+Using cURL:
+```console
+# Get JSON for processing README.md with foo parser
+> curl --form data=@README.md http://localhost:8080/run_parser/foo
+# Get STIX 2.1 JSON for processing README.md with foo parser
+> curl --form data=@README.md --form output=stix http://localhost:8080/run_parser/foo
+# Get STIX 2.1 JSON  without artifacts for processing README.md with foo parser
+> curl --form data=@README.md --form output=stix --form no_file_data=1 http://localhost:8080/run_parser/foo
+```
+
+Using Python requests:
+```python
+import requests
+req = requests.post("http://localhost:8080/run_parser/foo", files={'data': open("README.md", 'rb')})
+req.json()
+```
+
+Output:
+```json
+{
+    "url": [
+        "http://127.0.0.1"
+    ],
+    "address": [
+        "127.0.0.1"
+    ],
+    "debug": [
+        "size of inputfile is 7128 bytes",
+        "outputfile: fooconfigtest.txt",
+        "operating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfile-n4mw7uw3"
+    ],
+    "outputfile": [
+        [
+            "fooconfigtest.txt",
+            "example output file",
+            "5eb63bbbe01eeed093cb22bb8f5acdc3",
+            "aGVsbG8gd29ybGQ="
+        ]
+    ],
+    "output_text": "\n----Standard Metadata----\n\nurl                  http://127.0.0.1\naddress              127.0.0.1\n\n----Debug----\n\nsize of inputfile is 7128 bytes\noutputfile: fooconfigtest.txt\noperating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfile-n4mw7uw3\n\n----Output Files----\n\nfooconfigtest.txt    example output file\n                     5eb63bbbe01eeed093cb22bb8f5acdc3\n"
+}
+```
+
+By default, the original legacy json schema will be provided upon request.
+To use the new schema, you must set the `legacy` option in the query section to `False`.
+
+Eventually this new schema will replace the old one entirely. It is recommended to start using this flag
+to help transition your automation platform to use the new schema.
+
+
+```console
+> curl --form data=@README.md http://localhost:8080/run_parser/foo?legacy=False
+```
+
+```json
+[
+    {
+        "type": "report",
+        "tags": [],
+        "input_file": {
+            "type": "input_file",
+            "tags": [],
+            "name": "README.md",
+            "description": "Foo",
+            "md5": "80a3d9b88c956c960d1fea265db0882e",
+            "sha1": "994aa37fd26dd88272b8e661631eec8a5f425920",
+            "sha256": "3bef8d5dc4cd94c0ee92c9b6d7ee47a4794e550d287ee1affde84c2b7bcdf3cb",
+            "architecture": null,
+            "compile_time": null,
+            "file_path": "README.md",
+            "data": null
+        },
+        "parser": "foo",
+        "errors": [],
+        "logs": [
+            "[+] File README.md identified as Foo.",
+            "[+] size of inputfile is 15887 bytes",
+            "[+] README.md dispatched residual file: fooconfigtest.txt",
+            "[+] File fooconfigtest.txt described as example output file",
+            "[+] operating on inputfile README.md"
+        ],
+        "metadata": [
+            {
+                "type": "url",
+                "tags": [],
+                "url": "http://127.0.0.1",
+                "socket": {
+                    "type": "socket",
+                    "tags": [],
+                    "address": "127.0.0.1",
+                    "port": null,
+                    "network_protocol": "tcp",
+                    "c2": null,
+                    "listen": null
+                },
+                "path": null,
+                "query": "",
+                "application_protocol": "http",
+                "credential": null
+            },
+            {
+                "type": "socket",
+                "tags": [],
+                "address": "127.0.0.1",
+                "port": null,
+                "network_protocol": "tcp",
+                "c2": null,
+                "listen": null
+            },
+            {
+                "type": "residual_file",
+                "tags": [],
+                "name": "fooconfigtest.txt",
+                "description": "example output file",
+                "md5": "5eb63bbbe01eeed093cb22bb8f5acdc3",
+                "sha1": "2aae6c35c94fcfb415dbe95f408b9ce91ee846ed",
+                "sha256": "b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9",
+                "architecture": null,
+                "compile_time": null,
+                "file_path": "README.md_mwcp_output\\5eb63_fooconfigtest.txt",
+                "data": null
+            }
+        ]
+    }
+]
+```
+
+A simple HTML interface is also available at the same address. By default this
+is `http://localhost:8080/`. Individual samples can be submitted and results
+saved as JSON, plain text, or ZIP archives.
+
+
+### Python API
+DC3-MWCP can be run directly from Python.
+
+```python
+#!/usr/bin/env python
+"""
+Simple example to demonstrate use of the API provided by DC3-MWCP framework.
+"""
+
+# first, import mwcp
+import mwcp
+
+# register the builtin MWCP parsers and any other parser packages installed on the system
+mwcp.register_entry_points()
+
+# register a directory containing parsers
+mwcp.register_parser_directory(r'C:\my_parsers')
+
+# view all available parsers
+print(mwcp.get_parser_descriptions(config_only=False))
+
+# call the run() function to to generate a mwcp.Report object.
+report = mwcp.run("FooParser", "C:\\README.md")
+# alternate, run on provided buffer:
+report = mwcp.run("FooParser", data=b"lorem ipsum")
+
+# Display report results in a variety of formats:
+print(report.as_dict())
+print(report.as_json())
+print(report.as_text())
+
+# The metadata schema has changed recently. To get the legacy format use the following:
+print(report.as_dict_legacy())
+print(report.as_json_legacy())
+
+# You can also programmatically view results of report:
+from mwcp import metadata
+
+# display errors that may occur
+for log in report.errors:
+  print(log)
+
+# display data about original input file
+print(report.input_file)
+
+# get all url's using ftp protocol or has a query
+for url in report.get(metadata.URL):
+  if url.application_protocol == "ftp" or url.query:
+    print(url.url)
+
+# get residual files
+for residual_file in report.get(metadata.File):
+  print(residual_file.name)
+  print(residual_file.description)
+  print(residual_file.md5)
+
+# iterate through all metadata elements
+for element in report:
+  print(element)
+
+```
+
+## Configuration
+DC3-MWCP uses a configuration file which is located within the user's 
+profile directory. (`%APPDATA%\Local\mwcp\config.yml` for Windows or `~/.config/mwcp/config.yml` for Linux)
+
+This configuration file is used to manage configurable parameters, such as the location
+of the malware repository used for testing or the default parser source.
+
+To configure this file, run `mwcp config` to open up the file in your default text
+editor.
+
+An alternative configuration file can also be temporarily set using the `--config` parameter.
+```console
+> mwcp --config='new_config.yml' test Foo
+```
+
+Individual configuration parameters can be overwritten on the command line using the respective parameter.
+
+
+## Logging
+DC3-MWCP uses Python's builtin in `logging` module to log all messages.
+By default, logging is configured using the [log_config.yml](mwcp/config/log_config.yml) configuration
+file. Which is currently set to log all messages to the console and error messages to `%LOCALAPPDATA%/mwcp/errors.log`. 
+
+You can provide your own custom log configuration file by adding the path
+to the configuration parameter `LOG_CONFIG_PATH`. 
+(Please see [Python's documentation](http://docs.python.org/dev/library/logging.config.html) for more information on how to write your own configuration file.)
+
+You may also use the `--verbose` or `--debug` flags to adjust the logging level when using the `mwcp` tool.
+
+
+## Schema
+
+One of the major goals of DC3-MWCP is to standardize output for malware configuration parsers, making the data
+from one parser comparable with that of other parsers. This is achieved by establishing a schema of
+standardized metadata elements that represent the common malware configuration items seen across malware families.
+
+A formal [JSON Schema](https://json-schema.org) can be found at [schema.json](/mwcp/config/schema.json), by calling `mwcp schema` in the command line, or programmatically by calling `mwcp.schema()`. 
+This schema is versioned the same as DC3-MWCP. A change in the version may not necessarily
+reflect a change in the actual schema. However, any major or minor changes to the schema will
+be reflected in an appropriate change to the version and will be noted in the [changelog](/CHANGELOG.md).
+Please ensure you pin DC3-MWCP appropriately.
+
+It is acknowledged that a set of generic elements will often not be adequate to capture the nuances of
+individual malware families. To ensure that malware family specific attributes are appropriately captured
+in parser output, the schema includes an "Other" element which supports arbitrary key-value pairs.
+The keys and values are arbitrary to permit flexibility in describing the peculiarities of individual malware families.
+Information
+not captured in the abstract standardized elements is captured through this mechanism.
+
+The use of [tags](/docs/ParserComponents.md#tagging) is encouraged to provide additional context for the configuration items.
+For example, if a specific url is used to download a second stage component, a tag of "download"
+could be added to the reported URL element. Alternatively, if the URL is used for a proxy, 
+a tag of "proxy" could be included.
+There is no standard on what tags are available or when they should be included.
+This should be determined by your organization.
+
+
+### Extending the Schema
+
+It is possible to extend the schema to include your own custom metadata elements.
+This can be accomplished by creating a class that inherits from `mwcp.metadata.Metadata`. 
+This class must be decorated with [attr](https://attrs.org) using the custom configuration `mwcp.metadata.config`. 
+
+*NOTE: The class name must be unique from other metadata elements.*
+
+```python
+from typing import List
+
+import attr
+
+import mwcp
+from mwcp import metadata
+
+
+@attr.s(**metadata.config)
+class MyCustom(metadata.Metadata):
+    """
+    This is my custom metadata item.
+    """
+    field_a: str
+    field_b: int
+    field_c: List[str] = attr.ib(factory=list)
+
+    
+item = MyCustom(field_a="hello", field_b=42, field_c=["a", "b"])
+
+print(item)
+print(item.as_dict())
+
+# Custom items can be included in the report like normal.
+# MWCP will automatically format and display the custom element in the report.
+report = mwcp.Report()
+with report:
+    report.add(item)
+
+print(report.as_text())
+```
+
+```
+MyCustom(tags=set(), field_a='hello', field_b=42, field_c=['a', 'b'])
+{'type': 'my_custom', 'tags': [], 'field_a': 'hello', 'field_b': 42, 'field_c': ['a', 'b']}
+---- My Custom ----
+Tags    Field A      Field B  Field C
+------  ---------  ---------  ----------
+        hello             42  a, b
+```
+
+
+Please note, that extending the schema will obviously cause the [schema.json](/mwcp/config/schema.json) file to be incorrect.
+To regenerate the schema to also include the custom element run `mwcp.schema()` afterwards.
+
+```python
+import json
+import mwcp
+
+with open("schema.json", "w") as fo:
+    json.dump(mwcp.schema(id="https://acme.org/0.1/schema.json"), fo, indent=4)
+```
+
+
+## STIX Output
+
+MWCP can generate a [STIX 2.1](https://www.oasis-open.org/standard/stix-version-2-1/) JSON output that is suitable for integration into many
+systems that support the STIX standard. This output format makes use of three SCO 
+extensions and one property extension in addition to the currently defined STIX
+objects order to accurately convey MWCP's scan results.
+
+Some tools may not support these extensions yet which can result in the following data
+being omitted when ingesting MWCP's STIX output.  The following provides a list of STIX
+objects and extensions are used and what MWCP classes these are associated with:
+
+1. artifact (SCO)
+    1. File -- only used if the original binary is requested
+2. crypto-currency-address (SCO Extension)
+    1. CryptoAddress
+3. directory (SCO)
+    1. File
+    2. Path
+    3. Service
+4. domain-name (SCO)
+    1. Socket
+    2. URL
+5. email-address (SCO)
+    1. EmailAddress
+6. file (SCO)
+    1. File
+    2. Path
+    3. Service
+7. ipv4-address (SCO)
+    1. Socket
+    2. URL
+8. ipv6-address (SCO)
+    1. Socket
+    2. URL
+9. malware-analysis (SDO)
+    1. MWCP's scan results are tied together via a malware-analysis object showing the input object and the outputs
+10. mutex (SCO)
+    1. Mutex
+11. network-traffic (SCO)
+    1. Socket
+    2. URL
+12. note (SDO)
+    1. Boolean and Integer values for Other.  These are added to the description of the Note.
+    2. Descriptions and other narrative text tied to SCOs
+    3. Tags for SCOs excluding files
+13. observed-string (SCO Extension)
+    1. DecodedString
+    2. MissionID
+    3. Other
+    4. Pipe
+    5. User Agent
+    6. UUID
+14. process (SCO)
+    1. Command
+    2. Service
+15. relationship (SRO)
+    1. DecodedString
+    2. URL
+16. RSA Private Key (Property Extension for x509-certificate)
+    1. RSAPrivateKey
+17. symmetric-encryption (SCO)
+    1. EncryptionKey
+18. user-account (SCO)
+    1. Credential
+19. url (SCO)
+    1. URL
+20. x509-certificate (SCO)
+    1. RSAPrivateKey
+    2. RSAPublicKey
+    3. SSLCertSHA1
+21. windows-registry-key (SCO)
+    1. Registry2
+
+
+## YARA Matching
+
+MWCP includes a runner that can use YARA match results to determine which parser(s) to run on a given file.
+
+This will be used whenever you use `-` instead of specifying a parser on the command line,
+when a parser isn't specified in `mwcp.run()`, or when a parser isn't specified in a server request.
+
+```bash
+$ mwcp parse - input.exe
+$ curl --form data=@input.exe http://localhost:8080/run_parser
+```
+
+```python
+import mwcp 
+mwcp.register_entry_points()
+
+report = mwcp.run(data=b"file data")
+```
+
+As well, YARA matching will be recursively used on unidentified residual files.
+If you want to disable this, either set `--no-recursive` on the command line or set `recursive=False` on `mwcp.run()`.
+
+### Setup
+
+To enable YARA matching you'll need to specify a directory containing YARA signatures which use the `mwcp` 
+meta field to map a signature to a comma delimited list of parsers. Parsers can be specified in the same
+way as on the command line or Python API. That is, parser group names, `.` notation for specific parser components,
+and the use of `:` for specifying a parser source are all valid.
+
+Any signatures that don't have the `mwcp` meta field will be ignored.
+
+```yara
+rule SuperMalware {
+    meta:
+        mwcp = "SuperMalware"
+    ...
+}
+```
+
+To setup a YARA repo, set the `YARA_REPO` field to point to a directory containing YARA signatures (subdirectories allowed)
+in the configuration file that appears when you call `mwcp config`.
+If you have upgraded from an older version of MWCP, you may need to first backup and remove the original configuration file and
+then run `mwcp config` again to have MWCP recreate the file.
+
+Alternatively, the yara repo can be specified in the command line with `--yara-repo`. But the former method
+is necessary to use YARA matching with the server.
+
+
+## Helper Utilities
+MWCP comes with a few helper utilities (located in `mwcp.utils`) that may become useful for parsing malware files.
+
+- `pefileutils` - Provides helper functions for common routines done with the `pefile` library. (obtaining or checking for exports, imports, resources, sections, etc.)
+- `elffileutils` - Provides helper functions for common routines done with the `elftools` library. Provides a consistent interface similar to `pefileutils`.
+- `custombase64` - Provides functions for base64 encoding/decoding data with a custom alphabet.
+- `construct` - Provides extended functionality to the [construct](https://construct.readthedocs.io) library and brings
+back some lost features from version 2.8 into 2.9.
+    - This library has replaced the `enstructured` library originally found in the resources directory.
+    - Please follow [this tutorial](docs/construct.ipynb) for migrating from `enstructured` to `construct`.
+- `pecon` - PE file reconstruction utility.
+    - Please see docstring in [pecon.py](mwcp/utils/pecon.py) for more information.
+- `poshdeob` - An experimental powershell deobfuscator utility used to statically deobfuscate code and extract strings.
```

### Comparing `mwcp-3.8.0/mwcp/__init__.py` & `mwcp-3.9.0/mwcp/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,28 +1,27 @@
-"""Exposes interface for MWCP."""
-
-import logging
-
-# Add null handler to root logger to avoid "no handler" error when this is used as a library
-logging.getLogger().addHandler(logging.NullHandler())
-
-
-from mwcp.config import _config as config
-from mwcp.parser import Parser
-from mwcp.file_object import FileObject
-from mwcp.registry import (
-    register_entry_points, register_parser_directory, register_parser_package,
-    iter_parsers, get_parser_descriptions, set_default_source,
-    clear as clear_registry,
-    clear_default_source,
-    ParserNotFoundError
-)
-from mwcp.reporter import Reporter  # DEPRECATED
-from mwcp.runner import Runner
-from mwcp.report import Report
-from mwcp.dispatcher import Dispatcher, UnidentifiedFile
-from mwcp.utils.logutil import setup_logging
-from mwcp.core import run, schema
-from mwcp.exceptions import *
-
-
-__version__ = "3.8.0"
+"""Exposes interface for MWCP."""
+
+import logging
+
+# Add null handler to root logger to avoid "no handler" error when this is used as a library
+logging.getLogger().addHandler(logging.NullHandler())
+
+
+from mwcp.config import _config as config
+from mwcp.parser import Parser
+from mwcp.file_object import FileObject
+from mwcp.registry import (
+    register_entry_points, register_parser_directory, register_parser_package,
+    iter_parsers, get_parser_descriptions, set_default_source,
+    clear as clear_registry,
+    clear_default_source,
+    ParserNotFoundError
+)
+from mwcp.runner import Runner
+from mwcp.report import Report
+from mwcp.dispatcher import Dispatcher, UnidentifiedFile
+from mwcp.utils.logutil import setup_logging
+from mwcp.core import run, schema
+from mwcp.exceptions import *
+
+
+__version__ = "3.9.0"
```

### Comparing `mwcp-3.8.0/mwcp/config/__init__.py` & `mwcp-3.9.0/mwcp/config/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,95 +1,95 @@
-"""Stores default configuration values."""
-
-import logging
-import os
-import pathlib
-import pkg_resources
-
-
-import appdirs
-from ruamel.yaml import YAML
-
-
-logger = logging.getLogger(__name__)
-yaml = YAML()
-
-
-class Config(dict):
-
-    CONFIG_FILE_NAME = "config.yml"
-    USER_CONFIG_DIR = pathlib.Path(appdirs.user_config_dir("mwcp", appauthor=False))
-
-    # Fields which contain a file or directory path.
-    PATH_FIELDS = ["LOG_CONFIG_PATH", "TESTCASE_DIR", "MALWARE_REPO", "PARSER_DIR", "PARSER_CONFIG_PATH"]
-
-    def __init__(self, **kwargs):
-        super().__init__(**kwargs)
-        # We are going to manually add the fields.json path because
-        # the fields.json file is not currently designed to be modified.
-        self["FIELDS_PATH"] = os.path.abspath(pkg_resources.resource_filename("mwcp.config", "fields.json"))
-
-    def __repr__(self):
-        return f"Config({super().__repr__()})"
-
-    def clear(self):
-        """Clears config (and re-adds FIELDS_PATH)"""
-        super().clear()
-        self.__init__()
-
-    @property
-    def user_config_dir(self) -> pathlib.Path:
-        cfg_dir = self.USER_CONFIG_DIR
-        cfg_dir.mkdir(parents=True, exist_ok=True)
-        return cfg_dir
-
-    @property
-    def user_path(self) -> pathlib.Path:
-        """Returns the path to the user config file."""
-        # Get user directory.
-        cfg_dir = self.user_config_dir
-
-        # Create a user copy if it doesn"t exist.
-        cfg_file_path = cfg_dir / self.CONFIG_FILE_NAME
-        if not cfg_file_path.exists():
-            with pkg_resources.resource_stream("mwcp.config", self.CONFIG_FILE_NAME) as default_cfg:
-                with open(cfg_file_path, "wb") as fp:
-                    fp.write(default_cfg.read())
-
-        # Also copy over log_config.yml
-        log_config_path = cfg_dir / "log_config.yml"
-        if not log_config_path.exists():
-            with pkg_resources.resource_stream("mwcp.config", "log_config.yml") as default_log_cfg:
-                with open(log_config_path, "wb") as fp:
-                    fp.write(default_log_cfg.read())
-
-        return cfg_file_path
-
-    @property
-    def pytest_cache_dir(self) -> pathlib.Path:
-        return self.user_config_dir / ".pytest_cache"
-
-    def load(self, file_path=None):
-        """Loads configuration file."""
-        if not file_path:
-            file_path = self.user_path
-
-        # Convert str file_path to maintain backwards compatibility with previous function definition
-        if isinstance(file_path, str):
-            file_path = pathlib.Path(file_path)
-
-        with open(file_path, "r") as fp:
-            config = dict(yaml.load(fp))
-
-        # Convert file path into absolute paths.
-        directory = str(file_path.parent)
-        for key, value in config.items():
-            if key in self.PATH_FIELDS:
-                value = os.path.expanduser(value)
-                value = os.path.expandvars(value)
-                value = os.path.join(directory, value)
-                value = os.path.abspath(value)
-                config[key] = value
-        self.update(config)
-
-
-_config = Config()
+"""Stores default configuration values."""
+
+import logging
+import os
+import pathlib
+import pkg_resources
+
+
+import appdirs
+from ruamel.yaml import YAML
+
+
+logger = logging.getLogger(__name__)
+yaml = YAML()
+
+
+class Config(dict):
+
+    CONFIG_FILE_NAME = "config.yml"
+    USER_CONFIG_DIR = pathlib.Path(appdirs.user_config_dir("mwcp"))
+
+    # Fields which contain a file or directory path.
+    PATH_FIELDS = ["LOG_CONFIG_PATH", "TESTCASE_DIR", "MALWARE_REPO", "PARSER_DIR", "PARSER_CONFIG_PATH", "YARA_REPO"]
+
+    def __init__(self, **kwargs):
+        super().__init__(**kwargs)
+        # We are going to manually add the fields.json path because
+        # the fields.json file is not currently designed to be modified.
+        self["FIELDS_PATH"] = os.path.abspath(pkg_resources.resource_filename("mwcp.config", "fields.json"))
+
+    def __repr__(self):
+        return f"Config({super().__repr__()})"
+
+    def clear(self):
+        """Clears config (and re-adds FIELDS_PATH)"""
+        super().clear()
+        self.__init__()
+
+    @property
+    def user_config_dir(self) -> pathlib.Path:
+        cfg_dir = self.USER_CONFIG_DIR
+        cfg_dir.mkdir(parents=True, exist_ok=True)
+        return cfg_dir
+
+    @property
+    def user_path(self) -> pathlib.Path:
+        """Returns the path to the user config file."""
+        # Get user directory.
+        cfg_dir = self.user_config_dir
+
+        # Create a user copy if it doesn't exist.
+        cfg_file_path = cfg_dir / self.CONFIG_FILE_NAME
+        if not cfg_file_path.exists():
+            with pkg_resources.resource_stream("mwcp.config", self.CONFIG_FILE_NAME) as default_cfg:
+                with open(cfg_file_path, "wb") as fp:
+                    fp.write(default_cfg.read())
+
+        # Also copy over log_config.yml
+        log_config_path = cfg_dir / "log_config.yml"
+        if not log_config_path.exists():
+            with pkg_resources.resource_stream("mwcp.config", "log_config.yml") as default_log_cfg:
+                with open(log_config_path, "wb") as fp:
+                    fp.write(default_log_cfg.read())
+
+        return cfg_file_path
+
+    @property
+    def pytest_cache_dir(self) -> pathlib.Path:
+        return self.user_config_dir / ".pytest_cache"
+
+    def load(self, file_path=None):
+        """Loads configuration file."""
+        if not file_path:
+            file_path = self.user_path
+
+        # Convert str file_path to maintain backwards compatibility with previous function definition
+        if isinstance(file_path, str):
+            file_path = pathlib.Path(file_path)
+
+        with open(file_path, "r") as fp:
+            config = dict(yaml.load(fp))
+
+        # Convert file path into absolute paths.
+        directory = str(file_path.parent)
+        for key, value in config.items():
+            if key in self.PATH_FIELDS:
+                value = os.path.expanduser(value)
+                value = os.path.expandvars(value)
+                value = os.path.join(directory, value)
+                value = os.path.abspath(value)
+                config[key] = value
+        self.update(config)
+
+
+_config = Config()
```

### Comparing `mwcp-3.8.0/mwcp/config/fields.json` & `mwcp-3.9.0/mwcp/config/fields.json`

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

 * *Files 22% similar despite different names*

```diff
@@ -1,922 +1,893 @@
-00000000: 7b0d 0a20 2020 2022 6164 6472 6573 7322  {..    "address"
-00000010: 3a20 7b0d 0a20 2020 2020 2020 2022 6465  : {..        "de
-00000020: 7363 7269 7074 696f 6e22 3a20 2249 5020  scription": "IP 
-00000030: 6164 6472 6573 7320 6f72 2064 6f6d 6169  address or domai
-00000040: 6e20 6e61 6d65 222c 200d 0a20 2020 2020  n name", ..     
-00000050: 2020 2022 6578 616d 706c 6573 223a 205b     "examples": [
-00000060: 0d0a 2020 2020 2020 2020 2020 2020 2262  ..            "b
-00000070: 6164 2e63 6f6d 222c 200d 0a20 2020 2020  ad.com", ..     
-00000080: 2020 2020 2020 2022 3130 2e31 312e 3130         "10.11.10
-00000090: 2e31 3322 0d0a 2020 2020 2020 2020 5d2c  .13"..        ],
-000000a0: 200d 0a20 2020 2020 2020 2022 7479 7065   ..        "type
-000000b0: 223a 2022 6c69 7374 6f66 7374 7269 6e67  ": "listofstring
-000000c0: 7322 0d0a 2020 2020 7d2c 0d0a 2020 2020  s"..    },..    
-000000d0: 2262 6173 6531 365f 616c 7068 6162 6574  "base16_alphabet
-000000e0: 223a 207b 0d0a 2020 2020 2020 2020 2264  ": {..        "d
-000000f0: 6573 6372 6970 7469 6f6e 223a 2022 4261  escription": "Ba
-00000100: 7365 3136 2061 6c70 6861 6265 7420 7573  se16 alphabet us
-00000110: 6564 2066 6f72 2065 6e63 6f64 696e 672f  ed for encoding/
-00000120: 6465 636f 6469 6e67 222c 0d0a 2020 2020  decoding",..    
-00000130: 2020 2020 2265 7861 6d70 6c65 7322 3a20      "examples": 
-00000140: 5b0d 0a20 2020 2020 2020 2020 2020 2022  [..            "
-00000150: 3031 3233 3435 3637 3839 4142 4344 4546  0123456789ABCDEF
-00000160: 220d 0a20 2020 2020 2020 205d 2c0d 0a20  "..        ],.. 
-00000170: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
-00000180: 6c69 7374 6f66 7374 7269 6e67 7322 0d0a  listofstrings"..
-00000190: 2020 2020 7d2c 0d0a 2020 2020 2262 6173      },..    "bas
-000001a0: 6533 325f 616c 7068 6162 6574 223a 207b  e32_alphabet": {
-000001b0: 0d0a 2020 2020 2020 2020 2264 6573 6372  ..        "descr
-000001c0: 6970 7469 6f6e 223a 2022 4261 7365 3332  iption": "Base32
-000001d0: 2061 6c70 6861 6265 7420 7573 6564 2066   alphabet used f
-000001e0: 6f72 2065 6e63 6f64 696e 672f 6465 636f  or encoding/deco
-000001f0: 6469 6e67 222c 0d0a 2020 2020 2020 2020  ding",..        
-00000200: 2265 7861 6d70 6c65 7322 3a20 5b0d 0a20  "examples": [.. 
-00000210: 2020 2020 2020 2020 2020 2022 4142 4344             "ABCD
-00000220: 4546 4748 494a 4b4c 4d4e 4f50 5152 5354  EFGHIJKLMNOPQRST
-00000230: 5556 5758 595a 3233 3435 3637 3d22 0d0a  UVWXYZ234567="..
-00000240: 2020 2020 2020 2020 5d2c 0d0a 2020 2020          ],..    
-00000250: 2020 2020 2274 7970 6522 3a20 226c 6973      "type": "lis
-00000260: 746f 6673 7472 696e 6773 220d 0a20 2020  tofstrings"..   
-00000270: 207d 2c0d 0a20 2020 2022 6261 7365 3634   },..    "base64
-00000280: 5f61 6c70 6861 6265 7422 3a20 7b0d 0a20  _alphabet": {.. 
-00000290: 2020 2020 2020 2022 6465 7363 7269 7074         "descript
-000002a0: 696f 6e22 3a20 2242 6173 6536 3420 616c  ion": "Base64 al
-000002b0: 7068 6162 6574 2075 7365 6420 666f 7220  phabet used for 
-000002c0: 656e 636f 6469 6e67 2f64 6563 6f64 696e  encoding/decodin
-000002d0: 6722 2c0d 0a20 2020 2020 2020 2022 6578  g",..        "ex
-000002e0: 616d 706c 6573 223a 205b 0d0a 2020 2020  amples": [..    
-000002f0: 2020 2020 2020 2020 2241 4243 4445 4647          "ABCDEFG
-00000300: 4849 4a4b 4c4d 4e4f 5051 5253 5455 5657  HIJKLMNOPQRSTUVW
-00000310: 5859 5a61 6263 6465 6667 6869 6a6b 6c6d  XYZabcdefghijklm
-00000320: 6e6f 7071 7273 7475 7677 7879 7a30 3132  nopqrstuvwxyz012
-00000330: 3334 3536 3738 392b 2f3d 220d 0a20 2020  3456789+/="..   
-00000340: 2020 2020 205d 2c0d 0a20 2020 2020 2020       ],..       
-00000350: 2022 7479 7065 223a 2022 6c69 7374 6f66   "type": "listof
-00000360: 7374 7269 6e67 7322 0d0a 2020 2020 7d2c  strings"..    },
-00000370: 0d0a 2020 2020 2263 325f 6164 6472 6573  ..    "c2_addres
-00000380: 7322 3a20 7b0d 0a20 2020 2020 2020 2022  s": {..        "
-00000390: 6465 7363 7269 7074 696f 6e22 3a20 2273  description": "s
-000003a0: 7065 6369 616c 2063 6173 6520 6f66 2061  pecial case of a
-000003b0: 6464 7265 7373 2c20 7768 656e 2074 6865  ddress, when the
-000003c0: 2061 6464 7265 7373 2069 7320 7573 6564   address is used
-000003d0: 2066 6f72 2063 6f6d 6d61 6e64 2061 6e64   for command and
-000003e0: 2063 6f6e 7472 6f6c 222c 200d 0a20 2020   control", ..   
-000003f0: 2020 2020 2022 6578 616d 706c 6573 223a       "examples":
-00000400: 205b 0d0a 2020 2020 2020 2020 2020 2020   [..            
-00000410: 2262 6164 2e63 6f6d 222c 200d 0a20 2020  "bad.com", ..   
-00000420: 2020 2020 2020 2020 2022 3130 2e31 312e           "10.11.
-00000430: 3130 2e31 3322 0d0a 2020 2020 2020 2020  10.13"..        
-00000440: 5d2c 200d 0a20 2020 2020 2020 2022 7479  ], ..        "ty
-00000450: 7065 223a 2022 6c69 7374 6f66 7374 7269  pe": "listofstri
-00000460: 6e67 7322 0d0a 2020 2020 7d2c 200d 0a20  ngs"..    }, .. 
-00000470: 2020 2022 6332 5f73 6f63 6b65 7461 6464     "c2_socketadd
-00000480: 7265 7373 223a 207b 0d0a 2020 2020 2020  ress": {..      
-00000490: 2020 2264 6573 6372 6970 7469 6f6e 223a    "description":
-000004a0: 2022 7370 6563 6961 6c20 6361 7365 206f   "special case o
-000004b0: 6620 736f 636b 6574 6164 6472 6573 732c  f socketaddress,
-000004c0: 2077 6865 6e20 736f 636b 6574 6164 6472   when socketaddr
-000004d0: 6573 7320 6973 2075 7365 6420 666f 7220  ess is used for 
-000004e0: 636f 6d6d 616e 6420 616e 6420 636f 6e74  command and cont
-000004f0: 726f 6c22 2c20 0d0a 2020 2020 2020 2020  rol", ..        
-00000500: 2265 7861 6d70 6c65 7322 3a20 5b0d 0a20  "examples": [.. 
-00000510: 2020 2020 2020 2020 2020 205b 0d0a 2020             [..  
-00000520: 2020 2020 2020 2020 2020 2020 2020 2262                "b
-00000530: 6164 2e63 6f6d 222c 200d 0a20 2020 2020  ad.com", ..     
-00000540: 2020 2020 2020 2020 2020 2022 3231 222c             "21",
-00000550: 200d 0a20 2020 2020 2020 2020 2020 2020   ..             
-00000560: 2020 2022 7463 7022 0d0a 2020 2020 2020     "tcp"..      
-00000570: 2020 2020 2020 5d2c 200d 0a20 2020 2020        ], ..     
-00000580: 2020 2020 2020 205b 0d0a 2020 2020 2020         [..      
-00000590: 2020 2020 2020 2020 2020 2231 302e 3131            "10.11
-000005a0: 2e31 302e 3133 222c 200d 0a20 2020 2020  .10.13", ..     
-000005b0: 2020 2020 2020 2020 2020 2022 3434 3322             "443"
-000005c0: 2c20 0d0a 2020 2020 2020 2020 2020 2020  , ..            
-000005d0: 2020 2020 2274 6370 220d 0a20 2020 2020      "tcp"..     
-000005e0: 2020 2020 2020 205d 0d0a 2020 2020 2020         ]..      
-000005f0: 2020 5d2c 200d 0a20 2020 2020 2020 2022    ], ..        "
-00000600: 7479 7065 223a 2022 6c69 7374 6f66 7374  type": "listofst
-00000610: 7269 6e67 7475 706c 6573 220d 0a20 2020  ringtuples"..   
-00000620: 207d 2c20 0d0a 2020 2020 2263 325f 7572   }, ..    "c2_ur
-00000630: 6c22 3a20 7b0d 0a20 2020 2020 2020 2022  l": {..        "
-00000640: 6465 7363 7269 7074 696f 6e22 3a20 2273  description": "s
-00000650: 7065 6369 616c 2063 6173 6520 6f66 2075  pecial case of u
-00000660: 726c 2c20 7768 656e 2074 6865 2075 726c  rl, when the url
-00000670: 2069 7320 7573 6564 2066 6f72 2063 6f6d   is used for com
-00000680: 6d61 6e64 2061 6e64 2063 6f6e 7472 6f6c  mand and control
-00000690: 222c 200d 0a20 2020 2020 2020 2022 6578  ", ..        "ex
-000006a0: 616d 706c 6573 223a 205b 0d0a 2020 2020  amples": [..    
-000006b0: 2020 2020 2020 2020 2268 7474 703a 2f2f          "http://
-000006c0: 6d61 6c2e 636f 6d2f 7075 622f 7669 6577  mal.com/pub/view
-000006d0: 2e61 7370 222c 200d 0a20 2020 2020 2020  .asp", ..       
-000006e0: 2020 2020 2022 6874 7470 733a 2f2f 3130       "https://10
-000006f0: 2e31 312e 3130 2e31 333a 3434 332f 696d  .11.10.13:443/im
-00000700: 6167 6573 2f62 616e 6572 2e6a 7067 220d  ages/baner.jpg".
-00000710: 0a20 2020 2020 2020 205d 2c20 0d0a 2020  .        ], ..  
-00000720: 2020 2020 2020 2274 7970 6522 3a20 226c        "type": "l
-00000730: 6973 746f 6673 7472 696e 6773 220d 0a20  istofstrings".. 
-00000740: 2020 207d 2c20 0d0a 2020 2020 2263 7265     }, ..    "cre
-00000750: 6465 6e74 6961 6c22 3a20 7b0d 0a20 2020  dential": {..   
-00000760: 2020 2020 2022 6465 7363 7269 7074 696f       "descriptio
-00000770: 6e22 3a20 2274 7570 6c65 206f 6620 7573  n": "tuple of us
-00000780: 6572 6e61 6d65 2061 6e64 2070 6173 7377  ername and passw
-00000790: 6f72 6422 2c20 0d0a 2020 2020 2020 2020  ord", ..        
-000007a0: 2265 7861 6d70 6c65 7322 3a20 5b0d 0a20  "examples": [.. 
-000007b0: 2020 2020 2020 2020 2020 205b 0d0a 2020             [..  
-000007c0: 2020 2020 2020 2020 2020 2020 2020 2248                "H
-000007d0: 756e 7465 7222 2c20 0d0a 2020 2020 2020  unter", ..      
-000007e0: 2020 2020 2020 2020 2020 2242 656e 736f            "Benso
-000007f0: 6e22 0d0a 2020 2020 2020 2020 2020 2020  n"..            
-00000800: 5d2c 200d 0a20 2020 2020 2020 2020 2020  ], ..           
-00000810: 205b 0d0a 2020 2020 2020 2020 2020 2020   [..            
-00000820: 2020 2020 2261 646d 696e 222c 200d 0a20      "admin", .. 
-00000830: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00000840: 3132 3334 3536 220d 0a20 2020 2020 2020  123456"..       
-00000850: 2020 2020 205d 0d0a 2020 2020 2020 2020       ]..        
-00000860: 5d2c 200d 0a20 2020 2020 2020 2022 7479  ], ..        "ty
-00000870: 7065 223a 2022 6c69 7374 6f66 7374 7269  pe": "listofstri
-00000880: 6e67 7475 706c 6573 220d 0a20 2020 207d  ngtuples"..    }
-00000890: 2c20 0d0a 2020 2020 2264 6562 7567 223a  , ..    "debug":
-000008a0: 207b 0d0a 2020 2020 2020 2020 2264 6573   {..        "des
-000008b0: 6372 6970 7469 6f6e 223a 2022 4d65 7373  cription": "Mess
-000008c0: 6167 6520 7573 6564 2066 6f72 2064 6562  age used for deb
-000008d0: 7567 6769 6e67 206f 7220 746f 2072 6570  ugging or to rep
-000008e0: 6f72 7420 6572 726f 7273 2e20 4e6f 7420  ort errors. Not 
-000008f0: 6d61 6c77 6172 6520 636f 6e66 6967 7572  malware configur
-00000900: 6174 696f 6e20 7065 7220 7365 222c 200d  ation per se", .
-00000910: 0a20 2020 2020 2020 2022 6578 616d 706c  .        "exampl
-00000920: 6573 223a 205b 0d0a 2020 2020 2020 2020  es": [..        
-00000930: 2020 2020 2253 7563 6365 7373 6675 6c6c      "Successfull
-00000940: 7920 666f 756e 6420 636f 6e66 6967 2062  y found config b
-00000950: 6c6f 636b 2c20 6174 7465 6d70 7469 6e67  lock, attempting
-00000960: 2064 6563 6f64 6522 2c20 0d0a 2020 2020   decode", ..    
-00000970: 2020 2020 2020 2020 2244 6563 6f64 6520          "Decode 
-00000980: 6661 696c 6564 3a20 6465 7465 6374 6564  failed: detected
-00000990: 2063 6f6e 6669 6720 6c6f 6361 7469 6f6e   config location
-000009a0: 2033 3733 3539 3238 3535 3920 6f75 7473   3735928559 outs
-000009b0: 6964 6520 6669 6c65 2073 697a 6520 6f66  ide file size of
-000009c0: 2031 3834 3332 3022 0d0a 2020 2020 2020   184320"..      
-000009d0: 2020 5d2c 200d 0a20 2020 2020 2020 2022    ], ..        "
-000009e0: 7479 7065 223a 2022 6c69 7374 6f66 7374  type": "listofst
-000009f0: 7269 6e67 7322 0d0a 2020 2020 7d2c 200d  rings"..    }, .
-00000a00: 0a20 2020 2022 6469 7265 6374 6f72 7922  .    "directory"
-00000a10: 3a20 7b0d 0a20 2020 2020 2020 2022 6465  : {..        "de
-00000a20: 7363 7269 7074 696f 6e22 3a20 2264 6972  scription": "dir
-00000a30: 6563 746f 7279 2028 6469 726e 616d 6529  ectory (dirname)
-00000a40: 2075 7365 6420 6279 206d 616c 7761 7265   used by malware
-00000a50: 222c 200d 0a20 2020 2020 2020 2022 6578  ", ..        "ex
-00000a60: 616d 706c 6573 223a 205b 0d0a 2020 2020  amples": [..    
-00000a70: 2020 2020 2020 2020 2243 3a5c 5c77 696e          "C:\\win
-00000a80: 646f 7773 5c5c 7465 6d70 5c5c 315c 5c6c  dows\\temp\\1\\l
-00000a90: 6f67 222c 200d 0a20 2020 2020 2020 2020  og", ..         
-00000aa0: 2020 2022 2541 5050 4441 5441 255c 5c66     "%APPDATA%\\f
-00000ab0: 6f6f 220d 0a20 2020 2020 2020 205d 2c20  oo"..        ], 
-00000ac0: 0d0a 2020 2020 2020 2020 2274 7970 6522  ..        "type"
-00000ad0: 3a20 226c 6973 746f 6673 7472 696e 6773  : "listofstrings
-00000ae0: 220d 0a20 2020 207d 2c0d 0a20 2020 2022  "..    },..    "
-00000af0: 656d 6169 6c5f 6164 6472 6573 7322 3a20  email_address": 
-00000b00: 7b0d 0a20 2020 2020 2020 2022 6465 7363  {..        "desc
-00000b10: 7269 7074 696f 6e22 3a20 2245 6d61 696c  ription": "Email
-00000b20: 2061 6464 7265 7373 222c 0d0a 2020 2020   address",..    
-00000b30: 2020 2020 2265 7861 6d70 6c65 7322 3a20      "examples": 
-00000b40: 5b0d 0a20 2020 2020 2020 2020 2020 2022  [..            "
-00000b50: 7573 6572 4062 6164 2e63 6f6d 220d 0a20  user@bad.com".. 
-00000b60: 2020 2020 2020 205d 2c0d 0a20 2020 2020         ],..     
-00000b70: 2020 2022 7479 7065 223a 2022 6c69 7374     "type": "list
-00000b80: 6f66 7374 7269 6e67 7322 0d0a 2020 2020  ofstrings"..    
-00000b90: 7d2c 0d0a 2020 2020 2265 7665 6e74 223a  },..    "event":
-00000ba0: 207b 0d0a 2020 2020 2020 2020 2264 6573   {..        "des
-00000bb0: 6372 6970 7469 6f6e 223a 2022 4e61 6d65  cription": "Name
-00000bc0: 206f 6620 616e 2065 7665 6e74 206f 626a   of an event obj
-00000bd0: 6563 7422 2c0d 0a20 2020 2020 2020 2022  ect",..        "
-00000be0: 6578 616d 706c 6573 223a 205b 0d0a 2020  examples": [..  
-00000bf0: 2020 2020 2020 2020 2020 224d 6963 726f            "Micro
-00000c00: 736f 6674 4578 6974 220d 0a20 2020 2020  softExit"..     
-00000c10: 2020 205d 2c0d 0a20 2020 2020 2020 2022     ],..        "
-00000c20: 7479 7065 223a 2022 6c69 7374 6f66 7374  type": "listofst
-00000c30: 7269 6e67 7322 0d0a 2020 2020 7d2c 0d0a  rings"..    },..
-00000c40: 2020 2020 2266 696c 656e 616d 6522 3a20      "filename": 
-00000c50: 7b0d 0a20 2020 2020 2020 2022 6465 7363  {..        "desc
-00000c60: 7269 7074 696f 6e22 3a20 2266 696c 656e  ription": "filen
-00000c70: 616d 6520 2862 6173 656e 616d 6529 2075  ame (basename) u
-00000c80: 7365 6420 6279 206d 616c 7761 7265 222c  sed by malware",
-00000c90: 200d 0a20 2020 2020 2020 2022 6578 616d   ..        "exam
-00000ca0: 706c 6573 223a 205b 0d0a 2020 2020 2020  ples": [..      
-00000cb0: 2020 2020 2020 226b 6579 6462 2e74 7874        "keydb.txt
-00000cc0: 222c 200d 0a20 2020 2020 2020 2020 2020  ", ..           
-00000cd0: 2022 6261 722e 6578 6522 0d0a 2020 2020   "bar.exe"..    
-00000ce0: 2020 2020 5d2c 200d 0a20 2020 2020 2020      ], ..       
-00000cf0: 2022 7479 7065 223a 2022 6c69 7374 6f66   "type": "listof
-00000d00: 7374 7269 6e67 7322 0d0a 2020 2020 7d2c  strings"..    },
-00000d10: 200d 0a20 2020 2022 6669 6c65 7061 7468   ..    "filepath
-00000d20: 223a 207b 0d0a 2020 2020 2020 2020 2264  ": {..        "d
-00000d30: 6573 6372 6970 7469 6f6e 223a 2022 6669  escription": "fi
-00000d40: 6c65 7379 7374 656d 2070 6174 6820 7573  lesystem path us
-00000d50: 6564 2062 7920 6d61 6c77 6172 652e 2049  ed by malware. I
-00000d60: 6e63 6c75 6465 7320 626f 7468 2061 2064  ncludes both a d
-00000d70: 6972 6563 746f 7279 2061 6e64 2061 2066  irectory and a f
-00000d80: 696c 656e 616d 6522 2c20 0d0a 2020 2020  ilename", ..    
-00000d90: 2020 2020 2265 7861 6d70 6c65 7322 3a20      "examples": 
-00000da0: 5b0d 0a20 2020 2020 2020 2020 2020 2022  [..            "
-00000db0: 433a 5c5c 7769 6e64 6f77 735c 5c74 656d  C:\\windows\\tem
-00000dc0: 705c 5c31 5c5c 6c6f 675c 5c6b 6579 6462  p\\1\\log\\keydb
-00000dd0: 2e74 7874 222c 200d 0a20 2020 2020 2020  .txt", ..       
-00000de0: 2020 2020 2022 2541 5050 4441 5441 255c       "%APPDATA%\
-00000df0: 5c66 6f6f 5c5c 6261 722e 6578 6522 0d0a  \foo\\bar.exe"..
-00000e00: 2020 2020 2020 2020 5d2c 200d 0a20 2020          ], ..   
-00000e10: 2020 2020 2022 7479 7065 223a 2022 6c69       "type": "li
-00000e20: 7374 6f66 7374 7269 6e67 7322 0d0a 2020  stofstrings"..  
-00000e30: 2020 7d2c 0d0a 2020 2020 2266 7470 223a    },..    "ftp":
-00000e40: 207b 0d0a 2020 2020 2020 2020 2264 6573   {..        "des
-00000e50: 6372 6970 7469 6f6e 223a 2022 4654 5020  cription": "FTP 
-00000e60: 6372 6564 656e 7469 616c 7320 2875 7365  credentials (use
-00000e70: 726e 616d 6520 616e 6420 7061 7373 776f  rname and passwo
-00000e80: 7264 292c 2061 6e64 2066 756c 6c20 5552  rd), and full UR
-00000e90: 4c20 7769 7468 2073 6368 656d 652c 2061  L with scheme, a
-00000ea0: 6464 7265 7373 2c20 6f70 7469 6f6e 616c  ddress, optional
-00000eb0: 2070 6f72 742c 2061 6e64 206f 7074 696f   port, and optio
-00000ec0: 6e61 6c20 7061 7468 222c 0d0a 2020 2020  nal path",..    
-00000ed0: 2020 2020 2265 7861 6d70 6c65 7322 3a20      "examples": 
-00000ee0: 5b0d 0a20 2020 2020 2020 2020 2020 205b  [..            [
-00000ef0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00000f00: 2020 2261 646d 696e 222c 0d0a 2020 2020    "admin",..    
-00000f10: 2020 2020 2020 2020 2020 2020 2270 6173              "pas
-00000f20: 7322 2c0d 0a20 2020 2020 2020 2020 2020  s",..           
-00000f30: 2020 2020 2022 6674 703a 2f2f 6261 6468       "ftp://badh
-00000f40: 6f73 742e 636f 6d3a 3231 220d 0a20 2020  ost.com:21"..   
-00000f50: 2020 2020 2020 2020 205d 0d0a 2020 2020           ]..    
-00000f60: 2020 2020 5d2c 0d0a 2020 2020 2020 2020      ],..        
-00000f70: 2274 7970 6522 3a20 226c 6973 746f 6673  "type": "listofs
-00000f80: 7472 696e 6774 7570 6c65 7322 0d0a 2020  tringtuples"..  
-00000f90: 2020 7d2c 0d0a 2020 2020 2267 7569 6422    },..    "guid"
-00000fa0: 3a20 7b0d 0a20 2020 2020 2020 2022 6465  : {..        "de
-00000fb0: 7363 7269 7074 696f 6e22 3a20 2241 2031  scription": "A 1
-00000fc0: 3238 2d62 6974 206e 756d 6265 7220 7573  28-bit number us
-00000fd0: 6564 2074 6f20 6964 656e 7469 6679 2069  ed to identify i
-00000fe0: 6e66 6f72 6d61 7469 6f6e 2c20 616c 736f  nformation, also
-00000ff0: 2072 6566 6572 7265 6420 746f 2061 7320   referred to as 
-00001000: 6120 5555 4944 222c 0d0a 2020 2020 2020  a UUID",..      
-00001010: 2020 2265 7861 6d70 6c65 7322 3a20 5b0d    "examples": [.
-00001020: 0a20 2020 2020 2020 2020 2020 2022 7b36  .            "{6
-00001030: 3534 6535 6366 662d 3831 3763 2d34 6533  54e5cff-817c-4e3
-00001040: 642d 3862 3031 2d34 3761 3666 3435 6165  d-8b01-47a6f45ae
-00001050: 3039 617d 220d 0a20 2020 2020 2020 205d  09a}"..        ]
-00001060: 2c0d 0a20 2020 2020 2020 2022 7479 7065  ,..        "type
-00001070: 223a 2022 6c69 7374 6f66 7374 7269 6e67  ": "listofstring
-00001080: 7322 0d0a 2020 2020 7d2c 0d0a 2020 2020  s"..    },..    
-00001090: 2269 6e6a 6563 7469 6f6e 7072 6f63 6573  "injectionproces
-000010a0: 7322 3a20 7b0d 0a20 2020 2020 2020 2022  s": {..        "
-000010b0: 6465 7363 7269 7074 696f 6e22 3a20 2270  description": "p
-000010c0: 726f 6365 7373 2069 6e74 6f20 7768 6963  rocess into whic
-000010d0: 6820 6d61 6c77 6172 6520 6973 2069 6e6a  h malware is inj
-000010e0: 6563 7465 642e 2055 7375 616c 6c79 2074  ected. Usually t
-000010f0: 6869 7320 6973 2061 2070 726f 6365 7373  his is a process
-00001100: 206e 616d 6520 6275 7420 6974 206d 6179   name but it may
-00001110: 2074 616b 6520 6f74 6865 7220 666f 726d   take other form
-00001120: 7320 7375 6368 2061 7320 6120 6669 6c65  s such as a file
-00001130: 6e61 6d65 206f 6620 7468 6520 6578 6563  name of the exec
-00001140: 7574 6162 6c65 2e22 2c20 0d0a 2020 2020  utable.", ..    
-00001150: 2020 2020 2265 7861 6d70 6c65 7322 3a20      "examples": 
-00001160: 5b0d 0a20 2020 2020 2020 2020 2020 2022  [..            "
-00001170: 6965 7870 6c6f 7265 222c 200d 0a20 2020  iexplore", ..   
-00001180: 2020 2020 2020 2020 2022 7376 6368 6f73           "svchos
-00001190: 7422 0d0a 2020 2020 2020 2020 5d2c 200d  t"..        ], .
-000011a0: 0a20 2020 2020 2020 2022 7479 7065 223a  .        "type":
-000011b0: 2022 6c69 7374 6f66 7374 7269 6e67 7322   "listofstrings"
-000011c0: 0d0a 2020 2020 7d2c 200d 0a20 2020 2022  ..    }, ..    "
-000011d0: 696e 7465 7276 616c 223a 207b 0d0a 2020  interval": {..  
-000011e0: 2020 2020 2020 2264 6573 6372 6970 7469        "descripti
-000011f0: 6f6e 223a 2022 7469 6d65 206d 616c 7761  on": "time malwa
-00001200: 7265 2077 6169 7473 2062 6574 7765 656e  re waits between
-00001210: 2062 6561 636f 6e73 206f 7220 6f74 6865   beacons or othe
-00001220: 7220 6163 7469 7669 7479 2067 6976 656e  r activity given
-00001230: 2069 6e20 7365 636f 6e64 7322 2c20 0d0a   in seconds", ..
-00001240: 2020 2020 2020 2020 2265 7861 6d70 6c65          "example
-00001250: 7322 3a20 5b0d 0a20 2020 2020 2020 2020  s": [..         
-00001260: 2020 2022 3322 2c20 0d0a 2020 2020 2020     "3", ..      
-00001270: 2020 2020 2020 222e 3122 0d0a 2020 2020        ".1"..    
-00001280: 2020 2020 5d2c 200d 0a20 2020 2020 2020      ], ..       
-00001290: 2022 7479 7065 223a 2022 6c69 7374 6f66   "type": "listof
-000012a0: 7374 7269 6e67 7322 0d0a 2020 2020 7d2c  strings"..    },
-000012b0: 200d 0a20 2020 2022 6b65 7922 3a20 7b0d   ..    "key": {.
-000012c0: 0a20 2020 2020 2020 2022 6465 7363 7269  .        "descri
-000012d0: 7074 696f 6e22 3a20 2265 6e63 7279 7074  ption": "encrypt
-000012e0: 696f 6e2c 2065 6e63 6f64 696e 672c 206f  ion, encoding, o
-000012f0: 7220 6f62 6675 7363 6174 696f 6e20 6b65  r obfuscation ke
-00001300: 792e 2042 7920 636f 6e76 656e 7469 6f6e  y. By convention
-00001310: 2c20 7768 656e 2074 6865 7365 2072 6570  , when these rep
-00001320: 7265 7365 6e74 2062 696e 6172 7920 6461  resent binary da
-00001330: 7461 2c20 7468 6579 2073 686f 756c 6420  ta, they should 
-00001340: 6265 2062 6172 6520 6865 7820 656e 636f  be bare hex enco
-00001350: 6465 6420 7769 7468 206e 6f20 6f74 6865  ded with no othe
-00001360: 7220 6d61 726b 7570 2e20 4261 7365 3634  r markup. Base64
-00001370: 206f 7220 7369 6d69 6c61 7220 6375 7374   or similar cust
-00001380: 6f6d 2064 6963 7469 6f6e 6172 6965 7320  om dictionaries 
-00001390: 6172 6520 7374 6f72 6564 2061 7320 6973  are stored as is
-000013a0: 2e22 2c20 0d0a 2020 2020 2020 2020 2265  .", ..        "e
-000013b0: 7861 6d70 6c65 7322 3a20 5b0d 0a20 2020  xamples": [..   
-000013c0: 2020 2020 2020 2020 2022 3835 222c 200d           "85", .
-000013d0: 0a20 2020 2020 2020 2020 2020 2022 3664  .            "6d
-000013e0: 3739 3732 3633 3334 3662 3635 3739 220d  797263346b6579".
-000013f0: 0a20 2020 2020 2020 205d 2c20 0d0a 2020  .        ], ..  
-00001400: 2020 2020 2020 2274 7970 6522 3a20 226c        "type": "l
-00001410: 6973 746f 6673 7472 696e 6773 220d 0a20  istofstrings".. 
-00001420: 2020 207d 2c20 0d0a 2020 2020 226c 6973     }, ..    "lis
-00001430: 7465 6e70 6f72 7422 3a20 7b0d 0a20 2020  tenport": {..   
-00001440: 2020 2020 2022 6465 7363 7269 7074 696f       "descriptio
-00001450: 6e22 3a20 2254 4350 206f 7220 5544 5020  n": "TCP or UDP 
-00001460: 706f 7274 2074 6861 7420 6973 206f 7065  port that is ope
-00001470: 6e65 6420 666f 7220 6c69 7374 656e 696e  ned for listenin
-00001480: 672e 2054 6869 7320 6861 7320 7468 6520  g. This has the 
-00001490: 7361 6d65 2066 6f72 6d61 7420 6173 2061  same format as a
-000014a0: 2070 6f72 742c 2062 7574 2069 6e64 6963   port, but indic
-000014b0: 6174 6573 2061 6e20 696e 636f 6d69 6e67  ates an incoming
-000014c0: 2063 6f6e 6e65 6374 696f 6e20 7768 6572   connection wher
-000014d0: 6520 7468 6520 6d61 6c77 6172 6520 6973  e the malware is
-000014e0: 2074 6865 2073 6572 7665 722e 222c 200d   the server.", .
-000014f0: 0a20 2020 2020 2020 2022 6578 616d 706c  .        "exampl
-00001500: 6573 223a 205b 0d0a 2020 2020 2020 2020  es": [..        
-00001510: 2020 2020 5b0d 0a20 2020 2020 2020 2020      [..         
-00001520: 2020 2020 2020 2022 3533 222c 200d 0a20         "53", .. 
-00001530: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00001540: 7564 7022 0d0a 2020 2020 2020 2020 2020  udp"..          
-00001550: 2020 5d2c 200d 0a20 2020 2020 2020 2020    ], ..         
-00001560: 2020 205b 0d0a 2020 2020 2020 2020 2020     [..          
-00001570: 2020 2020 2020 2234 3433 222c 200d 0a20        "443", .. 
-00001580: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00001590: 7463 7022 0d0a 2020 2020 2020 2020 2020  tcp"..          
-000015a0: 2020 5d0d 0a20 2020 2020 2020 205d 2c20    ]..        ], 
-000015b0: 0d0a 2020 2020 2020 2020 2274 7970 6522  ..        "type"
-000015c0: 3a20 226c 6973 746f 6673 7472 696e 6774  : "listofstringt
-000015d0: 7570 6c65 7322 0d0a 2020 2020 7d2c 200d  uples"..    }, .
-000015e0: 0a20 2020 2022 6d69 7373 696f 6e69 6422  .    "missionid"
-000015f0: 3a20 7b0d 0a20 2020 2020 2020 2022 6465  : {..        "de
-00001600: 7363 7269 7074 696f 6e22 3a20 2261 7474  scription": "att
-00001610: 6163 6b65 7220 7370 6563 6966 6965 6420  acker specified 
-00001620: 6964 656e 7469 6669 6572 2065 6e63 6f64  identifier encod
-00001630: 6564 2069 6e20 6d61 6c77 6172 652c 2075  ed in malware, u
-00001640: 7375 616c 6c79 2072 6566 6c65 6374 6564  sually reflected
-00001650: 2069 6e20 6265 6163 6f6e 7320 616e 6420   in beacons and 
-00001660: 6f66 7465 6e20 7265 6c61 7465 6420 746f  often related to
-00001670: 2074 6172 6765 7420 6f72 2074 696d 6520   target or time 
-00001680: 6f66 2061 7474 6163 6b22 2c20 0d0a 2020  of attack", ..  
-00001690: 2020 2020 2020 2265 7861 6d70 6c65 7322        "examples"
-000016a0: 3a20 5b0d 0a20 2020 2020 2020 2020 2020  : [..           
-000016b0: 2022 7461 7267 6574 3422 2c20 0d0a 2020   "target4", ..  
-000016c0: 2020 2020 2020 2020 2020 2232 3031 3431            "20141
-000016d0: 3222 0d0a 2020 2020 2020 2020 5d2c 200d  2"..        ], .
-000016e0: 0a20 2020 2020 2020 2022 7479 7065 223a  .        "type":
-000016f0: 2022 6c69 7374 6f66 7374 7269 6e67 7322   "listofstrings"
-00001700: 0d0a 2020 2020 7d2c 200d 0a20 2020 2022  ..    }, ..    "
-00001710: 6d75 7465 7822 3a20 7b0d 0a20 2020 2020  mutex": {..     
-00001720: 2020 2022 6465 7363 7269 7074 696f 6e22     "description"
-00001730: 3a20 226d 7574 6578 206e 616d 6520 7573  : "mutex name us
-00001740: 6564 2074 6f20 7072 6576 656e 7420 6d75  ed to prevent mu
-00001750: 6c74 6970 6c65 2065 7865 6375 7469 6f6e  ltiple execution
-00001760: 7320 6f66 206d 616c 7761 7265 222c 200d  s of malware", .
-00001770: 0a20 2020 2020 2020 2022 6578 616d 706c  .        "exampl
-00001780: 6573 223a 205b 0d0a 2020 2020 2020 2020  es": [..        
-00001790: 2020 2020 2269 7468 696e 6b69 6d61 6c6f      "ithinkimalo
-000017a0: 6e65 6e6f 7722 2c20 0d0a 2020 2020 2020  nenow", ..      
-000017b0: 2020 2020 2020 2230 3033 3661 3831 3137        "0036a8117
-000017c0: 6166 6122 0d0a 2020 2020 2020 2020 5d2c  afa"..        ],
-000017d0: 200d 0a20 2020 2020 2020 2022 7479 7065   ..        "type
-000017e0: 223a 2022 6c69 7374 6f66 7374 7269 6e67  ": "listofstring
-000017f0: 7322 0d0a 2020 2020 7d2c 200d 0a20 2020  s"..    }, ..   
-00001800: 2022 6f74 6865 7222 3a20 7b0d 0a20 2020   "other": {..   
-00001810: 2020 2020 2022 6465 7363 7269 7074 696f       "descriptio
-00001820: 6e22 3a20 2241 6c6c 2069 7465 6d73 206f  n": "All items o
-00001830: 7468 6572 2074 6861 6e20 7468 6520 7374  ther than the st
-00001840: 616e 6461 7264 2066 6965 6c64 7320 6465  andard fields de
-00001850: 636c 6172 6564 2069 6e20 7468 6973 206c  clared in this l
-00001860: 6973 742e 2049 7465 6d73 206d 6179 2062  ist. Items may b
-00001870: 6520 6475 706c 6963 6174 6564 2068 6572  e duplicated her
-00001880: 6520 746f 2070 726f 7669 6465 206d 616c  e to provide mal
-00001890: 7761 7265 2073 7065 6369 6669 6320 636f  ware specific co
-000018a0: 6e74 6578 742e 222c 200d 0a20 2020 2020  ntext.", ..     
-000018b0: 2020 2022 6578 616d 706c 6573 223a 205b     "examples": [
-000018c0: 0d0a 2020 2020 2020 2020 2020 2020 7b0d  ..            {.
-000018d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000018e0: 2022 4163 7469 7661 7465 204b 6579 6c6f   "Activate Keylo
-000018f0: 6767 6572 223a 2022 5452 5545 220d 0a20  gger": "TRUE".. 
-00001900: 2020 2020 2020 2020 2020 207d 2c20 0d0a             }, ..
-00001910: 2020 2020 2020 2020 2020 2020 7b0d 0a20              {.. 
-00001920: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00001930: 436f 6e66 6967 2058 4f52 206b 6579 223a  Config XOR key":
-00001940: 2022 3839 220d 0a20 2020 2020 2020 2020   "89"..         
-00001950: 2020 207d 0d0a 2020 2020 2020 2020 5d2c     }..        ],
-00001960: 200d 0a20 2020 2020 2020 2022 7479 7065   ..        "type
-00001970: 223a 2022 6469 6374 6f66 7374 7269 6e67  ": "dictofstring
-00001980: 7322 0d0a 2020 2020 7d2c 200d 0a20 2020  s"..    }, ..   
-00001990: 2022 6f75 7470 7574 6669 6c65 223a 207b   "outputfile": {
-000019a0: 0d0a 2020 2020 2020 2020 2264 6573 6372  ..        "descr
-000019b0: 6970 7469 6f6e 223a 2022 7265 6c65 7661  iption": "releva
-000019c0: 6e74 206f 7220 7265 6c61 7465 6420 6669  nt or related fi
-000019d0: 6c65 2063 7265 6174 6564 2064 7572 696e  le created durin
-000019e0: 6720 7061 7273 696e 6720 6f66 206d 616c  g parsing of mal
-000019f0: 7761 7265 2e20 5475 706c 6520 6f66 2066  ware. Tuple of f
-00001a00: 696c 656e 616d 652c 2064 6573 6372 6970  ilename, descrip
-00001a10: 7469 6f6e 2c20 616e 6420 6d64 352e 222c  tion, and md5.",
-00001a20: 200d 0a20 2020 2020 2020 2022 6578 616d   ..        "exam
-00001a30: 706c 6573 223a 205b 0d0a 2020 2020 2020  ples": [..      
-00001a40: 2020 2020 2020 5b0d 0a20 2020 2020 2020        [..       
-00001a50: 2020 2020 2020 2020 2022 636f 6e66 6967           "config
-00001a60: 2e78 6d6c 222c 200d 0a20 2020 2020 2020  .xml", ..       
-00001a70: 2020 2020 2020 2020 2022 6578 7472 6163           "extrac
-00001a80: 7465 6420 6261 636b 646f 6f72 2046 6f6f  ted backdoor Foo
-00001a90: 2063 6f6e 6669 6720 6669 6c65 222c 0d0a   config file",..
-00001aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001ab0: 2231 3233 3435 3637 3839 3031 3233 3435  "123456789012345
-00001ac0: 3637 3839 3031 3233 3435 3637 3839 3031  6789012345678901
-00001ad0: 3222 0d0a 2020 2020 2020 2020 2020 2020  2"..            
-00001ae0: 5d2c 200d 0a20 2020 2020 2020 2020 2020  ], ..           
-00001af0: 205b 0d0a 2020 2020 2020 2020 2020 2020   [..            
-00001b00: 2020 2020 2263 6c69 656e 742e 6372 7422      "client.crt"
-00001b10: 2c20 0d0a 2020 2020 2020 2020 2020 2020  , ..            
-00001b20: 2020 2020 2263 6572 7469 6669 6361 7465      "certificate
-00001b30: 2066 6f72 2042 6172 5261 7420 544c 5320   for BarRat TLS 
-00001b40: 636c 6965 6e74 2061 7574 6865 6e74 6963  client authentic
-00001b50: 6174 696f 6e22 2c0d 0a20 2020 2020 2020  ation",..       
-00001b60: 2020 2020 2020 2020 2022 3039 3837 3635           "098765
-00001b70: 3433 3231 3039 3837 3635 3433 3231 3039  4321098765432109
-00001b80: 3837 3635 3433 3231 3039 220d 0a20 2020  8765432109"..   
-00001b90: 2020 2020 2020 2020 205d 0d0a 2020 2020           ]..    
-00001ba0: 2020 2020 5d2c 200d 0a20 2020 2020 2020      ], ..       
-00001bb0: 2022 7479 7065 223a 2022 6c69 7374 6f66   "type": "listof
-00001bc0: 7374 7269 6e67 7475 706c 6573 220d 0a20  stringtuples".. 
-00001bd0: 2020 207d 2c20 0d0a 2020 2020 2270 6173     }, ..    "pas
-00001be0: 7377 6f72 6422 3a20 7b0d 0a20 2020 2020  sword": {..     
-00001bf0: 2020 2022 6465 7363 7269 7074 696f 6e22     "description"
-00001c00: 3a20 2270 6173 7377 6f72 6420 7573 6564  : "password used
-00001c10: 2062 7920 6d61 6c77 6172 6522 2c20 0d0a   by malware", ..
-00001c20: 2020 2020 2020 2020 2265 7861 6d70 6c65          "example
-00001c30: 7322 3a20 5b0d 0a20 2020 2020 2020 2020  s": [..         
-00001c40: 2020 2022 4265 6e73 6f6e 222c 200d 0a20     "Benson", .. 
-00001c50: 2020 2020 2020 2020 2020 2022 3132 3334             "1234
-00001c60: 3536 220d 0a20 2020 2020 2020 205d 2c20  56"..        ], 
-00001c70: 0d0a 2020 2020 2020 2020 2274 7970 6522  ..        "type"
-00001c80: 3a20 226c 6973 746f 6673 7472 696e 6773  : "listofstrings
-00001c90: 220d 0a20 2020 207d 2c0d 0a20 2020 2022  "..    },..    "
-00001ca0: 7069 7065 223a 207b 0d0a 2020 2020 2020  pipe": {..      
-00001cb0: 2020 2264 6573 6372 6970 7469 6f6e 223a    "description":
-00001cc0: 2022 4e61 6d65 642c 206f 6e65 2d77 6179   "Named, one-way
-00001cd0: 206f 7220 6475 706c 6578 2070 6970 6520   or duplex pipe 
-00001ce0: 666f 7220 636f 6d6d 756e 6963 6174 696f  for communicatio
-00001cf0: 6e20 6265 7477 6565 6e20 7468 6520 7069  n between the pi
-00001d00: 7065 2073 6572 7665 7220 616e 6420 6f6e  pe server and on
-00001d10: 6520 6f72 206d 6f72 6520 7069 7065 2063  e or more pipe c
-00001d20: 6c69 656e 7473 222c 0d0a 2020 2020 2020  lients",..      
-00001d30: 2020 2265 7861 6d70 6c65 7322 3a20 5b0d    "examples": [.
-00001d40: 0a20 2020 2020 2020 2020 2020 2022 5c5c  .            "\\
-00001d50: 2e5c 5c70 6970 655c 5c6e 616d 6564 7069  .\\pipe\\namedpi
-00001d60: 7065 220d 0a20 2020 2020 2020 205d 2c0d  pe"..        ],.
-00001d70: 0a20 2020 2020 2020 2022 7479 7065 223a  .        "type":
-00001d80: 2022 6c69 7374 6f66 7374 7269 6e67 7322   "listofstrings"
-00001d90: 0d0a 2020 2020 7d2c 0d0a 2020 2020 2270  ..    },..    "p
-00001da0: 6f72 7422 3a20 7b0d 0a20 2020 2020 2020  ort": {..       
-00001db0: 2022 6465 7363 7269 7074 696f 6e22 3a20   "description": 
-00001dc0: 2254 4350 206f 7220 5544 5020 706f 7274  "TCP or UDP port
-00001dd0: 2e20 4120 7475 706c 6520 6f66 2061 2070  . A tuple of a p
-00001de0: 6f72 7420 6e75 6d62 6572 2061 6e64 2070  ort number and p
-00001df0: 726f 746f 636f 6c2e 2054 6869 7320 6765  rotocol. This ge
-00001e00: 6e65 7261 6c6c 7920 7265 6665 7273 2074  nerally refers t
-00001e10: 6f20 6f75 7462 6f75 6e64 2063 6f6e 6e65  o outbound conne
-00001e20: 6374 696f 6e73 2077 6865 7265 2074 6865  ctions where the
-00001e30: 206d 616c 7761 7265 2069 7320 7468 6520   malware is the 
-00001e40: 636c 6965 6e74 2e20 4f74 6865 7220 6e65  client. Other ne
-00001e50: 7477 6f72 6b20 6c61 7965 7220 7072 6f74  twork layer prot
-00001e60: 6f63 6f6c 732c 2073 7563 6820 6173 2049  ocols, such as I
-00001e70: 434d 5020 6361 6e20 6265 2072 6570 7265  CMP can be repre
-00001e80: 7365 6e74 6564 2068 6572 652e 2041 7070  sented here. App
-00001e90: 6c69 6361 7469 6f6e 206c 6179 6572 2070  lication layer p
-00001ea0: 726f 746f 636f 6c73 2c20 7375 6368 2061  rotocols, such a
-00001eb0: 7320 4854 5450 2c20 7368 6f75 6c64 2062  s HTTP, should b
-00001ec0: 6520 696e 6469 6361 7465 6420 696e 2061  e indicated in a
-00001ed0: 2055 524c 2e22 2c20 0d0a 2020 2020 2020   URL.", ..      
-00001ee0: 2020 2265 7861 6d70 6c65 7322 3a20 5b0d    "examples": [.
-00001ef0: 0a20 2020 2020 2020 2020 2020 205b 0d0a  .            [..
-00001f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001f10: 2232 3122 2c20 0d0a 2020 2020 2020 2020  "21", ..        
-00001f20: 2020 2020 2020 2020 2274 6370 220d 0a20          "tcp".. 
-00001f30: 2020 2020 2020 2020 2020 205d 2c20 0d0a             ], ..
-00001f40: 2020 2020 2020 2020 2020 2020 5b0d 0a20              [.. 
-00001f50: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00001f60: 3434 3322 2c20 0d0a 2020 2020 2020 2020  443", ..        
-00001f70: 2020 2020 2020 2020 2274 6370 220d 0a20          "tcp".. 
-00001f80: 2020 2020 2020 2020 2020 205d 0d0a 2020             ]..  
-00001f90: 2020 2020 2020 5d2c 200d 0a20 2020 2020        ], ..     
-00001fa0: 2020 2022 7479 7065 223a 2022 6c69 7374     "type": "list
-00001fb0: 6f66 7374 7269 6e67 7475 706c 6573 220d  ofstringtuples".
-00001fc0: 0a20 2020 207d 2c0d 0a20 2020 2022 7072  .    },..    "pr
-00001fd0: 6f78 7922 3a20 7b0d 0a20 2020 2020 2020  oxy": {..       
-00001fe0: 2022 6465 7363 7269 7074 696f 6e22 3a20   "description": 
-00001ff0: 2250 726f 7879 2063 7265 6465 6e74 6961  "Proxy credentia
-00002000: 6c73 2028 7573 6572 6e61 6d65 2061 6e64  ls (username and
-00002010: 2070 6173 7377 6f72 6429 2c20 6164 6472   password), addr
-00002020: 6573 732c 2070 6f72 742c 2061 6e64 2070  ess, port, and p
-00002030: 726f 746f 636f 6c20 636f 6d62 696e 6174  rotocol combinat
-00002040: 696f 6e20 7573 6564 2074 6f67 6574 6865  ion used togethe
-00002050: 7222 2c0d 0a20 2020 2020 2020 2022 6578  r",..        "ex
-00002060: 616d 706c 6573 223a 205b 0d0a 2020 2020  amples": [..    
-00002070: 2020 2020 2020 2020 5b0d 0a20 2020 2020          [..     
-00002080: 2020 2020 2020 2020 2020 2022 6164 6d69             "admi
-00002090: 6e22 2c0d 0a20 2020 2020 2020 2020 2020  n",..           
-000020a0: 2020 2020 2022 7061 7373 222c 0d0a 2020       "pass",..  
-000020b0: 2020 2020 2020 2020 2020 2020 2020 2231                "1
-000020c0: 3932 2e31 3638 2e31 2e31 222c 0d0a 2020  92.168.1.1",..  
-000020d0: 2020 2020 2020 2020 2020 2020 2020 2238                "8
-000020e0: 3022 2c0d 0a20 2020 2020 2020 2020 2020  0",..           
-000020f0: 2020 2020 2022 7463 7022 0d0a 2020 2020       "tcp"..    
-00002100: 2020 2020 2020 2020 5d0d 0a20 2020 2020          ]..     
-00002110: 2020 205d 2c0d 0a20 2020 2020 2020 2022     ],..        "
-00002120: 7479 7065 223a 2022 6c69 7374 6f66 7374  type": "listofst
-00002130: 7269 6e67 7475 706c 6573 220d 0a20 2020  ringtuples"..   
-00002140: 207d 2c0d 0a20 2020 2022 7072 6f78 795f   },..    "proxy_
-00002150: 736f 636b 6574 6164 6472 6573 7322 3a20  socketaddress": 
-00002160: 7b0d 0a20 2020 2020 2020 2022 6465 7363  {..        "desc
-00002170: 7269 7074 696f 6e22 3a20 2250 726f 7879  ription": "Proxy
-00002180: 2061 6464 7265 7373 2c20 706f 7274 2c20   address, port, 
-00002190: 616e 6420 7072 6f74 6f20 636f 6d62 696e  and proto combin
-000021a0: 6174 696f 6e20 7573 6564 2074 6f67 6574  ation used toget
-000021b0: 6865 7222 2c0d 0a20 2020 2020 2020 2022  her",..        "
-000021c0: 6578 616d 706c 6573 223a 205b 0d0a 2020  examples": [..  
-000021d0: 2020 2020 2020 2020 2020 5b0d 0a20 2020            [..   
-000021e0: 2020 2020 2020 2020 2020 2020 2022 3139               "19
-000021f0: 322e 3136 382e 312e 3122 2c0d 0a20 2020  2.168.1.1",..   
-00002200: 2020 2020 2020 2020 2020 2020 2022 3830               "80
-00002210: 222c 0d0a 2020 2020 2020 2020 2020 2020  ",..            
-00002220: 2020 2020 2274 6370 220d 0a20 2020 2020      "tcp"..     
-00002230: 2020 2020 2020 205d 0d0a 2020 2020 2020         ]..      
-00002240: 2020 5d2c 0d0a 2020 2020 2020 2020 2274    ],..        "t
-00002250: 7970 6522 3a20 226c 6973 746f 6673 7472  ype": "listofstr
-00002260: 696e 6774 7570 6c65 7322 0d0a 2020 2020  ingtuples"..    
-00002270: 7d2c 0d0a 2020 2020 2270 726f 7879 5f61  },..    "proxy_a
-00002280: 6464 7265 7373 223a 207b 0d0a 2020 2020  ddress": {..    
-00002290: 2020 2020 2264 6573 6372 6970 7469 6f6e      "description
-000022a0: 223a 2022 5072 6f78 7920 4950 2061 6464  ": "Proxy IP add
-000022b0: 7265 7373 206f 7220 646f 6d61 696e 206e  ress or domain n
-000022c0: 616d 6522 2c0d 0a20 2020 2020 2020 2022  ame",..        "
-000022d0: 6578 616d 706c 6573 223a 205b 0d0a 2020  examples": [..  
-000022e0: 2020 2020 2020 2020 2020 2262 6164 2e63            "bad.c
-000022f0: 6f6d 222c 0d0a 2020 2020 2020 2020 2020  om",..          
-00002300: 2020 2231 302e 3131 2e31 302e 3133 220d    "10.11.10.13".
-00002310: 0a20 2020 2020 2020 205d 2c0d 0a20 2020  .        ],..   
-00002320: 2020 2020 2022 7479 7065 223a 2022 6c69       "type": "li
-00002330: 7374 6f66 7374 7269 6e67 7322 0d0a 2020  stofstrings"..  
-00002340: 2020 7d2c 0d0a 2020 2020 2272 6567 6973    },..    "regis
-00002350: 7472 7964 6174 6122 3a20 7b0d 0a20 2020  trydata": {..   
-00002360: 2020 2020 2022 6465 7363 7269 7074 696f       "descriptio
-00002370: 6e22 3a20 2272 6567 6973 7472 7920 7661  n": "registry va
-00002380: 6c75 6520 6461 7461 2069 7465 6d22 2c20  lue data item", 
-00002390: 0d0a 2020 2020 2020 2020 2265 7861 6d70  ..        "examp
-000023a0: 6c65 7322 3a20 5b0d 0a20 2020 2020 2020  les": [..       
-000023b0: 2020 2020 2022 633a 5c5c 7570 6461 7465       "c:\\update
-000023c0: 2e65 7865 222c 200d 0a20 2020 2020 2020  .exe", ..       
-000023d0: 2020 2020 2022 3322 0d0a 2020 2020 2020       "3"..      
-000023e0: 2020 5d2c 200d 0a20 2020 2020 2020 2022    ], ..        "
-000023f0: 7479 7065 223a 2022 6c69 7374 6f66 7374  type": "listofst
-00002400: 7269 6e67 7322 0d0a 2020 2020 7d2c 0d0a  rings"..    },..
-00002410: 2020 2020 2272 6567 6973 7472 7970 6174      "registrypat
-00002420: 6822 3a20 7b0d 0a20 2020 2020 2020 2022  h": {..        "
-00002430: 6465 7363 7269 7074 696f 6e22 3a20 2261  description": "a
-00002440: 2072 6567 6973 7472 7920 6b65 792c 2076   registry key, v
-00002450: 616c 7565 206e 616d 652c 2063 6f6d 6269  alue name, combi
-00002460: 6e61 7469 6f6e 206f 6620 7468 6520 7477  nation of the tw
-00002470: 6f22 2c20 0d0a 2020 2020 2020 2020 2265  o", ..        "e
-00002480: 7861 6d70 6c65 7322 3a20 5b0d 0a20 2020  xamples": [..   
-00002490: 2020 2020 2020 2020 2022 484b 4c4d 5c5c           "HKLM\\
-000024a0: 536f 6674 7761 7265 5c5c 4d69 6372 6f73  Software\\Micros
-000024b0: 6f66 745c 5c57 696e 646f 7773 5c5c 4375  oft\\Windows\\Cu
-000024c0: 7272 656e 7456 6572 7369 6f6e 5c5c 5275  rrentVersion\\Ru
-000024d0: 6e5c 5c55 7064 6174 6572 222c 200d 0a20  n\\Updater", .. 
-000024e0: 2020 2020 2020 2020 2020 2022 484b 4c4d             "HKLM
-000024f0: 5c5c 5379 7374 656d 5c5c 4375 7272 656e  \\System\\Curren
-00002500: 7443 6f6e 7472 6f6c 5365 745c 5c53 6572  tControlSet\\Ser
-00002510: 7669 6365 735c 5c70 6e70 7376 635c 5c73  vices\\pnpsvc\\s
-00002520: 7461 7274 220d 0a20 2020 2020 2020 205d  tart"..        ]
-00002530: 2c20 0d0a 2020 2020 2020 2020 2274 7970  , ..        "typ
-00002540: 6522 3a20 226c 6973 746f 6673 7472 696e  e": "listofstrin
-00002550: 6773 220d 0a20 2020 207d 2c0d 0a20 2020  gs"..    },..   
-00002560: 2022 7265 6769 7374 7279 7061 7468 6461   "registrypathda
-00002570: 7461 223a 207b 0d0a 2020 2020 2020 2020  ta": {..        
-00002580: 2264 6573 6372 6970 7469 6f6e 223a 2022  "description": "
-00002590: 6120 7475 706c 6520 6f66 2072 6567 6973  a tuple of regis
-000025a0: 7472 7970 6174 6820 616e 6420 7265 6769  trypath and regi
-000025b0: 7374 7279 6461 7461 222c 0d0a 2020 2020  strydata",..    
-000025c0: 2020 2020 2265 7861 6d70 6c65 7322 3a20      "examples": 
-000025d0: 5b0d 0a20 2020 2020 2020 2020 2020 205b  [..            [
-000025e0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000025f0: 2020 2248 4b4c 4d5c 5c53 6f66 7477 6172    "HKLM\\Softwar
-00002600: 655c 5c4d 6963 726f 736f 6674 5c5c 5769  e\\Microsoft\\Wi
-00002610: 6e64 6f77 735c 5c43 7572 7265 6e74 5665  ndows\\CurrentVe
-00002620: 7273 696f 6e5c 5c52 756e 5c5c 5570 6461  rsion\\Run\\Upda
-00002630: 7465 7222 2c20 0d0a 2020 2020 2020 2020  ter", ..        
-00002640: 2020 2020 2020 2020 2263 3a5c 5c75 7064          "c:\\upd
-00002650: 6174 652e 6578 6522 0d0a 2020 2020 2020  ate.exe"..      
-00002660: 2020 2020 2020 5d2c 200d 0a20 2020 2020        ], ..     
-00002670: 2020 2020 2020 205b 0d0a 2020 2020 2020         [..      
-00002680: 2020 2020 2020 2020 2020 2248 4b4c 4d5c            "HKLM\
-00002690: 5c53 7973 7465 6d5c 5c43 7572 7265 6e74  \System\\Current
-000026a0: 436f 6e74 726f 6c53 6574 5c5c 5365 7276  ControlSet\\Serv
-000026b0: 6963 6573 5c5c 706e 7073 7663 5c5c 7374  ices\\pnpsvc\\st
-000026c0: 6172 7422 2c20 0d0a 2020 2020 2020 2020  art", ..        
-000026d0: 2020 2020 2020 2020 2233 220d 0a20 2020          "3"..   
-000026e0: 2020 2020 2020 2020 205d 0d0a 2020 2020           ]..    
-000026f0: 2020 2020 5d2c 200d 0a20 2020 2020 2020      ], ..       
-00002700: 2022 7479 7065 223a 2022 6c69 7374 6f66   "type": "listof
-00002710: 7374 7269 6e67 7475 706c 6573 220d 0a20  stringtuples".. 
-00002720: 2020 207d 2c0d 0a20 2020 2022 7273 615f     },..    "rsa_
-00002730: 7072 6976 6174 655f 6b65 7922 3a20 7b0d  private_key": {.
-00002740: 0a20 2020 2020 2020 2022 6465 7363 7269  .        "descri
-00002750: 7074 696f 6e22 3a20 2252 5341 2070 7269  ption": "RSA pri
-00002760: 7661 7465 206b 6579 2074 7570 6c65 2063  vate key tuple c
-00002770: 6f6e 7461 696e 696e 673a 2070 7562 6c69  ontaining: publi
-00002780: 635f 6578 706f 6e65 6e74 2c20 6d6f 6475  c_exponent, modu
-00002790: 6c75 732c 2070 7269 7661 7465 5f65 7870  lus, private_exp
-000027a0: 6f6e 656e 7420 2864 292c 2070 2c20 712c  onent (d), p, q,
-000027b0: 2064 206d 6f64 2028 702d 3129 2c20 6420   d mod (p-1), d 
-000027c0: 6d6f 6420 2871 2d31 292c 2071 2069 6e76  mod (q-1), q inv
-000027d0: 206d 6f64 2070 222c 0d0a 2020 2020 2020   mod p",..      
-000027e0: 2020 2265 7861 6d70 6c65 7322 3a20 5b0d    "examples": [.
-000027f0: 0a20 2020 2020 2020 2020 2020 205b 0d0a  .            [..
-00002800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002810: 2230 7830 3722 2c0d 0a20 2020 2020 2020  "0x07",..       
-00002820: 2020 2020 2020 2020 2022 3078 6262 222c           "0xbb",
-00002830: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00002840: 2020 2230 7831 3722 2c0d 0a20 2020 2020    "0x17",..     
-00002850: 2020 2020 2020 2020 2020 2022 3078 3131             "0x11
-00002860: 222c 0d0a 2020 2020 2020 2020 2020 2020  ",..            
-00002870: 2020 2020 2230 7830 6222 2c0d 0a20 2020      "0x0b",..   
-00002880: 2020 2020 2020 2020 2020 2020 2022 3078               "0x
-00002890: 3037 222c 0d0a 2020 2020 2020 2020 2020  07",..          
-000028a0: 2020 2020 2020 2230 7830 3322 2c0d 0a20        "0x03",.. 
-000028b0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-000028c0: 3078 3065 220d 0a20 2020 2020 2020 2020  0x0e"..         
-000028d0: 2020 205d 0d0a 2020 2020 2020 2020 5d2c     ]..        ],
-000028e0: 0d0a 2020 2020 2020 2020 2274 7970 6522  ..        "type"
-000028f0: 3a20 226c 6973 746f 6673 7472 696e 6774  : "listofstringt
-00002900: 7570 6c65 7322 0d0a 2020 2020 7d2c 0d0a  uples"..    },..
-00002910: 2020 2020 2272 7361 5f70 7562 6c69 635f      "rsa_public_
-00002920: 6b65 7922 3a20 7b0d 0a20 2020 2020 2020  key": {..       
-00002930: 2022 6465 7363 7269 7074 696f 6e22 3a20   "description": 
-00002940: 2252 5341 2070 7562 6c69 6320 6b65 7920  "RSA public key 
-00002950: 7475 706c 6520 636f 6e74 6169 6e69 6e67  tuple containing
-00002960: 3a20 7075 626c 6963 5f65 7870 6f6e 656e  : public_exponen
-00002970: 742c 206d 6f64 756c 7573 222c 0d0a 2020  t, modulus",..  
-00002980: 2020 2020 2020 2265 7861 6d70 6c65 7322        "examples"
-00002990: 3a20 5b0d 0a20 2020 2020 2020 2020 2020  : [..           
-000029a0: 205b 0d0a 2020 2020 2020 2020 2020 2020   [..            
-000029b0: 2020 2020 2230 7830 3722 2c0d 0a20 2020      "0x07",..   
-000029c0: 2020 2020 2020 2020 2020 2020 2022 3078               "0x
-000029d0: 6262 220d 0a20 2020 2020 2020 2020 2020  bb"..           
-000029e0: 205d 0d0a 2020 2020 2020 2020 5d2c 0d0a   ]..        ],..
-000029f0: 2020 2020 2020 2020 2274 7970 6522 3a20          "type": 
-00002a00: 226c 6973 746f 6673 7472 696e 6774 7570  "listofstringtup
-00002a10: 6c65 7322 0d0a 2020 2020 7d2c 0d0a 2020  les"..    },..  
-00002a20: 2020 2273 6572 7669 6365 223a 207b 0d0a    "service": {..
-00002a30: 2020 2020 2020 2020 2264 6573 6372 6970          "descrip
-00002a40: 7469 6f6e 223a 2022 4120 7475 706c 6520  tion": "A tuple 
-00002a50: 6f66 2073 6572 7669 6365 6e61 6d65 2c20  of servicename, 
-00002a60: 7365 7276 6963 6564 6973 706c 6179 6e61  servicedisplayna
-00002a70: 6d65 2c20 7365 7276 6963 6564 6573 6372  me, servicedescr
-00002a80: 6970 7469 6f6e 2c20 7365 7276 6963 6569  iption, servicei
-00002a90: 6d61 6765 2061 6e64 2073 6572 7669 6365  mage and service
-00002aa0: 646c 6c22 2c20 0d0a 2020 2020 2020 2020  dll", ..        
-00002ab0: 2265 7861 6d70 6c65 7322 3a20 5b0d 0a20  "examples": [.. 
-00002ac0: 2020 2020 2020 2020 2020 205b 0d0a 2020             [..  
-00002ad0: 2020 2020 2020 2020 2020 2020 2020 2257                "W
-00002ae0: 696e 646f 7773 5573 6572 4d61 6e61 6765  indowsUserManage
-00002af0: 6d65 6e74 222c 200d 0a20 2020 2020 2020  ment", ..       
-00002b00: 2020 2020 2020 2020 2022 5769 6e64 6f77           "Window
-00002b10: 7320 5573 6572 204d 616e 6167 656d 656e  s User Managemen
-00002b20: 7422 2c20 0d0a 2020 2020 2020 2020 2020  t", ..          
-00002b30: 2020 2020 2020 2250 726f 7669 6465 7320        "Provides 
-00002b40: 6120 636f 6d6d 6f6e 206d 616e 6167 656d  a common managem
-00002b50: 656e 7420 746f 2061 6363 6573 7320 696e  ent to access in
-00002b60: 666f 726d 6174 696f 6e20 6162 6f75 7420  formation about 
-00002b70: 7769 6e64 6f77 7320 7573 6572 2e22 2c20  windows user.", 
-00002b80: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00002b90: 2020 2225 5379 7374 656d 255c 5c73 766f    "%System%\\svo
-00002ba0: 686f 7374 2e65 7865 222c 200d 0a20 2020  host.exe", ..   
-00002bb0: 2020 2020 2020 2020 2020 2020 2022 220d               "".
-00002bc0: 0a20 2020 2020 2020 2020 2020 205d 2c20  .            ], 
-00002bd0: 0d0a 2020 2020 2020 2020 2020 2020 5b0d  ..            [.
-00002be0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00002bf0: 2022 706e 7073 7663 222c 200d 0a20 2020   "pnpsvc", ..   
-00002c00: 2020 2020 2020 2020 2020 2020 2022 506c               "Pl
-00002c10: 7567 2061 6e64 2050 6c61 7920 7376 6320  ug and Play svc 
-00002c20: 7365 7276 6963 6522 2c20 0d0a 2020 2020  service", ..    
-00002c30: 2020 2020 2020 2020 2020 2020 2250 726f              "Pro
-00002c40: 7669 6465 7320 706c 7567 2061 6e64 2070  vides plug and p
-00002c50: 6c61 7920 7376 6320 6465 7669 6365 7320  lay svc devices 
-00002c60: 7375 7070 6f72 7422 2c20 0d0a 2020 2020  support", ..    
-00002c70: 2020 2020 2020 2020 2020 2020 2243 3a5c              "C:\
-00002c80: 5c57 696e 646f 7773 5c5c 5379 7374 656d  \Windows\\System
-00002c90: 3332 5c5c 7275 6e64 6c6c 3332 2e65 7865  32\\rundll32.exe
-00002ca0: 2043 3a5c 5c57 696e 646f 7773 5c5c 5465   C:\\Windows\\Te
-00002cb0: 6d70 5c5c 312e 746d 7022 2c20 0d0a 2020  mp\\1.tmp", ..  
-00002cc0: 2020 2020 2020 2020 2020 2020 2020 2243                "C
-00002cd0: 3a5c 5c57 696e 646f 7773 5c5c 5465 6d70  :\\Windows\\Temp
-00002ce0: 5c5c 312e 746d 7022 0d0a 2020 2020 2020  \\1.tmp"..      
-00002cf0: 2020 2020 2020 5d0d 0a20 2020 2020 2020        ]..       
-00002d00: 205d 2c20 0d0a 2020 2020 2020 2020 2274   ], ..        "t
-00002d10: 7970 6522 3a20 226c 6973 746f 6673 7472  ype": "listofstr
-00002d20: 696e 6774 7570 6c65 7322 0d0a 2020 2020  ingtuples"..    
-00002d30: 7d2c 200d 0a20 2020 2022 7365 7276 6963  }, ..    "servic
-00002d40: 6564 6573 6372 6970 7469 6f6e 223a 207b  edescription": {
-00002d50: 0d0a 2020 2020 2020 2020 2264 6573 6372  ..        "descr
-00002d60: 6970 7469 6f6e 223a 2022 6465 7363 7269  iption": "descri
-00002d70: 7074 696f 6e20 666f 7220 6120 7365 7276  ption for a serv
-00002d80: 6963 6522 2c20 0d0a 2020 2020 2020 2020  ice", ..        
-00002d90: 2265 7861 6d70 6c65 7322 3a20 5b0d 0a20  "examples": [.. 
-00002da0: 2020 2020 2020 2020 2020 2022 5072 6f76             "Prov
-00002db0: 6964 6573 2061 2063 6f6d 6d6f 6e20 6d61  ides a common ma
-00002dc0: 6e61 6765 6d65 6e74 2074 6f20 6163 6365  nagement to acce
-00002dd0: 7373 2069 6e66 6f72 6d61 7469 6f6e 2061  ss information a
-00002de0: 626f 7574 2077 696e 646f 7773 2075 7365  bout windows use
-00002df0: 722e 222c 200d 0a20 2020 2020 2020 2020  r.", ..         
-00002e00: 2020 2022 5072 6f76 6964 6573 2070 6c75     "Provides plu
-00002e10: 6720 616e 6420 706c 6179 2073 7663 2064  g and play svc d
-00002e20: 6576 6963 6573 2073 7570 706f 7274 220d  evices support".
-00002e30: 0a20 2020 2020 2020 205d 2c20 0d0a 2020  .        ], ..  
-00002e40: 2020 2020 2020 2274 7970 6522 3a20 226c        "type": "l
-00002e50: 6973 746f 6673 7472 696e 6773 220d 0a20  istofstrings".. 
-00002e60: 2020 207d 2c20 0d0a 2020 2020 2273 6572     }, ..    "ser
-00002e70: 7669 6365 6469 7370 6c61 796e 616d 6522  vicedisplayname"
-00002e80: 3a20 7b0d 0a20 2020 2020 2020 2022 6465  : {..        "de
-00002e90: 7363 7269 7074 696f 6e22 3a20 2264 6973  scription": "dis
-00002ea0: 706c 6179 6e61 6d65 2066 6f72 2061 2073  playname for a s
-00002eb0: 6572 7669 6365 222c 200d 0a20 2020 2020  ervice", ..     
-00002ec0: 2020 2022 6578 616d 706c 6573 223a 205b     "examples": [
-00002ed0: 0d0a 2020 2020 2020 2020 2020 2020 2257  ..            "W
-00002ee0: 696e 646f 7773 2055 7365 7220 4d61 6e61  indows User Mana
-00002ef0: 6765 6d65 6e74 222c 200d 0a20 2020 2020  gement", ..     
-00002f00: 2020 2020 2020 2022 506c 7567 2061 6e64         "Plug and
-00002f10: 2050 6c61 7920 7376 6320 7365 7276 6963   Play svc servic
-00002f20: 6522 0d0a 2020 2020 2020 2020 5d2c 200d  e"..        ], .
-00002f30: 0a20 2020 2020 2020 2022 7479 7065 223a  .        "type":
-00002f40: 2022 6c69 7374 6f66 7374 7269 6e67 7322   "listofstrings"
-00002f50: 0d0a 2020 2020 7d2c 200d 0a20 2020 2022  ..    }, ..    "
-00002f60: 7365 7276 6963 6564 6c6c 223a 207b 0d0a  servicedll": {..
-00002f70: 2020 2020 2020 2020 2264 6573 6372 6970          "descrip
-00002f80: 7469 6f6e 223a 2022 2e64 6c6c 2075 7365  tion": ".dll use
-00002f90: 6420 6279 2073 6572 7669 6365 2c20 6966  d by service, if
-00002fa0: 2061 6e79 222c 200d 0a20 2020 2020 2020   any", ..       
-00002fb0: 2022 6578 616d 706c 6573 223a 205b 0d0a   "examples": [..
-00002fc0: 2020 2020 2020 2020 2020 2020 2222 2c20              "", 
-00002fd0: 0d0a 2020 2020 2020 2020 2020 2020 2243  ..            "C
-00002fe0: 3a5c 5c57 696e 646f 7773 5c5c 5465 6d70  :\\Windows\\Temp
-00002ff0: 5c5c 312e 746d 7022 0d0a 2020 2020 2020  \\1.tmp"..      
-00003000: 2020 5d2c 200d 0a20 2020 2020 2020 2022    ], ..        "
-00003010: 7479 7065 223a 2022 6c69 7374 6f66 7374  type": "listofst
-00003020: 7269 6e67 7322 0d0a 2020 2020 7d2c 200d  rings"..    }, .
-00003030: 0a20 2020 2022 7365 7276 6963 6569 6d61  .    "serviceima
-00003040: 6765 223a 207b 0d0a 2020 2020 2020 2020  ge": {..        
-00003050: 2264 6573 6372 6970 7469 6f6e 223a 2022  "description": "
-00003060: 696d 6167 6570 6174 6820 666f 7220 6120  imagepath for a 
-00003070: 7365 7276 6963 652e 2054 6869 7320 7479  service. This ty
-00003080: 7069 6361 6c6c 7920 696e 636c 7564 6573  pically includes
-00003090: 2074 6865 2070 6174 6820 746f 2074 6865   the path to the
-000030a0: 2065 7865 6375 7461 626c 6520 616e 6420   executable and 
-000030b0: 616e 7920 636f 6d6d 616e 6420 6c69 6e65  any command line
-000030c0: 206f 7074 696f 6e73 2e22 2c20 0d0a 2020   options.", ..  
-000030d0: 2020 2020 2020 2265 7861 6d70 6c65 7322        "examples"
-000030e0: 3a20 5b0d 0a20 2020 2020 2020 2020 2020  : [..           
-000030f0: 2022 2553 7973 7465 6d25 5c5c 7376 6f68   "%System%\\svoh
-00003100: 6f73 742e 6578 6522 2c20 0d0a 2020 2020  ost.exe", ..    
-00003110: 2020 2020 2020 2020 2243 3a5c 5c57 696e          "C:\\Win
-00003120: 646f 7773 5c5c 5379 7374 656d 3332 5c5c  dows\\System32\\
-00003130: 7275 6e64 6c6c 3332 2e65 7865 2043 3a5c  rundll32.exe C:\
-00003140: 5c57 696e 646f 7773 5c5c 5465 6d70 5c5c  \Windows\\Temp\\
-00003150: 312e 746d 7022 0d0a 2020 2020 2020 2020  1.tmp"..        
-00003160: 5d2c 200d 0a20 2020 2020 2020 2022 7479  ], ..        "ty
-00003170: 7065 223a 2022 6c69 7374 6f66 7374 7269  pe": "listofstri
-00003180: 6e67 7322 0d0a 2020 2020 7d2c 200d 0a20  ngs"..    }, .. 
-00003190: 2020 2022 7365 7276 6963 656e 616d 6522     "servicename"
-000031a0: 3a20 7b0d 0a20 2020 2020 2020 2022 6465  : {..        "de
-000031b0: 7363 7269 7074 696f 6e22 3a20 226e 616d  scription": "nam
-000031c0: 6520 666f 7220 6120 7365 7276 6963 6522  e for a service"
-000031d0: 2c20 0d0a 2020 2020 2020 2020 2265 7861  , ..        "exa
-000031e0: 6d70 6c65 7322 3a20 5b0d 0a20 2020 2020  mples": [..     
-000031f0: 2020 2020 2020 2022 5769 6e64 6f77 7355         "WindowsU
-00003200: 7365 724d 616e 6167 656d 656e 7422 2c20  serManagement", 
-00003210: 0d0a 2020 2020 2020 2020 2020 2020 2270  ..            "p
-00003220: 6e70 7376 6322 0d0a 2020 2020 2020 2020  npsvc"..        
-00003230: 5d2c 200d 0a20 2020 2020 2020 2022 7479  ], ..        "ty
-00003240: 7065 223a 2022 6c69 7374 6f66 7374 7269  pe": "listofstri
-00003250: 6e67 7322 0d0a 2020 2020 7d2c 200d 0a20  ngs"..    }, .. 
-00003260: 2020 2022 736f 636b 6574 6164 6472 6573     "socketaddres
-00003270: 7322 3a20 7b0d 0a20 2020 2020 2020 2022  s": {..        "
-00003280: 6465 7363 7269 7074 696f 6e22 3a20 2241  description": "A
-00003290: 6e20 6164 6472 6573 732c 2070 6f72 742c  n address, port,
-000032a0: 2061 6e64 2070 726f 746f 2063 6f6d 6269   and proto combi
-000032b0: 6e61 7469 6f6e 2075 7365 6420 746f 6765  nation used toge
-000032c0: 7468 6572 222c 200d 0a20 2020 2020 2020  ther", ..       
-000032d0: 2022 6578 616d 706c 6573 223a 205b 0d0a   "examples": [..
-000032e0: 2020 2020 2020 2020 2020 2020 5b0d 0a20              [.. 
-000032f0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00003300: 6261 642e 636f 6d22 2c20 0d0a 2020 2020  bad.com", ..    
-00003310: 2020 2020 2020 2020 2020 2020 2232 3122              "21"
-00003320: 2c20 0d0a 2020 2020 2020 2020 2020 2020  , ..            
-00003330: 2020 2020 2274 6370 220d 0a20 2020 2020      "tcp"..     
-00003340: 2020 2020 2020 205d 2c20 0d0a 2020 2020         ], ..    
-00003350: 2020 2020 2020 2020 5b0d 0a20 2020 2020          [..     
-00003360: 2020 2020 2020 2020 2020 2022 3130 2e31             "10.1
-00003370: 312e 3130 2e31 3322 2c20 0d0a 2020 2020  1.10.13", ..    
-00003380: 2020 2020 2020 2020 2020 2020 2234 3433              "443
-00003390: 222c 200d 0a20 2020 2020 2020 2020 2020  ", ..           
-000033a0: 2020 2020 2022 7463 7022 0d0a 2020 2020       "tcp"..    
-000033b0: 2020 2020 2020 2020 5d0d 0a20 2020 2020          ]..     
-000033c0: 2020 205d 2c20 0d0a 2020 2020 2020 2020     ], ..        
-000033d0: 2274 7970 6522 3a20 226c 6973 746f 6673  "type": "listofs
-000033e0: 7472 696e 6774 7570 6c65 7322 0d0a 2020  tringtuples"..  
-000033f0: 2020 7d2c 0d0a 2020 2020 2273 736c 5f63    },..    "ssl_c
-00003400: 6572 745f 7368 6131 223a 207b 0d0a 2020  ert_sha1": {..  
-00003410: 2020 2020 2020 2264 6573 6372 6970 7469        "descripti
-00003420: 6f6e 223a 2022 5353 4c20 4365 7274 6966  on": "SSL Certif
-00003430: 6963 6174 6520 5348 412d 3120 4861 7368  icate SHA-1 Hash
-00003440: 222c 0d0a 2020 2020 2020 2020 2265 7861  ",..        "exa
-00003450: 6d70 6c65 7322 3a20 5b0d 0a20 2020 2020  mples": [..     
-00003460: 2020 2020 2020 2022 6332 3964 3739 6466         "c29d79df
-00003470: 3962 3534 3136 6664 3431 3663 3331 6535  9b5416fd416c31e5
-00003480: 3763 6435 3235 6466 6332 3361 3866 3636  7cd525dfc23a8f66
-00003490: 220d 0a20 2020 2020 2020 205d 2c0d 0a20  "..        ],.. 
-000034a0: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
-000034b0: 6c69 7374 6f66 7374 7269 6e67 7322 0d0a  listofstrings"..
-000034c0: 2020 2020 7d2c 0d0a 2020 2020 2275 726c      },..    "url
-000034d0: 223a 207b 0d0a 2020 2020 2020 2020 2264  ": {..        "d
-000034e0: 6573 6372 6970 7469 6f6e 223a 2022 6675  escription": "fu
-000034f0: 6c6c 2055 524c 2077 6974 6820 7363 6865  ll URL with sche
-00003500: 6d65 2c20 6164 6472 6573 732c 206f 7074  me, address, opt
-00003510: 696f 6e61 6c20 706f 7274 2c20 616e 6420  ional port, and 
-00003520: 6f70 7469 6f6e 616c 2070 6174 6822 2c20  optional path", 
-00003530: 0d0a 2020 2020 2020 2020 2265 7861 6d70  ..        "examp
-00003540: 6c65 7322 3a20 5b0d 0a20 2020 2020 2020  les": [..       
-00003550: 2020 2020 2022 6874 7470 3a2f 2f6d 616c       "http://mal
-00003560: 2e63 6f6d 2f76 6965 772e 6173 7022 2c20  .com/view.asp", 
-00003570: 0d0a 2020 2020 2020 2020 2020 2020 2268  ..            "h
-00003580: 7474 7073 3a2f 2f31 302e 3131 2e31 302e  ttps://10.11.10.
-00003590: 3133 3a34 3433 2f69 6d61 6765 732f 6261  13:443/images/ba
-000035a0: 6e65 722e 6a70 6722 0d0a 2020 2020 2020  ner.jpg"..      
-000035b0: 2020 5d2c 200d 0a20 2020 2020 2020 2022    ], ..        "
-000035c0: 7479 7065 223a 2022 6c69 7374 6f66 7374  type": "listofst
-000035d0: 7269 6e67 7322 0d0a 2020 2020 7d2c 200d  rings"..    }, .
-000035e0: 0a20 2020 2022 7572 6c70 6174 6822 3a20  .    "urlpath": 
-000035f0: 7b0d 0a20 2020 2020 2020 2022 6465 7363  {..        "desc
-00003600: 7269 7074 696f 6e22 3a20 2270 6174 6820  ription": "path 
-00003610: 706f 7274 696f 6e20 6f66 2055 524c 222c  portion of URL",
-00003620: 200d 0a20 2020 2020 2020 2022 6578 616d   ..        "exam
-00003630: 706c 6573 223a 205b 0d0a 2020 2020 2020  ples": [..      
-00003640: 2020 2020 2020 222f 7669 6577 2e61 7370        "/view.asp
-00003650: 222c 200d 0a20 2020 2020 2020 2020 2020  ", ..           
-00003660: 2022 2f69 6d61 6765 732f 6261 6e65 722e   "/images/baner.
-00003670: 6a70 6722 0d0a 2020 2020 2020 2020 5d2c  jpg"..        ],
-00003680: 200d 0a20 2020 2020 2020 2022 7479 7065   ..        "type
-00003690: 223a 2022 6c69 7374 6f66 7374 7269 6e67  ": "listofstring
-000036a0: 7322 0d0a 2020 2020 7d2c 200d 0a20 2020  s"..    }, ..   
-000036b0: 2022 7573 6572 6167 656e 7422 3a20 7b0d   "useragent": {.
-000036c0: 0a20 2020 2020 2020 2022 6465 7363 7269  .        "descri
-000036d0: 7074 696f 6e22 3a20 2273 6f66 7477 6172  ption": "softwar
-000036e0: 6520 6964 656e 7469 6669 6572 2075 7365  e identifier use
-000036f0: 6420 6279 206d 616c 7761 7265 222c 200d  d by malware", .
-00003700: 0a20 2020 2020 2020 2022 6578 616d 706c  .        "exampl
-00003710: 6573 223a 205b 0d0a 2020 2020 2020 2020  es": [..        
-00003720: 2020 2020 224d 6f7a 696c 6c61 2f34 2e30      "Mozilla/4.0
-00003730: 2028 636f 6d70 6174 6962 6c65 3b20 4d49   (compatible; MI
-00003740: 5345 2036 2e30 3b20 5769 6e64 6f77 7320  SE 6.0; Windows 
-00003750: 4e54 2035 2e32 2922 2c20 0d0a 2020 2020  NT 5.2)", ..    
-00003760: 2020 2020 2020 2020 2231 3333 3768 7474          "1337htt
-00003770: 7022 0d0a 2020 2020 2020 2020 5d2c 200d  p"..        ], .
-00003780: 0a20 2020 2020 2020 2022 7479 7065 223a  .        "type":
-00003790: 2022 6c69 7374 6f66 7374 7269 6e67 7322   "listofstrings"
-000037a0: 0d0a 2020 2020 7d2c 200d 0a20 2020 2022  ..    }, ..    "
-000037b0: 7573 6572 6e61 6d65 223a 207b 0d0a 2020  username": {..  
-000037c0: 2020 2020 2020 2264 6573 6372 6970 7469        "descripti
-000037d0: 6f6e 223a 2022 7573 6572 6e61 6d65 2075  on": "username u
-000037e0: 7365 6420 6279 206d 616c 7761 7265 222c  sed by malware",
-000037f0: 200d 0a20 2020 2020 2020 2022 6578 616d   ..        "exam
-00003800: 706c 6573 223a 205b 0d0a 2020 2020 2020  ples": [..      
-00003810: 2020 2020 2020 2248 756e 7465 7222 2c20        "Hunter", 
-00003820: 0d0a 2020 2020 2020 2020 2020 2020 2261  ..            "a
-00003830: 646d 696e 220d 0a20 2020 2020 2020 205d  dmin"..        ]
-00003840: 2c20 0d0a 2020 2020 2020 2020 2274 7970  , ..        "typ
-00003850: 6522 3a20 226c 6973 746f 6673 7472 696e  e": "listofstrin
-00003860: 6773 220d 0a20 2020 207d 2c20 0d0a 2020  gs"..    }, ..  
-00003870: 2020 2276 6572 7369 6f6e 223a 207b 0d0a    "version": {..
-00003880: 2020 2020 2020 2020 2264 6573 6372 6970          "descrip
-00003890: 7469 6f6e 223a 2022 7468 6520 7665 7273  tion": "the vers
-000038a0: 696f 6e20 6f66 2074 6865 206d 616c 7761  ion of the malwa
-000038b0: 7265 2e20 546f 2074 6865 2064 6567 7265  re. To the degre
-000038c0: 6520 706f 7373 6962 6c65 2074 6869 7320  e possible this 
-000038d0: 7368 6f75 6c64 2062 6520 6261 7365 6420  should be based 
-000038e0: 6469 7265 6374 6c79 206f 6e20 6172 7469  directly on arti
-000038f0: 6661 6374 7320 6672 6f6d 2074 6865 206d  facts from the m
-00003900: 616c 7761 7265 222c 200d 0a20 2020 2020  alware", ..     
-00003910: 2020 2022 6578 616d 706c 6573 223a 205b     "examples": [
-00003920: 0d0a 2020 2020 2020 2020 2020 2020 2233  ..            "3
-00003930: 222c 200d 0a20 2020 2020 2020 2020 2020  ", ..           
-00003940: 2022 696e 6372 656d 656e 7469 6e67 2058   "incrementing X
-00003950: 4f52 2065 6e63 6f64 696e 6722 0d0a 2020  OR encoding"..  
-00003960: 2020 2020 2020 5d2c 200d 0a20 2020 2020        ], ..     
-00003970: 2020 2022 7479 7065 223a 2022 6c69 7374     "type": "list
-00003980: 6f66 7374 7269 6e67 7322 0d0a 2020 2020  ofstrings"..    
-00003990: 7d0d 0a7d 0d0a                           }..}..
+00000000: 7b0a 2020 2020 2261 6464 7265 7373 223a  {.    "address":
+00000010: 207b 0a20 2020 2020 2020 2022 6465 7363   {.        "desc
+00000020: 7269 7074 696f 6e22 3a20 2249 5020 6164  ription": "IP ad
+00000030: 6472 6573 7320 6f72 2064 6f6d 6169 6e20  dress or domain 
+00000040: 6e61 6d65 222c 200a 2020 2020 2020 2020  name", .        
+00000050: 2265 7861 6d70 6c65 7322 3a20 5b0a 2020  "examples": [.  
+00000060: 2020 2020 2020 2020 2020 2262 6164 2e63            "bad.c
+00000070: 6f6d 222c 200a 2020 2020 2020 2020 2020  om", .          
+00000080: 2020 2231 302e 3131 2e31 302e 3133 220a    "10.11.10.13".
+00000090: 2020 2020 2020 2020 5d2c 200a 2020 2020          ], .    
+000000a0: 2020 2020 2274 7970 6522 3a20 226c 6973      "type": "lis
+000000b0: 746f 6673 7472 696e 6773 220a 2020 2020  tofstrings".    
+000000c0: 7d2c 0a20 2020 2022 6261 7365 3136 5f61  },.    "base16_a
+000000d0: 6c70 6861 6265 7422 3a20 7b0a 2020 2020  lphabet": {.    
+000000e0: 2020 2020 2264 6573 6372 6970 7469 6f6e      "description
+000000f0: 223a 2022 4261 7365 3136 2061 6c70 6861  ": "Base16 alpha
+00000100: 6265 7420 7573 6564 2066 6f72 2065 6e63  bet used for enc
+00000110: 6f64 696e 672f 6465 636f 6469 6e67 222c  oding/decoding",
+00000120: 0a20 2020 2020 2020 2022 6578 616d 706c  .        "exampl
+00000130: 6573 223a 205b 0a20 2020 2020 2020 2020  es": [.         
+00000140: 2020 2022 3031 3233 3435 3637 3839 4142     "0123456789AB
+00000150: 4344 4546 220a 2020 2020 2020 2020 5d2c  CDEF".        ],
+00000160: 0a20 2020 2020 2020 2022 7479 7065 223a  .        "type":
+00000170: 2022 6c69 7374 6f66 7374 7269 6e67 7322   "listofstrings"
+00000180: 0a20 2020 207d 2c0a 2020 2020 2262 6173  .    },.    "bas
+00000190: 6533 325f 616c 7068 6162 6574 223a 207b  e32_alphabet": {
+000001a0: 0a20 2020 2020 2020 2022 6465 7363 7269  .        "descri
+000001b0: 7074 696f 6e22 3a20 2242 6173 6533 3220  ption": "Base32 
+000001c0: 616c 7068 6162 6574 2075 7365 6420 666f  alphabet used fo
+000001d0: 7220 656e 636f 6469 6e67 2f64 6563 6f64  r encoding/decod
+000001e0: 696e 6722 2c0a 2020 2020 2020 2020 2265  ing",.        "e
+000001f0: 7861 6d70 6c65 7322 3a20 5b0a 2020 2020  xamples": [.    
+00000200: 2020 2020 2020 2020 2241 4243 4445 4647          "ABCDEFG
+00000210: 4849 4a4b 4c4d 4e4f 5051 5253 5455 5657  HIJKLMNOPQRSTUVW
+00000220: 5859 5a32 3334 3536 373d 220a 2020 2020  XYZ234567=".    
+00000230: 2020 2020 5d2c 0a20 2020 2020 2020 2022      ],.        "
+00000240: 7479 7065 223a 2022 6c69 7374 6f66 7374  type": "listofst
+00000250: 7269 6e67 7322 0a20 2020 207d 2c0a 2020  rings".    },.  
+00000260: 2020 2262 6173 6536 345f 616c 7068 6162    "base64_alphab
+00000270: 6574 223a 207b 0a20 2020 2020 2020 2022  et": {.        "
+00000280: 6465 7363 7269 7074 696f 6e22 3a20 2242  description": "B
+00000290: 6173 6536 3420 616c 7068 6162 6574 2075  ase64 alphabet u
+000002a0: 7365 6420 666f 7220 656e 636f 6469 6e67  sed for encoding
+000002b0: 2f64 6563 6f64 696e 6722 2c0a 2020 2020  /decoding",.    
+000002c0: 2020 2020 2265 7861 6d70 6c65 7322 3a20      "examples": 
+000002d0: 5b0a 2020 2020 2020 2020 2020 2020 2241  [.            "A
+000002e0: 4243 4445 4647 4849 4a4b 4c4d 4e4f 5051  BCDEFGHIJKLMNOPQ
+000002f0: 5253 5455 5657 5859 5a61 6263 6465 6667  RSTUVWXYZabcdefg
+00000300: 6869 6a6b 6c6d 6e6f 7071 7273 7475 7677  hijklmnopqrstuvw
+00000310: 7879 7a30 3132 3334 3536 3738 392b 2f3d  xyz0123456789+/=
+00000320: 220a 2020 2020 2020 2020 5d2c 0a20 2020  ".        ],.   
+00000330: 2020 2020 2022 7479 7065 223a 2022 6c69       "type": "li
+00000340: 7374 6f66 7374 7269 6e67 7322 0a20 2020  stofstrings".   
+00000350: 207d 2c0a 2020 2020 2263 325f 6164 6472   },.    "c2_addr
+00000360: 6573 7322 3a20 7b0a 2020 2020 2020 2020  ess": {.        
+00000370: 2264 6573 6372 6970 7469 6f6e 223a 2022  "description": "
+00000380: 7370 6563 6961 6c20 6361 7365 206f 6620  special case of 
+00000390: 6164 6472 6573 732c 2077 6865 6e20 7468  address, when th
+000003a0: 6520 6164 6472 6573 7320 6973 2075 7365  e address is use
+000003b0: 6420 666f 7220 636f 6d6d 616e 6420 616e  d for command an
+000003c0: 6420 636f 6e74 726f 6c22 2c20 0a20 2020  d control", .   
+000003d0: 2020 2020 2022 6578 616d 706c 6573 223a       "examples":
+000003e0: 205b 0a20 2020 2020 2020 2020 2020 2022   [.            "
+000003f0: 6261 642e 636f 6d22 2c20 0a20 2020 2020  bad.com", .     
+00000400: 2020 2020 2020 2022 3130 2e31 312e 3130         "10.11.10
+00000410: 2e31 3322 0a20 2020 2020 2020 205d 2c20  .13".        ], 
+00000420: 0a20 2020 2020 2020 2022 7479 7065 223a  .        "type":
+00000430: 2022 6c69 7374 6f66 7374 7269 6e67 7322   "listofstrings"
+00000440: 0a20 2020 207d 2c20 0a20 2020 2022 6332  .    }, .    "c2
+00000450: 5f73 6f63 6b65 7461 6464 7265 7373 223a  _socketaddress":
+00000460: 207b 0a20 2020 2020 2020 2022 6465 7363   {.        "desc
+00000470: 7269 7074 696f 6e22 3a20 2273 7065 6369  ription": "speci
+00000480: 616c 2063 6173 6520 6f66 2073 6f63 6b65  al case of socke
+00000490: 7461 6464 7265 7373 2c20 7768 656e 2073  taddress, when s
+000004a0: 6f63 6b65 7461 6464 7265 7373 2069 7320  ocketaddress is 
+000004b0: 7573 6564 2066 6f72 2063 6f6d 6d61 6e64  used for command
+000004c0: 2061 6e64 2063 6f6e 7472 6f6c 222c 200a   and control", .
+000004d0: 2020 2020 2020 2020 2265 7861 6d70 6c65          "example
+000004e0: 7322 3a20 5b0a 2020 2020 2020 2020 2020  s": [.          
+000004f0: 2020 5b0a 2020 2020 2020 2020 2020 2020    [.            
+00000500: 2020 2020 2262 6164 2e63 6f6d 222c 200a      "bad.com", .
+00000510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000520: 2232 3122 2c20 0a20 2020 2020 2020 2020  "21", .         
+00000530: 2020 2020 2020 2022 7463 7022 0a20 2020         "tcp".   
+00000540: 2020 2020 2020 2020 205d 2c20 0a20 2020           ], .   
+00000550: 2020 2020 2020 2020 205b 0a20 2020 2020           [.     
+00000560: 2020 2020 2020 2020 2020 2022 3130 2e31             "10.1
+00000570: 312e 3130 2e31 3322 2c20 0a20 2020 2020  1.10.13", .     
+00000580: 2020 2020 2020 2020 2020 2022 3434 3322             "443"
+00000590: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+000005a0: 2020 2022 7463 7022 0a20 2020 2020 2020     "tcp".       
+000005b0: 2020 2020 205d 0a20 2020 2020 2020 205d       ].        ]
+000005c0: 2c20 0a20 2020 2020 2020 2022 7479 7065  , .        "type
+000005d0: 223a 2022 6c69 7374 6f66 7374 7269 6e67  ": "listofstring
+000005e0: 7475 706c 6573 220a 2020 2020 7d2c 200a  tuples".    }, .
+000005f0: 2020 2020 2263 325f 7572 6c22 3a20 7b0a      "c2_url": {.
+00000600: 2020 2020 2020 2020 2264 6573 6372 6970          "descrip
+00000610: 7469 6f6e 223a 2022 7370 6563 6961 6c20  tion": "special 
+00000620: 6361 7365 206f 6620 7572 6c2c 2077 6865  case of url, whe
+00000630: 6e20 7468 6520 7572 6c20 6973 2075 7365  n the url is use
+00000640: 6420 666f 7220 636f 6d6d 616e 6420 616e  d for command an
+00000650: 6420 636f 6e74 726f 6c22 2c20 0a20 2020  d control", .   
+00000660: 2020 2020 2022 6578 616d 706c 6573 223a       "examples":
+00000670: 205b 0a20 2020 2020 2020 2020 2020 2022   [.            "
+00000680: 6874 7470 3a2f 2f6d 616c 2e63 6f6d 2f70  http://mal.com/p
+00000690: 7562 2f76 6965 772e 6173 7022 2c20 0a20  ub/view.asp", . 
+000006a0: 2020 2020 2020 2020 2020 2022 6874 7470             "http
+000006b0: 733a 2f2f 3130 2e31 312e 3130 2e31 333a  s://10.11.10.13:
+000006c0: 3434 332f 696d 6167 6573 2f62 616e 6572  443/images/baner
+000006d0: 2e6a 7067 220a 2020 2020 2020 2020 5d2c  .jpg".        ],
+000006e0: 200a 2020 2020 2020 2020 2274 7970 6522   .        "type"
+000006f0: 3a20 226c 6973 746f 6673 7472 696e 6773  : "listofstrings
+00000700: 220a 2020 2020 7d2c 200a 2020 2020 2263  ".    }, .    "c
+00000710: 7265 6465 6e74 6961 6c22 3a20 7b0a 2020  redential": {.  
+00000720: 2020 2020 2020 2264 6573 6372 6970 7469        "descripti
+00000730: 6f6e 223a 2022 7475 706c 6520 6f66 2075  on": "tuple of u
+00000740: 7365 726e 616d 6520 616e 6420 7061 7373  sername and pass
+00000750: 776f 7264 222c 200a 2020 2020 2020 2020  word", .        
+00000760: 2265 7861 6d70 6c65 7322 3a20 5b0a 2020  "examples": [.  
+00000770: 2020 2020 2020 2020 2020 5b0a 2020 2020            [.    
+00000780: 2020 2020 2020 2020 2020 2020 2248 756e              "Hun
+00000790: 7465 7222 2c20 0a20 2020 2020 2020 2020  ter", .         
+000007a0: 2020 2020 2020 2022 4265 6e73 6f6e 220a         "Benson".
+000007b0: 2020 2020 2020 2020 2020 2020 5d2c 200a              ], .
+000007c0: 2020 2020 2020 2020 2020 2020 5b0a 2020              [.  
+000007d0: 2020 2020 2020 2020 2020 2020 2020 2261                "a
+000007e0: 646d 696e 222c 200a 2020 2020 2020 2020  dmin", .        
+000007f0: 2020 2020 2020 2020 2231 3233 3435 3622          "123456"
+00000800: 0a20 2020 2020 2020 2020 2020 205d 0a20  .            ]. 
+00000810: 2020 2020 2020 205d 2c20 0a20 2020 2020         ], .     
+00000820: 2020 2022 7479 7065 223a 2022 6c69 7374     "type": "list
+00000830: 6f66 7374 7269 6e67 7475 706c 6573 220a  ofstringtuples".
+00000840: 2020 2020 7d2c 200a 2020 2020 2264 6562      }, .    "deb
+00000850: 7567 223a 207b 0a20 2020 2020 2020 2022  ug": {.        "
+00000860: 6465 7363 7269 7074 696f 6e22 3a20 224d  description": "M
+00000870: 6573 7361 6765 2075 7365 6420 666f 7220  essage used for 
+00000880: 6465 6275 6767 696e 6720 6f72 2074 6f20  debugging or to 
+00000890: 7265 706f 7274 2065 7272 6f72 732e 204e  report errors. N
+000008a0: 6f74 206d 616c 7761 7265 2063 6f6e 6669  ot malware confi
+000008b0: 6775 7261 7469 6f6e 2070 6572 2073 6522  guration per se"
+000008c0: 2c20 0a20 2020 2020 2020 2022 6578 616d  , .        "exam
+000008d0: 706c 6573 223a 205b 0a20 2020 2020 2020  ples": [.       
+000008e0: 2020 2020 2022 5375 6363 6573 7366 756c       "Successful
+000008f0: 6c79 2066 6f75 6e64 2063 6f6e 6669 6720  ly found config 
+00000900: 626c 6f63 6b2c 2061 7474 656d 7074 696e  block, attemptin
+00000910: 6720 6465 636f 6465 222c 200a 2020 2020  g decode", .    
+00000920: 2020 2020 2020 2020 2244 6563 6f64 6520          "Decode 
+00000930: 6661 696c 6564 3a20 6465 7465 6374 6564  failed: detected
+00000940: 2063 6f6e 6669 6720 6c6f 6361 7469 6f6e   config location
+00000950: 2033 3733 3539 3238 3535 3920 6f75 7473   3735928559 outs
+00000960: 6964 6520 6669 6c65 2073 697a 6520 6f66  ide file size of
+00000970: 2031 3834 3332 3022 0a20 2020 2020 2020   184320".       
+00000980: 205d 2c20 0a20 2020 2020 2020 2022 7479   ], .        "ty
+00000990: 7065 223a 2022 6c69 7374 6f66 7374 7269  pe": "listofstri
+000009a0: 6e67 7322 0a20 2020 207d 2c20 0a20 2020  ngs".    }, .   
+000009b0: 2022 6469 7265 6374 6f72 7922 3a20 7b0a   "directory": {.
+000009c0: 2020 2020 2020 2020 2264 6573 6372 6970          "descrip
+000009d0: 7469 6f6e 223a 2022 6469 7265 6374 6f72  tion": "director
+000009e0: 7920 2864 6972 6e61 6d65 2920 7573 6564  y (dirname) used
+000009f0: 2062 7920 6d61 6c77 6172 6522 2c20 0a20   by malware", . 
+00000a00: 2020 2020 2020 2022 6578 616d 706c 6573         "examples
+00000a10: 223a 205b 0a20 2020 2020 2020 2020 2020  ": [.           
+00000a20: 2022 433a 5c5c 7769 6e64 6f77 735c 5c74   "C:\\windows\\t
+00000a30: 656d 705c 5c31 5c5c 6c6f 6722 2c20 0a20  emp\\1\\log", . 
+00000a40: 2020 2020 2020 2020 2020 2022 2541 5050             "%APP
+00000a50: 4441 5441 255c 5c66 6f6f 220a 2020 2020  DATA%\\foo".    
+00000a60: 2020 2020 5d2c 200a 2020 2020 2020 2020      ], .        
+00000a70: 2274 7970 6522 3a20 226c 6973 746f 6673  "type": "listofs
+00000a80: 7472 696e 6773 220a 2020 2020 7d2c 0a20  trings".    },. 
+00000a90: 2020 2022 656d 6169 6c5f 6164 6472 6573     "email_addres
+00000aa0: 7322 3a20 7b0a 2020 2020 2020 2020 2264  s": {.        "d
+00000ab0: 6573 6372 6970 7469 6f6e 223a 2022 456d  escription": "Em
+00000ac0: 6169 6c20 6164 6472 6573 7322 2c0a 2020  ail address",.  
+00000ad0: 2020 2020 2020 2265 7861 6d70 6c65 7322        "examples"
+00000ae0: 3a20 5b0a 2020 2020 2020 2020 2020 2020  : [.            
+00000af0: 2275 7365 7240 6261 642e 636f 6d22 0a20  "user@bad.com". 
+00000b00: 2020 2020 2020 205d 2c0a 2020 2020 2020         ],.      
+00000b10: 2020 2274 7970 6522 3a20 226c 6973 746f    "type": "listo
+00000b20: 6673 7472 696e 6773 220a 2020 2020 7d2c  fstrings".    },
+00000b30: 0a20 2020 2022 6576 656e 7422 3a20 7b0a  .    "event": {.
+00000b40: 2020 2020 2020 2020 2264 6573 6372 6970          "descrip
+00000b50: 7469 6f6e 223a 2022 4e61 6d65 206f 6620  tion": "Name of 
+00000b60: 616e 2065 7665 6e74 206f 626a 6563 7422  an event object"
+00000b70: 2c0a 2020 2020 2020 2020 2265 7861 6d70  ,.        "examp
+00000b80: 6c65 7322 3a20 5b0a 2020 2020 2020 2020  les": [.        
+00000b90: 2020 2020 224d 6963 726f 736f 6674 4578      "MicrosoftEx
+00000ba0: 6974 220a 2020 2020 2020 2020 5d2c 0a20  it".        ],. 
+00000bb0: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
+00000bc0: 6c69 7374 6f66 7374 7269 6e67 7322 0a20  listofstrings". 
+00000bd0: 2020 207d 2c0a 2020 2020 2266 696c 656e     },.    "filen
+00000be0: 616d 6522 3a20 7b0a 2020 2020 2020 2020  ame": {.        
+00000bf0: 2264 6573 6372 6970 7469 6f6e 223a 2022  "description": "
+00000c00: 6669 6c65 6e61 6d65 2028 6261 7365 6e61  filename (basena
+00000c10: 6d65 2920 7573 6564 2062 7920 6d61 6c77  me) used by malw
+00000c20: 6172 6522 2c20 0a20 2020 2020 2020 2022  are", .        "
+00000c30: 6578 616d 706c 6573 223a 205b 0a20 2020  examples": [.   
+00000c40: 2020 2020 2020 2020 2022 6b65 7964 622e           "keydb.
+00000c50: 7478 7422 2c20 0a20 2020 2020 2020 2020  txt", .         
+00000c60: 2020 2022 6261 722e 6578 6522 0a20 2020     "bar.exe".   
+00000c70: 2020 2020 205d 2c20 0a20 2020 2020 2020       ], .       
+00000c80: 2022 7479 7065 223a 2022 6c69 7374 6f66   "type": "listof
+00000c90: 7374 7269 6e67 7322 0a20 2020 207d 2c20  strings".    }, 
+00000ca0: 0a20 2020 2022 6669 6c65 7061 7468 223a  .    "filepath":
+00000cb0: 207b 0a20 2020 2020 2020 2022 6465 7363   {.        "desc
+00000cc0: 7269 7074 696f 6e22 3a20 2266 696c 6573  ription": "files
+00000cd0: 7973 7465 6d20 7061 7468 2075 7365 6420  ystem path used 
+00000ce0: 6279 206d 616c 7761 7265 2e20 496e 636c  by malware. Incl
+00000cf0: 7564 6573 2062 6f74 6820 6120 6469 7265  udes both a dire
+00000d00: 6374 6f72 7920 616e 6420 6120 6669 6c65  ctory and a file
+00000d10: 6e61 6d65 222c 200a 2020 2020 2020 2020  name", .        
+00000d20: 2265 7861 6d70 6c65 7322 3a20 5b0a 2020  "examples": [.  
+00000d30: 2020 2020 2020 2020 2020 2243 3a5c 5c77            "C:\\w
+00000d40: 696e 646f 7773 5c5c 7465 6d70 5c5c 315c  indows\\temp\\1\
+00000d50: 5c6c 6f67 5c5c 6b65 7964 622e 7478 7422  \log\\keydb.txt"
+00000d60: 2c20 0a20 2020 2020 2020 2020 2020 2022  , .            "
+00000d70: 2541 5050 4441 5441 255c 5c66 6f6f 5c5c  %APPDATA%\\foo\\
+00000d80: 6261 722e 6578 6522 0a20 2020 2020 2020  bar.exe".       
+00000d90: 205d 2c20 0a20 2020 2020 2020 2022 7479   ], .        "ty
+00000da0: 7065 223a 2022 6c69 7374 6f66 7374 7269  pe": "listofstri
+00000db0: 6e67 7322 0a20 2020 207d 2c0a 2020 2020  ngs".    },.    
+00000dc0: 2266 7470 223a 207b 0a20 2020 2020 2020  "ftp": {.       
+00000dd0: 2022 6465 7363 7269 7074 696f 6e22 3a20   "description": 
+00000de0: 2246 5450 2063 7265 6465 6e74 6961 6c73  "FTP credentials
+00000df0: 2028 7573 6572 6e61 6d65 2061 6e64 2070   (username and p
+00000e00: 6173 7377 6f72 6429 2c20 616e 6420 6675  assword), and fu
+00000e10: 6c6c 2055 524c 2077 6974 6820 7363 6865  ll URL with sche
+00000e20: 6d65 2c20 6164 6472 6573 732c 206f 7074  me, address, opt
+00000e30: 696f 6e61 6c20 706f 7274 2c20 616e 6420  ional port, and 
+00000e40: 6f70 7469 6f6e 616c 2070 6174 6822 2c0a  optional path",.
+00000e50: 2020 2020 2020 2020 2265 7861 6d70 6c65          "example
+00000e60: 7322 3a20 5b0a 2020 2020 2020 2020 2020  s": [.          
+00000e70: 2020 5b0a 2020 2020 2020 2020 2020 2020    [.            
+00000e80: 2020 2020 2261 646d 696e 222c 0a20 2020      "admin",.   
+00000e90: 2020 2020 2020 2020 2020 2020 2022 7061               "pa
+00000ea0: 7373 222c 0a20 2020 2020 2020 2020 2020  ss",.           
+00000eb0: 2020 2020 2022 6674 703a 2f2f 6261 6468       "ftp://badh
+00000ec0: 6f73 742e 636f 6d3a 3231 220a 2020 2020  ost.com:21".    
+00000ed0: 2020 2020 2020 2020 5d0a 2020 2020 2020          ].      
+00000ee0: 2020 5d2c 0a20 2020 2020 2020 2022 7479    ],.        "ty
+00000ef0: 7065 223a 2022 6c69 7374 6f66 7374 7269  pe": "listofstri
+00000f00: 6e67 7475 706c 6573 220a 2020 2020 7d2c  ngtuples".    },
+00000f10: 0a20 2020 2022 6775 6964 223a 207b 0a20  .    "guid": {. 
+00000f20: 2020 2020 2020 2022 6465 7363 7269 7074         "descript
+00000f30: 696f 6e22 3a20 2241 2031 3238 2d62 6974  ion": "A 128-bit
+00000f40: 206e 756d 6265 7220 7573 6564 2074 6f20   number used to 
+00000f50: 6964 656e 7469 6679 2069 6e66 6f72 6d61  identify informa
+00000f60: 7469 6f6e 2c20 616c 736f 2072 6566 6572  tion, also refer
+00000f70: 7265 6420 746f 2061 7320 6120 5555 4944  red to as a UUID
+00000f80: 222c 0a20 2020 2020 2020 2022 6578 616d  ",.        "exam
+00000f90: 706c 6573 223a 205b 0a20 2020 2020 2020  ples": [.       
+00000fa0: 2020 2020 2022 7b36 3534 6535 6366 662d       "{654e5cff-
+00000fb0: 3831 3763 2d34 6533 642d 3862 3031 2d34  817c-4e3d-8b01-4
+00000fc0: 3761 3666 3435 6165 3039 617d 220a 2020  7a6f45ae09a}".  
+00000fd0: 2020 2020 2020 5d2c 0a20 2020 2020 2020        ],.       
+00000fe0: 2022 7479 7065 223a 2022 6c69 7374 6f66   "type": "listof
+00000ff0: 7374 7269 6e67 7322 0a20 2020 207d 2c0a  strings".    },.
+00001000: 2020 2020 2269 6e6a 6563 7469 6f6e 7072      "injectionpr
+00001010: 6f63 6573 7322 3a20 7b0a 2020 2020 2020  ocess": {.      
+00001020: 2020 2264 6573 6372 6970 7469 6f6e 223a    "description":
+00001030: 2022 7072 6f63 6573 7320 696e 746f 2077   "process into w
+00001040: 6869 6368 206d 616c 7761 7265 2069 7320  hich malware is 
+00001050: 696e 6a65 6374 6564 2e20 5573 7561 6c6c  injected. Usuall
+00001060: 7920 7468 6973 2069 7320 6120 7072 6f63  y this is a proc
+00001070: 6573 7320 6e61 6d65 2062 7574 2069 7420  ess name but it 
+00001080: 6d61 7920 7461 6b65 206f 7468 6572 2066  may take other f
+00001090: 6f72 6d73 2073 7563 6820 6173 2061 2066  orms such as a f
+000010a0: 696c 656e 616d 6520 6f66 2074 6865 2065  ilename of the e
+000010b0: 7865 6375 7461 626c 652e 222c 200a 2020  xecutable.", .  
+000010c0: 2020 2020 2020 2265 7861 6d70 6c65 7322        "examples"
+000010d0: 3a20 5b0a 2020 2020 2020 2020 2020 2020  : [.            
+000010e0: 2269 6578 706c 6f72 6522 2c20 0a20 2020  "iexplore", .   
+000010f0: 2020 2020 2020 2020 2022 7376 6368 6f73           "svchos
+00001100: 7422 0a20 2020 2020 2020 205d 2c20 0a20  t".        ], . 
+00001110: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
+00001120: 6c69 7374 6f66 7374 7269 6e67 7322 0a20  listofstrings". 
+00001130: 2020 207d 2c20 0a20 2020 2022 696e 7465     }, .    "inte
+00001140: 7276 616c 223a 207b 0a20 2020 2020 2020  rval": {.       
+00001150: 2022 6465 7363 7269 7074 696f 6e22 3a20   "description": 
+00001160: 2274 696d 6520 6d61 6c77 6172 6520 7761  "time malware wa
+00001170: 6974 7320 6265 7477 6565 6e20 6265 6163  its between beac
+00001180: 6f6e 7320 6f72 206f 7468 6572 2061 6374  ons or other act
+00001190: 6976 6974 7920 6769 7665 6e20 696e 2073  ivity given in s
+000011a0: 6563 6f6e 6473 222c 200a 2020 2020 2020  econds", .      
+000011b0: 2020 2265 7861 6d70 6c65 7322 3a20 5b0a    "examples": [.
+000011c0: 2020 2020 2020 2020 2020 2020 2233 222c              "3",
+000011d0: 200a 2020 2020 2020 2020 2020 2020 222e   .            ".
+000011e0: 3122 0a20 2020 2020 2020 205d 2c20 0a20  1".        ], . 
+000011f0: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
+00001200: 6c69 7374 6f66 7374 7269 6e67 7322 0a20  listofstrings". 
+00001210: 2020 207d 2c20 0a20 2020 2022 6b65 7922     }, .    "key"
+00001220: 3a20 7b0a 2020 2020 2020 2020 2264 6573  : {.        "des
+00001230: 6372 6970 7469 6f6e 223a 2022 656e 6372  cription": "encr
+00001240: 7970 7469 6f6e 2c20 656e 636f 6469 6e67  yption, encoding
+00001250: 2c20 6f72 206f 6266 7573 6361 7469 6f6e  , or obfuscation
+00001260: 206b 6579 2e20 4279 2063 6f6e 7665 6e74   key. By convent
+00001270: 696f 6e2c 2077 6865 6e20 7468 6573 6520  ion, when these 
+00001280: 7265 7072 6573 656e 7420 6269 6e61 7279  represent binary
+00001290: 2064 6174 612c 2074 6865 7920 7368 6f75   data, they shou
+000012a0: 6c64 2062 6520 6261 7265 2068 6578 2065  ld be bare hex e
+000012b0: 6e63 6f64 6564 2077 6974 6820 6e6f 206f  ncoded with no o
+000012c0: 7468 6572 206d 6172 6b75 702e 2042 6173  ther markup. Bas
+000012d0: 6536 3420 6f72 2073 696d 696c 6172 2063  e64 or similar c
+000012e0: 7573 746f 6d20 6469 6374 696f 6e61 7269  ustom dictionari
+000012f0: 6573 2061 7265 2073 746f 7265 6420 6173  es are stored as
+00001300: 2069 732e 222c 200a 2020 2020 2020 2020   is.", .        
+00001310: 2265 7861 6d70 6c65 7322 3a20 5b0a 2020  "examples": [.  
+00001320: 2020 2020 2020 2020 2020 2238 3522 2c20            "85", 
+00001330: 0a20 2020 2020 2020 2020 2020 2022 3664  .            "6d
+00001340: 3739 3732 3633 3334 3662 3635 3739 220a  797263346b6579".
+00001350: 2020 2020 2020 2020 5d2c 200a 2020 2020          ], .    
+00001360: 2020 2020 2274 7970 6522 3a20 226c 6973      "type": "lis
+00001370: 746f 6673 7472 696e 6773 220a 2020 2020  tofstrings".    
+00001380: 7d2c 200a 2020 2020 226c 6973 7465 6e70  }, .    "listenp
+00001390: 6f72 7422 3a20 7b0a 2020 2020 2020 2020  ort": {.        
+000013a0: 2264 6573 6372 6970 7469 6f6e 223a 2022  "description": "
+000013b0: 5443 5020 6f72 2055 4450 2070 6f72 7420  TCP or UDP port 
+000013c0: 7468 6174 2069 7320 6f70 656e 6564 2066  that is opened f
+000013d0: 6f72 206c 6973 7465 6e69 6e67 2e20 5468  or listening. Th
+000013e0: 6973 2068 6173 2074 6865 2073 616d 6520  is has the same 
+000013f0: 666f 726d 6174 2061 7320 6120 706f 7274  format as a port
+00001400: 2c20 6275 7420 696e 6469 6361 7465 7320  , but indicates 
+00001410: 616e 2069 6e63 6f6d 696e 6720 636f 6e6e  an incoming conn
+00001420: 6563 7469 6f6e 2077 6865 7265 2074 6865  ection where the
+00001430: 206d 616c 7761 7265 2069 7320 7468 6520   malware is the 
+00001440: 7365 7276 6572 2e22 2c20 0a20 2020 2020  server.", .     
+00001450: 2020 2022 6578 616d 706c 6573 223a 205b     "examples": [
+00001460: 0a20 2020 2020 2020 2020 2020 205b 0a20  .            [. 
+00001470: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00001480: 3533 222c 200a 2020 2020 2020 2020 2020  53", .          
+00001490: 2020 2020 2020 2275 6470 220a 2020 2020        "udp".    
+000014a0: 2020 2020 2020 2020 5d2c 200a 2020 2020          ], .    
+000014b0: 2020 2020 2020 2020 5b0a 2020 2020 2020          [.      
+000014c0: 2020 2020 2020 2020 2020 2234 3433 222c            "443",
+000014d0: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+000014e0: 2020 2274 6370 220a 2020 2020 2020 2020    "tcp".        
+000014f0: 2020 2020 5d0a 2020 2020 2020 2020 5d2c      ].        ],
+00001500: 200a 2020 2020 2020 2020 2274 7970 6522   .        "type"
+00001510: 3a20 226c 6973 746f 6673 7472 696e 6774  : "listofstringt
+00001520: 7570 6c65 7322 0a20 2020 207d 2c20 0a20  uples".    }, . 
+00001530: 2020 2022 6d69 7373 696f 6e69 6422 3a20     "missionid": 
+00001540: 7b0a 2020 2020 2020 2020 2264 6573 6372  {.        "descr
+00001550: 6970 7469 6f6e 223a 2022 6174 7461 636b  iption": "attack
+00001560: 6572 2073 7065 6369 6669 6564 2069 6465  er specified ide
+00001570: 6e74 6966 6965 7220 656e 636f 6465 6420  ntifier encoded 
+00001580: 696e 206d 616c 7761 7265 2c20 7573 7561  in malware, usua
+00001590: 6c6c 7920 7265 666c 6563 7465 6420 696e  lly reflected in
+000015a0: 2062 6561 636f 6e73 2061 6e64 206f 6674   beacons and oft
+000015b0: 656e 2072 656c 6174 6564 2074 6f20 7461  en related to ta
+000015c0: 7267 6574 206f 7220 7469 6d65 206f 6620  rget or time of 
+000015d0: 6174 7461 636b 222c 200a 2020 2020 2020  attack", .      
+000015e0: 2020 2265 7861 6d70 6c65 7322 3a20 5b0a    "examples": [.
+000015f0: 2020 2020 2020 2020 2020 2020 2274 6172              "tar
+00001600: 6765 7434 222c 200a 2020 2020 2020 2020  get4", .        
+00001610: 2020 2020 2232 3031 3431 3222 0a20 2020      "201412".   
+00001620: 2020 2020 205d 2c20 0a20 2020 2020 2020       ], .       
+00001630: 2022 7479 7065 223a 2022 6c69 7374 6f66   "type": "listof
+00001640: 7374 7269 6e67 7322 0a20 2020 207d 2c20  strings".    }, 
+00001650: 0a20 2020 2022 6d75 7465 7822 3a20 7b0a  .    "mutex": {.
+00001660: 2020 2020 2020 2020 2264 6573 6372 6970          "descrip
+00001670: 7469 6f6e 223a 2022 6d75 7465 7820 6e61  tion": "mutex na
+00001680: 6d65 2075 7365 6420 746f 2070 7265 7665  me used to preve
+00001690: 6e74 206d 756c 7469 706c 6520 6578 6563  nt multiple exec
+000016a0: 7574 696f 6e73 206f 6620 6d61 6c77 6172  utions of malwar
+000016b0: 6522 2c20 0a20 2020 2020 2020 2022 6578  e", .        "ex
+000016c0: 616d 706c 6573 223a 205b 0a20 2020 2020  amples": [.     
+000016d0: 2020 2020 2020 2022 6974 6869 6e6b 696d         "ithinkim
+000016e0: 616c 6f6e 656e 6f77 222c 200a 2020 2020  alonenow", .    
+000016f0: 2020 2020 2020 2020 2230 3033 3661 3831          "0036a81
+00001700: 3137 6166 6122 0a20 2020 2020 2020 205d  17afa".        ]
+00001710: 2c20 0a20 2020 2020 2020 2022 7479 7065  , .        "type
+00001720: 223a 2022 6c69 7374 6f66 7374 7269 6e67  ": "listofstring
+00001730: 7322 0a20 2020 207d 2c20 0a20 2020 2022  s".    }, .    "
+00001740: 6f74 6865 7222 3a20 7b0a 2020 2020 2020  other": {.      
+00001750: 2020 2264 6573 6372 6970 7469 6f6e 223a    "description":
+00001760: 2022 416c 6c20 6974 656d 7320 6f74 6865   "All items othe
+00001770: 7220 7468 616e 2074 6865 2073 7461 6e64  r than the stand
+00001780: 6172 6420 6669 656c 6473 2064 6563 6c61  ard fields decla
+00001790: 7265 6420 696e 2074 6869 7320 6c69 7374  red in this list
+000017a0: 2e20 4974 656d 7320 6d61 7920 6265 2064  . Items may be d
+000017b0: 7570 6c69 6361 7465 6420 6865 7265 2074  uplicated here t
+000017c0: 6f20 7072 6f76 6964 6520 6d61 6c77 6172  o provide malwar
+000017d0: 6520 7370 6563 6966 6963 2063 6f6e 7465  e specific conte
+000017e0: 7874 2e22 2c20 0a20 2020 2020 2020 2022  xt.", .        "
+000017f0: 6578 616d 706c 6573 223a 205b 0a20 2020  examples": [.   
+00001800: 2020 2020 2020 2020 207b 0a20 2020 2020           {.     
+00001810: 2020 2020 2020 2020 2020 2022 4163 7469             "Acti
+00001820: 7661 7465 204b 6579 6c6f 6767 6572 223a  vate Keylogger":
+00001830: 2022 5452 5545 220a 2020 2020 2020 2020   "TRUE".        
+00001840: 2020 2020 7d2c 200a 2020 2020 2020 2020      }, .        
+00001850: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
+00001860: 2020 2020 2020 2243 6f6e 6669 6720 584f        "Config XO
+00001870: 5220 6b65 7922 3a20 2238 3922 0a20 2020  R key": "89".   
+00001880: 2020 2020 2020 2020 207d 0a20 2020 2020           }.     
+00001890: 2020 205d 2c20 0a20 2020 2020 2020 2022     ], .        "
+000018a0: 7479 7065 223a 2022 6469 6374 6f66 7374  type": "dictofst
+000018b0: 7269 6e67 7322 0a20 2020 207d 2c20 0a20  rings".    }, . 
+000018c0: 2020 2022 6f75 7470 7574 6669 6c65 223a     "outputfile":
+000018d0: 207b 0a20 2020 2020 2020 2022 6465 7363   {.        "desc
+000018e0: 7269 7074 696f 6e22 3a20 2272 656c 6576  ription": "relev
+000018f0: 616e 7420 6f72 2072 656c 6174 6564 2066  ant or related f
+00001900: 696c 6520 6372 6561 7465 6420 6475 7269  ile created duri
+00001910: 6e67 2070 6172 7369 6e67 206f 6620 6d61  ng parsing of ma
+00001920: 6c77 6172 652e 2054 7570 6c65 206f 6620  lware. Tuple of 
+00001930: 6669 6c65 6e61 6d65 2c20 6465 7363 7269  filename, descri
+00001940: 7074 696f 6e2c 2061 6e64 206d 6435 2e22  ption, and md5."
+00001950: 2c20 0a20 2020 2020 2020 2022 6578 616d  , .        "exam
+00001960: 706c 6573 223a 205b 0a20 2020 2020 2020  ples": [.       
+00001970: 2020 2020 205b 0a20 2020 2020 2020 2020       [.         
+00001980: 2020 2020 2020 2022 636f 6e66 6967 2e78         "config.x
+00001990: 6d6c 222c 200a 2020 2020 2020 2020 2020  ml", .          
+000019a0: 2020 2020 2020 2265 7874 7261 6374 6564        "extracted
+000019b0: 2062 6163 6b64 6f6f 7220 466f 6f20 636f   backdoor Foo co
+000019c0: 6e66 6967 2066 696c 6522 2c0a 2020 2020  nfig file",.    
+000019d0: 2020 2020 2020 2020 2020 2020 2231 3233              "123
+000019e0: 3435 3637 3839 3031 3233 3435 3637 3839  4567890123456789
+000019f0: 3031 3233 3435 3637 3839 3031 3222 0a20  0123456789012". 
+00001a00: 2020 2020 2020 2020 2020 205d 2c20 0a20             ], . 
+00001a10: 2020 2020 2020 2020 2020 205b 0a20 2020             [.   
+00001a20: 2020 2020 2020 2020 2020 2020 2022 636c               "cl
+00001a30: 6965 6e74 2e63 7274 222c 200a 2020 2020  ient.crt", .    
+00001a40: 2020 2020 2020 2020 2020 2020 2263 6572              "cer
+00001a50: 7469 6669 6361 7465 2066 6f72 2042 6172  tificate for Bar
+00001a60: 5261 7420 544c 5320 636c 6965 6e74 2061  Rat TLS client a
+00001a70: 7574 6865 6e74 6963 6174 696f 6e22 2c0a  uthentication",.
+00001a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001a90: 2230 3938 3736 3534 3332 3130 3938 3736  "098765432109876
+00001aa0: 3534 3332 3130 3938 3736 3534 3332 3130  5432109876543210
+00001ab0: 3922 0a20 2020 2020 2020 2020 2020 205d  9".            ]
+00001ac0: 0a20 2020 2020 2020 205d 2c20 0a20 2020  .        ], .   
+00001ad0: 2020 2020 2022 7479 7065 223a 2022 6c69       "type": "li
+00001ae0: 7374 6f66 7374 7269 6e67 7475 706c 6573  stofstringtuples
+00001af0: 220a 2020 2020 7d2c 200a 2020 2020 2270  ".    }, .    "p
+00001b00: 6173 7377 6f72 6422 3a20 7b0a 2020 2020  assword": {.    
+00001b10: 2020 2020 2264 6573 6372 6970 7469 6f6e      "description
+00001b20: 223a 2022 7061 7373 776f 7264 2075 7365  ": "password use
+00001b30: 6420 6279 206d 616c 7761 7265 222c 200a  d by malware", .
+00001b40: 2020 2020 2020 2020 2265 7861 6d70 6c65          "example
+00001b50: 7322 3a20 5b0a 2020 2020 2020 2020 2020  s": [.          
+00001b60: 2020 2242 656e 736f 6e22 2c20 0a20 2020    "Benson", .   
+00001b70: 2020 2020 2020 2020 2022 3132 3334 3536           "123456
+00001b80: 220a 2020 2020 2020 2020 5d2c 200a 2020  ".        ], .  
+00001b90: 2020 2020 2020 2274 7970 6522 3a20 226c        "type": "l
+00001ba0: 6973 746f 6673 7472 696e 6773 220a 2020  istofstrings".  
+00001bb0: 2020 7d2c 0a20 2020 2022 7069 7065 223a    },.    "pipe":
+00001bc0: 207b 0a20 2020 2020 2020 2022 6465 7363   {.        "desc
+00001bd0: 7269 7074 696f 6e22 3a20 224e 616d 6564  ription": "Named
+00001be0: 2c20 6f6e 652d 7761 7920 6f72 2064 7570  , one-way or dup
+00001bf0: 6c65 7820 7069 7065 2066 6f72 2063 6f6d  lex pipe for com
+00001c00: 6d75 6e69 6361 7469 6f6e 2062 6574 7765  munication betwe
+00001c10: 656e 2074 6865 2070 6970 6520 7365 7276  en the pipe serv
+00001c20: 6572 2061 6e64 206f 6e65 206f 7220 6d6f  er and one or mo
+00001c30: 7265 2070 6970 6520 636c 6965 6e74 7322  re pipe clients"
+00001c40: 2c0a 2020 2020 2020 2020 2265 7861 6d70  ,.        "examp
+00001c50: 6c65 7322 3a20 5b0a 2020 2020 2020 2020  les": [.        
+00001c60: 2020 2020 225c 5c2e 5c5c 7069 7065 5c5c      "\\.\\pipe\\
+00001c70: 6e61 6d65 6470 6970 6522 0a20 2020 2020  namedpipe".     
+00001c80: 2020 205d 2c0a 2020 2020 2020 2020 2274     ],.        "t
+00001c90: 7970 6522 3a20 226c 6973 746f 6673 7472  ype": "listofstr
+00001ca0: 696e 6773 220a 2020 2020 7d2c 0a20 2020  ings".    },.   
+00001cb0: 2022 706f 7274 223a 207b 0a20 2020 2020   "port": {.     
+00001cc0: 2020 2022 6465 7363 7269 7074 696f 6e22     "description"
+00001cd0: 3a20 2254 4350 206f 7220 5544 5020 706f  : "TCP or UDP po
+00001ce0: 7274 2e20 4120 7475 706c 6520 6f66 2061  rt. A tuple of a
+00001cf0: 2070 6f72 7420 6e75 6d62 6572 2061 6e64   port number and
+00001d00: 2070 726f 746f 636f 6c2e 2054 6869 7320   protocol. This 
+00001d10: 6765 6e65 7261 6c6c 7920 7265 6665 7273  generally refers
+00001d20: 2074 6f20 6f75 7462 6f75 6e64 2063 6f6e   to outbound con
+00001d30: 6e65 6374 696f 6e73 2077 6865 7265 2074  nections where t
+00001d40: 6865 206d 616c 7761 7265 2069 7320 7468  he malware is th
+00001d50: 6520 636c 6965 6e74 2e20 4f74 6865 7220  e client. Other 
+00001d60: 6e65 7477 6f72 6b20 6c61 7965 7220 7072  network layer pr
+00001d70: 6f74 6f63 6f6c 732c 2073 7563 6820 6173  otocols, such as
+00001d80: 2049 434d 5020 6361 6e20 6265 2072 6570   ICMP can be rep
+00001d90: 7265 7365 6e74 6564 2068 6572 652e 2041  resented here. A
+00001da0: 7070 6c69 6361 7469 6f6e 206c 6179 6572  pplication layer
+00001db0: 2070 726f 746f 636f 6c73 2c20 7375 6368   protocols, such
+00001dc0: 2061 7320 4854 5450 2c20 7368 6f75 6c64   as HTTP, should
+00001dd0: 2062 6520 696e 6469 6361 7465 6420 696e   be indicated in
+00001de0: 2061 2055 524c 2e22 2c20 0a20 2020 2020   a URL.", .     
+00001df0: 2020 2022 6578 616d 706c 6573 223a 205b     "examples": [
+00001e00: 0a20 2020 2020 2020 2020 2020 205b 0a20  .            [. 
+00001e10: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00001e20: 3231 222c 200a 2020 2020 2020 2020 2020  21", .          
+00001e30: 2020 2020 2020 2274 6370 220a 2020 2020        "tcp".    
+00001e40: 2020 2020 2020 2020 5d2c 200a 2020 2020          ], .    
+00001e50: 2020 2020 2020 2020 5b0a 2020 2020 2020          [.      
+00001e60: 2020 2020 2020 2020 2020 2234 3433 222c            "443",
+00001e70: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+00001e80: 2020 2274 6370 220a 2020 2020 2020 2020    "tcp".        
+00001e90: 2020 2020 5d0a 2020 2020 2020 2020 5d2c      ].        ],
+00001ea0: 200a 2020 2020 2020 2020 2274 7970 6522   .        "type"
+00001eb0: 3a20 226c 6973 746f 6673 7472 696e 6774  : "listofstringt
+00001ec0: 7570 6c65 7322 0a20 2020 207d 2c0a 2020  uples".    },.  
+00001ed0: 2020 2270 726f 7879 223a 207b 0a20 2020    "proxy": {.   
+00001ee0: 2020 2020 2022 6465 7363 7269 7074 696f       "descriptio
+00001ef0: 6e22 3a20 2250 726f 7879 2063 7265 6465  n": "Proxy crede
+00001f00: 6e74 6961 6c73 2028 7573 6572 6e61 6d65  ntials (username
+00001f10: 2061 6e64 2070 6173 7377 6f72 6429 2c20   and password), 
+00001f20: 6164 6472 6573 732c 2070 6f72 742c 2061  address, port, a
+00001f30: 6e64 2070 726f 746f 636f 6c20 636f 6d62  nd protocol comb
+00001f40: 696e 6174 696f 6e20 7573 6564 2074 6f67  ination used tog
+00001f50: 6574 6865 7222 2c0a 2020 2020 2020 2020  ether",.        
+00001f60: 2265 7861 6d70 6c65 7322 3a20 5b0a 2020  "examples": [.  
+00001f70: 2020 2020 2020 2020 2020 5b0a 2020 2020            [.    
+00001f80: 2020 2020 2020 2020 2020 2020 2261 646d              "adm
+00001f90: 696e 222c 0a20 2020 2020 2020 2020 2020  in",.           
+00001fa0: 2020 2020 2022 7061 7373 222c 0a20 2020       "pass",.   
+00001fb0: 2020 2020 2020 2020 2020 2020 2022 3139               "19
+00001fc0: 322e 3136 382e 312e 3122 2c0a 2020 2020  2.168.1.1",.    
+00001fd0: 2020 2020 2020 2020 2020 2020 2238 3022              "80"
+00001fe0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00001ff0: 2020 2274 6370 220a 2020 2020 2020 2020    "tcp".        
+00002000: 2020 2020 5d0a 2020 2020 2020 2020 5d2c      ].        ],
+00002010: 0a20 2020 2020 2020 2022 7479 7065 223a  .        "type":
+00002020: 2022 6c69 7374 6f66 7374 7269 6e67 7475   "listofstringtu
+00002030: 706c 6573 220a 2020 2020 7d2c 0a20 2020  ples".    },.   
+00002040: 2022 7072 6f78 795f 736f 636b 6574 6164   "proxy_socketad
+00002050: 6472 6573 7322 3a20 7b0a 2020 2020 2020  dress": {.      
+00002060: 2020 2264 6573 6372 6970 7469 6f6e 223a    "description":
+00002070: 2022 5072 6f78 7920 6164 6472 6573 732c   "Proxy address,
+00002080: 2070 6f72 742c 2061 6e64 2070 726f 746f   port, and proto
+00002090: 2063 6f6d 6269 6e61 7469 6f6e 2075 7365   combination use
+000020a0: 6420 746f 6765 7468 6572 222c 0a20 2020  d together",.   
+000020b0: 2020 2020 2022 6578 616d 706c 6573 223a       "examples":
+000020c0: 205b 0a20 2020 2020 2020 2020 2020 205b   [.            [
+000020d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000020e0: 2022 3139 322e 3136 382e 312e 3122 2c0a   "192.168.1.1",.
+000020f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002100: 2238 3022 2c0a 2020 2020 2020 2020 2020  "80",.          
+00002110: 2020 2020 2020 2274 6370 220a 2020 2020        "tcp".    
+00002120: 2020 2020 2020 2020 5d0a 2020 2020 2020          ].      
+00002130: 2020 5d2c 0a20 2020 2020 2020 2022 7479    ],.        "ty
+00002140: 7065 223a 2022 6c69 7374 6f66 7374 7269  pe": "listofstri
+00002150: 6e67 7475 706c 6573 220a 2020 2020 7d2c  ngtuples".    },
+00002160: 0a20 2020 2022 7072 6f78 795f 6164 6472  .    "proxy_addr
+00002170: 6573 7322 3a20 7b0a 2020 2020 2020 2020  ess": {.        
+00002180: 2264 6573 6372 6970 7469 6f6e 223a 2022  "description": "
+00002190: 5072 6f78 7920 4950 2061 6464 7265 7373  Proxy IP address
+000021a0: 206f 7220 646f 6d61 696e 206e 616d 6522   or domain name"
+000021b0: 2c0a 2020 2020 2020 2020 2265 7861 6d70  ,.        "examp
+000021c0: 6c65 7322 3a20 5b0a 2020 2020 2020 2020  les": [.        
+000021d0: 2020 2020 2262 6164 2e63 6f6d 222c 0a20      "bad.com",. 
+000021e0: 2020 2020 2020 2020 2020 2022 3130 2e31             "10.1
+000021f0: 312e 3130 2e31 3322 0a20 2020 2020 2020  1.10.13".       
+00002200: 205d 2c0a 2020 2020 2020 2020 2274 7970   ],.        "typ
+00002210: 6522 3a20 226c 6973 746f 6673 7472 696e  e": "listofstrin
+00002220: 6773 220a 2020 2020 7d2c 0a20 2020 2022  gs".    },.    "
+00002230: 7265 6769 7374 7279 6461 7461 223a 207b  registrydata": {
+00002240: 0a20 2020 2020 2020 2022 6465 7363 7269  .        "descri
+00002250: 7074 696f 6e22 3a20 2272 6567 6973 7472  ption": "registr
+00002260: 7920 7661 6c75 6520 6461 7461 2069 7465  y value data ite
+00002270: 6d22 2c20 0a20 2020 2020 2020 2022 6578  m", .        "ex
+00002280: 616d 706c 6573 223a 205b 0a20 2020 2020  amples": [.     
+00002290: 2020 2020 2020 2022 633a 5c5c 7570 6461         "c:\\upda
+000022a0: 7465 2e65 7865 222c 200a 2020 2020 2020  te.exe", .      
+000022b0: 2020 2020 2020 2233 220a 2020 2020 2020        "3".      
+000022c0: 2020 5d2c 200a 2020 2020 2020 2020 2274    ], .        "t
+000022d0: 7970 6522 3a20 226c 6973 746f 6673 7472  ype": "listofstr
+000022e0: 696e 6773 220a 2020 2020 7d2c 0a20 2020  ings".    },.   
+000022f0: 2022 7265 6769 7374 7279 7061 7468 223a   "registrypath":
+00002300: 207b 0a20 2020 2020 2020 2022 6465 7363   {.        "desc
+00002310: 7269 7074 696f 6e22 3a20 2261 2072 6567  ription": "a reg
+00002320: 6973 7472 7920 6b65 792c 2076 616c 7565  istry key, value
+00002330: 206e 616d 652c 2063 6f6d 6269 6e61 7469   name, combinati
+00002340: 6f6e 206f 6620 7468 6520 7477 6f22 2c20  on of the two", 
+00002350: 0a20 2020 2020 2020 2022 6578 616d 706c  .        "exampl
+00002360: 6573 223a 205b 0a20 2020 2020 2020 2020  es": [.         
+00002370: 2020 2022 484b 4c4d 5c5c 536f 6674 7761     "HKLM\\Softwa
+00002380: 7265 5c5c 4d69 6372 6f73 6f66 745c 5c57  re\\Microsoft\\W
+00002390: 696e 646f 7773 5c5c 4375 7272 656e 7456  indows\\CurrentV
+000023a0: 6572 7369 6f6e 5c5c 5275 6e5c 5c55 7064  ersion\\Run\\Upd
+000023b0: 6174 6572 222c 200a 2020 2020 2020 2020  ater", .        
+000023c0: 2020 2020 2248 4b4c 4d5c 5c53 7973 7465      "HKLM\\Syste
+000023d0: 6d5c 5c43 7572 7265 6e74 436f 6e74 726f  m\\CurrentContro
+000023e0: 6c53 6574 5c5c 5365 7276 6963 6573 5c5c  lSet\\Services\\
+000023f0: 706e 7073 7663 5c5c 7374 6172 7422 0a20  pnpsvc\\start". 
+00002400: 2020 2020 2020 205d 2c20 0a20 2020 2020         ], .     
+00002410: 2020 2022 7479 7065 223a 2022 6c69 7374     "type": "list
+00002420: 6f66 7374 7269 6e67 7322 0a20 2020 207d  ofstrings".    }
+00002430: 2c0a 2020 2020 2272 6567 6973 7472 7970  ,.    "registryp
+00002440: 6174 6864 6174 6122 3a20 7b0a 2020 2020  athdata": {.    
+00002450: 2020 2020 2264 6573 6372 6970 7469 6f6e      "description
+00002460: 223a 2022 6120 7475 706c 6520 6f66 2072  ": "a tuple of r
+00002470: 6567 6973 7472 7970 6174 6820 616e 6420  egistrypath and 
+00002480: 7265 6769 7374 7279 6461 7461 222c 0a20  registrydata",. 
+00002490: 2020 2020 2020 2022 6578 616d 706c 6573         "examples
+000024a0: 223a 205b 0a20 2020 2020 2020 2020 2020  ": [.           
+000024b0: 205b 0a20 2020 2020 2020 2020 2020 2020   [.             
+000024c0: 2020 2022 484b 4c4d 5c5c 536f 6674 7761     "HKLM\\Softwa
+000024d0: 7265 5c5c 4d69 6372 6f73 6f66 745c 5c57  re\\Microsoft\\W
+000024e0: 696e 646f 7773 5c5c 4375 7272 656e 7456  indows\\CurrentV
+000024f0: 6572 7369 6f6e 5c5c 5275 6e5c 5c55 7064  ersion\\Run\\Upd
+00002500: 6174 6572 222c 200a 2020 2020 2020 2020  ater", .        
+00002510: 2020 2020 2020 2020 2263 3a5c 5c75 7064          "c:\\upd
+00002520: 6174 652e 6578 6522 0a20 2020 2020 2020  ate.exe".       
+00002530: 2020 2020 205d 2c20 0a20 2020 2020 2020       ], .       
+00002540: 2020 2020 205b 0a20 2020 2020 2020 2020       [.         
+00002550: 2020 2020 2020 2022 484b 4c4d 5c5c 5379         "HKLM\\Sy
+00002560: 7374 656d 5c5c 4375 7272 656e 7443 6f6e  stem\\CurrentCon
+00002570: 7472 6f6c 5365 745c 5c53 6572 7669 6365  trolSet\\Service
+00002580: 735c 5c70 6e70 7376 635c 5c73 7461 7274  s\\pnpsvc\\start
+00002590: 222c 200a 2020 2020 2020 2020 2020 2020  ", .            
+000025a0: 2020 2020 2233 220a 2020 2020 2020 2020      "3".        
+000025b0: 2020 2020 5d0a 2020 2020 2020 2020 5d2c      ].        ],
+000025c0: 200a 2020 2020 2020 2020 2274 7970 6522   .        "type"
+000025d0: 3a20 226c 6973 746f 6673 7472 696e 6774  : "listofstringt
+000025e0: 7570 6c65 7322 0a20 2020 207d 2c0a 2020  uples".    },.  
+000025f0: 2020 2272 7361 5f70 7269 7661 7465 5f6b    "rsa_private_k
+00002600: 6579 223a 207b 0a20 2020 2020 2020 2022  ey": {.        "
+00002610: 6465 7363 7269 7074 696f 6e22 3a20 2252  description": "R
+00002620: 5341 2070 7269 7661 7465 206b 6579 2074  SA private key t
+00002630: 7570 6c65 2063 6f6e 7461 696e 696e 673a  uple containing:
+00002640: 2070 7562 6c69 635f 6578 706f 6e65 6e74   public_exponent
+00002650: 2c20 6d6f 6475 6c75 732c 2070 7269 7661  , modulus, priva
+00002660: 7465 5f65 7870 6f6e 656e 7420 2864 292c  te_exponent (d),
+00002670: 2070 2c20 712c 2064 206d 6f64 2028 702d   p, q, d mod (p-
+00002680: 3129 2c20 6420 6d6f 6420 2871 2d31 292c  1), d mod (q-1),
+00002690: 2071 2069 6e76 206d 6f64 2070 222c 0a20   q inv mod p",. 
+000026a0: 2020 2020 2020 2022 6578 616d 706c 6573         "examples
+000026b0: 223a 205b 0a20 2020 2020 2020 2020 2020  ": [.           
+000026c0: 205b 0a20 2020 2020 2020 2020 2020 2020   [.             
+000026d0: 2020 2022 3078 3037 222c 0a20 2020 2020     "0x07",.     
+000026e0: 2020 2020 2020 2020 2020 2022 3078 6262             "0xbb
+000026f0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00002700: 2020 2022 3078 3137 222c 0a20 2020 2020     "0x17",.     
+00002710: 2020 2020 2020 2020 2020 2022 3078 3131             "0x11
+00002720: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00002730: 2020 2022 3078 3062 222c 0a20 2020 2020     "0x0b",.     
+00002740: 2020 2020 2020 2020 2020 2022 3078 3037             "0x07
+00002750: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00002760: 2020 2022 3078 3033 222c 0a20 2020 2020     "0x03",.     
+00002770: 2020 2020 2020 2020 2020 2022 3078 3065             "0x0e
+00002780: 220a 2020 2020 2020 2020 2020 2020 5d0a  ".            ].
+00002790: 2020 2020 2020 2020 5d2c 0a20 2020 2020          ],.     
+000027a0: 2020 2022 7479 7065 223a 2022 6c69 7374     "type": "list
+000027b0: 6f66 7374 7269 6e67 7475 706c 6573 220a  ofstringtuples".
+000027c0: 2020 2020 7d2c 0a20 2020 2022 7273 615f      },.    "rsa_
+000027d0: 7075 626c 6963 5f6b 6579 223a 207b 0a20  public_key": {. 
+000027e0: 2020 2020 2020 2022 6465 7363 7269 7074         "descript
+000027f0: 696f 6e22 3a20 2252 5341 2070 7562 6c69  ion": "RSA publi
+00002800: 6320 6b65 7920 7475 706c 6520 636f 6e74  c key tuple cont
+00002810: 6169 6e69 6e67 3a20 7075 626c 6963 5f65  aining: public_e
+00002820: 7870 6f6e 656e 742c 206d 6f64 756c 7573  xponent, modulus
+00002830: 222c 0a20 2020 2020 2020 2022 6578 616d  ",.        "exam
+00002840: 706c 6573 223a 205b 0a20 2020 2020 2020  ples": [.       
+00002850: 2020 2020 205b 0a20 2020 2020 2020 2020       [.         
+00002860: 2020 2020 2020 2022 3078 3037 222c 0a20         "0x07",. 
+00002870: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00002880: 3078 6262 220a 2020 2020 2020 2020 2020  0xbb".          
+00002890: 2020 5d0a 2020 2020 2020 2020 5d2c 0a20    ].        ],. 
+000028a0: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
+000028b0: 6c69 7374 6f66 7374 7269 6e67 7475 706c  listofstringtupl
+000028c0: 6573 220a 2020 2020 7d2c 0a20 2020 2022  es".    },.    "
+000028d0: 7365 7276 6963 6522 3a20 7b0a 2020 2020  service": {.    
+000028e0: 2020 2020 2264 6573 6372 6970 7469 6f6e      "description
+000028f0: 223a 2022 4120 7475 706c 6520 6f66 2073  ": "A tuple of s
+00002900: 6572 7669 6365 6e61 6d65 2c20 7365 7276  ervicename, serv
+00002910: 6963 6564 6973 706c 6179 6e61 6d65 2c20  icedisplayname, 
+00002920: 7365 7276 6963 6564 6573 6372 6970 7469  servicedescripti
+00002930: 6f6e 2c20 7365 7276 6963 6569 6d61 6765  on, serviceimage
+00002940: 2061 6e64 2073 6572 7669 6365 646c 6c22   and servicedll"
+00002950: 2c20 0a20 2020 2020 2020 2022 6578 616d  , .        "exam
+00002960: 706c 6573 223a 205b 0a20 2020 2020 2020  ples": [.       
+00002970: 2020 2020 205b 0a20 2020 2020 2020 2020       [.         
+00002980: 2020 2020 2020 2022 5769 6e64 6f77 7355         "WindowsU
+00002990: 7365 724d 616e 6167 656d 656e 7422 2c20  serManagement", 
+000029a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000029b0: 2022 5769 6e64 6f77 7320 5573 6572 204d   "Windows User M
+000029c0: 616e 6167 656d 656e 7422 2c20 0a20 2020  anagement", .   
+000029d0: 2020 2020 2020 2020 2020 2020 2022 5072               "Pr
+000029e0: 6f76 6964 6573 2061 2063 6f6d 6d6f 6e20  ovides a common 
+000029f0: 6d61 6e61 6765 6d65 6e74 2074 6f20 6163  management to ac
+00002a00: 6365 7373 2069 6e66 6f72 6d61 7469 6f6e  cess information
+00002a10: 2061 626f 7574 2077 696e 646f 7773 2075   about windows u
+00002a20: 7365 722e 222c 200a 2020 2020 2020 2020  ser.", .        
+00002a30: 2020 2020 2020 2020 2225 5379 7374 656d          "%System
+00002a40: 255c 5c73 766f 686f 7374 2e65 7865 222c  %\\svohost.exe",
+00002a50: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+00002a60: 2020 2222 0a20 2020 2020 2020 2020 2020    "".           
+00002a70: 205d 2c20 0a20 2020 2020 2020 2020 2020   ], .           
+00002a80: 205b 0a20 2020 2020 2020 2020 2020 2020   [.             
+00002a90: 2020 2022 706e 7073 7663 222c 200a 2020     "pnpsvc", .  
+00002aa0: 2020 2020 2020 2020 2020 2020 2020 2250                "P
+00002ab0: 6c75 6720 616e 6420 506c 6179 2073 7663  lug and Play svc
+00002ac0: 2073 6572 7669 6365 222c 200a 2020 2020   service", .    
+00002ad0: 2020 2020 2020 2020 2020 2020 2250 726f              "Pro
+00002ae0: 7669 6465 7320 706c 7567 2061 6e64 2070  vides plug and p
+00002af0: 6c61 7920 7376 6320 6465 7669 6365 7320  lay svc devices 
+00002b00: 7375 7070 6f72 7422 2c20 0a20 2020 2020  support", .     
+00002b10: 2020 2020 2020 2020 2020 2022 433a 5c5c             "C:\\
+00002b20: 5769 6e64 6f77 735c 5c53 7973 7465 6d33  Windows\\System3
+00002b30: 325c 5c72 756e 646c 6c33 322e 6578 6520  2\\rundll32.exe 
+00002b40: 433a 5c5c 5769 6e64 6f77 735c 5c54 656d  C:\\Windows\\Tem
+00002b50: 705c 5c31 2e74 6d70 222c 200a 2020 2020  p\\1.tmp", .    
+00002b60: 2020 2020 2020 2020 2020 2020 2243 3a5c              "C:\
+00002b70: 5c57 696e 646f 7773 5c5c 5465 6d70 5c5c  \Windows\\Temp\\
+00002b80: 312e 746d 7022 0a20 2020 2020 2020 2020  1.tmp".         
+00002b90: 2020 205d 0a20 2020 2020 2020 205d 2c20     ].        ], 
+00002ba0: 0a20 2020 2020 2020 2022 7479 7065 223a  .        "type":
+00002bb0: 2022 6c69 7374 6f66 7374 7269 6e67 7475   "listofstringtu
+00002bc0: 706c 6573 220a 2020 2020 7d2c 200a 2020  ples".    }, .  
+00002bd0: 2020 2273 6572 7669 6365 6465 7363 7269    "servicedescri
+00002be0: 7074 696f 6e22 3a20 7b0a 2020 2020 2020  ption": {.      
+00002bf0: 2020 2264 6573 6372 6970 7469 6f6e 223a    "description":
+00002c00: 2022 6465 7363 7269 7074 696f 6e20 666f   "description fo
+00002c10: 7220 6120 7365 7276 6963 6522 2c20 0a20  r a service", . 
+00002c20: 2020 2020 2020 2022 6578 616d 706c 6573         "examples
+00002c30: 223a 205b 0a20 2020 2020 2020 2020 2020  ": [.           
+00002c40: 2022 5072 6f76 6964 6573 2061 2063 6f6d   "Provides a com
+00002c50: 6d6f 6e20 6d61 6e61 6765 6d65 6e74 2074  mon management t
+00002c60: 6f20 6163 6365 7373 2069 6e66 6f72 6d61  o access informa
+00002c70: 7469 6f6e 2061 626f 7574 2077 696e 646f  tion about windo
+00002c80: 7773 2075 7365 722e 222c 200a 2020 2020  ws user.", .    
+00002c90: 2020 2020 2020 2020 2250 726f 7669 6465          "Provide
+00002ca0: 7320 706c 7567 2061 6e64 2070 6c61 7920  s plug and play 
+00002cb0: 7376 6320 6465 7669 6365 7320 7375 7070  svc devices supp
+00002cc0: 6f72 7422 0a20 2020 2020 2020 205d 2c20  ort".        ], 
+00002cd0: 0a20 2020 2020 2020 2022 7479 7065 223a  .        "type":
+00002ce0: 2022 6c69 7374 6f66 7374 7269 6e67 7322   "listofstrings"
+00002cf0: 0a20 2020 207d 2c20 0a20 2020 2022 7365  .    }, .    "se
+00002d00: 7276 6963 6564 6973 706c 6179 6e61 6d65  rvicedisplayname
+00002d10: 223a 207b 0a20 2020 2020 2020 2022 6465  ": {.        "de
+00002d20: 7363 7269 7074 696f 6e22 3a20 2264 6973  scription": "dis
+00002d30: 706c 6179 6e61 6d65 2066 6f72 2061 2073  playname for a s
+00002d40: 6572 7669 6365 222c 200a 2020 2020 2020  ervice", .      
+00002d50: 2020 2265 7861 6d70 6c65 7322 3a20 5b0a    "examples": [.
+00002d60: 2020 2020 2020 2020 2020 2020 2257 696e              "Win
+00002d70: 646f 7773 2055 7365 7220 4d61 6e61 6765  dows User Manage
+00002d80: 6d65 6e74 222c 200a 2020 2020 2020 2020  ment", .        
+00002d90: 2020 2020 2250 6c75 6720 616e 6420 506c      "Plug and Pl
+00002da0: 6179 2073 7663 2073 6572 7669 6365 220a  ay svc service".
+00002db0: 2020 2020 2020 2020 5d2c 200a 2020 2020          ], .    
+00002dc0: 2020 2020 2274 7970 6522 3a20 226c 6973      "type": "lis
+00002dd0: 746f 6673 7472 696e 6773 220a 2020 2020  tofstrings".    
+00002de0: 7d2c 200a 2020 2020 2273 6572 7669 6365  }, .    "service
+00002df0: 646c 6c22 3a20 7b0a 2020 2020 2020 2020  dll": {.        
+00002e00: 2264 6573 6372 6970 7469 6f6e 223a 2022  "description": "
+00002e10: 2e64 6c6c 2075 7365 6420 6279 2073 6572  .dll used by ser
+00002e20: 7669 6365 2c20 6966 2061 6e79 222c 200a  vice, if any", .
+00002e30: 2020 2020 2020 2020 2265 7861 6d70 6c65          "example
+00002e40: 7322 3a20 5b0a 2020 2020 2020 2020 2020  s": [.          
+00002e50: 2020 2222 2c20 0a20 2020 2020 2020 2020    "", .         
+00002e60: 2020 2022 433a 5c5c 5769 6e64 6f77 735c     "C:\\Windows\
+00002e70: 5c54 656d 705c 5c31 2e74 6d70 220a 2020  \Temp\\1.tmp".  
+00002e80: 2020 2020 2020 5d2c 200a 2020 2020 2020        ], .      
+00002e90: 2020 2274 7970 6522 3a20 226c 6973 746f    "type": "listo
+00002ea0: 6673 7472 696e 6773 220a 2020 2020 7d2c  fstrings".    },
+00002eb0: 200a 2020 2020 2273 6572 7669 6365 696d   .    "serviceim
+00002ec0: 6167 6522 3a20 7b0a 2020 2020 2020 2020  age": {.        
+00002ed0: 2264 6573 6372 6970 7469 6f6e 223a 2022  "description": "
+00002ee0: 696d 6167 6570 6174 6820 666f 7220 6120  imagepath for a 
+00002ef0: 7365 7276 6963 652e 2054 6869 7320 7479  service. This ty
+00002f00: 7069 6361 6c6c 7920 696e 636c 7564 6573  pically includes
+00002f10: 2074 6865 2070 6174 6820 746f 2074 6865   the path to the
+00002f20: 2065 7865 6375 7461 626c 6520 616e 6420   executable and 
+00002f30: 616e 7920 636f 6d6d 616e 6420 6c69 6e65  any command line
+00002f40: 206f 7074 696f 6e73 2e22 2c20 0a20 2020   options.", .   
+00002f50: 2020 2020 2022 6578 616d 706c 6573 223a       "examples":
+00002f60: 205b 0a20 2020 2020 2020 2020 2020 2022   [.            "
+00002f70: 2553 7973 7465 6d25 5c5c 7376 6f68 6f73  %System%\\svohos
+00002f80: 742e 6578 6522 2c20 0a20 2020 2020 2020  t.exe", .       
+00002f90: 2020 2020 2022 433a 5c5c 5769 6e64 6f77       "C:\\Window
+00002fa0: 735c 5c53 7973 7465 6d33 325c 5c72 756e  s\\System32\\run
+00002fb0: 646c 6c33 322e 6578 6520 433a 5c5c 5769  dll32.exe C:\\Wi
+00002fc0: 6e64 6f77 735c 5c54 656d 705c 5c31 2e74  ndows\\Temp\\1.t
+00002fd0: 6d70 220a 2020 2020 2020 2020 5d2c 200a  mp".        ], .
+00002fe0: 2020 2020 2020 2020 2274 7970 6522 3a20          "type": 
+00002ff0: 226c 6973 746f 6673 7472 696e 6773 220a  "listofstrings".
+00003000: 2020 2020 7d2c 200a 2020 2020 2273 6572      }, .    "ser
+00003010: 7669 6365 6e61 6d65 223a 207b 0a20 2020  vicename": {.   
+00003020: 2020 2020 2022 6465 7363 7269 7074 696f       "descriptio
+00003030: 6e22 3a20 226e 616d 6520 666f 7220 6120  n": "name for a 
+00003040: 7365 7276 6963 6522 2c20 0a20 2020 2020  service", .     
+00003050: 2020 2022 6578 616d 706c 6573 223a 205b     "examples": [
+00003060: 0a20 2020 2020 2020 2020 2020 2022 5769  .            "Wi
+00003070: 6e64 6f77 7355 7365 724d 616e 6167 656d  ndowsUserManagem
+00003080: 656e 7422 2c20 0a20 2020 2020 2020 2020  ent", .         
+00003090: 2020 2022 706e 7073 7663 220a 2020 2020     "pnpsvc".    
+000030a0: 2020 2020 5d2c 200a 2020 2020 2020 2020      ], .        
+000030b0: 2274 7970 6522 3a20 226c 6973 746f 6673  "type": "listofs
+000030c0: 7472 696e 6773 220a 2020 2020 7d2c 200a  trings".    }, .
+000030d0: 2020 2020 2273 6f63 6b65 7461 6464 7265      "socketaddre
+000030e0: 7373 223a 207b 0a20 2020 2020 2020 2022  ss": {.        "
+000030f0: 6465 7363 7269 7074 696f 6e22 3a20 2241  description": "A
+00003100: 6e20 6164 6472 6573 732c 2070 6f72 742c  n address, port,
+00003110: 2061 6e64 2070 726f 746f 2063 6f6d 6269   and proto combi
+00003120: 6e61 7469 6f6e 2075 7365 6420 746f 6765  nation used toge
+00003130: 7468 6572 222c 200a 2020 2020 2020 2020  ther", .        
+00003140: 2265 7861 6d70 6c65 7322 3a20 5b0a 2020  "examples": [.  
+00003150: 2020 2020 2020 2020 2020 5b0a 2020 2020            [.    
+00003160: 2020 2020 2020 2020 2020 2020 2262 6164              "bad
+00003170: 2e63 6f6d 222c 200a 2020 2020 2020 2020  .com", .        
+00003180: 2020 2020 2020 2020 2232 3122 2c20 0a20          "21", . 
+00003190: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000031a0: 7463 7022 0a20 2020 2020 2020 2020 2020  tcp".           
+000031b0: 205d 2c20 0a20 2020 2020 2020 2020 2020   ], .           
+000031c0: 205b 0a20 2020 2020 2020 2020 2020 2020   [.             
+000031d0: 2020 2022 3130 2e31 312e 3130 2e31 3322     "10.11.10.13"
+000031e0: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+000031f0: 2020 2022 3434 3322 2c20 0a20 2020 2020     "443", .     
+00003200: 2020 2020 2020 2020 2020 2022 7463 7022             "tcp"
+00003210: 0a20 2020 2020 2020 2020 2020 205d 0a20  .            ]. 
+00003220: 2020 2020 2020 205d 2c20 0a20 2020 2020         ], .     
+00003230: 2020 2022 7479 7065 223a 2022 6c69 7374     "type": "list
+00003240: 6f66 7374 7269 6e67 7475 706c 6573 220a  ofstringtuples".
+00003250: 2020 2020 7d2c 0a20 2020 2022 7373 6c5f      },.    "ssl_
+00003260: 6365 7274 5f73 6861 3122 3a20 7b0a 2020  cert_sha1": {.  
+00003270: 2020 2020 2020 2264 6573 6372 6970 7469        "descripti
+00003280: 6f6e 223a 2022 5353 4c20 4365 7274 6966  on": "SSL Certif
+00003290: 6963 6174 6520 5348 412d 3120 4861 7368  icate SHA-1 Hash
+000032a0: 222c 0a20 2020 2020 2020 2022 6578 616d  ",.        "exam
+000032b0: 706c 6573 223a 205b 0a20 2020 2020 2020  ples": [.       
+000032c0: 2020 2020 2022 6332 3964 3739 6466 3962       "c29d79df9b
+000032d0: 3534 3136 6664 3431 3663 3331 6535 3763  5416fd416c31e57c
+000032e0: 6435 3235 6466 6332 3361 3866 3636 220a  d525dfc23a8f66".
+000032f0: 2020 2020 2020 2020 5d2c 0a20 2020 2020          ],.     
+00003300: 2020 2022 7479 7065 223a 2022 6c69 7374     "type": "list
+00003310: 6f66 7374 7269 6e67 7322 0a20 2020 207d  ofstrings".    }
+00003320: 2c0a 2020 2020 2275 726c 223a 207b 0a20  ,.    "url": {. 
+00003330: 2020 2020 2020 2022 6465 7363 7269 7074         "descript
+00003340: 696f 6e22 3a20 2266 756c 6c20 5552 4c20  ion": "full URL 
+00003350: 7769 7468 2073 6368 656d 652c 2061 6464  with scheme, add
+00003360: 7265 7373 2c20 6f70 7469 6f6e 616c 2070  ress, optional p
+00003370: 6f72 742c 2061 6e64 206f 7074 696f 6e61  ort, and optiona
+00003380: 6c20 7061 7468 222c 200a 2020 2020 2020  l path", .      
+00003390: 2020 2265 7861 6d70 6c65 7322 3a20 5b0a    "examples": [.
+000033a0: 2020 2020 2020 2020 2020 2020 2268 7474              "htt
+000033b0: 703a 2f2f 6d61 6c2e 636f 6d2f 7669 6577  p://mal.com/view
+000033c0: 2e61 7370 222c 200a 2020 2020 2020 2020  .asp", .        
+000033d0: 2020 2020 2268 7474 7073 3a2f 2f31 302e      "https://10.
+000033e0: 3131 2e31 302e 3133 3a34 3433 2f69 6d61  11.10.13:443/ima
+000033f0: 6765 732f 6261 6e65 722e 6a70 6722 0a20  ges/baner.jpg". 
+00003400: 2020 2020 2020 205d 2c20 0a20 2020 2020         ], .     
+00003410: 2020 2022 7479 7065 223a 2022 6c69 7374     "type": "list
+00003420: 6f66 7374 7269 6e67 7322 0a20 2020 207d  ofstrings".    }
+00003430: 2c20 0a20 2020 2022 7572 6c70 6174 6822  , .    "urlpath"
+00003440: 3a20 7b0a 2020 2020 2020 2020 2264 6573  : {.        "des
+00003450: 6372 6970 7469 6f6e 223a 2022 7061 7468  cription": "path
+00003460: 2070 6f72 7469 6f6e 206f 6620 5552 4c22   portion of URL"
+00003470: 2c20 0a20 2020 2020 2020 2022 6578 616d  , .        "exam
+00003480: 706c 6573 223a 205b 0a20 2020 2020 2020  ples": [.       
+00003490: 2020 2020 2022 2f76 6965 772e 6173 7022       "/view.asp"
+000034a0: 2c20 0a20 2020 2020 2020 2020 2020 2022  , .            "
+000034b0: 2f69 6d61 6765 732f 6261 6e65 722e 6a70  /images/baner.jp
+000034c0: 6722 0a20 2020 2020 2020 205d 2c20 0a20  g".        ], . 
+000034d0: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
+000034e0: 6c69 7374 6f66 7374 7269 6e67 7322 0a20  listofstrings". 
+000034f0: 2020 207d 2c20 0a20 2020 2022 7573 6572     }, .    "user
+00003500: 6167 656e 7422 3a20 7b0a 2020 2020 2020  agent": {.      
+00003510: 2020 2264 6573 6372 6970 7469 6f6e 223a    "description":
+00003520: 2022 736f 6674 7761 7265 2069 6465 6e74   "software ident
+00003530: 6966 6965 7220 7573 6564 2062 7920 6d61  ifier used by ma
+00003540: 6c77 6172 6522 2c20 0a20 2020 2020 2020  lware", .       
+00003550: 2022 6578 616d 706c 6573 223a 205b 0a20   "examples": [. 
+00003560: 2020 2020 2020 2020 2020 2022 4d6f 7a69             "Mozi
+00003570: 6c6c 612f 342e 3020 2863 6f6d 7061 7469  lla/4.0 (compati
+00003580: 626c 653b 204d 4953 4520 362e 303b 2057  ble; MISE 6.0; W
+00003590: 696e 646f 7773 204e 5420 352e 3229 222c  indows NT 5.2)",
+000035a0: 200a 2020 2020 2020 2020 2020 2020 2231   .            "1
+000035b0: 3333 3768 7474 7022 0a20 2020 2020 2020  337http".       
+000035c0: 205d 2c20 0a20 2020 2020 2020 2022 7479   ], .        "ty
+000035d0: 7065 223a 2022 6c69 7374 6f66 7374 7269  pe": "listofstri
+000035e0: 6e67 7322 0a20 2020 207d 2c20 0a20 2020  ngs".    }, .   
+000035f0: 2022 7573 6572 6e61 6d65 223a 207b 0a20   "username": {. 
+00003600: 2020 2020 2020 2022 6465 7363 7269 7074         "descript
+00003610: 696f 6e22 3a20 2275 7365 726e 616d 6520  ion": "username 
+00003620: 7573 6564 2062 7920 6d61 6c77 6172 6522  used by malware"
+00003630: 2c20 0a20 2020 2020 2020 2022 6578 616d  , .        "exam
+00003640: 706c 6573 223a 205b 0a20 2020 2020 2020  ples": [.       
+00003650: 2020 2020 2022 4875 6e74 6572 222c 200a       "Hunter", .
+00003660: 2020 2020 2020 2020 2020 2020 2261 646d              "adm
+00003670: 696e 220a 2020 2020 2020 2020 5d2c 200a  in".        ], .
+00003680: 2020 2020 2020 2020 2274 7970 6522 3a20          "type": 
+00003690: 226c 6973 746f 6673 7472 696e 6773 220a  "listofstrings".
+000036a0: 2020 2020 7d2c 200a 2020 2020 2276 6572      }, .    "ver
+000036b0: 7369 6f6e 223a 207b 0a20 2020 2020 2020  sion": {.       
+000036c0: 2022 6465 7363 7269 7074 696f 6e22 3a20   "description": 
+000036d0: 2274 6865 2076 6572 7369 6f6e 206f 6620  "the version of 
+000036e0: 7468 6520 6d61 6c77 6172 652e 2054 6f20  the malware. To 
+000036f0: 7468 6520 6465 6772 6565 2070 6f73 7369  the degree possi
+00003700: 626c 6520 7468 6973 2073 686f 756c 6420  ble this should 
+00003710: 6265 2062 6173 6564 2064 6972 6563 746c  be based directl
+00003720: 7920 6f6e 2061 7274 6966 6163 7473 2066  y on artifacts f
+00003730: 726f 6d20 7468 6520 6d61 6c77 6172 6522  rom the malware"
+00003740: 2c20 0a20 2020 2020 2020 2022 6578 616d  , .        "exam
+00003750: 706c 6573 223a 205b 0a20 2020 2020 2020  ples": [.       
+00003760: 2020 2020 2022 3322 2c20 0a20 2020 2020       "3", .     
+00003770: 2020 2020 2020 2022 696e 6372 656d 656e         "incremen
+00003780: 7469 6e67 2058 4f52 2065 6e63 6f64 696e  ting XOR encodin
+00003790: 6722 0a20 2020 2020 2020 205d 2c20 0a20  g".        ], . 
+000037a0: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
+000037b0: 6c69 7374 6f66 7374 7269 6e67 7322 0a20  listofstrings". 
+000037c0: 2020 207d 0a7d 0a                           }.}.
```

### Comparing `mwcp-3.8.0/mwcp/dispatcher.py` & `mwcp-3.9.0/mwcp/dispatcher.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,346 +1,346 @@
-"""
-Implements a data pump for extracted file data which allows for
-more robust file identification, reporting, and objectifying
-content to ease maintenance.
-"""
-
-import logging
-import warnings
-from collections import deque
-
-from mwcp import metadata
-from mwcp.exceptions import UnableToParse
-from mwcp.file_object import FileObject
-from mwcp.parser import Parser
-from mwcp.report import Report
-
-logger = logging.getLogger(__name__)
-
-
-class UnidentifiedFile(Parser):
-    """Describes an unidentified file. This parser will hit on any FileObject."""
-
-    DESCRIPTION = "Unidentified file"
-
-    @classmethod
-    def identify(cls, file_object):
-        """
-        Identifies an unidentified file... which means this is always True.
-
-        :param file_object: dispatcher.FileObject object
-        :return: Boolean indicating identification
-        """
-        return True
-
-
-# NOTE: This object is duck typed to look like a Parser object to allow recursion.
-# TODO: Create abstract inteface for these two.
-class Dispatcher(object):
-    # TODO: Rewrite this documentation.
-    """
-    This class will continuously process items that are in the queue.  When the queue is empty,
-    this will ultimately signal that processing is complete and the script will terminate.
-    This class will process the items using the supplied list of Parser classes provided.
-
-    This class can be used as a mixin along with the Parser class or
-    can be initialized by itself.
-    When used as a mixin, the dispatcher will automatically add the file in the reporter
-    to the queue and run dispatch() when run() is called.
-    """
-
-    # Caches results for identification to improve speed.
-    _identify_cache = {}
-
-    def __init__(
-        self,
-        name,
-        source,
-        author="",
-        description="",
-        parsers=None,
-        greedy=False,
-        default=UnidentifiedFile,
-        output_unidentified=True,
-        overwrite_descriptions=False,
-        embedded=False,
-    ):
-        """
-        Initializes the Dispatcher with the given parsers to run.
-
-        :param str name: Unique name to give to this group of parsers.
-        :param str source: Name of source this group comes from.
-        :param str author: Author of the parser.
-        :param str description: Description of the parser.
-        :param list parsers: A list of parser classes (or other dispatchers) to use for detection and running.
-            Order of this list is the order the Dispatcher will perform its identification.
-            If not provided, it will default to an empty list.
-        :param bool greedy: By default, the dispatcher will only run on the first parser it detects
-            to be a valid parser. If greedy is set to true, the dispatcher will try all parsers
-            even if a previous parser was successful.
-        :param ComponentParser default: The Parser class to default to if no parsers in the parsers list
-            has identified it. If set to None, no parser will be run as default.
-            (By default, the dispatcher.UnidentifiedFile will be run.)
-        :param bool output_unidentified: Whether to output files that have not been identified by
-            any parsers.
-        :param bool overwrite_descriptions: Whether to allow dispatcher to overwrite any previous
-            set description with the parser's
-        :param bool embedded: If True, all dispatched files will be passed up to the parent
-            dispatcher instead of being processed locally.
-            Ie, this is the equivalent of embedding the listed parsers directly into the parent's list.
-        """
-        self.name = name
-        self.source = source
-        # TODO: Deprecate the author attribute?
-        self.AUTHOR = author
-        self.DESCRIPTION = description  # In all caps to match Parser interface
-        self.TAGS = ()
-        self.parsers = parsers or []
-        self.greedy = greedy
-        self.default = default
-        self._fifo_buffer = deque()
-        self._current_file_object = None
-        self._current_parser = None
-        self._output_unidentified = output_unidentified
-        self._overwrite_descriptions = overwrite_descriptions
-        self._embedded = embedded
-
-        # Dictionary that can be used by parsers to pass variables across parsers.
-        # E.g. an encryption key found in the loader to be used by the implant.
-        self.knowledge_base = {}
-
-    def __repr__(self):
-        return "{}({})".format(self.name, ", ".join(repr(parser) for parser in self.parsers))
-
-    def identify(self, file_object):
-        """
-        Determines if this dispatcher is identified to support the given file_object.
-
-        :param file_object: file object to use for identification
-        :type file_object: dispatcher.FileObject
-
-        :return bool: Boolean indicating if this dispatcher supports the file_object
-        """
-        return any(self._identify_parsers(file_object))
-
-    def add_to_queue(self, file_object: FileObject, parent: FileObject = None):
-        warnings.warn(
-            "add_to_queue() has been renamed to add()",
-            DeprecationWarning
-        )
-        self.add(file_object, parent=parent)
-
-    def add(self, file_object: FileObject, parent: FileObject = None):
-        """
-        Add a FileObject to the FIFO queue for processing.
-        :param file_object: a FileObject object requiring processing.
-        :param parent: original parent for given file_object.
-            If not provided, the parent is assumed to be the file being currently
-            processed. (which should be true most of the time)
-
-        :return:
-        """
-        if not parent:
-            parent = self._current_file_object
-        assert isinstance(file_object, FileObject), "Not a FileObject: {!r}".format(file_object)
-
-        # FIXME: Disabled for now.
-        # if parent == file_object:
-        #     # Letting this be info instead of warning, since it is not necessarily
-        #     # a problem. (e.g. deobfuscation parser runs on already deobfuscated file)
-        #     logger.info(f"{parent.name} dispatched itself, ignoring...")
-        #     return
-
-        # If we already have a parent, this means this file is trickling up from a sub-dispatcher.
-        # Don't duplicate logs or change the parent.
-        if not file_object.parent:
-            file_object.parent = parent
-            if parent:
-                parent.children.append(file_object)
-                logger.info(f"{parent.name} dispatched residual file: {file_object.name}")
-                if file_object.description:
-                    logger.info(f"File {file_object.name} described as {file_object.description}")
-
-        self._fifo_buffer.appendleft(file_object)
-
-    def _identify_parsers(self, file_object: FileObject):
-        """
-        Generator that detects and yields identified parsers to run based on given file_object.
-
-        :param file_object: file object that needs to be identified
-
-        :yields: Identified Parser class or another Dispatcher that can be run
-        """
-        for parser in self.parsers:
-            logger.debug(u"Identifying {} with {!r}.".format(file_object.name, parser))
-
-            # First see if result has been cached.
-            key = (parser, file_object)
-            if key in self._identify_cache:
-                ret = self._identify_cache[key]
-            else:
-                ret = parser.identify(file_object)
-                self._identify_cache[key] = ret
-
-            if isinstance(ret, tuple) and isinstance(ret[0], bool):
-                identified, *rest = ret
-                rest = tuple(rest)
-            else:
-                identified = ret
-                rest = tuple()
-
-            if identified:
-                yield parser, rest
-
-    def _parse(self, file_object, parser, report, *run_args):
-        """
-        Parse given file_object with given sub parser
-
-        :raises UnableToParse: If the subparser raised an error.
-        """
-        self._current_file_object = file_object
-        self._current_parser = parser
-
-        # If a description wasn't set for the file, use the parser's
-        # (But ignore setting it for sub dispatchers)
-        orig_description = file_object.description
-        if (not file_object.description or self._overwrite_descriptions) and not isinstance(parser, Dispatcher):
-            file_object.description = parser.DESCRIPTION
-
-        # Add tags to the file.
-        orig_tags = set(file_object.tags)
-        for tag in parser.TAGS:
-            file_object.add_tag(tag)
-
-        # Set parser class used in order to keep a history.
-        orig_parser = file_object.parser
-        file_object.parser = parser
-
-        try:
-            parser.parse(file_object, report, *run_args, dispatcher=self)
-        except UnableToParse as exception:
-            # Undo setting parser metadata to file if we misidentify.
-            file_object.description = orig_description
-            file_object.tags = orig_tags
-            file_object.parser = orig_parser
-
-            # Mark identify cache as failure, so we don't need to go through this again.
-            self._identify_cache[(parser, file_object)] = False
-
-            # Log to user before reraising.
-            if isinstance(parser, Dispatcher):
-                # Parser is a group, change wording
-                logger.info(
-                    f"File {file_object.file_name} was misidentified with {parser.DESCRIPTION} parser, due to: "
-                    f"({exception}) Trying other parsers..."
-                )
-            else:
-                logger.info(
-                    f"File {file_object.file_name} was misidentified as {parser.DESCRIPTION}, due to: "
-                    f"({exception}) Trying other parsers..."
-                )
-            raise
-        except Exception:
-            logger.exception(u"{} dispatch parser failed".format(parser.name))
-
-    def parse(self, file_object: FileObject, report: Report, *run_args, dispatcher: "Dispatcher" = None):
-        """
-        Runs dispatcher on given file_object.
-
-        :param file_object: Object containing data about component file.
-        :param report: Report object to be filled in.
-        :param run_args: Extra arguments returned from identify() to pass to run() function.
-        :param dispatcher: reference to the parent dispatcher object that called this parse command.
-            (None if this dispatcher is the root)
-        :return:
-        """
-        parent = dispatcher
-        orig_file_object = file_object
-        self.add(file_object)
-
-        # Pull knowledge_base from previous dispatcher.
-        if parent:
-            self.knowledge_base = parent.knowledge_base
-
-        while self._fifo_buffer:
-            file_object = self._fifo_buffer.pop()
-            first = file_object is orig_file_object
-
-            # If this dispatcher is embedded, simply pass any dispatched files to the parent.
-            if self._embedded and parent and not first:
-                parent.add(file_object)
-                continue
-
-            identified = False
-            unable_to_parse_error = None
-
-            try:
-                # If file has already been parsed, don't bother running it again.
-                # (This also helps with cyclic loops)
-                # FIXME: Disabled until we can fix bug with greedy parsers.
-                if file_object.md5 in report.parsed_files and False:
-                    logger.info(f"File {file_object.name} has already been parsed. Ignoring...")
-                    # Copy file description from the already parsed version and mark as duplicate.
-                    parsed_file = report.parsed_files[file_object.md5]
-                    file_object.description = parsed_file.description
-                    file_object.add_tag("duplicate")
-                    continue
-
-                # Run applicable parsers.
-                for parser, _run_args in self._identify_parsers(file_object):
-                    if isinstance(parser, Dispatcher):
-                        # Parser is a group, change wording
-                        logger.info(f"File {file_object.name} identified with {parser.DESCRIPTION} parser.")
-                    else:
-                        logger.info(f"File {file_object.name} identified as {parser.DESCRIPTION}.")
-                    logger.debug(f"{file_object.name} identified with {parser!r}")
-
-                    try:
-                        self._parse(file_object, parser, report, *_run_args)
-                    except UnableToParse as e:
-                        unable_to_parse_error = e
-                        continue
-                    identified = True
-                    if not self.greedy:
-                        break
-
-                if identified:
-                    continue
-
-                # If this is the first file in the buffer and we get UnableToParse, that means one of the parsers
-                # that identified it to use this dispatcher instance is wrong.
-                # Propogate that up.
-                if unable_to_parse_error and parent and first:
-                    raise unable_to_parse_error
-
-                # Give it to the parent dispatcher if we can't identify it.
-                if parent:
-                    parent.add(file_object)
-                    continue
-
-                # If no parsers match and developer didn't set a description,
-                # mark as unidentified file and run default.
-                if not file_object.description:
-                    logger.info(f"Supplied file {file_object.name} was not identified.")
-                    if self.default:
-                        try:
-                            self._parse(file_object, self.default, report)
-                        except UnableToParse:
-                            pass
-
-            finally:
-                # Report the file as residual if we identified it or we are the root parser.
-                # NOTE: We don't want to report the file until the very end, since a parser may want to change
-                # the file's filename or description.
-                if identified or (not parent and self._output_unidentified):
-                    if file_object.output_file:
-                        # Temporarily set current file back to parent so residual file is
-                        # reported correctly.
-                        report.set_file(file_object.parent)
-                        report.add(metadata.File.from_file_object(file_object))
-                        report.set_file(file_object)
-
-                    if file_object.md5 not in report.parsed_files:
-                        report.parsed_files[file_object.md5] = file_object
-
-                # Cleanup any temporary files the file_object may have created.
-                file_object._cleanup()
+"""
+Implements a data pump for extracted file data which allows for
+more robust file identification, reporting, and objectifying
+content to ease maintenance.
+"""
+
+import logging
+import warnings
+from collections import deque
+
+from mwcp import metadata
+from mwcp.exceptions import UnableToParse
+from mwcp.file_object import FileObject
+from mwcp.parser import Parser
+from mwcp.report import Report
+
+logger = logging.getLogger(__name__)
+
+
+class UnidentifiedFile(Parser):
+    """Describes an unidentified file. This parser will hit on any FileObject."""
+
+    DESCRIPTION = "Unidentified file"
+
+    @classmethod
+    def identify(cls, file_object):
+        """
+        Identifies an unidentified file... which means this is always True.
+
+        :param file_object: dispatcher.FileObject object
+        :return: Boolean indicating identification
+        """
+        return True
+
+
+# NOTE: This object is duck typed to look like a Parser object to allow recursion.
+# TODO: Create abstract inteface for these two.
+class Dispatcher(object):
+    # TODO: Rewrite this documentation.
+    """
+    This class will continuously process items that are in the queue.  When the queue is empty,
+    this will ultimately signal that processing is complete and the script will terminate.
+    This class will process the items using the supplied list of Parser classes provided.
+
+    This class can be used as a mixin along with the Parser class or
+    can be initialized by itself.
+    When used as a mixin, the dispatcher will automatically add the file in the reporter
+    to the queue and run dispatch() when run() is called.
+    """
+
+    # Caches results for identification to improve speed.
+    _identify_cache = {}
+
+    def __init__(
+        self,
+        name,
+        source,
+        author="",
+        description="",
+        parsers=None,
+        greedy=False,
+        default=UnidentifiedFile,
+        output_unidentified=True,
+        overwrite_descriptions=False,
+        embedded=False,
+    ):
+        """
+        Initializes the Dispatcher with the given parsers to run.
+
+        :param str name: Unique name to give to this group of parsers.
+        :param str source: Name of source this group comes from.
+        :param str author: Author of the parser.
+        :param str description: Description of the parser.
+        :param list parsers: A list of parser classes (or other dispatchers) to use for detection and running.
+            Order of this list is the order the Dispatcher will perform its identification.
+            If not provided, it will default to an empty list.
+        :param bool greedy: By default, the dispatcher will only run on the first parser it detects
+            to be a valid parser. If greedy is set to true, the dispatcher will try all parsers
+            even if a previous parser was successful.
+        :param ComponentParser default: The Parser class to default to if no parsers in the parsers list
+            has identified it. If set to None, no parser will be run as default.
+            (By default, the dispatcher.UnidentifiedFile will be run.)
+        :param bool output_unidentified: Whether to output files that have not been identified by
+            any parsers.
+        :param bool overwrite_descriptions: Whether to allow dispatcher to overwrite any previous
+            set description with the parser's
+        :param bool embedded: If True, all dispatched files will be passed up to the parent
+            dispatcher instead of being processed locally.
+            Ie, this is the equivalent of embedding the listed parsers directly into the parent's list.
+        """
+        self.name = name
+        self.source = source
+        # TODO: Deprecate the author attribute?
+        self.AUTHOR = author
+        self.DESCRIPTION = description  # In all caps to match Parser interface
+        self.TAGS = ()
+        self.parsers = parsers or []
+        self.greedy = greedy
+        self.default = default
+        self._fifo_buffer = deque()
+        self._current_file_object = None
+        self._current_parser = None
+        self._output_unidentified = output_unidentified
+        self._overwrite_descriptions = overwrite_descriptions
+        self._embedded = embedded
+
+        # Dictionary that can be used by parsers to pass variables across parsers.
+        # E.g. an encryption key found in the loader to be used by the implant.
+        self.knowledge_base = {}
+
+    def __repr__(self):
+        return "{}({})".format(self.name, ", ".join(repr(parser) for parser in self.parsers))
+
+    def identify(self, file_object):
+        """
+        Determines if this dispatcher is identified to support the given file_object.
+
+        :param file_object: file object to use for identification
+        :type file_object: dispatcher.FileObject
+
+        :return bool: Boolean indicating if this dispatcher supports the file_object
+        """
+        return any(self._identify_parsers(file_object))
+
+    def add_to_queue(self, file_object: FileObject, parent: FileObject = None):
+        warnings.warn(
+            "add_to_queue() has been renamed to add()",
+            DeprecationWarning
+        )
+        self.add(file_object, parent=parent)
+
+    def add(self, file_object: FileObject, parent: FileObject = None):
+        """
+        Add a FileObject to the FIFO queue for processing.
+        :param file_object: a FileObject object requiring processing.
+        :param parent: original parent for given file_object.
+            If not provided, the parent is assumed to be the file being currently
+            processed. (which should be true most of the time)
+
+        :return:
+        """
+        if not parent:
+            parent = self._current_file_object
+        assert isinstance(file_object, FileObject), "Not a FileObject: {!r}".format(file_object)
+
+        # FIXME: Disabled for now.
+        # if parent == file_object:
+        #     # Letting this be info instead of warning, since it is not necessarily
+        #     # a problem. (e.g. deobfuscation parser runs on already deobfuscated file)
+        #     logger.info(f"{parent.name} dispatched itself, ignoring...")
+        #     return
+
+        # If we already have a parent, this means this file is trickling up from a sub-dispatcher.
+        # Don't duplicate logs or change the parent.
+        if not file_object.parent:
+            file_object.parent = parent
+            if parent:
+                parent.children.append(file_object)
+                logger.info(f"{parent.name} dispatched residual file: {file_object.name}")
+                if file_object.description:
+                    logger.info(f"File {file_object.name} described as {file_object.description}")
+
+        self._fifo_buffer.appendleft(file_object)
+
+    def _identify_parsers(self, file_object: FileObject):
+        """
+        Generator that detects and yields identified parsers to run based on given file_object.
+
+        :param file_object: file object that needs to be identified
+
+        :yields: Identified Parser class or another Dispatcher that can be run
+        """
+        for parser in self.parsers:
+            logger.debug(u"Identifying {} with {!r}.".format(file_object.name, parser))
+
+            # First see if result has been cached.
+            key = (parser, file_object)
+            if key in self._identify_cache:
+                ret = self._identify_cache[key]
+            else:
+                ret = parser.identify(file_object)
+                self._identify_cache[key] = ret
+
+            if isinstance(ret, tuple) and isinstance(ret[0], bool):
+                identified, *rest = ret
+                rest = tuple(rest)
+            else:
+                identified = ret
+                rest = tuple()
+
+            if identified:
+                yield parser, rest
+
+    def _parse(self, file_object, parser, report, *run_args):
+        """
+        Parse given file_object with given sub parser
+
+        :raises UnableToParse: If the subparser raised an error.
+        """
+        self._current_file_object = file_object
+        self._current_parser = parser
+
+        # If a description wasn't set for the file, use the parser's
+        # (But ignore setting it for sub dispatchers)
+        orig_description = file_object.description
+        if (not file_object.description or self._overwrite_descriptions) and not isinstance(parser, Dispatcher):
+            file_object.description = parser.DESCRIPTION
+
+        # Add tags to the file.
+        orig_tags = set(file_object.tags)
+        for tag in parser.TAGS:
+            file_object.add_tag(tag)
+
+        # Set parser class used in order to keep a history.
+        orig_parser = file_object.parser
+        file_object.parser = parser
+
+        try:
+            parser.parse(file_object, report, *run_args, dispatcher=self)
+        except UnableToParse as exception:
+            # Undo setting parser metadata to file if we misidentify.
+            file_object.description = orig_description
+            file_object.tags = orig_tags
+            file_object.parser = orig_parser
+
+            # Mark identify cache as failure, so we don't need to go through this again.
+            self._identify_cache[(parser, file_object)] = False
+
+            # Log to user before reraising.
+            if isinstance(parser, Dispatcher):
+                # Parser is a group, change wording
+                logger.info(
+                    f"File {file_object.file_name} was misidentified with {parser.DESCRIPTION} parser, due to: "
+                    f"({exception}) Trying other parsers..."
+                )
+            else:
+                logger.info(
+                    f"File {file_object.file_name} was misidentified as {parser.DESCRIPTION}, due to: "
+                    f"({exception}) Trying other parsers..."
+                )
+            raise
+        except Exception:
+            logger.exception(u"{} dispatch parser failed".format(parser.name))
+
+    def parse(self, file_object: FileObject, report: Report, *run_args, dispatcher: "Dispatcher" = None):
+        """
+        Runs dispatcher on given file_object.
+
+        :param file_object: Object containing data about component file.
+        :param report: Report object to be filled in.
+        :param run_args: Extra arguments returned from identify() to pass to run() function.
+        :param dispatcher: reference to the parent dispatcher object that called this parse command.
+            (None if this dispatcher is the root)
+        :return:
+        """
+        parent = dispatcher
+        orig_file_object = file_object
+        self.add(file_object)
+
+        # Pull knowledge_base from previous dispatcher.
+        if parent:
+            self.knowledge_base = parent.knowledge_base
+
+        while self._fifo_buffer:
+            file_object = self._fifo_buffer.pop()
+            first = file_object is orig_file_object
+
+            # If this dispatcher is embedded, simply pass any dispatched files to the parent.
+            if self._embedded and parent and not first:
+                parent.add(file_object)
+                continue
+
+            identified = False
+            unable_to_parse_error = None
+
+            try:
+                # If file has already been parsed, don't bother running it again.
+                # (This also helps with cyclic loops)
+                # FIXME: Disabled until we can fix bug with greedy parsers.
+                if file_object.md5 in report.parsed_files and False:
+                    logger.info(f"File {file_object.name} has already been parsed. Ignoring...")
+                    # Copy file description from the already parsed version and mark as duplicate.
+                    parsed_file = report.parsed_files[file_object.md5]
+                    file_object.description = parsed_file.description
+                    file_object.add_tag("duplicate")
+                    continue
+
+                # Run applicable parsers.
+                for parser, _run_args in self._identify_parsers(file_object):
+                    if isinstance(parser, Dispatcher):
+                        # Parser is a group, change wording
+                        logger.info(f"File {file_object.name} identified with {parser.DESCRIPTION} parser.")
+                    else:
+                        logger.info(f"File {file_object.name} identified as {parser.DESCRIPTION}.")
+                    logger.debug(f"{file_object.name} identified with {parser!r}")
+
+                    try:
+                        self._parse(file_object, parser, report, *_run_args)
+                    except UnableToParse as e:
+                        unable_to_parse_error = e
+                        continue
+                    identified = True
+                    if not self.greedy:
+                        break
+
+                if identified:
+                    continue
+
+                # If this is the first file in the buffer and we get UnableToParse, that means one of the parsers
+                # that identified it to use this dispatcher instance is wrong.
+                # Propogate that up.
+                if unable_to_parse_error and parent and first:
+                    raise unable_to_parse_error
+
+                # Give it to the parent dispatcher if we can't identify it.
+                if parent:
+                    parent.add(file_object)
+                    continue
+
+                # If no parsers match and developer didn't set a description,
+                # mark as unidentified file and run default.
+                if not file_object.description:
+                    logger.info(f"Supplied file {file_object.name} was not identified.")
+                    if self.default:
+                        try:
+                            self._parse(file_object, self.default, report)
+                        except UnableToParse:
+                            pass
+
+            finally:
+                # Report the file as residual if we identified it or we are the root parser.
+                # NOTE: We don't want to report the file until the very end, since a parser may want to change
+                # the file's filename or description.
+                if identified or (not parent and self._output_unidentified):
+                    if file_object.output_file:
+                        # Temporarily set current file back to parent so residual file is
+                        # reported correctly.
+                        report.set_file(file_object.parent)
+                        report.add(metadata.File.from_file_object(file_object))
+                        report.set_file(file_object)
+
+                    if file_object.md5 not in report.parsed_files:
+                        report.parsed_files[file_object.md5] = file_object
+
+                # Cleanup any temporary files the file_object may have created.
+                file_object._cleanup()
```

### Comparing `mwcp-3.8.0/mwcp/exceptions.py` & `mwcp-3.9.0/mwcp/exceptions.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,25 +1,25 @@
-
-
-class MWCPError(Exception):
-    """
-    Base class for custom exceptions thrown by MWCP.
-    """
-
-
-class UnableToParse(MWCPError):
-    """
-    This exception can be thrown if a parser that has been correctly identified has failed to parse
-    the file and you would like other parsers to be tried.
-    """
-
-
-class ValidationError(MWCPError):
-    """
-    This exception can be thrown if validation fails when adding metadata.
-    """
-
-
-class ParserNotFoundError(MWCPError):
-    """
-    This exception gets thrown if a parser can't be found.
-    """
+
+
+class MWCPError(Exception):
+    """
+    Base class for custom exceptions thrown by MWCP.
+    """
+
+
+class UnableToParse(MWCPError):
+    """
+    This exception can be thrown if a parser that has been correctly identified has failed to parse
+    the file and you would like other parsers to be tried.
+    """
+
+
+class ValidationError(MWCPError):
+    """
+    This exception can be thrown if validation fails when adding metadata.
+    """
+
+
+class ParserNotFoundError(MWCPError):
+    """
+    This exception gets thrown if a parser can't be found.
+    """
```

### Comparing `mwcp-3.8.0/mwcp/file_object.py` & `mwcp-3.9.0/mwcp/file_object.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,531 +1,558 @@
-"""
-Implements FileObject class used to provide an interface for the file being parsed.
-"""
-from __future__ import annotations
-import contextlib
-import datetime
-import hashlib
-import io
-import logging
-import os
-import pathlib
-import shutil
-import sys
-import tempfile
-import warnings
-from typing import List, Optional, Iterable, Union, TYPE_CHECKING, ContextManager
-
-import pefile
-
-from mwcp import metadata
-from mwcp.utils import elffileutils, pefileutils
-from mwcp.utils.stringutils import convert_to_unicode, sanitize_filename
-
-try:
-    import kordesii
-except ImportError:
-    # Kordesii support is optional.
-    kordesii = None
-
-try:
-    import dragodis
-except ImportError:
-    dragodis = None
-
-
-if TYPE_CHECKING:
-    from mwcp import Report
-
-
-logger = logging.getLogger(__name__)
-
-
-class FileObject(object):
-    """
-    This class represents a file object which is to be parsed by the MWCP parser.
-    It is pushed into the dispatcher queue for processing.
-    """
-
-    # Collection of file_object instances that have been created.
-    # This is necessary so the Runner can cleanup temp files that have been created
-    # for backwards compatibility.
-    # TODO: Remove this when original implementation of .file_path is removed.
-    _instances = []
-
-    def __init__(
-        self,
-        file_data: bytes,
-        reporter=None,  # DEPRECATED
-        pe: pefile.PE = None,
-        file_name=None,
-        file_path=None,
-        def_stub=None,
-        description=None,
-        output_file=True,
-        use_supplied_fname=True,
-        use_arch=False,
-        ext=".bin",
-        derivation: str = None,
-    ):
-        """
-        Initializes the FileObject.
-
-        :param bytes file_data: Data for the file.
-        :param pefile.PE pe: PE object for the file.
-        :param mwcp.Report reporter: MWCP Report.
-        :param str file_name: File name to use if file is not a PE or use_supplied_fname was specified.
-        :param str file_path: Actual file path as found in the file system.
-            (This is primarily used for the initial input file)
-        :param str description: Description of the file object.
-        :param bool output_file: Boolean indicating if file should be outputted when the dispatcher process the file.
-        :param bool use_supplied_fname: Boolean indicating if the file_name should be used even if the file is a PE.
-        :param str def_stub: def_stub argument to pass to obtain_original_filename()
-        :param bool use_arch: use_arch argument to pass to obtain_original_filename()
-        :param str ext: default extension to use if not determined from pe file.
-        :param derivation: Description of how the file was obtained or its categorization.
-            e.g. "decrypted", "deobfuscated", "supplemental"
-        """
-        if reporter:
-            warnings.warn(
-                "Passing a reporter argument to FileObject is deprecated and will be removed in a future release. "
-                "Please update your code to not include the argument.",
-                DeprecationWarning
-            )
-
-        # Ensure we are getting a bytes string. Libraries like pefile depend on this.
-        if not isinstance(file_data, bytes):
-            raise TypeError("file_data must be a bytes string.")
-
-        self._file_path = file_path
-        self._exists = bool(file_path)  # Indicates if the user provided the path and the file exists on the host file system.
-        self._temp_path = None
-        self._temp_path_ctx = None
-        self._md5 = None
-        self._sha1 = None
-        self._sha256 = None
-        self._stack_strings = None
-        self._static_strings = None
-        self._resources = None
-        self._elf = None
-        self._elf_attempt = False
-        self.output_file = output_file
-        self._outputted_file = False
-        self._kordesii_cache = {}
-        self.parent = None  # Parent FileObject from which FileObject was extracted from (this is set externally).
-        self.parser = None  # This will be set by the dispatcher.
-        self.children = []  # List of residual FileObject
-        self._data = file_data
-        self._use_arch = use_arch
-        self._ext = ext
-        self._def_stub = def_stub
-        self._report = reporter  # DEPRECATED
-        self.description = description
-        self.derivation = derivation
-        self.knowledge_base = {}
-        self.tags = set()
-
-        self.pe = pe or pefileutils.obtain_pe(file_data)
-
-        use_supplied_fname = use_supplied_fname or not self.pe
-
-        if file_path:
-            file_name = pathlib.PurePath(file_path).name
-
-        if file_name and use_supplied_fname:
-            self._name = file_name
-        else:
-            self._name = pefileutils.obtain_original_filename(
-                def_stub or self.md5, pe=self.pe, use_arch=use_arch, ext=ext
-            )
-        self._name = convert_to_unicode(self._name)
-
-        # Keep track of instances so we can clean them up when Runner finishes.
-        self._instances.append(self)
-
-    def __enter__(self):
-        warnings.warn(
-            "Using FileObject directly as a context manager is deprecated. "
-            "Please use .open() instead.",
-            DeprecationWarning
-        )
-        self._open_file = io.BytesIO(self.data)
-        return self._open_file
-
-    def __exit__(self, *args):
-        self._open_file.close()
-
-    def __repr__(self):
-        return f"<{self.name} ({self.md5}) : {self.description}>"
-
-    @classmethod
-    def from_path(cls, file_path: Union[str, os.PathLike], **kwargs) -> "FileObject":
-        """
-        Generate FileObject from existing file on system by path.
-        """
-        with open(file_path, "rb") as fo:
-            return FileObject(fo.read(), file_path=str(file_path), **kwargs)
-
-    @contextlib.contextmanager
-    def open(self):
-        """
-        This allows us to use the file_data as a file-like object when used as a context manager.
-
-        e.g.
-            >> file_object = FileObject('hello world', None)
-            >> with file_object.open() as fo:
-            ..     _ = fo.seek(6)
-            ..     print fo.read()
-            world
-        """
-        with io.BytesIO(self.data) as fo:
-            yield fo
-
-    def _cleanup(self):
-        """
-        Cleans up temporary file if created.
-        TODO: This is temporary in order to support backwards compatibility.
-        """
-        if self._temp_path_ctx:
-            self._temp_path_ctx.__exit__(*sys.exc_info())
-            self._temp_path_ctx = None
-            self._temp_path = None
-
-    def add_tag(self, *tags: Iterable[str]) -> "FileObject":
-        """
-        Adds tag(s) for the file.
-
-        :param tags: One or more tags to add to the file.
-        :returns: self to make this function chainable.
-        """
-        for tag in tags:
-            self.tags.add(tag)
-        return self
-
-    @property
-    def reporter(self):
-        warnings.warn(
-            "FileObject.reporter has been deprecated and should not be accessed from FileObject.",
-            DeprecationWarning
-        )
-        return self._report
-
-    @property
-    def siblings(self) -> List["FileObject"]:
-        """List of FileObjects that came from the same parent."""
-        if not self.parent:
-            return []
-        return [fo for fo in self.parent.children if fo is not self]
-
-    @property
-    def file_data(self):
-        warnings.warn(
-            ".file_data is deprecated. Please use .data instead.",
-            DeprecationWarning
-        )
-        return self.data
-
-    @file_data.setter
-    def file_data(self, value):
-        warnings.warn(
-            ".file_data is deprecated. Please use .data instead.",
-            DeprecationWarning
-        )
-        raise ValueError("FileObject.file_data is ready only!")
-
-    @property
-    def data(self) -> bytes:
-        return self._data
-
-    @property
-    def elf(self):
-        """Returns elftools.ELFFile object or None if not an ELF file."""
-        if not self._elf and not self._elf_attempt:
-            self._elf_attempt = True
-            self._elf = elffileutils.obtain_elf(self.data)
-        return self._elf
-
-    # TODO: Deprecate "file_name" name in exhange for "name"?
-    @property
-    def file_name(self):
-        warnings.warn(
-            ".file_name attribute is deprecated. Please use .name instead.",
-            DeprecationWarning
-        )
-        return self.name
-
-    @file_name.setter
-    def file_name(self, value):
-        warnings.warn(
-            ".file_name attribute is deprecated. Please use .name instead.",
-            DeprecationWarning
-        )
-        self.name = value
-
-    @property
-    def name(self):
-        return self._name
-
-    @name.setter
-    def name(self, value):
-        # If someone changes the name, record the rename.
-        value = convert_to_unicode(value)
-        if self._name != value:
-            logger.info("Renamed {} to {}".format(self._name, value))
-        self._name = value
-
-    @property
-    def parser_history(self):
-        """
-        Returns a history of the parser classes (including current) that has lead to the creation of the file object.
-        e.g. [MalwareDropper, MalwareLoader, MalwareImplant]
-        :return list: List of parser classes.
-        """
-        history = [self.parser]
-        parent = self.parent
-        while parent:
-            history.append(parent.parser)
-            parent = parent.parent
-        return reversed(history)
-
-    @property
-    def md5(self):
-        """
-        Returns md5 hash of file.
-        :return: hash of the file as a hex string
-        """
-        if not self._md5:
-            self._md5 = hashlib.md5(self.data).hexdigest()
-        return self._md5
-
-    @property
-    def sha1(self):
-        """
-        Returns sha1 hash of file.
-        :return: hash of the file as a hex string
-        """
-        if not self._sha1:
-            self._sha1 = hashlib.sha1(self.data).hexdigest()
-        return self._sha1
-
-    @property
-    def sha256(self):
-        """
-        Returns sha256 hash of file.
-        :return: hash of the file as a hex string
-        """
-        if not self._sha256:
-            self._sha256 = hashlib.sha256(self.data).hexdigest()
-        return self._sha256
-
-    @property
-    def compile_time(self) -> Optional[datetime.datetime]:
-        """
-        Returns UTC datetime of compile time (if applicable)
-        """
-        if self.pe:
-            timestamp = self.pe.FILE_HEADER.TimeDateStamp
-            return datetime.datetime.fromtimestamp(timestamp, datetime.timezone.utc)
-
-    @contextlib.contextmanager
-    def temp_path(self):
-        """
-        Context manager for creating a temporary full file path to the file object.
-        This is useful for when you want to use this file on libraries which require
-        a file path instead of data or file-like object. (e.g. cabinet).
-
-        WARNING: Take care when using this function. This will cause the potentially
-            malicious file to be written out to the file system!
-
-        Usage:
-            with file_object.temp_path() as file_path:
-                _some_library_that_needs_a_path(file_path)
-        """
-        # TODO: Provide and option to change location of temporary files through the use
-        #   of the configuration file.
-        with tempfile.TemporaryDirectory(prefix="mwcp_") as tmpdir:
-            temp_file = os.path.join(tmpdir, sanitize_filename(self.name) if self.name else self.md5)
-            with open(temp_file, "wb") as fo:
-                fo.write(self.data)
-            yield temp_file
-
-    @property
-    def file_path(self) -> Optional[str]:
-        """
-        The full file path of the file object if backed by a real file on the file system.
-        (This is usually just for the original input file.)
-
-        This property is currently set to be backwards compatible with the original usage
-        which has been moved to .temp_path()
-        In the future, this attribute will only be applicable if the FileObject is backed
-        by a real file on the file system and will be None otherwise.
-        In the meantime, you can confirm if this attribute represents a real file path
-        (future usage) or a temporary path (deprecated usage) by checking if ._exists is
-        True or False first. Eventually, this check will no longer be needed.
-        """
-        warnings.warn(
-            "Original usage of .file_path is deprecated. Please use .temp_path() instead. "
-            "In the future, this attribute will only be applicable if the FileObject "
-            "is backed by a real file on the file system.",
-            DeprecationWarning
-        )
-        if self._file_path:
-            return self._file_path
-
-        if not self._temp_path:
-            self._cleanup()
-            self._temp_path_ctx = self.temp_path()
-            self._temp_path = self._temp_path_ctx.__enter__()
-        return self._temp_path
-
-    @file_path.setter
-    def file_path(self, value):
-        """
-        Setter for the file_path attribute. This is used if an external entity can
-        provided a valid file_path.
-        """
-        self._file_path = value
-        self._exists = bool(value)
-
-    @property
-    def stack_strings(self) -> List[str]:
-        """
-        Returns the stack strings for the file.
-        """
-        if not self._stack_strings:
-            kordesii_reporter = self.run_kordesii_decoder("stack_string")
-            self._stack_strings = kordesii_reporter.get_strings()
-        return self._stack_strings
-
-    # TODO: Create a static_strings property?
-
-    @property
-    def resources(self) -> List[pefileutils.Resource]:
-        """Returns a list of the PE resources for the given file."""
-        if self.pe and not self._resources:
-            self._resources = list(pefileutils.iter_rsrc(self.pe))
-        return self._resources
-
-    @property
-    def is_64bit(self) -> Optional[bool]:
-        """
-        Evaluates whether the file is a 64 bit pe file.
-
-        :return: True if 64-bit, False if 32-bit, None if could not be determined.
-        """
-        if not self.pe:
-            return None
-        return pefileutils.is_64bit(pe=self.pe)
-
-    @property
-    def architecture(self) -> Optional[str]:
-        """
-        The architecture of the file (if an executable).
-        """
-        if self.pe:
-            return pefileutils.obtain_architecture_string(pe=self.pe, bitterm=False)
-        elif self.elf:
-            arch = self.elf.get_machine_arch()
-            if arch == "<unknown>":
-                arch = None
-            return arch
-        else:
-            return None
-
-    def output(self):
-        """
-        Outputs FileObject instance to reporter if it hasn't already been outputted.
-        """
-        warnings.warn(
-            "output() is deprecated. Please call report.add() on a File metadata "
-            "object to report and output on a file instead.",
-            DeprecationWarning
-        )
-        if self.output_file:
-            self._report.add(metadata.File.from_file_object(self))
-
-    @contextlib.contextmanager
-    def disassembly(self, disassembler: str = None, report: Report = None, **config) -> ContextManager["dragodis.Disassembler"]:
-        """
-        Produces a Dragodis Disassembler object for the file.
-        Dragodis must be installed for this work.
-
-        e.g.
-            with self.file_object.disassembly() as dis:
-                mnemonic = dis.get_instruction(0x1234).mnemonic
-
-        :param disassembler: Name of the backend disassembler to use.
-            (e.g. "ida" or "ghidra")
-            If not provided, the disassembler setup in the environment variable
-            DRAGODIS_DISASSEMBLER will be used.
-            (It is usually recommended to not set the variable so the parser is cross
-            compatible with any disassembler Dragodis supports.)
-        :param report: Provide the Report object if you want the annotated disassembler project file to
-            be added after processing.
-            This is usually only recommended if the parser plans to annotate the disassembly. e.g. API resolution
-        """
-        if not dragodis:
-            raise RuntimeError("Please install Dragodis to use this function.")
-
-        with self.temp_path() as file_path:
-            with dragodis.open_program(file_path, disassembler, **config) as dis:
-                yield dis
-
-            # After processing we want to save the annotated project file if report was provided.
-            if report:
-                project_file = None
-                if dis.name.casefold() == "ida":
-                    project_file = dis.input_path.parent / (dis.input_path.name + ".idb")
-                elif dis.name.casefold() == "ghidra":
-                    folder_path = dis.input_path.parent / (dis.input_path.name + "_ghidra")
-                    project_file = pathlib.Path(shutil.make_archive(
-                        str(folder_path), format="zip", root_dir=folder_path
-                    ))
-                if project_file and project_file.exists():
-                    data = project_file.read_bytes()
-                    report.add(metadata.File(
-                        name=project_file.name,
-                        data=data,
-                        description=f"{dis.name} Project File",
-                        derivation="supplemental",
-                    ))
-
-    def run_kordesii_decoder(self, decoder_name: str, warn_no_strings=True, **run_config):
-        """
-        Run the specified kordesii decoder against the file data.  The reporter object is returned
-        and can be accessed as necessary to obtain output files, etc.
-
-        :param decoder_name: name of the decoder to run
-        :param warn_no_strings: Whether to produce a warning if no string were found.
-        :param run_config: Run configuration options to pass along to kordesii.run_ida()
-
-        :return: Instance of the kordesii_reporter.
-
-        :raises RuntimeError: If kordesii is not installed.
-        """
-        if not kordesii:
-            raise RuntimeError("Please install kordesii to use this function.")
-
-        # Pull from cache if we already ran this decoder.
-        if decoder_name in self._kordesii_cache:
-            return self._kordesii_cache[decoder_name]
-
-        logger.info(f"Running {decoder_name} kordesii decoder on file {self.name}.")
-        # Ensure decoderdir sources are populated
-        kordesii.register_entry_points()
-
-        kordesii_reporter = kordesii.Reporter(base64outputfiles=True)
-
-        if "log" not in run_config:
-            run_config["log"] = True
-        kordesii_reporter.run_decoder(decoder_name, data=self.data, **run_config)
-
-        if warn_no_strings:
-            decrypted_strings = kordesii_reporter.get_strings()
-            if not decrypted_strings:
-                # Not necessarily a bad thing, the decoder might be used for something else.
-                logger.info(f"No decrypted strings were returned by the decoder for file {self.name}.")
-
-        # Cache results
-        self._kordesii_cache[decoder_name] = kordesii_reporter
-
-        return kordesii_reporter
+"""
+Implements FileObject class used to provide an interface for the file being parsed.
+"""
+from __future__ import annotations
+import contextlib
+import datetime
+import hashlib
+import io
+import logging
+import os
+import pathlib
+import shutil
+import sys
+import tempfile
+import warnings
+from typing import List, Optional, Iterable, Union, TYPE_CHECKING, ContextManager
+
+import pefile
+
+from mwcp import metadata
+from mwcp.utils import elffileutils, pefileutils
+from mwcp.utils.stringutils import convert_to_unicode, sanitize_filename
+
+try:
+    import kordesii
+except ImportError:
+    # Kordesii support is optional.
+    kordesii = None
+
+try:
+    import dragodis
+except ImportError:
+    dragodis = None
+
+
+if TYPE_CHECKING:
+    from mwcp import Report
+
+
+logger = logging.getLogger(__name__)
+
+
+class FileObject(object):
+    """
+    This class represents a file object which is to be parsed by the MWCP parser.
+    It is pushed into the dispatcher queue for processing.
+    """
+
+    # Collection of file_object instances that have been created.
+    # This is necessary so the Runner can cleanup temp files that have been created
+    # for backwards compatibility.
+    # TODO: Remove this when original implementation of .file_path is removed.
+    _instances = []
+
+    def __init__(
+        self,
+        file_data: bytes,
+        reporter=None,  # DEPRECATED
+        pe: pefile.PE = None,
+        file_name=None,
+        file_path=None,
+        def_stub=None,
+        description=None,
+        output_file=True,
+        use_supplied_fname=True,
+        use_arch=False,
+        ext=".bin",
+        derivation: str = None,
+    ):
+        """
+        Initializes the FileObject.
+
+        :param bytes file_data: Data for the file.
+        :param pefile.PE pe: PE object for the file.
+        :param mwcp.Report reporter: MWCP Report.
+        :param str file_name: File name to use if file is not a PE or use_supplied_fname was specified.
+        :param str file_path: Actual file path as found in the file system.
+            (This is primarily used for the initial input file)
+        :param str description: Description of the file object.
+        :param bool output_file: Boolean indicating if file should be outputted when the dispatcher process the file.
+        :param bool use_supplied_fname: Boolean indicating if the file_name should be used even if the file is a PE.
+        :param str def_stub: def_stub argument to pass to obtain_original_filename()
+        :param bool use_arch: use_arch argument to pass to obtain_original_filename()
+        :param str ext: default extension to use if not determined from pe file.
+        :param derivation: Description of how the file was obtained or its categorization.
+            e.g. "decrypted", "deobfuscated", "supplemental"
+        """
+        if reporter:
+            warnings.warn(
+                "Passing a reporter argument to FileObject is deprecated and will be removed in a future release. "
+                "Please update your code to not include the argument.",
+                DeprecationWarning
+            )
+
+        # Ensure we are getting a bytes string. Libraries like pefile depend on this.
+        if not isinstance(file_data, bytes):
+            raise TypeError("file_data must be a bytes string.")
+
+        self._file_path = file_path
+        self._exists = bool(file_path)  # Indicates if the user provided the path and the file exists on the host file system.
+        self._temp_path = None
+        self._temp_path_ctx = None
+        self._md5 = None
+        self._sha1 = None
+        self._sha256 = None
+        self._stack_strings = None
+        self._static_strings = None
+        self._resources = None
+        self._elf = None
+        self._elf_attempt = False
+        self.output_file = output_file
+        self._outputted_file = False
+        self._kordesii_cache = {}
+        self.parent = None  # Parent FileObject from which FileObject was extracted from (this is set externally).
+        self.parser = None  # This will be set by the dispatcher.
+        self.children = []  # List of residual FileObject
+        self._data = file_data
+        self._use_arch = use_arch
+        self._ext = ext
+        self._def_stub = def_stub
+        self._report = reporter  # DEPRECATED
+        self.description = description
+        self.derivation = derivation
+        self.knowledge_base = {}
+        self.tags = set()
+
+        self.pe = pe or pefileutils.obtain_pe(file_data)
+
+        use_supplied_fname = use_supplied_fname or not self.pe
+
+        if file_path:
+            file_name = pathlib.PurePath(file_path).name
+
+        if file_name and use_supplied_fname:
+            self._name = file_name
+        else:
+            self._name = pefileutils.obtain_original_filename(
+                def_stub or self.md5, pe=self.pe, use_arch=use_arch, ext=ext
+            )
+        self._name = convert_to_unicode(self._name)
+
+        # Keep track of instances so we can clean them up when Runner finishes.
+        self._instances.append(self)
+
+    def __enter__(self):
+        warnings.warn(
+            "Using FileObject directly as a context manager is deprecated. "
+            "Please use .open() instead.",
+            DeprecationWarning
+        )
+        self._open_file = io.BytesIO(self.data)
+        return self._open_file
+
+    def __exit__(self, *args):
+        self._open_file.close()
+
+    def __repr__(self):
+        return f"<{self.name} ({self.md5}) : {self.description}>"
+
+    @classmethod
+    def from_path(cls, file_path: Union[str, os.PathLike], **kwargs) -> "FileObject":
+        """
+        Generate FileObject from existing file on system by path.
+        """
+        with open(file_path, "rb") as fo:
+            return FileObject(fo.read(), file_path=str(file_path), **kwargs)
+
+    @contextlib.contextmanager
+    def open(self):
+        """
+        This allows us to use the file_data as a file-like object when used as a context manager.
+
+        e.g.
+            >> file_object = FileObject('hello world', None)
+            >> with file_object.open() as fo:
+            ..     _ = fo.seek(6)
+            ..     print fo.read()
+            world
+        """
+        with io.BytesIO(self.data) as fo:
+            yield fo
+
+    def _cleanup(self):
+        """
+        Cleans up temporary file if created.
+        TODO: This is temporary in order to support backwards compatibility.
+        """
+        if self._temp_path_ctx:
+            self._temp_path_ctx.__exit__(*sys.exc_info())
+            self._temp_path_ctx = None
+            self._temp_path = None
+
+    def add_tag(self, *tags: Iterable[str]) -> FileObject:
+        """
+        Adds tag(s) for the file.
+
+        :param tags: One or more tags to add to the file.
+        :returns: self to make this function chainable.
+        """
+        for tag in tags:
+            self.tags.add(tag)
+        return self
+
+    @property
+    def reporter(self):
+        warnings.warn(
+            "FileObject.reporter has been deprecated and should not be accessed from FileObject.",
+            DeprecationWarning
+        )
+        return self._report
+
+    @property
+    def siblings(self) -> List[FileObject]:
+        """List of FileObjects that came from the same parent."""
+        if not self.parent:
+            return []
+        return [fo for fo in self.parent.children if fo is not self]
+
+    @property
+    def ancestors(self) -> List[FileObject]:
+        """List of FileObjects for the full parental hierarchy."""
+        if not self.parent:
+            return []
+        return [self.parent, *self.parent.ancestors]
+
+    @property
+    def descendants(self) -> List[FileObject]:
+        """List of FileObjects that came from the current file."""
+        ret = list(self.children)
+        for child in self.children:
+            ret.extend(child.descendants)
+        return ret
+
+    @property
+    def file_data(self):
+        warnings.warn(
+            ".file_data is deprecated. Please use .data instead.",
+            DeprecationWarning
+        )
+        return self.data
+
+    @file_data.setter
+    def file_data(self, value):
+        warnings.warn(
+            ".file_data is deprecated. Please use .data instead.",
+            DeprecationWarning
+        )
+        raise ValueError("FileObject.file_data is ready only!")
+
+    @property
+    def data(self) -> bytes:
+        return self._data
+
+    @property
+    def elf(self):
+        """Returns elftools.ELFFile object or None if not an ELF file."""
+        if not self._elf and not self._elf_attempt:
+            self._elf_attempt = True
+            self._elf = elffileutils.obtain_elf(self.data)
+        return self._elf
+
+    # TODO: Deprecate "file_name" name in exhange for "name"?
+    @property
+    def file_name(self):
+        warnings.warn(
+            ".file_name attribute is deprecated. Please use .name instead.",
+            DeprecationWarning
+        )
+        return self.name
+
+    @file_name.setter
+    def file_name(self, value):
+        warnings.warn(
+            ".file_name attribute is deprecated. Please use .name instead.",
+            DeprecationWarning
+        )
+        self.name = value
+
+    @property
+    def name(self):
+        return self._name
+
+    @name.setter
+    def name(self, value):
+        # If someone changes the name, record the rename.
+        value = convert_to_unicode(value)
+        if self._name != value:
+            logger.info("Renamed {} to {}".format(self._name, value))
+        self._name = value
+
+    @property
+    def ext(self):
+        """The extension of the file."""
+        return pathlib.PurePath(self.name).suffix
+
+    @ext.setter
+    def ext(self, new_ext: str):
+        """Sets a new extension for the file."""
+        if not new_ext.startswith("."):
+            new_ext = f".{new_ext}"
+        self.name = pathlib.PurePath(self.name).stem + new_ext
+
+    @property
+    def parser_history(self):
+        """
+        Returns a history of the parser classes (including current) that has lead to the creation of the file object.
+        e.g. [MalwareDropper, MalwareLoader, MalwareImplant]
+        :return list: List of parser classes.
+        """
+        history = [self.parser]
+        parent = self.parent
+        while parent:
+            history.append(parent.parser)
+            parent = parent.parent
+        return reversed(history)
+
+    @property
+    def md5(self):
+        """
+        Returns md5 hash of file.
+        :return: hash of the file as a hex string
+        """
+        if not self._md5:
+            self._md5 = hashlib.md5(self.data).hexdigest()
+        return self._md5
+
+    @property
+    def sha1(self):
+        """
+        Returns sha1 hash of file.
+        :return: hash of the file as a hex string
+        """
+        if not self._sha1:
+            self._sha1 = hashlib.sha1(self.data).hexdigest()
+        return self._sha1
+
+    @property
+    def sha256(self):
+        """
+        Returns sha256 hash of file.
+        :return: hash of the file as a hex string
+        """
+        if not self._sha256:
+            self._sha256 = hashlib.sha256(self.data).hexdigest()
+        return self._sha256
+
+    @property
+    def compile_time(self) -> Optional[datetime.datetime]:
+        """
+        Returns UTC datetime of compile time (if applicable)
+        """
+        if self.pe:
+            timestamp = self.pe.FILE_HEADER.TimeDateStamp
+            return datetime.datetime.fromtimestamp(timestamp, datetime.timezone.utc)
+
+    @contextlib.contextmanager
+    def temp_path(self):
+        """
+        Context manager for creating a temporary full file path to the file object.
+        This is useful for when you want to use this file on libraries which require
+        a file path instead of data or file-like object. (e.g. cabinet).
+
+        WARNING: Take care when using this function. This will cause the potentially
+            malicious file to be written out to the file system!
+
+        Usage:
+            with file_object.temp_path() as file_path:
+                _some_library_that_needs_a_path(file_path)
+        """
+        # TODO: Provide and option to change location of temporary files through the use
+        #   of the configuration file.
+        with tempfile.TemporaryDirectory(prefix="mwcp_") as tmpdir:
+            temp_file = os.path.join(tmpdir, sanitize_filename(self.name) if self.name else self.md5)
+            with open(temp_file, "wb") as fo:
+                fo.write(self.data)
+            yield temp_file
+
+    @property
+    def file_path(self) -> Optional[str]:
+        """
+        The full file path of the file object if backed by a real file on the file system.
+        (This is usually just for the original input file.)
+
+        This property is currently set to be backwards compatible with the original usage
+        which has been moved to .temp_path()
+        In the future, this attribute will only be applicable if the FileObject is backed
+        by a real file on the file system and will be None otherwise.
+        In the meantime, you can confirm if this attribute represents a real file path
+        (future usage) or a temporary path (deprecated usage) by checking if ._exists is
+        True or False first. Eventually, this check will no longer be needed.
+        """
+        warnings.warn(
+            "Original usage of .file_path is deprecated. Please use .temp_path() instead. "
+            "In the future, this attribute will only be applicable if the FileObject "
+            "is backed by a real file on the file system.",
+            DeprecationWarning
+        )
+        if self._file_path:
+            return self._file_path
+
+        if not self._temp_path:
+            self._cleanup()
+            self._temp_path_ctx = self.temp_path()
+            self._temp_path = self._temp_path_ctx.__enter__()
+        return self._temp_path
+
+    @file_path.setter
+    def file_path(self, value):
+        """
+        Setter for the file_path attribute. This is used if an external entity can
+        provided a valid file_path.
+        """
+        self._file_path = value
+        self._exists = bool(value)
+
+    @property
+    def stack_strings(self) -> List[str]:
+        """
+        Returns the stack strings for the file.
+        """
+        if not self._stack_strings:
+            kordesii_reporter = self.run_kordesii_decoder("stack_string")
+            self._stack_strings = kordesii_reporter.get_strings()
+        return self._stack_strings
+
+    # TODO: Create a static_strings property?
+
+    @property
+    def resources(self) -> List[pefileutils.Resource]:
+        """Returns a list of the PE resources for the given file."""
+        if self.pe and not self._resources:
+            self._resources = list(pefileutils.iter_rsrc(self.pe))
+        return self._resources
+
+    @property
+    def is_64bit(self) -> Optional[bool]:
+        """
+        Evaluates whether the file is a 64 bit pe file.
+
+        :return: True if 64-bit, False if 32-bit, None if could not be determined.
+        """
+        if not self.pe:
+            return None
+        return pefileutils.is_64bit(pe=self.pe)
+
+    @property
+    def architecture(self) -> Optional[str]:
+        """
+        The architecture of the file (if an executable).
+        """
+        if self.pe:
+            return pefileutils.obtain_architecture_string(pe=self.pe, bitterm=False)
+        elif self.elf:
+            arch = self.elf.get_machine_arch()
+            if arch == "<unknown>":
+                arch = None
+            return arch
+        else:
+            return None
+
+    def output(self):
+        """
+        Outputs FileObject instance to reporter if it hasn't already been outputted.
+        """
+        warnings.warn(
+            "output() is deprecated. Please call report.add() on a File metadata "
+            "object to report and output on a file instead.",
+            DeprecationWarning
+        )
+        if self.output_file:
+            self._report.add(metadata.File.from_file_object(self))
+
+    @contextlib.contextmanager
+    def disassembly(self, disassembler: str = None, report: Report = None, **config) -> ContextManager["dragodis.Disassembler"]:
+        """
+        Produces a Dragodis Disassembler object for the file.
+        Dragodis must be installed for this work.
+
+        e.g.
+            with self.file_object.disassembly() as dis:
+                mnemonic = dis.get_instruction(0x1234).mnemonic
+
+        :param disassembler: Name of the backend disassembler to use.
+            (e.g. "ida" or "ghidra")
+            If not provided, the disassembler setup in the environment variable
+            DRAGODIS_DISASSEMBLER will be used.
+            (It is usually recommended to not set the variable so the parser is cross
+            compatible with any disassembler Dragodis supports.)
+        :param report: Provide the Report object if you want the annotated disassembler project file to
+            be added after processing.
+            This is usually only recommended if the parser plans to annotate the disassembly. e.g. API resolution
+        """
+        if not dragodis:
+            raise RuntimeError("Please install Dragodis to use this function.")
+
+        with self.temp_path() as file_path:
+            with dragodis.open_program(file_path, disassembler, **config) as dis:
+                yield dis
+
+            # After processing we want to save the annotated project file if report was provided.
+            if report:
+                project_file = None
+                if dis.name.casefold() == "ida":
+                    project_file = dis.input_path.parent / (dis.input_path.name + ".idb")
+                elif dis.name.casefold() == "ghidra":
+                    folder_path = dis.input_path.parent / (dis.input_path.name + "_ghidra")
+                    project_file = pathlib.Path(shutil.make_archive(
+                        str(folder_path), format="zip", root_dir=folder_path
+                    ))
+                if project_file and project_file.exists():
+                    data = project_file.read_bytes()
+                    report.add(metadata.File(
+                        name=project_file.name,
+                        data=data,
+                        description=f"{dis.name} Project File",
+                        derivation="supplemental",
+                    ))
+
+    def run_kordesii_decoder(self, decoder_name: str, warn_no_strings=True, **run_config):
+        """
+        Run the specified kordesii decoder against the file data.  The reporter object is returned
+        and can be accessed as necessary to obtain output files, etc.
+
+        :param decoder_name: name of the decoder to run
+        :param warn_no_strings: Whether to produce a warning if no string were found.
+        :param run_config: Run configuration options to pass along to kordesii.run_ida()
+
+        :return: Instance of the kordesii_reporter.
+
+        :raises RuntimeError: If kordesii is not installed.
+        """
+        if not kordesii:
+            raise RuntimeError("Please install kordesii to use this function.")
+
+        # Pull from cache if we already ran this decoder.
+        if decoder_name in self._kordesii_cache:
+            return self._kordesii_cache[decoder_name]
+
+        logger.info(f"Running {decoder_name} kordesii decoder on file {self.name}.")
+        # Ensure decoderdir sources are populated
+        kordesii.register_entry_points()
+
+        kordesii_reporter = kordesii.Reporter(base64outputfiles=True)
+
+        if "log" not in run_config:
+            run_config["log"] = True
+        kordesii_reporter.run_decoder(decoder_name, data=self.data, **run_config)
+
+        if warn_no_strings:
+            decrypted_strings = kordesii_reporter.get_strings()
+            if not decrypted_strings:
+                # Not necessarily a bad thing, the decoder might be used for something else.
+                logger.info(f"No decrypted strings were returned by the decoder for file {self.name}.")
+
+        # Cache results
+        self._kordesii_cache[decoder_name] = kordesii_reporter
+
+        return kordesii_reporter
```

### Comparing `mwcp-3.8.0/mwcp/metadata.py` & `mwcp-3.9.0/mwcp/metadata.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,2445 +1,2443 @@
-"""
-Schema for reportable metadata.
-
-- Using attrs for easy of use and validation.
-"""
-import base64
-import binascii
-import hashlib
-import inspect
-import io
-import json
-import logging
-import pathlib
-import re
-import textwrap
-import warnings
-import ntpath
-from enum import IntEnum
-import uuid
-from typing import Any, Union, List, Optional, TypeVar, Type, Iterable, Tuple
-
-from stix2 import v21 as stix
-
-import attr
-from bitarray import bitarray
-import cattr
-from defusedxml import ElementTree
-import jsonschema_extractor
-from pyasn1.codec.der import decoder as asn1_decoder
-from pyasn1_modules import rfc2437, rfc2459, pem
-from pyasn1.error import PyAsn1Error
-
-import mwcp
-from mwcp.exceptions import ValidationError
-from mwcp.utils import construct
-from mwcp.stix import extensions as stix_extensions
-from mwcp.stix.objects import STIXResult
-
-logger = logging.getLogger(__name__)
-
-
-cattr = cattr.GenConverter()
-
-# Register support for pathlib.
-cattr.register_structure_hook(pathlib.Path, lambda d, t: pathlib.Path(d))
-cattr.register_unstructure_hook(pathlib.Path, str)
-
-# Register support for enums.
-cattr.register_structure_hook(IntEnum, lambda d, t: t[d.upper()] if isinstance(d, str) else t(d))
-cattr.register_unstructure_hook(IntEnum, lambda d: None if d is None else d.name)
-
-
-T = TypeVar("T")
-
-
-def _cast(value: Any, type_: Type[T]) -> T:
-    """
-    Casts given value to the given type.
-    Usually uses cattr.structure()
-    :param value: Value to cast.
-    :param type_: Type to cast to.
-        (For things like Union, it will try each type listed
-        within, until one works.)
-    :return: Converted value.
-    """
-    # Convert bytes to string, Python 2 style!
-    if type_ is str and isinstance(value, bytes):
-        return value.decode("latin1")
-
-    # Prevent accidentally casting an integer to bytes.
-    # Since bytes(some_int) will cause it to create a zero byte string with that many bytes,
-    # this can stall or crash the process if the integer is large enough.
-    if type_ is bytes and isinstance(value, int):
-        raise ValueError("Cannot convert int to bytes.")
-
-    # cattr doesn't handle Unions very nicely, so we'll recursively
-    # handle the innards of Union types instead.
-    # NOTE: Based on documentation, the cattr devs will eventually provide
-    # better support for Unions in the future.
-    if hasattr(type_, "__origin__") and type_.__origin__ is Union:
-        # First see if value is already one of the types.
-        if type(value) in type_.__args__:
-            return value
-        # Otherwise, attempt to case using types in order they are found in the Union.
-        for sub_type in type_.__args__:
-            try:
-                return _cast(value, sub_type)
-            except Exception:
-                continue
-        raise ValueError("No subtypes matched.")
-
-    # Otherwise use cattr
-    return cattr.structure(value, type_)
-
-
-def _auto_convert(cls, fields):
-    """
-    Automatically applies type coercion to all fields.
-    (This also acts as validation)
-    """
-    def converter(field_type):
-        def _wrapper(v):
-            if v is None:
-                return v
-            try:
-                return _cast(v, field_type)
-            except Exception as e:
-                raise ValidationError(f"Failed to cast {v!r} to {field_type} with error: {e}")
-        return _wrapper
-
-    new_fields = []
-    for field in fields:
-        if field.converter is None and field.type:
-            field = field.evolve(converter=converter(field.type))
-        new_fields.append(field)
-    return new_fields
-
-
-def _camel_to_snake(name):
-    name = re.sub("(.)([A-Z][a-z]+)", r"\1_\2", name)
-    return re.sub("([a-z0-9])([A-Z])", r"\1_\2", name).lower()
-
-
-def _strip_null(d: dict) -> dict:
-    """
-    Strips away any entries that have the value None.
-    """
-    new_dict = {}
-    for key, value in d.items():
-        if isinstance(value, dict):
-            value = _strip_null(value)
-        if value is not None:
-            new_dict[key] = value
-    return new_dict
-
-
-def _flatten_dict(dict_: dict) -> dict:
-    """
-    Flattens given element dictionary into a single level of key/value pairs.
-    Combines tags into one.
-    """
-    new_dict = {}
-    for key, value in dict_.items():
-        if isinstance(value, dict):
-            value.pop("type", None)
-            tags = value.pop("tags", None)
-            value = {
-                f"{key}.{_key}" if _key in dict_ else _key: _value
-                for _key, _value in _flatten_dict(value).items()
-            }
-            new_dict.update(value)
-
-            # Consolidate tags into main dictionary.
-            if tags:
-                try:
-                    new_dict["tags"].append(tags)
-                except KeyError:
-                    new_dict["tags"] = tags
-        else:
-            new_dict[key] = value
-
-    # Pop off type.
-    new_dict.pop("type", None)
-    return new_dict
-
-
-# Global configuration for all elements.
-config = dict(auto_attribs=True, field_transformer=_auto_convert)
-
-
-@attr.s(**config)
-class Element:
-    """
-    Base class for handling reporting elements.
-    These should be created using attr for convenience.
-    """
-    tags: List[str] = attr.ib(init=False, factory=list)
-
-    _registry = {}
-
-    def __init_subclass__(cls, **kwargs):
-        """
-        Registers all subclasses of Element.
-        """
-        typ = cls._type()
-        if not typ.startswith("_") and typ != "metadata":
-            if typ in cls._registry:
-                raise ValueError(f"Metadata element of type {typ} already exists.")
-            cls._registry[typ] = cls
-        super().__init_subclass__(**kwargs)
-
-    @classmethod
-    def _all_subclasses(cls):
-        """
-        Returns all registered subclasses of the class, sorted by type.
-        """
-        return [
-            subclass
-            for _, subclass in sorted(cls._registry.items())
-            if issubclass(subclass, cls) and subclass != cls
-        ]
-
-    @classmethod
-    def _type(cls):
-        """This function is used to determine name identifier for the """
-        # By default, type is determined by class name.
-        return _camel_to_snake(cls.__name__)
-
-    @classmethod
-    def fields(cls):
-        return attr.fields(cls)
-
-    @classmethod
-    def _schema(cls, extractor):
-        """
-        Generates schema for this particular Element class.
-        """
-        # First get the short description by looking for the first complete sentence.
-        description = []
-        for line in inspect.getdoc(cls).splitlines():
-            # Stop when we hit an empty line or see variable statements.
-            if not line or line.startswith(":"):
-                break
-            description.append(line.strip())
-        description = " ".join(description)
-
-        schema = {
-            "title": cls.__name__.strip("_").rstrip("2"),
-            "description": description,
-            "type": "object",
-            "properties": {
-                # Include the "type" property that gets added dynamically during serialization.
-                "type": {
-                    "const": cls._type(),
-                }
-            },
-            "additionalProperties": False,
-            "required": ["type"],
-        }
-        for field in cls.fields():
-            is_required = field.default is not None
-
-            # Allow customization within attr metadata field for corner cases.
-            if "jsonschema" in field.metadata:
-                sub_schema = field.metadata["jsonschema"]
-            else:
-                sub_schema = extractor.extract(field.type)
-
-            # Anything not required is nullable.
-            if not is_required:
-                if list(sub_schema.keys()) == ["type"]:
-                    if isinstance(sub_schema["type"], list):
-                        if "null" not in sub_schema["type"]:
-                            sub_schema["type"].append("null")
-                    elif sub_schema["type"] != "null":
-                        sub_schema["type"] = [sub_schema["type"], "null"]
-                elif list(sub_schema.keys()) == ["anyOf"]:
-                    if {"type": "null"} not in sub_schema["anyOf"]:
-                        sub_schema["anyOf"].append({"type": "null"})
-                else:
-                    sub_schema = {"anyOf": [sub_schema, {"type": "null"}]}
-
-            schema["properties"][field.name] = sub_schema
-
-            if is_required:
-                schema["required"].append(field.name)
-
-        return schema
-
-    @classmethod
-    def schema(cls) -> dict:
-        """
-        Generates a JSONSchema from the given element.
-        :return: Dictionary representing the schema.
-        """
-        typing_extractor = jsonschema_extractor.TypingExtractor()
-        typing_extractor.register(Element, lambda extractor, typ: typ._schema(extractor))
-        typing_extractor.register(bytes, lambda extractor, typ: {
-            "type": "string",
-            "contentEncoding": "base64",
-        })
-        # IntEnums are converted to their names before serialization by cattr.
-        typing_extractor.register(IntEnum, lambda extractor, typ: {
-            "enum": [c.name for c in typ]
-        })
-        extractor = jsonschema_extractor.SchemaExtractorSet([typing_extractor])
-        return extractor.extract(cls)
-
-    @classmethod
-    def from_dict(cls, obj: dict) -> "Element":
-        obj = obj.copy()
-        if "type" not in obj:
-            obj["type"] = cls._type()
-        if "tags" not in obj:
-            obj["tags"] = []
-        return cattr.structure(obj, cls)
-
-    def as_dict(self, flat=False) -> dict:
-        ret = cattr.unstructure(self)
-        if flat:
-            ret = _flatten_dict(ret)
-        return ret
-
-    def as_formatted_dict(self, flat=False) -> dict:
-        """
-        Converts metadata element into a well formatted dictionary usually
-        used for presenting metadata elements as tabular data.
-        """
-        ret = {}
-        for field in self.fields():
-            name = field.name
-            value = getattr(self, name)
-            # Convert bytes to a string representation.
-            if isinstance(value, bytes):
-                value = str(value)
-            # Recursively handle nested elements.
-            if isinstance(value, Element):
-                value = value.as_formatted_dict()
-            ret[name] = value
-
-        if flat:
-            ret = _flatten_dict(ret)
-        return ret
-
-    def as_json(self) -> str:
-        class _JSONEncoder(json.JSONEncoder):
-            def default(self, o):
-                # Encode Collection objects using as_dict()
-                if isinstance(o, Element):
-                    return o.as_dict()
-                # Encode bytes as base64
-                if isinstance(o, bytes):
-                    return base64.b64encode(o).decode()
-                # Convert sets to list
-                if isinstance(o, set):
-                    return sorted(o)
-                # Convert UUID
-                if isinstance(o, uuid.UUID):
-                    return str(o)
-                return super().default(o)
-        return json.dumps(self, cls=_JSONEncoder, indent=4)
-
-    def as_json_dict(self) -> dict:
-        """
-        Jsonifies the element and then loads it back as a dictionary.
-        NOTE: This is different from .as_dict() because things like bytes
-        will be converted to a base64 encoded string.
-        """
-        return json.loads(self.as_json())
-
-    def validate(self):
-        attr.validate(self)
-
-    def elements(self) -> List["Element"]:
-        """
-        All elements contained within the given element. (including self)
-        """
-        elements = [self]
-        for field in self.fields():
-            value = getattr(self, field.name)
-            if isinstance(value, Element):
-                elements.extend(value.elements())
-        return elements
-
-    def post_processing(self, report):
-        """
-        Performs and adds extra additions to the Report when the Element gets created.
-        :param report: mwcp Report used to add metadata.
-        """
-
-    def add_tag(self, *tags: Iterable[str]) -> "Element":
-        """
-        Adds a tag for the given metadata.
-
-        :param tags: One or more tags to add to the metadata.
-        :returns: self to make this function chainable.
-        """
-        for tag in tags:
-            if tag not in self.tags:
-                self.tags.append(tag)
-        # Ensure we keep the tags sorted.
-        self.tags = sorted(self.tags)
-        return self
-
-
-# Create a hook that uses the "type" field to determine the appropriate class to use for Element.
-def _structure_hook(value: dict, klass):
-    # Value may be partially converted
-    # github.com/python-attrs/cattrs/issues/78
-    if hasattr(value, "__attrs_attrs__"):
-        return value
-
-    value = dict(value)  # create copy
-
-    # Determine class to use based on "type" field.
-    klass = Element._registry[value.pop("type")]
-
-    # Remove None values from dictionary, since that seems to be causing
-    # cattr (or our autocasting) to convert them to the string "None"
-    # TODO: Remove when github.com/python-attrs/cattrs/issues/53 is solved.
-    value = _strip_null(value)
-
-    # cattrs doesn't support init=False values, so we need to remove tags and
-    # then re-add them.
-    tags = value.pop("tags")
-    ret = cattr.structure_attrs_fromdict(value, klass)
-    ret.tags = tags
-    return ret
-
-
-cattr.register_structure_hook(Element, _structure_hook)
-
-
-# Create hook to add a "type" field to help with serialization of Element types.
-def _unstructure_hook(obj):
-    # obj may be None because we don't use Optional in our typing.
-    if obj is None:
-        return obj
-    return {"type": obj._type(), **cattr.unstructure_attrs_asdict(obj)}
-
-
-cattr.register_unstructure_hook(Element, _unstructure_hook)
-
-
-class Metadata(Element):
-    """
-    Represents a collection of reportable metadata attributes that together represent an idea.
-
-    This class can be subclassed to create your own reportable metadata element.
-    """
-
-    @classmethod
-    def _schema(cls, extractor):
-        # If we are typing the base Metadata class, this means we want to represent
-        # all subclasses instead.
-        if cls == Metadata:
-            return {"anyOf": [
-                extractor.extract(subclass) for subclass in Metadata._all_subclasses()
-            ]}
-        else:
-            return super()._schema(extractor)
-    
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        """
-        Returns STIX content for a class.  All metadata objects should implement this, but if one does not a warning will be supplied.
-
-        """
-        warnings.warn(
-            "as_stix is not implmeneted by " + type(self).__name__ + " so data may be missing from the result",
-            UserWarning
-        )
-        return STIXResult()
-
-    def as_stix_tags(self, parent, fixed_timestamp=None):
-        """
-        Returns an object containing tag information for a given parent assuming there is content
-        """
-        if self.tags:
-            return stix.Note(
-                labels=self.tags,
-                content=f"MWCP Tags: {', '.join(self.tags)}",
-                object_refs=[parent.id],
-                created=fixed_timestamp,
-                modified=fixed_timestamp,
-                allow_custom=True
-            )
-
-
-@attr.s(**config)
-class Path2(Metadata):
-    r"""
-    Filesystem path used by malware.
-
-    Current directory (".") represents the directory of the malware sample that produced this metadata.
-
-    e.g.
-        Path2(r"C:\windows\temp\1\log\keydb.txt", is_dir=False)  # pass full path
-        Path2(r"C:\foo\logs", is_dir=True)
-        Path2("bar.exe", is_dir=False)  # Represents a file name with unknown location
-        Path2(".\bar.exe", is_dir=False)  # Represents a file path within the same directory as the source malware sample.
-    """
-    path: str
-    is_dir: bool = None
-    posix: bool = None
-    file_system: str = None  # NTFS, ext4, etc.
-
-    def __attrs_post_init__(self):
-        # If posix wasn't provided, determine this based on presence of drive letter or separator.
-        if self.posix is None and (self.path.count("\\") or self.path.count("/")):
-            self.posix = not (re.match("^[A-Z]:\\\\", self.path) or self.path.count("\\") > self.path.count("/"))
-
-    @classmethod
-    def _type(cls):
-        return "path"
-
-    @classmethod
-    def from_segments(cls, *segments: str, is_dir: bool = None, posix: bool = False, file_system: str = None):
-        """
-        Provides ability to construct a Path from segments.
-        NOTE: Path is assumed to be Windows if posix flag is not provided.
-
-        e.g.
-            Path2.from_segments("C:", "windows", "temp", "1", "log", "keydb.txt", posix=False, is_dir=False)
-        """
-        if not segments:
-            raise ValidationError(f"from_segments() requires at least one segment.")
-        if len(segments) == 1:
-            return Path2(segments[0], is_dir=is_dir, posix=posix, file_system=file_system)
-
-        # Ensure we do not have secondary segments starting with a slash.
-        # This would cause pathlib's constructor to just take the last absolute path ignored the ones before it.
-        # Which is something we don't want in this context.
-        slash = "/" if posix else "\\"
-        segments = [segments[0], *(segment.lstrip(slash) for segment in segments[1:])]
-
-        if posix:
-            path = pathlib.PurePosixPath(*segments)
-        else:
-            segments = list(segments)
-            # If first segment is a drive, we need to include the \ in order for pathlib to see it as such.
-            if segments[0].endswith(":"):
-                segments[0] += "\\"
-            path = pathlib.PureWindowsPath(*segments)
-        return cls.from_pathlib_path(path, is_dir=is_dir, file_system=file_system)
-
-    @classmethod
-    def from_pathlib_path(cls, path: pathlib.PurePath, is_dir: bool = None, file_system: str = None):
-        """
-        Generate Path from pathlib.PurePath instance.
-        """
-        return Path2(str(path), is_dir=is_dir, posix=isinstance(path, pathlib.PurePosixPath), file_system=file_system)
-
-    @property
-    def _pathlib_path(self) -> Optional[pathlib.PurePath]:
-        if self.posix is None:
-            return None
-        elif self.posix:
-            return pathlib.PurePosixPath(self.path)
-        else:
-            return pathlib.PureWindowsPath(self.path)
-
-    @property
-    def directory_path(self) -> Optional[str]:
-        if self.is_dir:
-            return self.path
-        else:
-            path = self._pathlib_path
-            if path:
-                return str(path.parent)
-            else:
-                return None
-
-    @property
-    def name(self) -> str:
-        path = self._pathlib_path
-        if path:
-            return path.name
-        else:
-            return self.path
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-
-        if self.is_dir:
-            result.add_linked(stix.Directory(path=self.path))
-        else:
-            file_data = {}
-
-            if self.directory_path:
-                cur_dir = stix.Directory(path=self.directory_path)
-                result.add_unlinked(cur_dir)
-                file_data["parent_directory_ref"] = cur_dir.id
-
-            if self.name:
-                file_data["name"] = self.name
-                result.add_linked(stix.File(**file_data))
-
-        result.create_tag_note(self, result.linked_stix[-1])
-
-        return result
-
-
-def Path(
-        path: str = None,
-        directory_path: str = None,
-        name: str = None,
-        is_dir: bool = None,
-        file_system: str = None
-) -> Path2:
-    warnings.warn(
-        "Path has been renamed to Path2 during a transitional period to a new version of Path " 
-        "with a new signature. "
-        "Please update to use Path2 which explicitly expects a path string with no directory/name separation."
-        "NOTE: In a future version, once this function is deprecated, Path2 will be renamed back to Path "
-        "using the new signature.",
-        DeprecationWarning
-    )
-    # Replicating original logic. (existence of directory_path and name overwrite path)
-    if directory_path and name:
-        path = ntpath.join(directory_path, name)
-    # If a directory_path was provided without a name, overwrite is_dir.
-    elif directory_path and not name:
-        path = directory_path
-        is_dir = True
-    elif name and not directory_path:
-        path = name
-        is_dir = False
-    return Path2(path, is_dir=is_dir, file_system=file_system)
-
-
-def Directory(path: str, posix: bool = None) -> Path2:
-    return Path2(path, posix=posix, is_dir=True)
-
-
-def FilePath(path: str, posix: bool = None) -> Path2:
-    return Path2(path, posix=posix, is_dir=False)
-
-
-def FileName(name: str) -> Path2:
-    return Path2(name, is_dir=False)
-
-
-@attr.s(**config)
-class Alphabet(Metadata):
-    """
-    Generic baseXX alphabet
-    """
-    alphabet: str = attr.ib()
-    base: int = attr.ib()
-
-    @alphabet.validator
-    def _validate_alphabet(self, attribute, value):
-        alphabet = value
-        base = self.base
-        if alphabet and base:
-            if len(alphabet) not in (base, base + 1):
-                raise ValidationError(
-                    "Invalid alphabet provided: "
-                    "Length of alphabet must be size of base or base + 1 (if including the pad character)."
-                )
-            # TODO: Determine if this is a valid.
-            # if len(alphabet) != len(set(alphabet)):
-            #     raise ValidationError('mapping must be unique')
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        content = f"Alphabet: {self.alphabet}\nAlphabet Base: {self.base}"
-
-        if self.tags:
-            content += "\n    Alphabet Tags: " + ", ".join(self.tags)
-
-        return STIXResult(content)
-
-
-def Base16Alphabet(alphabet: str) -> Alphabet:
-    """
-    Base16 alphabet
-
-    e.g.
-        Base16Alphabet("0123456789ABCDEF")
-    """
-    return Alphabet(alphabet=alphabet, base=16)
-
-
-def Base32Alphabet(alphabet: str) -> Alphabet:
-    """
-    Base32 alphabet
-
-    e.g.
-        Base32Alphabet("ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=")
-    """
-    return Alphabet(alphabet=alphabet, base=32)
-
-
-def Base64Alphabet(alphabet: str) -> Alphabet:
-    """
-    Base64 alphabet
-
-    e.g.
-        Base64Alphabet("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=")
-    """
-    return Alphabet(alphabet=alphabet, base=64)
-
-
-@attr.s(**config)
-class Command(Metadata):
-    """
-    Shell command
-    """
-    value: str
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        # Process generally uses a UUIDv4 but we want to deduplicate when the same command is used so we will use a v5
-        namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
-        id = "process--" + str(uuid.uuid5(namespace, f"{self.value}"))
-
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        result.add_linked(stix.Process(command_line=self.value, id=id))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-
-@attr.s(**config)
-class Credential(Metadata):
-    """
-    Collection of username and password used as credentials.
-
-    e.g.
-        Credential(username="admin", password="123456")
-    """
-    username: str = None
-    password: str = None
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        
-        params = {}
-        if self.username:
-            params["account_login"] = self.username
-
-        if self.password:
-            params["credential"] = self.password
-
-            # the default UUIDv5 generation scheme for user-account does not factor in credentials so it is possible to overwrite the same username with separate creds
-            # since we do not want this with MWCP if a password is present will generate the ID in our own deterministic manner
-            namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
-            params["id"] = "user-account--" + str(uuid.uuid5(namespace, f"{self.username}//{self.password}"))
-
-        result.add_linked(stix.UserAccount(**params))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-
-def Password(password: str) -> Credential:
-    return Credential(password=password)
-
-
-def Username(username: str) -> Credential:
-    return Credential(username=username)
-
-
-@attr.s(**config)
-class CryptoAddress(Metadata):
-    """
-    A cryptocurrency address and its symbol.
-
-    :param address: The address or unique identifier of the crypto wallet.
-    :param symbol: A unique symbol for the cryptocurrency platform.
-        This is usually the ticker symbol like "BTC", but can be something else more appropriate.
-
-    e.g.
-        # Sample address pulled from bitcoinwiki.org/wiki/Bitcoin_address
-        CryptoAddress("14qViLJfdGaP4EeHnDyJbEGQysnCpwk3gd", "BTC")
-    """
-    address: str
-    symbol: str = None
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        params = {
-            "address": self.address
-        }
-
-        if self.symbol:
-            params["currency_type"] = self.symbol.lower().replace(" ", "-")
-
-        result.add_linked(stix_extensions.CryptoCurrencyAddress(**params))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-
-@attr.s(**config)
-class Socket(Metadata):
-    """
-    A collection of address, port, and protocol used together to make a socket
-    connection.
-
-    e.g.
-        Socket(address="bad.com", port=21, protocol="tcp")
-    """
-    _VALID_PROTOCOLS = {"tcp", "udp", "icmp"}
-
-    address: str = None  # ip address or domain  # TODO: should this be split up?
-    port: int = attr.ib(
-        default=None,
-        metadata={"jsonschema": {
-            "type": "integer",
-            "minimum": 0,
-            "maximum": 65535,
-        }}
-    )
-    network_protocol: str = attr.ib(
-        default=None,
-        converter=lambda v: str(v).lower() if v is not None else v,
-        metadata={"jsonschema": {
-            "enum": sorted(_VALID_PROTOCOLS),
-        }}
-    )
-    # Determines if socket is for a C2 server.
-    #   True == known C2, False == known not a C2, None == unknown
-    c2: bool = None
-    listen: bool = None
-
-    def __attrs_post_init__(self):
-        # Add the _from_port attribute, used internally for backwards compatibility support.
-        self._from_port = False
-
-    @port.validator
-    def _validate_port(self, attribute, value):
-        if value is not None and not 0 <= value <= 65535:
-            raise ValidationError(f"port must be between 0 and 65535. Got {value}")
-
-    @network_protocol.validator
-    def _validate_protocol(self, attribute, value):
-        if value is not None and value not in self._VALID_PROTOCOLS:
-            raise ValidationError(f"protocol {value} is not one of {sorted(self._VALID_PROTOCOLS)}")
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        # we define a static namespace explicitly for MWCP network traffic objects to ensure we deduplicate within MWCP
-        # in general it is bad practice to deduplicate Network Traffic but as this is static analysis we want
-        # to find correlation in a live environment this would be highly discouraged
-        namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
-
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        network_values = {
-            "is_active": False,
-            "id": "network-traffic--" + str(uuid.uuid5(
-                namespace,
-                f"{self.address}//{self.port}//{self.network_protocol}//{self.c2}//{self.listen}"
-            ))
-        }
-
-        # Make an address object if this is present but add it to the list after the network traffic
-        # for better malware analysis results
-        address = None
-        if self.address:
-            address_type = self._guess_address_type(self.address)
-            if address_type == "ipv6":
-                network_values["dst_ref"] = stix.IPv6Address(value = self.address)
-                network_values["protocols"] = ["ipv6"]
-            elif address_type == "ipv4":
-                network_values["dst_ref"] = stix.IPv4Address(value = self.address)
-                network_values["protocols"] = ["ipv4"]
-            else:
-                network_values["dst_ref"] = stix.DomainName(value = self.address)
-                # This is ultimately a guess but it is safer to assume a domain maps
-                # to ipv4 than ipv6 and we must pick one
-                network_values["protocols"] = ["ipv4"]
-        else:
-            network_values["src_ref"] = stix.IPv4Address(value = "0.0.0.0")
-            network_values["protocols"] = ["ipv4"]
-
-        # if a value was provided it should sit after ipv4 or ipv6 respectively
-        if self.network_protocol:
-            network_values["protocols"].append(self.network_protocol)
-
-        if self.port:
-            if self.listen:
-                network_values["src_port"] = self.port
-            else:
-                network_values["dst_port"] = self.port
-
-        if "src_ref" in network_values:
-            result.add_unlinked(network_values["src_ref"])
-        else:
-            result.add_unlinked(network_values["dst_ref"])
-
-        traffic = stix.NetworkTraffic(**network_values)
-        result.create_tag_note(self, traffic)
-
-        # we want the network traffic to be the last object so it is always consistently placed
-        result.add_linked(traffic)
-
-        return result
-    
-    @staticmethod
-    def _guess_address_type(address) -> str:
-        """
-        Used to see if an address is ipv4, ipv6, or a domain
-        """
-        # the fewest number of : in an ipv6 is for ::1.  A domain or IP should never have one so checking for 2 is safe
-        if address.count(":") > 1:
-            return "ipv6"
-
-        # IPv4 must be 4 octets and no TLD can be a number so checking for both gives us a good guess between the two
-        parts = address.split(".")
-        if len(parts) == 4:
-            if parts[3].isnumeric():
-                if int(parts[3]) >= 0 and int(parts[3]) < 256:
-                    return "ipv4"
-        
-        return "domain"
-
-
-def SocketAddress(*args, **kwargs) -> Socket:
-    warnings.warn(
-        "This function is a temporary helper. This may be removed in a future version. "
-        "Please use Socket() instead.",
-        DeprecationWarning
-    )
-    return Socket(*args, **kwargs)
-
-
-def C2SocketAddress(address: str, port: int = None, protocol: str = None) -> Socket:
-    warnings.warn(
-        "This function is a temporary helper. This may be removed in a future version",
-        DeprecationWarning
-    )
-    return Socket(address=address, port=port, network_protocol=protocol, c2=True)
-
-
-def Port(port: int, protocol: str = None) -> Socket:
-    """
-    TCP or UDP port.
-    This generally refers to outbound connections where the malware is the client.
-    Other network layer protocols, such as ICMP can be represented here.
-    Application layer connections, such as HTTP, should be indicated by making a URL instead.
-    """
-    socket = Socket(port=port, network_protocol=protocol)
-    socket._from_port = True
-    return socket
-
-
-def ListenPort(port: int, protocol: str = None) -> Socket:
-    socket = Socket(port=port, network_protocol=protocol, listen=True)
-    socket._from_port = True
-    return socket
-
-
-def Address(address: str) -> Socket:
-    return Socket(address=address)
-
-
-def C2Address(address: str) -> Socket:
-    return Socket(address=address, c2=True)
-
-
-@attr.s(**config)
-class URL(Metadata):
-    """
-    RFC 3986 URL
-
-    e.g.
-        URL("https://10.11.10.13:443/images/baner.jpg")
-
-        creds = Credential(username="user", password="pass")
-        URL(socket=Socket("mail.badhost.com"), application_protocol="smtp", credential=creds))
-    """
-    url: str = None
-    socket: Socket = None
-    path: str = None
-    query: str = None
-    application_protocol: str = None
-    credential: Credential = None
-
-    _URL_RE = re.compile(
-        r"((?P<app_protocol>[a-z\.\-+]{1,40})://)?(?P<address>\[?[^/]+\]?)"
-        r"(?P<path>/[^?]+)?(?P<query>.*)",
-        flags=re.IGNORECASE
-    )
-
-    def __attrs_post_init__(self):
-        if self.url is not None:
-            self._parse_url(self.url)
-
-    def _parse_url(self, url: str):
-        """
-        Parses provided url in order to set individual components.
-        """
-        match = self._URL_RE.match(url)
-        if not match:
-            # TODO: To keeps backwards compatibility we still must allow the url
-            #   to be set.
-            logger.error(f"Error parsing as url: {url}")
-            return
-
-        app_protocol = match.group("app_protocol")
-        path = match.group("path")
-        query = match.group("query")
-        port = None
-
-        address = match.group("address")
-        if address:
-            address = address.rstrip(": ")
-            if address.startswith("["):
-                # ipv6--something like
-                # [fe80::20c:1234:5678:9abc]:80
-                address, found, port = address[1:].partition("]:")
-            else:
-                address, found, port = address.partition(":")
-            if found and not port:
-                raise ValidationError(f"Invalid URL {url}, found ':' at end without a port.")
-            elif not port:
-                port = None
-
-        if not self.socket:
-            self.socket = Socket(address=address, port=port)
-        if not self.path:
-            self.path = path
-        if not self.query:
-            self.query = query
-        if not self.application_protocol:
-            self.application_protocol = app_protocol
-
-    @property
-    def c2(self) -> Optional[bool]:
-        return self.socket and self.socket.c2
-
-    @c2.setter
-    def c2(self, value: bool):
-        """
-        Convenience for setting url as a c2.
-        """
-        if not isinstance(value, bool):
-            raise ValidationError(f"C2 {repr(value)} is not a boolean.")
-        if not self.socket:
-            self.socket = Socket()
-        self.socket.c2 = value
-
-    @property
-    def listen(self) -> Optional[bool]:
-        return self.socket and self.socket.listen
-
-    @listen.setter
-    def listen(self, value: bool):
-        """
-        Convenience for setting url as a listen.
-        """
-        if not isinstance(value, bool):
-            raise ValidationError("Listen {repr(value)} is not a boolean.")
-        if not self.socket:
-            self.socket = Socket()
-        self.socket.listen = value
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-
-        # Some parsers can have a URL without a URL so we skip it in these cases
-        if self.url is None:
-            warnings.warn("Skipped creation of STIX URL since the parser provided no URL")
-            return result
-
-        result.add_linked(stix.URL(value = self.url))
-        result.create_tag_note(self, result.linked_stix[-1])
-
-        if self.socket:
-            result.merge(self.socket.as_stix(base_object))
-            result.add_unlinked(stix.Relationship(relationship_type="used", source_ref=result.linked_stix[-1].id, target_ref=result.linked_stix[0].id, created=fixed_timestamp, modified=fixed_timestamp))
-
-        if self.credential:
-            result.merge(self.credential.as_stix(base_object))
-            result.add_unlinked(stix.Relationship(relationship_type="contained", source_ref=result.linked_stix[0].id, target_ref=result.linked_stix[-1].id, created=fixed_timestamp, modified=fixed_timestamp))
-
-        return result
-
-def C2URL(
-        url: str = None,
-        socket: Socket = None,
-        path: str = None,
-        query: str = None,
-        application_protocol: str = None,
-        credential: Credential = None
-) -> URL:
-    url = URL(
-        url=url,
-        socket=socket,
-        path=path,
-        query=query,
-        application_protocol=application_protocol,
-        credential=credential
-    )
-    url.c2 = True
-    return url
-
-
-def URLPath(path: str) -> URL:
-    """Path portion of URL"""
-    warnings.warn(
-        "This function is a temporary helper. This may be removed in a future version. "
-        "Please use URL() instead.",
-        DeprecationWarning
-    )
-    return URL(path=path)
-
-
-def Proxy(
-        username: str = None,
-        password: str = None,
-        address: str = None,
-        port: int = None,
-        protocol: str = None
-) -> URL:
-    """
-    Generates URL object from given proxy connection information.
-
-    e.g.
-        Proxy(
-            username="admin",
-            password="pass",
-            address="192.168.1.1",
-            port=80,
-            protocol="tcp",
-        )
-    """
-    url = URL()
-    if address or port or protocol:
-        url.socket = Socket(address=address, port=port, network_protocol=protocol)
-    if username or password:
-        url.credential = Credential(username=username, password=password)
-    url.add_tag("proxy")
-    return url
-
-
-def ProxySocketAddress(address: str, port: int = None, protocol: str = None) -> URL:
-    warnings.warn(
-        "This function is a temporary helper. This may be removed in a future version. "
-        "Please use Proxy() instead.",
-        DeprecationWarning
-    )
-    return Proxy(address=address, port=port, protocol=protocol)
-
-
-def ProxyAddress(address: str) -> URL:
-    warnings.warn(
-        "This function is a temporary helper. This may be removed in a future version. "
-        "Please use Proxy() instead.",
-        DeprecationWarning
-    )
-    return Proxy(address=address)
-
-
-def FTP(
-        username: str = None,
-        password: str = None,
-        url: str = None,
-        address: str = None,
-        port: Port = None,
-) -> URL:
-    """
-    Generates URL object from given FTP credentials and URL or address information.
-
-    e.g.
-        FTP(
-            username="admin",
-            password="pass",
-            url="ftp://badhost.com:21",
-        )
-    """
-    warnings.warn(
-        "This function is a temporary helper. This may be removed in a future version",
-        DeprecationWarning
-    )
-    if url and address:
-        raise ValidationError("Must provide either url or address. Both provided.")
-    if url:
-        url_object = URL(url)
-    else:
-        url_object = URL(socket=Socket(address=address, port=port))
-    if username or password:
-        url_object.credential = Credential(username=username, password=password)
-    url_object.application_protocol = "ftp"
-    return url_object
-
-
-@attr.s(**config)
-class EmailAddress(Metadata):
-    """
-    Email address
-
-    e.g.
-        EmailAddress("email@bad.com")
-    """
-    value: str = attr.ib(metadata={"jsonschema": {
-        "type": "string",
-        "format": "email",
-    }})
-
-    @value.validator
-    def _validate(self, attribute, value):
-        if "@" not in value:
-            raise ValidationError(f"Email address should at least have a '@' character.")
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        result.add_linked(stix.EmailAddress(value=self.value))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-@attr.s(**config)
-class Event(Metadata):
-    """
-    Event object
-
-    e.g.
-        Event("MicrosoftExit")
-    """
-    value: str
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        content = f"Event Name: {self.value}"
-
-        if self.tags:
-            content += "\n    Event Name Tags: " + ", ".join(self.tags)
-        
-        return STIXResult(content)
-
-
-def _uuid_convert(value):
-    """
-    Converts value into a uuid.UUID value (if not already).
-    This is necessary because uuid.UUID can't handle being constructed twice.
-    """
-    try:
-        if isinstance(value, str):
-            return uuid.UUID(value)
-        elif isinstance(value, bytes):
-            return uuid.UUID(bytes=value)
-        elif isinstance(value, int):
-            return uuid.UUID(int=value)
-        elif isinstance(value, uuid.UUID):
-            return value
-        else:
-            raise ValidationError(f"Invalid UUID: {value}")
-    except Exception as e:
-        raise ValidationError(f"Invalid UUID: {e}")
-
-# NOTE: We are not typing this as uuid.UUID because that has caused issues with serialization.
-#   Validation occurs in the below function.
-@attr.s(**config)
-class UUID(Metadata):
-    """
-    A 128-bit number used to identify information, also referred to as a GUID.
-
-    e.g.
-        UUID("654e5cff-817c-4e3d-8b01-47a6f45ae09a")
-    """
-    value: uuid.UUID = attr.ib(converter=_uuid_convert, metadata={"jsonschema": {
-        "type": "string",
-        "format": "uuid",
-    }})
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        result.add_linked(stix_extensions.ObservedString(purpose="uuid", value=self.value))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-
-GUID = UUID  # alias
-
-
-@attr.s(**config)
-class UUIDLegacy(Metadata):
-    """
-    Legacy version of UUID that doesn't validate or convert the uuid in order to ensure
-    the original raw strings is displayed.
-
-    WARNING: This should not be used in new code. Use UUID instead.
-    """
-    value: str
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        result.add_linked(stix_extensions.ObservedString(purpose="uuid", value=self.value))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-@attr.s(**config)
-class InjectionProcess(Metadata):
-    """
-    Process into which malware is injected.
-    Usually this is a process name but it may take other forms such as a filename of the executable.
-
-    e.g.
-        InjectionProcess("iexplore")
-        InjectionProcess("svchost")
-    """
-    value: str
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        content = f"Injects Into: {self.value}"
-
-        if self.tags:
-            content += "\n    Injects Into Tags: " + ", ".join(self.tags)
-
-        return STIXResult(content)
-        
-
-
-@attr.s(**config)
-class Interval(Metadata):
-    """
-    Time malware waits between beacons or other activity given in seconds.
-
-    e.g.
-        Interval(3.0)
-        Interval(0.1)
-    """
-    value: float
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        content = f"Interval: {self.value}"
-
-        if self.tags:
-            content += "\n    Interval Tags: " + ", ".join(self.tags)
-        
-        return STIXResult(content)
-
-
-
-@attr.s(**config)
-class IntervalLegacy(Metadata):
-    """
-    Legacy version of interval that uses a string type instead of float in order to preserve original
-    display of the interval.
-    This was done in order to ensure the decimal is either included or not depending on what the user provides.
-
-    WARNING: This should not be used in new code!
-    """
-    value: str
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        content = f"Interval: {self.value}"
-
-        if self.tags:
-            content += "\n    Interval Tags: " + ", ".join(self.tags)
-        
-        return STIXResult(content)
-
-
-@attr.s(**config)
-class EncryptionKey(Metadata):
-    """
-    Encryption, encoding, or obfuscation key.
-
-    e.g.
-        EncryptionKey(
-            b"\x6d\x79\x72\x63\x34\x6b\x65\x79",
-            algorithm="rc4",
-        )
-        EncryptionKey(
-            b"\x6d\x79\x72\x63\x34\x6b\x65\x79",
-            algorithm="aes",
-            mode="ecb",
-            iv=b"\x00\x00\x00\x00\x00\x00\x00\x01",
-        )
-    """
-    key: bytes
-    algorithm: str = None
-    mode: str = None
-    iv: bytes = None
-
-    def __attrs_post_init__(self):
-        # Determines if key is an encoded utf8 string.
-        # (Used for backwards compatibility support.)
-        self._raw_string = False
-
-    def as_formatted_dict(self, flat=False) -> dict:
-        # Convert key into hex number
-        key = f"0x{self.key.hex()}"
-
-        # Add context if encoding can be detected from key.
-        encoding = None
-        if self._raw_string:
-            encoding = "utf-8"
-        else:
-            # Test for encoding by determining which encoding creates pure ascii.
-            for test_encoding in ["utf-16", "ascii", "utf-8"]:
-                try:
-                    if self.key.decode(test_encoding).isprintable():
-                        encoding = test_encoding
-                        break
-                except UnicodeDecodeError:
-                    continue
-        if encoding:
-            key += f' ("{self.key.decode(encoding)}")'
-
-        return {
-            "tags": self.tags,
-            "key": key,
-            "algorithm": self.algorithm,
-            "mode": self.mode,
-            "iv": f"0x{self.iv.hex()}" if self.iv else None,
-        }
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        params = { "key_hex": self.key.hex() }
-
-        if self.algorithm:
-            params["algorithm"] = self.algorithm
-
-        if self.mode:
-            params["mode"] = self.mode
-
-        if self.iv:
-            params["iv_hex"] = self.iv.hex()
-
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        result.add_linked(stix_extensions.SymmetricEncryption(**params))
-        result.create_tag_note(self, result.linked_stix[-1])
-
-        return result
-
-def EncryptionKeyLegacy(key: str) -> EncryptionKey:
-    """
-    Legacy version of 'key' field which takes a string value instead of bytes.
-    """
-    warnings.warn(
-        "EncryptionKeyLegacy is only for backwards compatibility support. Please use EncryptionKey instead.",
-        DeprecationWarning
-    )
-    encryption_key = EncryptionKey(key.encode("utf-8"))
-    encryption_key._raw_string = True
-    return encryption_key
-
-
-@attr.s(**config)
-class DecodedString(Metadata):
-    """
-    Extracted decrypted or decoded string.
-
-    e.g.
-        DecodedString("badman")
-        DecodedString("evilstring", encryption_key=EncryptionKey(b"secret", algorithm="xor"))
-    """
-    value: str
-    encryption_key: EncryptionKey = None
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-
-        # sometimes empty strings come up so we should just discard these
-        if not self.value:
-            return result
-
-        
-
-        cur = stix_extensions.ObservedString(purpose="decoded", value=self.value)
-        result.add_linked(cur)
-        result.create_tag_note(self, cur)
-
-        if self.encryption_key:
-            sub = self.encryption_key.as_stix(base_object)
-            result.merge(sub)
-            result.add_unlinked(stix.Relationship(relationship_type="outputs", source_ref=sub.linked_stix[0].id, target_ref=cur.id, allow_custom=True, created=fixed_timestamp, modified=fixed_timestamp))
-            
-        return result
-        
-
-@attr.s(**config)
-class MissionID(Metadata):
-    """
-    Attacker specified identifier encoded in malware,
-    usually reflected in beacons and often related to target or time of attack.
-
-    e.g.
-        MissionID("target4")
-        MissionID("201412")
-    """
-    value: str
-    
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        result.add_linked(stix_extensions.ObservedString(purpose="mission-id", value=self.value))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-
-@attr.s(**config)
-class Mutex(Metadata):
-    """
-    Mutex name used to prevent multiple executions of malware
-
-    e.g.
-        Mutex("ithinkimalonenow")
-        Mutex("0036a8117afa")
-    """
-    value: str
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        result.add_linked(stix.Mutex(name=self.value))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-
-@attr.s(**config)
-class Other(Metadata):
-    """
-    All other items that don't fit within the existing declared schema.
-    Value type is determined by the "value_format" property.
-
-    e.g.
-        Other("keylogger", True)
-        Other("custom_info", b"\xde\xad\xbe\xef")
-        Other("custom_info2", "hello")
-    """
-    key: str
-    value: Union[int, bytes, str, bool]
-    value_format: str = attr.ib(
-        init=False,
-        metadata={"jsonschema": {
-            "enum": ["string", "bytes", "integer", "boolean"],
-        }}
-    )
-
-    def __attrs_post_init__(self):
-        if isinstance(self.value, bool):
-            self.value_format = "boolean"
-        elif isinstance(self.value, int):
-            self.value_format = "integer"
-        elif isinstance(self.value, str):
-            self.value_format = "string"
-        elif isinstance(self.value, bytes):
-            self.value_format = "bytes"
-        else:
-            raise ValidationError(f"Got unexpected data: {self.value}")
-
-    def as_formatted_dict(self, flat=False) -> dict:
-        ret = super().as_formatted_dict()
-        # Don't show value_format.
-        del ret["value_format"]
-        return ret
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        # boolean values and numbers should be appended as a single master Note instead of using this mechanism
-        if self.value_format in ("boolean", "integer") or self.value in (b"", ""):
-            content = f"{self.key}: {self.value}"
-
-            if self.tags:
-                content += f"\n    {self.key} Tags: " + ", ".join(self.tags)
-
-            result = STIXResult(content)
-        else:
-            content = {
-                "purpose": self.key.replace("_", "-").replace(" ", "-").lower(),
-                "value": self.value
-            }
-
-            result = STIXResult(fixed_timestamp=fixed_timestamp)
-            result.add_linked(stix_extensions.ObservedString(**content))
-            result.create_tag_note(self, result.linked_stix[-1])
-
-        return result
-
-
-@attr.s(**config)
-class Pipe(Metadata):
-    r"""
-    Named, one-way or duplex pipe for communication between the pipe server and one or more pipe clients.
-
-    e.g.
-        Pipe("\\.\\pipe\\namedpipe")
-    """
-    value: str
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        result.add_linked(stix_extensions.ObservedString(purpose="pipe", value=self.value))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-
-class RegistryHive(IntEnum):
-    HKEY_CLASSES_ROOT = 0x80000000
-    HKEY_CURRENT_USER = 0x80000001
-    HKEY_LOCAL_MACHINE = 0x80000002
-    HKEY_USERS = 0x80000003
-    HKEY_PERFORMANCE_DATA = 0x80000004
-    HKEY_CURRENT_CONFIG = 0x80000005
-    HKEY_DYN_DATA = 0x80000006
-    HKEY_CURRENT_USER_LOCAL_SETTINGS = 0x80000007
-    HKEY_PERFORMANCE_TEXT = 0x80000050
-    HKEY_PERFORMANCE_NLSTEXT = 0x80000060
-
-    # Aliases
-    HKCR = HKEY_CLASSES_ROOT
-    HKCU = HKEY_CURRENT_USER
-    HKLM = HKEY_LOCAL_MACHINE
-    HKU = HKEY_USERS
-    HKPD = HKEY_PERFORMANCE_DATA
-    HKCC = HKEY_CURRENT_CONFIG
-    HKDD = HKEY_DYN_DATA
-    HKCULS = HKEY_CURRENT_USER_LOCAL_SETTINGS
-    HKPT = HKEY_PERFORMANCE_TEXT
-    HKPN = HKEY_PERFORMANCE_NLSTEXT
-
-
-class RegistryDataType(IntEnum):
-    """Registry value data types in winreg.h"""
-    REG_NONE = 0
-    REG_SZ = 1
-    REG_EXPAND_SZ = 2
-    REG_BINARY = 3
-    REG_DWORD = 4
-    REG_DWORD_LITTLE_ENDIAN = REG_DWORD
-    REG_DWORD_BIG_ENDIAN = 5
-    REG_LINK = 6
-    REG_MULTI_SZ = 7
-    REG_QWORD = 11
-
-
-@attr.s(**config)
-class Registry2(Metadata):
-    """
-    Registry key, value (or name), and data.
-    (see docs.microsoft.com/en-us/windows/win32/sysinfo/structure-of-the-registry)
-
-    e.g.
-        Registry2(
-            hive="HKLM",  # or metadata.RegistryHive.HKEY_LOCAL_MACHINE
-            subkey="Software\\Microsoft\\Windows\\CurrentVersion\\Run",
-            value="Updater",
-            data="c:\\update.exe"
-        )
-    """
-    hive: RegistryHive = None
-    subkey: str = None
-    value: str = None  # registry key, value name, combination of the two
-    data: Union[bytes, str, int, List[str]] = attr.ib(default=None)
-    data_type: RegistryDataType = None
-
-    def __attrs_post_init__(self):
-        # Pull out hive if it was included in subkey.
-        if not self.hive and self.subkey:
-            hive, _, subkey = self.subkey.partition("\\")
-            try:
-                self.hive = RegistryHive[hive.upper()]
-            except KeyError:
-                pass
-            else:
-                self.subkey = subkey
-
-        # Strip off leading or trailing \'s on subkey.
-        if self.subkey:
-            self.subkey = self.subkey.strip("\\")
-
-        # Automatically set data type for some data values.
-        if self.data_type is None and self.data is not None:
-            if isinstance(self.data, str):
-                # If we have more than one "\0", this is a string list.
-                if self.data.count("\0") > 1:
-                    self.data_type = RegistryDataType.REG_MULTI_SZ
-                else:
-                    self.data_type = RegistryDataType.REG_SZ
-            elif isinstance(self.data, list) and all(isinstance(entry, str) for entry in self.data):
-                self.data_type = RegistryDataType.REG_MULTI_SZ
-            elif isinstance(self.data, bytes):
-                self.data_type = RegistryDataType.REG_BINARY
-            elif isinstance(self.data, int):
-                if self.data <= 0xffffffff:
-                    self.data_type = RegistryDataType.REG_DWORD
-                else:
-                    self.data_type = RegistryDataType.REG_QWORD
-            # NOTE: We are not going to convert a data of None to be type REG_NONE because data could
-            #   not be provided because we couldn't obtain it.
-            #   User must explicitly set data_type to REG_NONE if it is known to be None.
-
-        # Auto convert data set as REG_MULTI_SZ if given as a full string with null-terminations.
-        if self.data_type == RegistryDataType.REG_MULTI_SZ and isinstance(self.data, str) and "\0" in self.data:
-            if self.data.endswith("\0"):
-                self.data = self.data[:-1]
-            self.data = self.data.split("\0")
-
-        # Strip off null termination for strings.
-        if self.data and self.data_type == RegistryDataType.REG_SZ:
-            self.data = self.data.rstrip("\0")
-
-    @data.validator
-    def _validate_data(self, attribute, value):
-        if isinstance(value, int) and value < 0:
-            raise ValidationError(f"Integer data value must be positive. Got {value}")
-
-    @classmethod
-    def _type(cls):
-        return "registry"
-
-    @classmethod
-    def from_path(cls, path: str, data: Union[bytes, str, int] = None) -> "Registry2":
-        """
-        Generates a Registry from a given full path.
-        The last segment of the path is assumed to be the value.
-        """
-        # Cast path to string to be more backwards compatible.
-        if isinstance(path, bytes):
-            path = path.decode("utf8")
-        subkey, _, value = path.rpartition("\\")
-        return Registry2(subkey=subkey or None, value=value or None, data=data)
-
-    @property
-    def key(self) -> Optional[str]:
-        """
-        The combination of the hive + subkey.
-        """
-        hive_name = self.hive.name if self.hive is not None else ""
-        if hive_name or self.subkey:
-            return "\\".join([hive_name, self.subkey or ""])
-        else:
-            return None
-
-    def as_formatted_dict(self, flat=False) -> dict:
-        return {
-            "tags": self.tags,
-            "key": self.key,
-            "value": self.value,
-            "data": self.data,
-            "data_type": self.data_type.name if self.data_type is not None else None,
-        }
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        value = {}
-        properties = {}
-
-        if self.key:
-            properties["key"] = self.key
-
-        if self.value:
-            value["data"] = self.value
-        
-        # this will be read as a string with the class name included so we need to strip out the class time
-        if self.data_type:
-            value["data_type"] = str(self.data_type).split(".")[-1]
-
-        if value:
-            properties["values"] = [value]
-
-        
-        result.add_linked(stix.WindowsRegistryKey(**properties))
-        result.create_tag_note(self, result.linked_stix[-1])
-
-        return result
-
-def Registry(path: str = None, key: str = None, value: str = None, data: Union[bytes, str, int] = None) -> Registry2:
-    """
-    Registry key and value.
-
-    e.g.
-        Registry(
-            "HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\Updater",
-            data="c:\\update.exe",
-        )
-    """
-    warnings.warn(
-        "Registry has been renamed to Registry2 during a transitional period to a new version of Registry " 
-        "with a new signature. "
-        "Please update to use Registry2 with explicit key/value fields or use the .from_path() constructor. "
-        "NOTE: In a future version, once this function is deprecated, Registry2 will be renamed back to Registry "
-        "using the new signature.",
-        DeprecationWarning
-    )
-    if path is not None:
-        registry = Registry2.from_path(path, data=data)
-        # Need to overwrite key and value if provided in order to replicate legacy logic.
-        if key:
-            registry.subkey = key
-        if value:
-            registry.value = value
-        return registry
-    else:
-        return Registry2(subkey=key, value=value, data=data)
-
-
-def RegistryData(data: str) -> Registry2:
-    warnings.warn(
-        "This is a temporary helper that may be removed in a future version. "
-        "Please use Registry() instead.", DeprecationWarning
-    )
-    return Registry2(data=data)
-
-
-def RegistryPath(path: str) -> Registry2:
-    warnings.warn(
-        "This is a temporary helper that may be removed in a future version. "
-        "Please use Registry() instead.", DeprecationWarning
-    )
-    return Registry2.from_path(path)
-
-
-def RegistryPathData(path: str, data: str) -> Registry2:
-    warnings.warn(
-        "This is a temporary helper that may be removed in a future version. "
-        "Please use Registry() instead.", DeprecationWarning
-    )
-    return Registry2.from_path(path, data=data)
-
-
-def _int_dump(value: int) -> str:
-    """
-    Dumps integer into hex format in same style used by openssl.
-    """
-    # Display smaller values as decimal with hex in parenthesis.
-    if value < (0x1 << (15 * 8)):
-        return f"{value} ({hex(value)})"
-    # Otherwise display as hex dump with bytes separated by ":"
-    value_bytes = value.to_bytes((value.bit_length() + 7) // 8, "big")
-    hex_dump = ":".join(f"{byte:02x}" for byte in value_bytes)
-    hex_dump = textwrap.fill(hex_dump, width=45)
-    return hex_dump
-
-
-def _parse_rsa_xml(data: str):
-    """
-    Parses RSA key data from XML notation.
-    Logs any errors as warnings.
-
-    :raises ValueError: If nothing could be parsed out.
-    """
-    try:
-        root = ElementTree.fromstring(data)
-    except ElementTree.ParseError as e:
-        raise ValueError(f"Failed to parse XML data: {e}")
-    if root.tag != "RSAKeyValue":
-        raise ValueError(f"Expected root tag to be 'RSAKeyValue', got '{root.tag}'")
-    fields = {}
-    for child in root:
-        try:
-            fields[child.tag] = int.from_bytes(base64.b64decode(child.text), byteorder="big")
-        except binascii.Error as e:
-            logger.warning(f"Failed to base64 decode data in '{child.tag}': '{child.text}' with error: {e}")
-
-    if not fields:
-        raise ValueError(f"Failed to parse any RSA key data from XML.")
-
-    return fields
-
-
-@attr.s(**config)
-class RSAPrivateKey(Metadata):
-    """
-    RSA private key containing: public exponent, modulus, private exponent (d),
-        p, q, d mod (p-1), d mod (q-1), q inv mod p
-    """
-    public_exponent: int = None
-    modulus: int = None
-    private_exponent: int = None
-    p: int = None
-    q: int = None
-    d_mod_p1: int = None
-    d_mod_q1: int = None
-    q_inv_mod_p: int = None
-
-    @classmethod
-    def from_DER(cls, data: bytes) -> "RSAPrivateKey":
-        """
-        Generates RSAPrivateKey from data in ASN.1 DER format.
-
-        :param data: RSA key data in ASN.1 DER format
-
-        :raises ValueError: on failure
-        """
-        try:
-            privkey, _ = asn1_decoder.decode(data, asn1Spec=rfc2437.RSAPrivateKey())
-            return RSAPrivateKey(
-                public_exponent=int(privkey.getComponentByName("publicExponent")),
-                modulus=int(privkey.getComponentByName("modulus")),
-                private_exponent=int(privkey.getComponentByName("privateExponent")),
-                p=int(privkey.getComponentByName("prime1")),
-                q=int(privkey.getComponentByName("prime2")),
-                d_mod_p1=int(privkey.getComponentByName("exponent1")),
-                d_mod_q1=int(privkey.getComponentByName("exponent2")),
-                q_inv_mod_p=int(privkey.getComponentByName("coefficient")),
-            )
-        except PyAsn1Error as e:
-            raise ValueError(f"Failed to extract RSA public key: {e}")
-
-    @classmethod
-    def from_PEM(
-            cls, data: str,
-            start_marker="-----BEGIN RSA PRIVATE KEY-----",
-            end_marker="-----END RSA PRIVATE KEY-----"
-    ) -> "RSAPrivateKey":
-        """
-        Generates RSAPrivateKey from data in ASN.1 PEM format.
-
-        :param data: RSA key data in ASN.1 PEM format
-        :param start_marker: Marks the beginning of the private key in PEM format.
-        :param end_marker: Marks the end of the private key in PEM format.
-
-        :raises ValueError: on failure
-        """
-        with io.StringIO(data) as fo:
-            der = pem.readPemFromFile(fo, startMarker=start_marker, endMarker=end_marker)
-            return cls.from_DER(der)
-
-    @classmethod
-    def from_BLOB(cls, data: bytes) -> "RSAPrivateKey":
-        """
-        Generates RSAPrivateKey from data stored in a Microsoft PRIVATEKEYBLOB format.
-
-        :param data: RSA key data in Microsoft Blob format
-
-        :raises ValueError: on failure
-        """
-        try:
-            privkey = construct.PRIVATEKEYBLOB.parse(data)
-            return RSAPrivateKey(
-                public_exponent=privkey.pubexponent,
-                modulus=privkey.modulus,
-                private_exponent=privkey.D,
-                p=privkey.P,
-                q=privkey.Q,
-                d_mod_p1=privkey.Dp,
-                d_mod_q1=privkey.Dq,
-                q_inv_mod_p=privkey.Iq,
-            )
-        except construct.ConstructError as e:
-            raise ValueError(f"Failed to parse Private Key BLOB: {e}")
-
-    @classmethod
-    def from_XML(cls, data: str, fallback=False) -> Union["RSAPrivateKey", "RSAPublicKey"]:
-        """
-        Generates RSAPrivateKey from data stored in serialized .NET XML resource.
-        (see RSA.FromXMLString() from .NET API documentation)
-
-        :param data: .NET Microsoft XML resource data
-        :param fallback: Whether to fallback to creating a RSAPublicKey if only the public exponent and modulus exists.
-            (useful if you don't know/care if the XML data contains a public or private key)
-
-        :raises ValueError: on failure
-        """
-        fields = _parse_rsa_xml(data)
-        if fallback and not any(key in fields for key in ("D", "P", "Q", "DP", "DQ", "InverseQ")):
-            return RSAPublicKey.from_XML(data)
-        return RSAPrivateKey(
-            public_exponent=fields.get("Exponent", None),
-            modulus=fields.get("Modulus", None),
-            private_exponent=fields.get("D", None),
-            p=fields.get("P", None),
-            q=fields.get("Q", None),
-            d_mod_p1=fields.get("DP", None),
-            d_mod_q1=fields.get("DQ", None),
-            q_inv_mod_p=fields.get("InverseQ", None),
-        )
-
-    def as_formatted_dict(self, flat=False) -> dict:
-        """
-        Display of RSAPrivateKey tends to create really wide output.
-        Reformatting results to equivalent output you would get with:
-            `openssl rsa -in key.pem -text -noout`
-        """
-        # NOTE: Not using openssl's field names since they are less descriptive.
-        fields = [
-            ("Modulus (n)", self.modulus),
-            ("Public Exponent (e)", self.public_exponent),
-            ("Private Exponent (d)", self.private_exponent),
-            ("p", self.p),
-            ("q", self.q),
-            ("d mod (p-1)", self.d_mod_p1),
-            ("d mod (q-1)", self.d_mod_q1),
-            ("(inverse of q) mod p", self.q_inv_mod_p),
-        ]
-
-        value = ""
-        for field, _value in fields:
-            if _value is not None:
-                value += f"{field}:\n{textwrap.indent(_int_dump(_value), '    ')}\n"
-
-        return {"tags": self.tags, "value": value or None}
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-
-        # x509 specifies hashes and serial for deterministic IDs in most cases, but we will never have that
-        # As such we are using our own namespace to generate a deterministic ID instead of forcing it to be a UUIDv4
-        # We only use the properties for the public key to make this ID so that we can avoid duplicating the public + private key data when both are present
-        namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
-        params = {
-            "id": "x509-certificate--" + str(uuid.uuid5(namespace, f"{self.public_exponent}//{self.modulus}"))
-        }
-
-        if self.public_exponent:
-            params["subject_public_key_exponent"] = self.public_exponent
-
-        if self.modulus:
-            params["subject_public_key_modulus"] = str(self.modulus)
-
-        extensions = stix_extensions.rsa_private_key_extension(self.private_exponent, self.p, self.q, self.d_mod_p1, self.d_mod_q1, self.q_inv_mod_p)
-
-        if extensions:
-            params["extensions"] = extensions
-
-        result.add_linked(stix.X509Certificate(**params))
-        result.create_tag_note(self, result.linked_stix[-1])
-
-        return result        
-
-@attr.s(**config)
-class RSAPublicKey(Metadata):
-    """
-    RSA public key containing: public_exponent, modulus
-    """
-    public_exponent: int = None
-    modulus: int = None
-
-    @classmethod
-    def from_DER(cls, data: bytes) -> "RSAPublicKey":
-        """
-        Generates RSAPublicKey from data in ASN.1 DER format.
-
-        :param data: RSA key data in ASN.1 DER format
-
-        :raises ValueError: on failure
-        """
-        try:
-            keyinfo, _ = asn1_decoder.decode(data, asn1Spec=rfc2459.SubjectPublicKeyInfo())
-            pubkey_obj = keyinfo.getComponentByName("subjectPublicKey")
-            key_data = bitarray(pubkey_obj.asBinary()).tobytes()
-            pubkey, _ = asn1_decoder.decode(key_data, asn1Spec=rfc2437.RSAPublicKey())
-            return RSAPublicKey(
-                public_exponent=int(pubkey.getComponentByName("publicExponent")),
-                modulus=int(pubkey.getComponentByName("modulus")),
-            )
-        except PyAsn1Error as e:
-            raise ValueError(f"Failed to extract RSA public key: {e}")
-
-    @classmethod
-    def from_PEM(
-            cls, data: str,
-            start_marker="-----BEGIN PUBLIC KEY-----",
-            end_marker="-----END PUBLIC KEY-----"
-    ) -> "RSAPublicKey":
-        """
-        Generates RSAPublicKey from data in ASN.1 PEM format.
-
-        :param data: RSA key data in ASN.1 PEM format
-        :param start_marker: Marks the beginning of the public key in PEM format.
-        :param end_marker: Marks the end of the public key in PEM format.
-
-        :raises ValueError: on failure
-        """
-        with io.StringIO(data) as fo:
-            der = pem.readPemFromFile(fo, startMarker=start_marker, endMarker=end_marker)
-            return cls.from_DER(der)
-
-    @classmethod
-    def from_BLOB(cls, data: bytes) -> "RSAPublicKey":
-        """
-        Generates RSAPublicKey from data stored in a Microsoft PUBLICKEYBLOB format.
-
-        :param data: RSA key data in Microsoft Blob format
-
-        :raises ValueError: on failure
-        """
-        try:
-            pubkey = construct.PUBLICKEYBLOB.parse(data)
-            return RSAPublicKey(
-                public_exponent=pubkey.pubexponent,
-                modulus=pubkey.modulus,
-            )
-        except construct.ConstructError as e:
-            raise ValueError(f"Failed to parse Public Key BLOB: {e}")
-
-    @classmethod
-    def from_XML(cls, data: str) -> "RSAPublicKey":
-        """
-        Generates RSAPublicKey from data stored in serialized .NET XML resource.
-        (see RSA.FromXMLString() from .NET API documentation)
-
-        :param data: .NET Microsoft XML resource data
-
-        :raises ValueError: on failure
-        """
-        fields = _parse_rsa_xml(data)
-        return RSAPublicKey(
-            public_exponent=fields.get("Exponent", None),
-            modulus=fields.get("Modulus", None),
-        )
-
-    def as_formatted_dict(self, flat=False) -> dict:
-        """
-        Display of RSAPublicKey tends to create really wide output.
-        Reformatting results to equivalent output you would get with:
-            `openssl rsa -in key.pem -text -noout -pubin`
-        """
-        fields = [
-            ("Modulus (n)", self.modulus),
-            ("Public Exponent (e)", self.public_exponent),
-        ]
-
-        value = ""
-        for field, _value in fields:
-            if _value is not None:
-                value += f"{field}:\n{textwrap.indent(_int_dump(_value), '    ')}\n"
-
-        return {"tags": self.tags, "value": value or None}
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-
-        # x509 specifies hashes and serial for deterministic IDs in most cases, but we will never have that
-        # As such we are using our own namespace to generate a deterministic ID instead of forcing it to be a UUIDv4
-        namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
-        params = {
-            "id": "x509-certificate--" + str(uuid.uuid5(namespace, f"{self.public_exponent}//{self.modulus}"))
-        }
-
-        if self.public_exponent:
-            params["subject_public_key_exponent"] = self.public_exponent
-
-        if self.modulus:
-            params["subject_public_key_modulus"] = str(self.modulus)
-
-        result.add_linked(stix.X509Certificate(**params))
-        result.create_tag_note(self, result.linked_stix[-1])
-
-        return result
-
-@attr.s(**config)
-class Service(Metadata):
-    r"""
-    Windows service information
-
-    :var name: The name of the service (lpServiceName)
-    :var display_name: The display name to be used by user interface programs to identify the service. (lpDisplayName)
-    :var description: The description of the service. (lpDescription)
-    :var image: The fully qualified path to the service binary file. (lpBinaryPathName)
-        Path can also include arguments e.g. "d:\myshare\myservice.exe arg1 arg2"
-    :var dll: Path to DLL file used by service, if any.
-
-    e.g.
-        Service(
-            name="WindowsUserManagement",
-            display_name="Windows User Management",
-            description="Provides a common management to access information about windows user."
-            image="%System%\\svohost.exe"
-        )
-    """
-    name: str = None
-    display_name: str = None
-    description: str = None
-    image: str = None
-    dll: str = None
-
-    def post_processing(self, report):
-        """Add file path in image field to report as a file path."""
-        # we use tactic of looking for first .exe in value. This is
-        # not guaranteed to be reliable
-        # TODO: This is here just to keep legacy logic. Determine if this is still appropriate when we remove
-        #   deprecations.
-        if self.image and ".exe" in self.image:
-            report.add(FilePath(self.image[:self.image.find(".exe") + 4]))
-        # TODO: doing this over setting dll as a Path type so we can set it as a "FilePath"
-        if self.dll:
-            report.add(FilePath(self.dll))
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        # Process generally uses a UUIDv4 but we want to deduplicate when the same command is used so we will use a v5
-        namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
-        
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        params = {
-            "id": "process--" + str(uuid.uuid5(namespace, f"{self.image}/{self.name}/{self.display_name}/{self.description}/{self.image}/{self.dll}"))
-        }
-        extension = {}
-
-        if self.name:
-            extension["service_name"] = self.name
-
-        if self.display_name:
-            extension["display_name"] = self.display_name
-
-        if self.description:
-            extension["descriptions"] = [self.description]
-
-        if self.image:
-            params["command_line"] = self.image
-        
-        if self.dll and self.dll != self.image:
-            dir_path = str(pathlib.Path(self.dll).parent)
-
-            if dir_path:
-                result.add_unlinked(stix.Directory(path = dir_path))
-                result.add_unlinked(stix.File(name = self.image, parent_directory_ref = result.unlinked_stix[-1].id))
-                params["image_ref"] = result.unlinked_stix[-1].id
-
-        if extension:
-            params["extensions"] = {"windows-service-ext": extension}
-
-        
-        result.add_linked(stix.Process(**params))
-        result.create_tag_note(self, result.linked_stix[-1])
-
-        return result
-
-# TODO: legacy helpers
-def ServiceName(name: str) -> Service:
-    warnings.warn(
-        "This is a temporary helper that may be removed in a future version. "
-        "Please use Service() instead.", DeprecationWarning
-    )
-    return Service(name=name)
-
-
-def ServiceDescription(description: str) -> Service:
-    warnings.warn(
-        "This is a temporary helper that may be removed in a future version. "
-        "Please use Service() instead.", DeprecationWarning
-    )
-    return Service(description=description)
-
-
-def ServiceDisplayName(display_name: str) -> Service:
-    warnings.warn(
-        "This is a temporary helper that may be removed in a future version. "
-        "Please use Service() instead.", DeprecationWarning
-    )
-    return Service(display_name=display_name)
-
-
-def ServiceDLL(dll: str) -> Service:
-    warnings.warn(
-        "This is a temporary helper that may be removed in a future version. "
-        "Please use Service() instead.", DeprecationWarning
-    )
-    return Service(dll=dll)
-
-
-def ServiceImage(image: str) -> Service:
-    warnings.warn(
-        "This is a temporary helper that may be removed in a future version. "
-        "Please use Service() instead.", DeprecationWarning
-    )
-    return Service(image=image)
-
-
-@attr.s(**config)
-class SSLCertSHA1(Metadata):
-    """
-    SSL Certificate SHA-1 Hash
-
-    e.g.
-        SSLCertSHA1("c29d79df9b5416fd416c31e57cd525dfc23a8f66")
-    """
-    value: str = attr.ib(metadata={"jsonschema": {
-        "type": "string",
-        "pattern": "^[0-9a-fA-F]{40}$",
-    }})
-
-    _SHA1_RE = re.compile("[0-9a-fA-F]{40}")
-
-    @value.validator
-    def _validate(self, attribute, value):
-        if not self._SHA1_RE.match(value):
-            raise ValidationError(f"Invalid SHA1 hash found: {value!r}")
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        result.add_linked(stix.x509Certificate(hashes={"SHA-1": self.value}))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-
-@attr.s(**config)
-class UserAgent(Metadata):
-    """
-    Software identifier used by malware
-
-    e.g.
-        UserAgent("Mozilla/4.0 (compatible; MISE 6.0; Windows NT 5.2)")
-    """
-    value: str
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-        result.add_linked(stix_extensions.ObservedString(purpose="user-agent", value=self.value))
-        result.create_tag_note(self, result.linked_stix[-1])
-        return result
-
-
-
-@attr.s(**config)
-class Version(Metadata):
-    """
-    The version of the malware.
-    To the degree possible this should be based directly on artifacts from the malware.
-
-    e.g.
-        Version("3.1")
-        Version("incrementing XOR encoding")
-    """
-    value: str
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        content = f"Version: {self.value}"
-
-        if self.tags:
-            content += "\n    Version: " + ", ".join(self.tags)
-        
-        return STIXResult(content)
-
-
-@attr.s(**config)
-class File(Metadata):
-    """
-    Represents a file, which is either the original input file, a file dispatched by the parser,
-    or a supplemental file generated by the parser
-
-    :var name: Name of the file.
-    :var description: Description of the file.
-    :var md5: MD5 hash of the file represented as a hex string.
-    :var sha1: SHA1 hash of the file represented as a hex string.
-    :var sha256: SHA256 hash of the file represented as a hex string.
-    :var architecture: Type of architecture of the file (if applicable)
-    :var compile_time: UTC Timestamp the file was compiled as reported (if applicable)
-    :var file_path: Path where the file exists or has been written out to on the local file system.
-    :var data: Raw bytes of the file.
-    :var derivation: Description of how the file was obtained or its categorization.
-        e.g. "decrypted", "deobfuscated", "supplemental"
-    """
-    name: str = None
-    description: str = None
-    md5: str = attr.ib(default=None)
-    sha1: str = attr.ib(default=None)
-    sha256: str = attr.ib(default=None)
-    architecture: str = None
-    compile_time: str = attr.ib(default=None, metadata={"jsonschema": {
-        "type": "string",
-        "format": "date-time",
-    }})
-    file_path: str = None
-    data: bytes = None
-    derivation: str = None
-
-    def __attrs_post_init__(self):
-        if self.data is not None:
-            if not self.md5:
-                self.md5 = hashlib.md5(self.data).hexdigest()
-            if not self.sha1:
-                self.sha1 = hashlib.sha1(self.data).hexdigest()
-            if not self.sha256:
-                self.sha256 = hashlib.sha256(self.data).hexdigest()
-
-    # TODO: Add validation for hashes.
-
-    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
-        hashes = {}
-        result = STIXResult(fixed_timestamp=fixed_timestamp)
-
-        if self.md5:
-            hashes["MD5"] = self.md5
-        if self.sha1:
-            hashes["SHA-1"] = self.sha1
-        if self.sha1:
-            hashes["SHA-256"] = self.sha256
-        
-        params = {
-            "name": self.name
-            , "hashes": hashes
-        }
-
-        if self.data:
-            result.add_unlinked(stix.Artifact(payload_bin=base64.b64encode(self.data)))
-            params["content_ref"] = result.unlinked_stix[0].id
-
-        result.add_linked(stix.File(**params))
-
-        # description is skipped because that is added to the malware-analysis that is later built for the
-        # file by the report writer
-
-        if self.compile_time or self.architecture:
-            result.note_content = f"Compiled on: {self.compile_time}\nFor architecture: {self.architecture}"
-        
-        result.note_labels = self.tags
-        
-        return result
-
-    @classmethod
-    def from_file_object(cls, file_object):
-        return cls(
-            name=file_object.name,
-            description=file_object.description,
-            md5=file_object.md5,
-            sha1=file_object.sha1,
-            sha256=file_object.sha256,
-            architecture=file_object.architecture,
-            compile_time=file_object.compile_time.isoformat() if file_object.compile_time else None,
-            # TODO: Update this when .file_path deprecation is removed.
-            file_path=file_object.file_path if file_object._exists else None,
-            data=file_object.data,
-            derivation=file_object.derivation,
-        ).add_tag(*file_object.tags)
-
-
-# Helper aliases
-InputFile = File  # Original input malware file that triggered parsing.
-ResidualFile = File  # Relevant or related file created during parsing of malware.
-
-
-def SupplementalFile(
-        name: str = None,
-        description: str = None,
-        md5: str = None,
-        sha1: str = None,
-        sha256: str = None,
-        architecture: str = None,
-        compile_time: str = None,
-        file_path: str = None,
-        data: bytes = None
-) -> File:
-    """
-    Helper function for creating a file that supplements the malware sample but isn't
-    something obtained from the sample.
-    e.g. string dump, annotated IDB, etc.
-    """
-    return File(
-        name=name,
-        description=description,
-        md5=md5,
-        sha1=sha1,
-        sha256=sha256,
-        architecture=architecture,
-        compile_time=compile_time,
-        file_path=file_path,
-        data=data,
-        derivation="supplemental",
-    )
-
-
-@attr.s(**config)
-class Report(Element):
-    """
-    Defines the report of all metadata elements.
-
-    :var mwcp_version: The version of MWCP used.
-    :var input_file: The initial file processed.
-    :var parser: The initial parser used to process the file.
-    :var errors: List of error messages that have occurred.
-    :var logs: List of all log messages that have occurred.
-    :var metadata: List of extracted metadata elements.
-    """
-    mwcp_version: str = attr.ib(init=False, factory=lambda: mwcp.__version__)
-    input_file: File = None
-    parser: str = None
-    errors: List[str] = attr.ib(factory=list)
-    logs: List[str] = attr.ib(factory=list)
-    metadata: List[Metadata] = attr.ib(factory=list)
-
-
-@attr.s(**config)
-class StringReport(Element):
-    """
-    Defines a report of decoded strings for a file.
-    """
-    file: File
-    strings: List[DecodedString] = attr.ib(factory=list)
+"""
+Schema for reportable metadata.
+
+- Using attrs for easy of use and validation.
+"""
+import base64
+import binascii
+import hashlib
+import inspect
+import io
+import json
+import logging
+import pathlib
+import re
+import textwrap
+import warnings
+import ntpath
+from enum import IntEnum
+import uuid
+from typing import Any, Union, List, Optional, TypeVar, Type, Iterable, Tuple
+
+from stix2 import v21 as stix
+
+import attr
+from bitarray import bitarray
+import cattr
+from defusedxml import ElementTree
+import jsonschema_extractor
+from pyasn1.codec.der import decoder as asn1_decoder
+from pyasn1_modules import rfc2437, rfc2459, pem
+from pyasn1.error import PyAsn1Error
+
+import mwcp
+from mwcp.exceptions import ValidationError
+from mwcp.utils import construct
+from mwcp.stix import extensions as stix_extensions
+from mwcp.stix.objects import STIXResult
+
+logger = logging.getLogger(__name__)
+
+
+cattr = cattr.GenConverter()
+
+# Register support for pathlib.
+cattr.register_structure_hook(pathlib.Path, lambda d, t: pathlib.Path(d))
+cattr.register_unstructure_hook(pathlib.Path, str)
+
+# Register support for enums.
+cattr.register_structure_hook(IntEnum, lambda d, t: t[d.upper()] if isinstance(d, str) else t(d))
+cattr.register_unstructure_hook(IntEnum, lambda d: None if d is None else d.name)
+
+
+T = TypeVar("T")
+
+
+def _cast(value: Any, type_: Type[T]) -> T:
+    """
+    Casts given value to the given type.
+    Usually uses cattr.structure()
+    :param value: Value to cast.
+    :param type_: Type to cast to.
+        (For things like Union, it will try each type listed
+        within, until one works.)
+    :return: Converted value.
+    """
+    # Convert bytes to string, Python 2 style!
+    if type_ is str and isinstance(value, bytes):
+        return value.decode("latin1")
+
+    # Prevent accidentally casting an integer to bytes.
+    # Since bytes(some_int) will cause it to create a zero byte string with that many bytes,
+    # this can stall or crash the process if the integer is large enough.
+    if type_ is bytes and isinstance(value, int):
+        raise ValueError("Cannot convert int to bytes.")
+
+    # cattr doesn't handle Unions very nicely, so we'll recursively
+    # handle the innards of Union types instead.
+    # NOTE: Based on documentation, the cattr devs will eventually provide
+    # better support for Unions in the future.
+    if hasattr(type_, "__origin__") and type_.__origin__ is Union:
+        # First see if value is already one of the types.
+        if type(value) in type_.__args__:
+            return value
+        # Otherwise, attempt to case using types in order they are found in the Union.
+        for sub_type in type_.__args__:
+            try:
+                return _cast(value, sub_type)
+            except Exception:
+                continue
+        raise ValueError("No subtypes matched.")
+
+    # Otherwise use cattr
+    return cattr.structure(value, type_)
+
+
+def _auto_convert(cls, fields):
+    """
+    Automatically applies type coercion to all fields.
+    (This also acts as validation)
+    """
+    def converter(field_type):
+        def _wrapper(v):
+            if v is None:
+                return v
+            try:
+                return _cast(v, field_type)
+            except Exception as e:
+                raise ValidationError(f"Failed to cast {v!r} to {field_type} with error: {e}")
+        return _wrapper
+
+    new_fields = []
+    for field in fields:
+        if field.converter is None and field.type:
+            field = field.evolve(converter=converter(field.type))
+        new_fields.append(field)
+    return new_fields
+
+
+def _camel_to_snake(name):
+    name = re.sub("(.)([A-Z][a-z]+)", r"\1_\2", name)
+    return re.sub("([a-z0-9])([A-Z])", r"\1_\2", name).lower()
+
+
+def _strip_null(d: dict) -> dict:
+    """
+    Strips away any entries that have the value None.
+    """
+    new_dict = {}
+    for key, value in d.items():
+        if isinstance(value, dict):
+            value = _strip_null(value)
+        if value is not None:
+            new_dict[key] = value
+    return new_dict
+
+
+def _flatten_dict(dict_: dict) -> dict:
+    """
+    Flattens given element dictionary into a single level of key/value pairs.
+    Combines tags into one.
+    """
+    new_dict = {}
+    for key, value in dict_.items():
+        if isinstance(value, dict):
+            value.pop("type", None)
+            tags = value.pop("tags", None)
+            value = {
+                f"{key}.{_key}" if _key in dict_ else _key: _value
+                for _key, _value in _flatten_dict(value).items()
+            }
+            new_dict.update(value)
+
+            # Consolidate tags into main dictionary.
+            if tags:
+                try:
+                    new_dict["tags"].append(tags)
+                except KeyError:
+                    new_dict["tags"] = tags
+        else:
+            new_dict[key] = value
+
+    # Pop off type.
+    new_dict.pop("type", None)
+    return new_dict
+
+
+# Global configuration for all elements.
+config = dict(auto_attribs=True, field_transformer=_auto_convert)
+
+
+@attr.s(**config)
+class Element:
+    """
+    Base class for handling reporting elements.
+    These should be created using attr for convenience.
+    """
+    tags: List[str] = attr.ib(init=False, factory=list)
+
+    _registry = {}
+
+    def __init_subclass__(cls, **kwargs):
+        """
+        Registers all subclasses of Element.
+        """
+        typ = cls._type()
+        if not typ.startswith("_") and typ != "metadata":
+            if typ in cls._registry:
+                raise ValueError(f"Metadata element of type {typ} already exists.")
+            cls._registry[typ] = cls
+        super().__init_subclass__(**kwargs)
+
+    @classmethod
+    def _all_subclasses(cls):
+        """
+        Returns all registered subclasses of the class, sorted by type.
+        """
+        return [
+            subclass
+            for _, subclass in sorted(cls._registry.items())
+            if issubclass(subclass, cls) and subclass != cls
+        ]
+
+    @classmethod
+    def _type(cls):
+        """This function is used to determine name identifier for the """
+        # By default, type is determined by class name.
+        return _camel_to_snake(cls.__name__)
+
+    @classmethod
+    def fields(cls):
+        return attr.fields(cls)
+
+    @classmethod
+    def _schema(cls, extractor):
+        """
+        Generates schema for this particular Element class.
+        """
+        # First get the short description by looking for the first complete sentence.
+        description = []
+        for line in inspect.getdoc(cls).splitlines():
+            # Stop when we hit an empty line or see variable statements.
+            if not line or line.startswith(":"):
+                break
+            description.append(line.strip())
+        description = " ".join(description)
+
+        schema = {
+            "title": cls.__name__.strip("_").rstrip("2"),
+            "description": description,
+            "type": "object",
+            "properties": {
+                # Include the "type" property that gets added dynamically during serialization.
+                "type": {
+                    "const": cls._type(),
+                }
+            },
+            "additionalProperties": False,
+            "required": ["type"],
+        }
+        for field in cls.fields():
+            is_required = field.default is not None
+
+            # Allow customization within attr metadata field for corner cases.
+            if "jsonschema" in field.metadata:
+                sub_schema = field.metadata["jsonschema"]
+            else:
+                sub_schema = extractor.extract(field.type)
+
+            # Anything not required is nullable.
+            if not is_required:
+                if list(sub_schema.keys()) == ["type"]:
+                    if isinstance(sub_schema["type"], list):
+                        if "null" not in sub_schema["type"]:
+                            sub_schema["type"].append("null")
+                    elif sub_schema["type"] != "null":
+                        sub_schema["type"] = [sub_schema["type"], "null"]
+                elif list(sub_schema.keys()) == ["anyOf"]:
+                    if {"type": "null"} not in sub_schema["anyOf"]:
+                        sub_schema["anyOf"].append({"type": "null"})
+                else:
+                    sub_schema = {"anyOf": [sub_schema, {"type": "null"}]}
+
+            schema["properties"][field.name] = sub_schema
+
+            if is_required:
+                schema["required"].append(field.name)
+
+        return schema
+
+    @classmethod
+    def schema(cls) -> dict:
+        """
+        Generates a JSONSchema from the given element.
+        :return: Dictionary representing the schema.
+        """
+        typing_extractor = jsonschema_extractor.TypingExtractor()
+        typing_extractor.register(Element, lambda extractor, typ: typ._schema(extractor))
+        typing_extractor.register(bytes, lambda extractor, typ: {
+            "type": "string",
+            "contentEncoding": "base64",
+        })
+        # IntEnums are converted to their names before serialization by cattr.
+        typing_extractor.register(IntEnum, lambda extractor, typ: {
+            "enum": [c.name for c in typ]
+        })
+        extractor = jsonschema_extractor.SchemaExtractorSet([typing_extractor])
+        return extractor.extract(cls)
+
+    @classmethod
+    def from_dict(cls, obj: dict) -> "Element":
+        obj = obj.copy()
+        if "type" not in obj:
+            obj["type"] = cls._type()
+        if "tags" not in obj:
+            obj["tags"] = []
+        return cattr.structure(obj, cls)
+
+    def as_dict(self, flat=False) -> dict:
+        ret = cattr.unstructure(self)
+        if flat:
+            ret = _flatten_dict(ret)
+        return ret
+
+    def as_formatted_dict(self, flat=False) -> dict:
+        """
+        Converts metadata element into a well formatted dictionary usually
+        used for presenting metadata elements as tabular data.
+        """
+        ret = {}
+        for field in self.fields():
+            name = field.name
+            value = getattr(self, name)
+            # Convert bytes to a string representation.
+            if isinstance(value, bytes):
+                value = str(value)
+            # Recursively handle nested elements.
+            if isinstance(value, Element):
+                value = value.as_formatted_dict()
+            ret[name] = value
+
+        if flat:
+            ret = _flatten_dict(ret)
+        return ret
+
+    def as_json(self) -> str:
+        class _JSONEncoder(json.JSONEncoder):
+            def default(self, o):
+                # Encode Collection objects using as_dict()
+                if isinstance(o, Element):
+                    return o.as_dict()
+                # Encode bytes as base64
+                if isinstance(o, bytes):
+                    return base64.b64encode(o).decode()
+                # Convert sets to list
+                if isinstance(o, set):
+                    return sorted(o)
+                # Convert UUID
+                if isinstance(o, uuid.UUID):
+                    return str(o)
+                return super().default(o)
+        return json.dumps(self, cls=_JSONEncoder, indent=4)
+
+    def as_json_dict(self) -> dict:
+        """
+        Jsonifies the element and then loads it back as a dictionary.
+        NOTE: This is different from .as_dict() because things like bytes
+        will be converted to a base64 encoded string.
+        """
+        return json.loads(self.as_json())
+
+    def validate(self):
+        attr.validate(self)
+
+    def elements(self) -> List["Element"]:
+        """
+        All elements contained within the given element. (including self)
+        """
+        elements = [self]
+        for field in self.fields():
+            value = getattr(self, field.name)
+            if isinstance(value, Element):
+                elements.extend(value.elements())
+        return elements
+
+    def post_processing(self, report):
+        """
+        Performs and adds extra additions to the Report when the Element gets created.
+        :param report: mwcp Report used to add metadata.
+        """
+
+    def add_tag(self, *tags: Iterable[str]) -> "Element":
+        """
+        Adds a tag for the given metadata.
+
+        :param tags: One or more tags to add to the metadata.
+        :returns: self to make this function chainable.
+        """
+        for tag in tags:
+            if tag not in self.tags:
+                self.tags.append(tag)
+        # Ensure we keep the tags sorted.
+        self.tags = sorted(self.tags)
+        return self
+
+
+# Create a hook that uses the "type" field to determine the appropriate class to use for Element.
+def _structure_hook(value: dict, klass):
+    # Value may be partially converted
+    # github.com/python-attrs/cattrs/issues/78
+    if hasattr(value, "__attrs_attrs__"):
+        return value
+
+    value = dict(value)  # create copy
+
+    # Determine class to use based on "type" field.
+    klass = Element._registry[value.pop("type")]
+
+    # Remove None values from dictionary, since that seems to be causing
+    # cattr (or our autocasting) to convert them to the string "None"
+    # TODO: Remove when github.com/python-attrs/cattrs/issues/53 is solved.
+    value = _strip_null(value)
+
+    # cattrs doesn't support init=False values, so we need to remove tags and
+    # then re-add them.
+    tags = value.pop("tags")
+    ret = cattr.structure_attrs_fromdict(value, klass)
+    ret.tags = tags
+    return ret
+
+
+cattr.register_structure_hook(Element, _structure_hook)
+
+
+# Create hook to add a "type" field to help with serialization of Element types.
+def _unstructure_hook(obj):
+    # obj may be None because we don't use Optional in our typing.
+    if obj is None:
+        return obj
+    return {"type": obj._type(), **cattr.unstructure_attrs_asdict(obj)}
+
+
+cattr.register_unstructure_hook(Element, _unstructure_hook)
+
+
+class Metadata(Element):
+    """
+    Represents a collection of reportable metadata attributes that together represent an idea.
+
+    This class can be subclassed to create your own reportable metadata element.
+    """
+
+    @classmethod
+    def _schema(cls, extractor):
+        # If we are typing the base Metadata class, this means we want to represent
+        # all subclasses instead.
+        if cls == Metadata:
+            return {"anyOf": [
+                extractor.extract(subclass) for subclass in Metadata._all_subclasses()
+            ]}
+        else:
+            return super()._schema(extractor)
+    
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        """
+        Returns STIX content for a class.  All metadata objects should implement this, but if one does not a warning will be supplied.
+
+        """
+        warnings.warn(
+            "as_stix is not implmeneted by " + type(self).__name__ + " so data may be missing from the result",
+            UserWarning
+        )
+        return STIXResult()
+
+    def as_stix_tags(self, parent, fixed_timestamp=None):
+        """
+        Returns an object containing tag information for a given parent assuming there is content
+        """
+        if self.tags:
+            return stix.Note(
+                labels=self.tags,
+                content=f"MWCP Tags: {', '.join(self.tags)}",
+                object_refs=[parent.id],
+                created=fixed_timestamp,
+                modified=fixed_timestamp,
+                allow_custom=True
+            )
+
+
+@attr.s(**config)
+class Path2(Metadata):
+    r"""
+    Filesystem path used by malware.
+
+    Current directory (".") represents the directory of the malware sample that produced this metadata.
+
+    e.g.
+        Path2(r"C:\windows\temp\1\log\keydb.txt", is_dir=False)  # pass full path
+        Path2(r"C:\foo\logs", is_dir=True)
+        Path2("bar.exe", is_dir=False)  # Represents a file name with unknown location
+        Path2(".\bar.exe", is_dir=False)  # Represents a file path within the same directory as the source malware sample.
+    """
+    path: str
+    is_dir: bool = None
+    posix: bool = None
+    file_system: str = None  # NTFS, ext4, etc.
+
+    def __attrs_post_init__(self):
+        # If posix wasn't provided, determine this based on presence of drive letter or separator.
+        if self.posix is None and (self.path.count("\\") or self.path.count("/")):
+            self.posix = not (re.match("^[A-Z]:\\\\", self.path) or self.path.count("\\") > self.path.count("/"))
+
+    @classmethod
+    def _type(cls):
+        return "path"
+
+    @classmethod
+    def from_segments(cls, *segments: str, is_dir: bool = None, posix: bool = False, file_system: str = None):
+        """
+        Provides ability to construct a Path from segments.
+        NOTE: Path is assumed to be Windows if posix flag is not provided.
+
+        e.g.
+            Path2.from_segments("C:", "windows", "temp", "1", "log", "keydb.txt", posix=False, is_dir=False)
+        """
+        if not segments:
+            raise ValidationError(f"from_segments() requires at least one segment.")
+        if len(segments) == 1:
+            return Path2(segments[0], is_dir=is_dir, posix=posix, file_system=file_system)
+
+        # Ensure we do not have secondary segments starting with a slash.
+        # This would cause pathlib's constructor to just take the last absolute path ignored the ones before it.
+        # Which is something we don't want in this context.
+        slash = "/" if posix else "\\"
+        segments = [segments[0], *(segment.lstrip(slash) for segment in segments[1:])]
+
+        if posix:
+            path = pathlib.PurePosixPath(*segments)
+        else:
+            segments = list(segments)
+            # If first segment is a drive, we need to include the \ in order for pathlib to see it as such.
+            if segments[0].endswith(":"):
+                segments[0] += "\\"
+            path = pathlib.PureWindowsPath(*segments)
+        return cls.from_pathlib_path(path, is_dir=is_dir, file_system=file_system)
+
+    @classmethod
+    def from_pathlib_path(cls, path: pathlib.PurePath, is_dir: bool = None, file_system: str = None):
+        """
+        Generate Path from pathlib.PurePath instance.
+        """
+        return Path2(str(path), is_dir=is_dir, posix=isinstance(path, pathlib.PurePosixPath), file_system=file_system)
+
+    @property
+    def _pathlib_path(self) -> Optional[pathlib.PurePath]:
+        if self.posix is None:
+            return None
+        elif self.posix:
+            return pathlib.PurePosixPath(self.path)
+        else:
+            return pathlib.PureWindowsPath(self.path)
+
+    @property
+    def directory_path(self) -> Optional[str]:
+        if self.is_dir:
+            return self.path
+        else:
+            path = self._pathlib_path
+            if path:
+                return str(path.parent)
+            else:
+                return None
+
+    @property
+    def name(self) -> str:
+        path = self._pathlib_path
+        if path:
+            return path.name
+        else:
+            return self.path
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+
+        if self.is_dir:
+            result.add_linked(stix.Directory(path=self.path))
+        else:
+            file_data = {}
+
+            if self.directory_path:
+                cur_dir = stix.Directory(path=self.directory_path)
+                result.add_unlinked(cur_dir)
+                file_data["parent_directory_ref"] = cur_dir.id
+
+            if self.name:
+                file_data["name"] = self.name
+                result.add_linked(stix.File(**file_data))
+
+        result.create_tag_note(self, result.linked_stix[-1])
+
+        return result
+
+
+def Path(
+        path: str = None,
+        directory_path: str = None,
+        name: str = None,
+        is_dir: bool = None,
+        file_system: str = None
+) -> Path2:
+    warnings.warn(
+        "Path has been renamed to Path2 during a transitional period to a new version of Path " 
+        "with a new signature. "
+        "Please update to use Path2 which explicitly expects a path string with no directory/name separation."
+        "NOTE: In a future version, once this function is deprecated, Path2 will be renamed back to Path "
+        "using the new signature.",
+        DeprecationWarning
+    )
+    # Replicating original logic. (existence of directory_path and name overwrite path)
+    if directory_path and name:
+        path = ntpath.join(directory_path, name)
+    # If a directory_path was provided without a name, overwrite is_dir.
+    elif directory_path and not name:
+        path = directory_path
+        is_dir = True
+    elif name and not directory_path:
+        path = name
+        is_dir = False
+    return Path2(path, is_dir=is_dir, file_system=file_system)
+
+
+def Directory(path: str, posix: bool = None) -> Path2:
+    return Path2(path, posix=posix, is_dir=True)
+
+
+def FilePath(path: str, posix: bool = None) -> Path2:
+    return Path2(path, posix=posix, is_dir=False)
+
+
+def FileName(name: str) -> Path2:
+    return Path2(name, is_dir=False)
+
+
+@attr.s(**config)
+class Alphabet(Metadata):
+    """
+    Generic baseXX alphabet
+    """
+    alphabet: str = attr.ib()
+    base: int = attr.ib()
+
+    @alphabet.validator
+    def _validate_alphabet(self, attribute, value):
+        alphabet = value
+        base = self.base
+        if alphabet and base:
+            if len(alphabet) not in (base, base + 1):
+                raise ValidationError(
+                    "Invalid alphabet provided: "
+                    "Length of alphabet must be size of base or base + 1 (if including the pad character)."
+                )
+            # TODO: Determine if this is a valid.
+            # if len(alphabet) != len(set(alphabet)):
+            #     raise ValidationError('mapping must be unique')
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        content = f"Alphabet: {self.alphabet}\nAlphabet Base: {self.base}"
+
+        if self.tags:
+            content += "\n    Alphabet Tags: " + ", ".join(self.tags)
+
+        return STIXResult(content)
+
+
+def Base16Alphabet(alphabet: str) -> Alphabet:
+    """
+    Base16 alphabet
+
+    e.g.
+        Base16Alphabet("0123456789ABCDEF")
+    """
+    return Alphabet(alphabet=alphabet, base=16)
+
+
+def Base32Alphabet(alphabet: str) -> Alphabet:
+    """
+    Base32 alphabet
+
+    e.g.
+        Base32Alphabet("ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=")
+    """
+    return Alphabet(alphabet=alphabet, base=32)
+
+
+def Base64Alphabet(alphabet: str) -> Alphabet:
+    """
+    Base64 alphabet
+
+    e.g.
+        Base64Alphabet("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=")
+    """
+    return Alphabet(alphabet=alphabet, base=64)
+
+
+@attr.s(**config)
+class Command(Metadata):
+    """
+    Shell command
+    """
+    value: str
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        # Process generally uses a UUIDv4 but we want to deduplicate when the same command is used so we will use a v5
+        namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
+        id = "process--" + str(uuid.uuid5(namespace, f"{self.value}"))
+
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        result.add_linked(stix.Process(command_line=self.value, id=id))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+
+@attr.s(**config)
+class Credential(Metadata):
+    """
+    Collection of username and password used as credentials.
+
+    e.g.
+        Credential(username="admin", password="123456")
+    """
+    username: str = None
+    password: str = None
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        
+        params = {}
+        if self.username:
+            params["account_login"] = self.username
+
+        if self.password:
+            params["credential"] = self.password
+
+            # the default UUIDv5 generation scheme for user-account does not factor in credentials so it is possible to overwrite the same username with separate creds
+            # since we do not want this with MWCP if a password is present will generate the ID in our own deterministic manner
+            namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
+            params["id"] = "user-account--" + str(uuid.uuid5(namespace, f"{self.username}//{self.password}"))
+
+        result.add_linked(stix.UserAccount(**params))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+
+def Password(password: str) -> Credential:
+    return Credential(password=password)
+
+
+def Username(username: str) -> Credential:
+    return Credential(username=username)
+
+
+@attr.s(**config)
+class CryptoAddress(Metadata):
+    """
+    A cryptocurrency address and its symbol.
+
+    :param address: The address or unique identifier of the crypto wallet.
+    :param symbol: A unique symbol for the cryptocurrency platform.
+        This is usually the ticker symbol like "BTC", but can be something else more appropriate.
+
+    e.g.
+        # Sample address pulled from bitcoinwiki.org/wiki/Bitcoin_address
+        CryptoAddress("14qViLJfdGaP4EeHnDyJbEGQysnCpwk3gd", "BTC")
+    """
+    address: str
+    symbol: str = None
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        params = {
+            "address": self.address
+        }
+
+        if self.symbol:
+            params["currency_type"] = self.symbol.lower().replace(" ", "-")
+
+        result.add_linked(stix_extensions.CryptoCurrencyAddress(**params))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+
+@attr.s(**config)
+class Socket(Metadata):
+    """
+    A collection of address, port, and protocol used together to make a socket
+    connection.
+
+    e.g.
+        Socket(address="bad.com", port=21, protocol="tcp")
+    """
+    _VALID_PROTOCOLS = {"tcp", "udp", "icmp"}
+
+    address: str = None  # ip address or domain  # TODO: should this be split up?
+    port: int = attr.ib(
+        default=None,
+        metadata={"jsonschema": {
+            "type": "integer",
+            "minimum": 0,
+            "maximum": 65535,
+        }}
+    )
+    network_protocol: str = attr.ib(
+        default=None,
+        converter=lambda v: str(v).lower() if v is not None else v,
+        metadata={"jsonschema": {
+            "enum": sorted(_VALID_PROTOCOLS),
+        }}
+    )
+    # Determines if socket is for a C2 server.
+    #   True == known C2, False == known not a C2, None == unknown
+    c2: bool = None
+    listen: bool = None
+
+    def __attrs_post_init__(self):
+        # Add the _from_port attribute, used internally for backwards compatibility support.
+        self._from_port = False
+
+    @port.validator
+    def _validate_port(self, attribute, value):
+        if value is not None and not 0 <= value <= 65535:
+            raise ValidationError(f"port must be between 0 and 65535. Got {value}")
+
+    @network_protocol.validator
+    def _validate_protocol(self, attribute, value):
+        if value is not None and value not in self._VALID_PROTOCOLS:
+            raise ValidationError(f"protocol {value} is not one of {sorted(self._VALID_PROTOCOLS)}")
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        # we define a static namespace explicitly for MWCP network traffic objects to ensure we deduplicate within MWCP
+        # in general it is bad practice to deduplicate Network Traffic but as this is static analysis we want
+        # to find correlation in a live environment this would be highly discouraged
+        namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
+
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        network_values = {
+            "is_active": False,
+            "id": "network-traffic--" + str(uuid.uuid5(
+                namespace,
+                f"{self.address}//{self.port}//{self.network_protocol}//{self.c2}//{self.listen}"
+            ))
+        }
+
+        # Make an address object if this is present but add it to the list after the network traffic
+        # for better malware analysis results
+        address = None
+        if self.address:
+            address_type = self._guess_address_type(self.address)
+            if address_type == "ipv6":
+                network_values["dst_ref"] = stix.IPv6Address(value = self.address)
+                network_values["protocols"] = ["ipv6"]
+            elif address_type == "ipv4":
+                network_values["dst_ref"] = stix.IPv4Address(value = self.address)
+                network_values["protocols"] = ["ipv4"]
+            else:
+                network_values["dst_ref"] = stix.DomainName(value = self.address)
+                # This is ultimately a guess but it is safer to assume a domain maps
+                # to ipv4 than ipv6 and we must pick one
+                network_values["protocols"] = ["ipv4"]
+        else:
+            network_values["src_ref"] = stix.IPv4Address(value = "0.0.0.0")
+            network_values["protocols"] = ["ipv4"]
+
+        # if a value was provided it should sit after ipv4 or ipv6 respectively
+        if self.network_protocol:
+            network_values["protocols"].append(self.network_protocol)
+
+        if self.port:
+            if self.listen:
+                network_values["src_port"] = self.port
+            else:
+                network_values["dst_port"] = self.port
+
+        if "src_ref" in network_values:
+            result.add_unlinked(network_values["src_ref"])
+        else:
+            result.add_unlinked(network_values["dst_ref"])
+
+        traffic = stix.NetworkTraffic(**network_values)
+        result.create_tag_note(self, traffic)
+
+        # we want the network traffic to be the last object so it is always consistently placed
+        result.add_linked(traffic)
+
+        return result
+    
+    @staticmethod
+    def _guess_address_type(address) -> str:
+        """
+        Used to see if an address is ipv4, ipv6, or a domain
+        """
+        # the fewest number of : in an ipv6 is for ::1.  A domain or IP should never have one so checking for 2 is safe
+        if address.count(":") > 1:
+            return "ipv6"
+
+        # IPv4 must be 4 octets and no TLD can be a number so checking for both gives us a good guess between the two
+        parts = address.split(".")
+        if len(parts) == 4:
+            if parts[3].isnumeric():
+                if int(parts[3]) >= 0 and int(parts[3]) < 256:
+                    return "ipv4"
+        
+        return "domain"
+
+
+def SocketAddress(*args, **kwargs) -> Socket:
+    warnings.warn(
+        "This function is a temporary helper. This may be removed in a future version. "
+        "Please use Socket() instead.",
+        DeprecationWarning
+    )
+    return Socket(*args, **kwargs)
+
+
+def C2SocketAddress(address: str, port: int = None, protocol: str = None) -> Socket:
+    warnings.warn(
+        "This function is a temporary helper. This may be removed in a future version",
+        DeprecationWarning
+    )
+    return Socket(address=address, port=port, network_protocol=protocol, c2=True)
+
+
+def Port(port: int, protocol: str = None) -> Socket:
+    """
+    TCP or UDP port.
+    This generally refers to outbound connections where the malware is the client.
+    Other network layer protocols, such as ICMP can be represented here.
+    Application layer connections, such as HTTP, should be indicated by making a URL instead.
+    """
+    socket = Socket(port=port, network_protocol=protocol)
+    socket._from_port = True
+    return socket
+
+
+def ListenPort(port: int, protocol: str = None) -> Socket:
+    socket = Socket(port=port, network_protocol=protocol, listen=True)
+    socket._from_port = True
+    return socket
+
+
+def Address(address: str) -> Socket:
+    return Socket(address=address)
+
+
+def C2Address(address: str) -> Socket:
+    return Socket(address=address, c2=True)
+
+
+@attr.s(**config)
+class URL(Metadata):
+    """
+    RFC 3986 URL
+
+    e.g.
+        URL("https://10.11.10.13:443/images/baner.jpg")
+
+        creds = Credential(username="user", password="pass")
+        URL(socket=Socket("mail.badhost.com"), application_protocol="smtp", credential=creds))
+    """
+    url: str = None
+    socket: Socket = None
+    path: str = None
+    query: str = None
+    application_protocol: str = None
+    credential: Credential = None
+
+    _URL_RE = re.compile(
+        r"((?P<app_protocol>[a-z\.\-+]{1,40})://)?(?P<address>\[?[^/]+\]?)"
+        r"(?P<path>/[^?]+)?(?P<query>.*)",
+        flags=re.IGNORECASE
+    )
+
+    def __attrs_post_init__(self):
+        if self.url is not None:
+            self._parse_url(self.url)
+
+    def _parse_url(self, url: str):
+        """
+        Parses provided url in order to set individual components.
+        """
+        match = self._URL_RE.match(url)
+        if not match:
+            # TODO: To keeps backwards compatibility we still must allow the url
+            #   to be set.
+            logger.error(f"Error parsing as url: {url}")
+            return
+
+        app_protocol = match.group("app_protocol")
+        path = match.group("path")
+        query = match.group("query")
+        port = None
+
+        address = match.group("address")
+        if address:
+            address = address.rstrip(": ")
+            if address.startswith("["):
+                # ipv6--something like
+                # [fe80::20c:1234:5678:9abc]:80
+                address, found, port = address[1:].partition("]:")
+            else:
+                address, found, port = address.partition(":")
+            if found and not port:
+                raise ValidationError(f"Invalid URL {url}, found ':' at end without a port.")
+            elif not port:
+                port = None
+
+        if not self.socket:
+            self.socket = Socket(address=address, port=port)
+        if not self.path:
+            self.path = path
+        if not self.query:
+            self.query = query
+        if not self.application_protocol:
+            self.application_protocol = app_protocol
+
+    @property
+    def c2(self) -> Optional[bool]:
+        return self.socket and self.socket.c2
+
+    @c2.setter
+    def c2(self, value: bool):
+        """
+        Convenience for setting url as a c2.
+        """
+        if not isinstance(value, bool):
+            raise ValidationError(f"C2 {repr(value)} is not a boolean.")
+        if not self.socket:
+            self.socket = Socket()
+        self.socket.c2 = value
+
+    @property
+    def listen(self) -> Optional[bool]:
+        return self.socket and self.socket.listen
+
+    @listen.setter
+    def listen(self, value: bool):
+        """
+        Convenience for setting url as a listen.
+        """
+        if not isinstance(value, bool):
+            raise ValidationError("Listen {repr(value)} is not a boolean.")
+        if not self.socket:
+            self.socket = Socket()
+        self.socket.listen = value
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+
+        # Some parsers can have a URL without a URL so we skip it in these cases
+        if self.url is None:
+            warnings.warn("Skipped creation of STIX URL since the parser provided no URL")
+            return result
+
+        result.add_linked(stix.URL(value = self.url))
+        result.create_tag_note(self, result.linked_stix[-1])
+
+        if self.socket:
+            result.merge(self.socket.as_stix(base_object))
+            result.add_unlinked(stix.Relationship(relationship_type="used", source_ref=result.linked_stix[-1].id, target_ref=result.linked_stix[0].id, created=fixed_timestamp, modified=fixed_timestamp))
+
+        if self.credential:
+            result.merge(self.credential.as_stix(base_object))
+            result.add_unlinked(stix.Relationship(relationship_type="contained", source_ref=result.linked_stix[0].id, target_ref=result.linked_stix[-1].id, created=fixed_timestamp, modified=fixed_timestamp))
+
+        return result
+
+def C2URL(
+        url: str = None,
+        socket: Socket = None,
+        path: str = None,
+        query: str = None,
+        application_protocol: str = None,
+        credential: Credential = None
+) -> URL:
+    url = URL(
+        url=url,
+        socket=socket,
+        path=path,
+        query=query,
+        application_protocol=application_protocol,
+        credential=credential
+    )
+    url.c2 = True
+    return url
+
+
+def URLPath(path: str) -> URL:
+    """Path portion of URL"""
+    warnings.warn(
+        "This function is a temporary helper. This may be removed in a future version. "
+        "Please use URL() instead.",
+        DeprecationWarning
+    )
+    return URL(path=path)
+
+
+def Proxy(
+        username: str = None,
+        password: str = None,
+        address: str = None,
+        port: int = None,
+        protocol: str = None
+) -> URL:
+    """
+    Generates URL object from given proxy connection information.
+
+    e.g.
+        Proxy(
+            username="admin",
+            password="pass",
+            address="192.168.1.1",
+            port=80,
+            protocol="tcp",
+        )
+    """
+    url = URL()
+    if address or port or protocol:
+        url.socket = Socket(address=address, port=port, network_protocol=protocol)
+    if username or password:
+        url.credential = Credential(username=username, password=password)
+    url.add_tag("proxy")
+    return url
+
+
+def ProxySocketAddress(address: str, port: int = None, protocol: str = None) -> URL:
+    warnings.warn(
+        "This function is a temporary helper. This may be removed in a future version. "
+        "Please use Proxy() instead.",
+        DeprecationWarning
+    )
+    return Proxy(address=address, port=port, protocol=protocol)
+
+
+def ProxyAddress(address: str) -> URL:
+    warnings.warn(
+        "This function is a temporary helper. This may be removed in a future version. "
+        "Please use Proxy() instead.",
+        DeprecationWarning
+    )
+    return Proxy(address=address)
+
+
+def FTP(
+        username: str = None,
+        password: str = None,
+        url: str = None,
+        address: str = None,
+        port: Port = None,
+) -> URL:
+    """
+    Generates URL object from given FTP credentials and URL or address information.
+
+    e.g.
+        FTP(
+            username="admin",
+            password="pass",
+            url="ftp://badhost.com:21",
+        )
+    """
+    warnings.warn(
+        "This function is a temporary helper. This may be removed in a future version",
+        DeprecationWarning
+    )
+    if url and address:
+        raise ValidationError("Must provide either url or address. Both provided.")
+    if url:
+        url_object = URL(url)
+    else:
+        url_object = URL(socket=Socket(address=address, port=port))
+    if username or password:
+        url_object.credential = Credential(username=username, password=password)
+    url_object.application_protocol = "ftp"
+    return url_object
+
+
+@attr.s(**config)
+class EmailAddress(Metadata):
+    """
+    Email address
+
+    e.g.
+        EmailAddress("email@bad.com")
+    """
+    value: str = attr.ib(metadata={"jsonschema": {
+        "type": "string",
+        "format": "email",
+    }})
+
+    @value.validator
+    def _validate(self, attribute, value):
+        if "@" not in value:
+            raise ValidationError(f"Email address should at least have a '@' character.")
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        result.add_linked(stix.EmailAddress(value=self.value))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+@attr.s(**config)
+class Event(Metadata):
+    """
+    Event object
+
+    e.g.
+        Event("MicrosoftExit")
+    """
+    value: str
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        content = f"Event Name: {self.value}"
+
+        if self.tags:
+            content += "\n    Event Name Tags: " + ", ".join(self.tags)
+        
+        return STIXResult(content)
+
+
+def _uuid_convert(value):
+    """
+    Converts value into a uuid.UUID value (if not already).
+    This is necessary because uuid.UUID can't handle being constructed twice.
+    """
+    try:
+        if isinstance(value, str):
+            return uuid.UUID(value)
+        elif isinstance(value, bytes):
+            return uuid.UUID(bytes=value)
+        elif isinstance(value, int):
+            return uuid.UUID(int=value)
+        elif isinstance(value, uuid.UUID):
+            return value
+        else:
+            raise ValidationError(f"Invalid UUID: {value}")
+    except Exception as e:
+        raise ValidationError(f"Invalid UUID: {e}")
+
+# NOTE: We are not typing this as uuid.UUID because that has caused issues with serialization.
+#   Validation occurs in the below function.
+@attr.s(**config)
+class UUID(Metadata):
+    """
+    A 128-bit number used to identify information, also referred to as a GUID.
+
+    e.g.
+        UUID("654e5cff-817c-4e3d-8b01-47a6f45ae09a")
+    """
+    value: uuid.UUID = attr.ib(converter=_uuid_convert, metadata={"jsonschema": {
+        "type": "string",
+        "format": "uuid",
+    }})
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        result.add_linked(stix_extensions.ObservedString(purpose="uuid", value=self.value))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+
+GUID = UUID  # alias
+
+
+@attr.s(**config)
+class UUIDLegacy(Metadata):
+    """
+    Legacy version of UUID that doesn't validate or convert the uuid in order to ensure
+    the original raw strings is displayed.
+
+    WARNING: This should not be used in new code. Use UUID instead.
+    """
+    value: str
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        result.add_linked(stix_extensions.ObservedString(purpose="uuid", value=self.value))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+@attr.s(**config)
+class InjectionProcess(Metadata):
+    """
+    Process into which malware is injected.
+    Usually this is a process name but it may take other forms such as a filename of the executable.
+
+    e.g.
+        InjectionProcess("iexplore")
+        InjectionProcess("svchost")
+    """
+    value: str
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        content = f"Injects Into: {self.value}"
+
+        if self.tags:
+            content += "\n    Injects Into Tags: " + ", ".join(self.tags)
+
+        return STIXResult(content)
+        
+
+
+@attr.s(**config)
+class Interval(Metadata):
+    """
+    Time malware waits between beacons or other activity given in seconds.
+
+    e.g.
+        Interval(3.0)
+        Interval(0.1)
+    """
+    value: float
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        content = f"Interval: {self.value}"
+
+        if self.tags:
+            content += "\n    Interval Tags: " + ", ".join(self.tags)
+        
+        return STIXResult(content)
+
+
+
+@attr.s(**config)
+class IntervalLegacy(Metadata):
+    """
+    Legacy version of interval that uses a string type instead of float in order to preserve original
+    display of the interval.
+    This was done in order to ensure the decimal is either included or not depending on what the user provides.
+
+    WARNING: This should not be used in new code!
+    """
+    value: str
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        content = f"Interval: {self.value}"
+
+        if self.tags:
+            content += "\n    Interval Tags: " + ", ".join(self.tags)
+        
+        return STIXResult(content)
+
+
+@attr.s(**config)
+class EncryptionKey(Metadata):
+    """
+    Encryption, encoding, or obfuscation key.
+
+    e.g.
+        EncryptionKey(
+            b"\x6d\x79\x72\x63\x34\x6b\x65\x79",
+            algorithm="rc4",
+        )
+        EncryptionKey(
+            b"\x6d\x79\x72\x63\x34\x6b\x65\x79",
+            algorithm="aes",
+            mode="ecb",
+            iv=b"\x00\x00\x00\x00\x00\x00\x00\x01",
+        )
+    """
+    key: bytes
+    algorithm: str = None
+    mode: str = None
+    iv: bytes = None
+
+    def __attrs_post_init__(self):
+        # Determines if key is an encoded utf8 string.
+        # (Used for backwards compatibility support.)
+        self._raw_string = False
+
+    def as_formatted_dict(self, flat=False) -> dict:
+        # Convert key into hex number
+        key = f"0x{self.key.hex()}"
+
+        # Add context if encoding can be detected from key.
+        encoding = None
+        if self._raw_string:
+            encoding = "utf-8"
+        else:
+            # Test for encoding by determining which encoding creates pure ascii.
+            for test_encoding in ["utf-16", "ascii", "utf-8"]:
+                try:
+                    if self.key.decode(test_encoding).isprintable():
+                        encoding = test_encoding
+                        break
+                except UnicodeDecodeError:
+                    continue
+        if encoding:
+            key += f' ("{self.key.decode(encoding)}")'
+
+        return {
+            "tags": self.tags,
+            "key": key,
+            "algorithm": self.algorithm,
+            "mode": self.mode,
+            "iv": f"0x{self.iv.hex()}" if self.iv else None,
+        }
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        params = { "key_hex": self.key.hex() }
+
+        if self.algorithm:
+            params["algorithm"] = self.algorithm
+
+        if self.mode:
+            params["mode"] = self.mode
+
+        if self.iv:
+            params["iv_hex"] = self.iv.hex()
+
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        result.add_linked(stix_extensions.SymmetricEncryption(**params))
+        result.create_tag_note(self, result.linked_stix[-1])
+
+        return result
+
+def EncryptionKeyLegacy(key: str) -> EncryptionKey:
+    """
+    Legacy version of 'key' field which takes a string value instead of bytes.
+    """
+    warnings.warn(
+        "EncryptionKeyLegacy is only for backwards compatibility support. Please use EncryptionKey instead.",
+        DeprecationWarning
+    )
+    encryption_key = EncryptionKey(key.encode("utf-8"))
+    encryption_key._raw_string = True
+    return encryption_key
+
+
+@attr.s(**config)
+class DecodedString(Metadata):
+    """
+    Extracted decrypted or decoded string.
+
+    e.g.
+        DecodedString("badman")
+        DecodedString("evilstring", encryption_key=EncryptionKey(b"secret", algorithm="xor"))
+    """
+    value: str
+    encryption_key: EncryptionKey = None
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+
+        # sometimes empty strings come up so we should just discard these
+        if not self.value:
+            return result
+
+        cur = stix_extensions.ObservedString(purpose="decoded", value=self.value)
+        result.add_linked(cur)
+        result.create_tag_note(self, cur)
+
+        if self.encryption_key:
+            sub = self.encryption_key.as_stix(base_object)
+            result.merge(sub)
+            result.add_unlinked(stix.Relationship(relationship_type="outputs", source_ref=sub.linked_stix[0].id, target_ref=cur.id, allow_custom=True, created=fixed_timestamp, modified=fixed_timestamp))
+            
+        return result
+        
+
+@attr.s(**config)
+class MissionID(Metadata):
+    """
+    Attacker specified identifier encoded in malware,
+    usually reflected in beacons and often related to target or time of attack.
+
+    e.g.
+        MissionID("target4")
+        MissionID("201412")
+    """
+    value: str
+    
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        result.add_linked(stix_extensions.ObservedString(purpose="mission-id", value=self.value))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+
+@attr.s(**config)
+class Mutex(Metadata):
+    """
+    Mutex name used to prevent multiple executions of malware
+
+    e.g.
+        Mutex("ithinkimalonenow")
+        Mutex("0036a8117afa")
+    """
+    value: str
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        result.add_linked(stix.Mutex(name=self.value))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+
+@attr.s(**config)
+class Other(Metadata):
+    """
+    All other items that don't fit within the existing declared schema.
+    Value type is determined by the "value_format" property.
+
+    e.g.
+        Other("keylogger", True)
+        Other("custom_info", b"\xde\xad\xbe\xef")
+        Other("custom_info2", "hello")
+    """
+    key: str
+    value: Union[int, bytes, str, bool]
+    value_format: str = attr.ib(
+        init=False,
+        metadata={"jsonschema": {
+            "enum": ["string", "bytes", "integer", "boolean"],
+        }}
+    )
+
+    def __attrs_post_init__(self):
+        if isinstance(self.value, bool):
+            self.value_format = "boolean"
+        elif isinstance(self.value, int):
+            self.value_format = "integer"
+        elif isinstance(self.value, str):
+            self.value_format = "string"
+        elif isinstance(self.value, bytes):
+            self.value_format = "bytes"
+        else:
+            raise ValidationError(f"Got unexpected data: {self.value}")
+
+    def as_formatted_dict(self, flat=False) -> dict:
+        ret = super().as_formatted_dict()
+        # Don't show value_format.
+        del ret["value_format"]
+        return ret
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        # boolean values and numbers should be appended as a single master Note instead of using this mechanism
+        if self.value_format in ("boolean", "integer") or self.value in (b"", ""):
+            content = f"{self.key}: {self.value}"
+
+            if self.tags:
+                content += f"\n    {self.key} Tags: " + ", ".join(self.tags)
+
+            result = STIXResult(content)
+        else:
+            content = {
+                "purpose": self.key.replace("_", "-").replace(" ", "-").lower(),
+                "value": self.value
+            }
+
+            result = STIXResult(fixed_timestamp=fixed_timestamp)
+            result.add_linked(stix_extensions.ObservedString(**content))
+            result.create_tag_note(self, result.linked_stix[-1])
+
+        return result
+
+
+@attr.s(**config)
+class Pipe(Metadata):
+    r"""
+    Named, one-way or duplex pipe for communication between the pipe server and one or more pipe clients.
+
+    e.g.
+        Pipe("\\.\\pipe\\namedpipe")
+    """
+    value: str
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        result.add_linked(stix_extensions.ObservedString(purpose="pipe", value=self.value))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+
+class RegistryHive(IntEnum):
+    HKEY_CLASSES_ROOT = 0x80000000
+    HKEY_CURRENT_USER = 0x80000001
+    HKEY_LOCAL_MACHINE = 0x80000002
+    HKEY_USERS = 0x80000003
+    HKEY_PERFORMANCE_DATA = 0x80000004
+    HKEY_CURRENT_CONFIG = 0x80000005
+    HKEY_DYN_DATA = 0x80000006
+    HKEY_CURRENT_USER_LOCAL_SETTINGS = 0x80000007
+    HKEY_PERFORMANCE_TEXT = 0x80000050
+    HKEY_PERFORMANCE_NLSTEXT = 0x80000060
+
+    # Aliases
+    HKCR = HKEY_CLASSES_ROOT
+    HKCU = HKEY_CURRENT_USER
+    HKLM = HKEY_LOCAL_MACHINE
+    HKU = HKEY_USERS
+    HKPD = HKEY_PERFORMANCE_DATA
+    HKCC = HKEY_CURRENT_CONFIG
+    HKDD = HKEY_DYN_DATA
+    HKCULS = HKEY_CURRENT_USER_LOCAL_SETTINGS
+    HKPT = HKEY_PERFORMANCE_TEXT
+    HKPN = HKEY_PERFORMANCE_NLSTEXT
+
+
+class RegistryDataType(IntEnum):
+    """Registry value data types in winreg.h"""
+    REG_NONE = 0
+    REG_SZ = 1
+    REG_EXPAND_SZ = 2
+    REG_BINARY = 3
+    REG_DWORD = 4
+    REG_DWORD_LITTLE_ENDIAN = REG_DWORD
+    REG_DWORD_BIG_ENDIAN = 5
+    REG_LINK = 6
+    REG_MULTI_SZ = 7
+    REG_QWORD = 11
+
+
+@attr.s(**config)
+class Registry2(Metadata):
+    """
+    Registry key, value (or name), and data.
+    (see docs.microsoft.com/en-us/windows/win32/sysinfo/structure-of-the-registry)
+
+    e.g.
+        Registry2(
+            hive="HKLM",  # or metadata.RegistryHive.HKEY_LOCAL_MACHINE
+            subkey="Software\\Microsoft\\Windows\\CurrentVersion\\Run",
+            value="Updater",
+            data="c:\\update.exe"
+        )
+    """
+    hive: RegistryHive = None
+    subkey: str = None
+    value: str = None  # registry key, value name, combination of the two
+    data: Union[bytes, str, int, List[str]] = attr.ib(default=None)
+    data_type: RegistryDataType = None
+
+    def __attrs_post_init__(self):
+        # Pull out hive if it was included in subkey.
+        if not self.hive and self.subkey:
+            hive, _, subkey = self.subkey.partition("\\")
+            try:
+                self.hive = RegistryHive[hive.upper()]
+            except KeyError:
+                pass
+            else:
+                self.subkey = subkey
+
+        # Strip off leading or trailing \'s on subkey.
+        if self.subkey:
+            self.subkey = self.subkey.strip("\\")
+
+        # Automatically set data type for some data values.
+        if self.data_type is None and self.data is not None:
+            if isinstance(self.data, str):
+                # If we have more than one "\0", this is a string list.
+                if self.data.count("\0") > 1:
+                    self.data_type = RegistryDataType.REG_MULTI_SZ
+                else:
+                    self.data_type = RegistryDataType.REG_SZ
+            elif isinstance(self.data, list) and all(isinstance(entry, str) for entry in self.data):
+                self.data_type = RegistryDataType.REG_MULTI_SZ
+            elif isinstance(self.data, bytes):
+                self.data_type = RegistryDataType.REG_BINARY
+            elif isinstance(self.data, int):
+                if self.data <= 0xffffffff:
+                    self.data_type = RegistryDataType.REG_DWORD
+                else:
+                    self.data_type = RegistryDataType.REG_QWORD
+            # NOTE: We are not going to convert a data of None to be type REG_NONE because data could
+            #   not be provided because we couldn't obtain it.
+            #   User must explicitly set data_type to REG_NONE if it is known to be None.
+
+        # Auto convert data set as REG_MULTI_SZ if given as a full string with null-terminations.
+        if self.data_type == RegistryDataType.REG_MULTI_SZ and isinstance(self.data, str) and "\0" in self.data:
+            if self.data.endswith("\0"):
+                self.data = self.data[:-1]
+            self.data = self.data.split("\0")
+
+        # Strip off null termination for strings.
+        if self.data and self.data_type == RegistryDataType.REG_SZ:
+            self.data = self.data.rstrip("\0")
+
+    @data.validator
+    def _validate_data(self, attribute, value):
+        if isinstance(value, int) and value < 0:
+            raise ValidationError(f"Integer data value must be positive. Got {value}")
+
+    @classmethod
+    def _type(cls):
+        return "registry"
+
+    @classmethod
+    def from_path(cls, path: str, data: Union[bytes, str, int] = None) -> "Registry2":
+        """
+        Generates a Registry from a given full path.
+        The last segment of the path is assumed to be the value.
+        """
+        # Cast path to string to be more backwards compatible.
+        if isinstance(path, bytes):
+            path = path.decode("utf8")
+        subkey, _, value = path.rpartition("\\")
+        return Registry2(subkey=subkey or None, value=value or None, data=data)
+
+    @property
+    def key(self) -> Optional[str]:
+        """
+        The combination of the hive + subkey.
+        """
+        hive_name = self.hive.name if self.hive is not None else ""
+        if hive_name or self.subkey:
+            return "\\".join([hive_name, self.subkey or ""])
+        else:
+            return None
+
+    def as_formatted_dict(self, flat=False) -> dict:
+        return {
+            "tags": self.tags,
+            "key": self.key,
+            "value": self.value,
+            "data": self.data,
+            "data_type": self.data_type.name if self.data_type is not None else None,
+        }
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        value = {}
+        properties = {}
+
+        if self.key:
+            properties["key"] = self.key
+
+        if self.value:
+            value["data"] = self.value
+        
+        # this will be read as a string with the class name included so we need to strip out the class time
+        if self.data_type:
+            value["data_type"] = str(self.data_type).split(".")[-1]
+
+        if value:
+            properties["values"] = [value]
+
+        
+        result.add_linked(stix.WindowsRegistryKey(**properties))
+        result.create_tag_note(self, result.linked_stix[-1])
+
+        return result
+
+def Registry(path: str = None, key: str = None, value: str = None, data: Union[bytes, str, int] = None) -> Registry2:
+    """
+    Registry key and value.
+
+    e.g.
+        Registry(
+            "HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\Updater",
+            data="c:\\update.exe",
+        )
+    """
+    warnings.warn(
+        "Registry has been renamed to Registry2 during a transitional period to a new version of Registry " 
+        "with a new signature. "
+        "Please update to use Registry2 with explicit key/value fields or use the .from_path() constructor. "
+        "NOTE: In a future version, once this function is deprecated, Registry2 will be renamed back to Registry "
+        "using the new signature.",
+        DeprecationWarning
+    )
+    if path is not None:
+        registry = Registry2.from_path(path, data=data)
+        # Need to overwrite key and value if provided in order to replicate legacy logic.
+        if key:
+            registry.subkey = key
+        if value:
+            registry.value = value
+        return registry
+    else:
+        return Registry2(subkey=key, value=value, data=data)
+
+
+def RegistryData(data: str) -> Registry2:
+    warnings.warn(
+        "This is a temporary helper that may be removed in a future version. "
+        "Please use Registry() instead.", DeprecationWarning
+    )
+    return Registry2(data=data)
+
+
+def RegistryPath(path: str) -> Registry2:
+    warnings.warn(
+        "This is a temporary helper that may be removed in a future version. "
+        "Please use Registry() instead.", DeprecationWarning
+    )
+    return Registry2.from_path(path)
+
+
+def RegistryPathData(path: str, data: str) -> Registry2:
+    warnings.warn(
+        "This is a temporary helper that may be removed in a future version. "
+        "Please use Registry() instead.", DeprecationWarning
+    )
+    return Registry2.from_path(path, data=data)
+
+
+def _int_dump(value: int) -> str:
+    """
+    Dumps integer into hex format in same style used by openssl.
+    """
+    # Display smaller values as decimal with hex in parenthesis.
+    if value < (0x1 << (15 * 8)):
+        return f"{value} ({hex(value)})"
+    # Otherwise display as hex dump with bytes separated by ":"
+    value_bytes = value.to_bytes((value.bit_length() + 7) // 8, "big")
+    hex_dump = ":".join(f"{byte:02x}" for byte in value_bytes)
+    hex_dump = textwrap.fill(hex_dump, width=45)
+    return hex_dump
+
+
+def _parse_rsa_xml(data: str):
+    """
+    Parses RSA key data from XML notation.
+    Logs any errors as warnings.
+
+    :raises ValueError: If nothing could be parsed out.
+    """
+    try:
+        root = ElementTree.fromstring(data)
+    except ElementTree.ParseError as e:
+        raise ValueError(f"Failed to parse XML data: {e}")
+    if root.tag != "RSAKeyValue":
+        raise ValueError(f"Expected root tag to be 'RSAKeyValue', got '{root.tag}'")
+    fields = {}
+    for child in root:
+        try:
+            fields[child.tag] = int.from_bytes(base64.b64decode(child.text), byteorder="big")
+        except binascii.Error as e:
+            logger.warning(f"Failed to base64 decode data in '{child.tag}': '{child.text}' with error: {e}")
+
+    if not fields:
+        raise ValueError(f"Failed to parse any RSA key data from XML.")
+
+    return fields
+
+
+@attr.s(**config)
+class RSAPrivateKey(Metadata):
+    """
+    RSA private key containing: public exponent, modulus, private exponent (d),
+        p, q, d mod (p-1), d mod (q-1), q inv mod p
+    """
+    public_exponent: int = None
+    modulus: int = None
+    private_exponent: int = None
+    p: int = None
+    q: int = None
+    d_mod_p1: int = None
+    d_mod_q1: int = None
+    q_inv_mod_p: int = None
+
+    @classmethod
+    def from_DER(cls, data: bytes) -> "RSAPrivateKey":
+        """
+        Generates RSAPrivateKey from data in ASN.1 DER format.
+
+        :param data: RSA key data in ASN.1 DER format
+
+        :raises ValueError: on failure
+        """
+        try:
+            privkey, _ = asn1_decoder.decode(data, asn1Spec=rfc2437.RSAPrivateKey())
+            return RSAPrivateKey(
+                public_exponent=int(privkey.getComponentByName("publicExponent")),
+                modulus=int(privkey.getComponentByName("modulus")),
+                private_exponent=int(privkey.getComponentByName("privateExponent")),
+                p=int(privkey.getComponentByName("prime1")),
+                q=int(privkey.getComponentByName("prime2")),
+                d_mod_p1=int(privkey.getComponentByName("exponent1")),
+                d_mod_q1=int(privkey.getComponentByName("exponent2")),
+                q_inv_mod_p=int(privkey.getComponentByName("coefficient")),
+            )
+        except PyAsn1Error as e:
+            raise ValueError(f"Failed to extract RSA public key: {e}")
+
+    @classmethod
+    def from_PEM(
+            cls, data: str,
+            start_marker="-----BEGIN RSA PRIVATE KEY-----",
+            end_marker="-----END RSA PRIVATE KEY-----"
+    ) -> "RSAPrivateKey":
+        """
+        Generates RSAPrivateKey from data in ASN.1 PEM format.
+
+        :param data: RSA key data in ASN.1 PEM format
+        :param start_marker: Marks the beginning of the private key in PEM format.
+        :param end_marker: Marks the end of the private key in PEM format.
+
+        :raises ValueError: on failure
+        """
+        with io.StringIO(data) as fo:
+            der = pem.readPemFromFile(fo, startMarker=start_marker, endMarker=end_marker)
+            return cls.from_DER(der)
+
+    @classmethod
+    def from_BLOB(cls, data: bytes) -> "RSAPrivateKey":
+        """
+        Generates RSAPrivateKey from data stored in a Microsoft PRIVATEKEYBLOB format.
+
+        :param data: RSA key data in Microsoft Blob format
+
+        :raises ValueError: on failure
+        """
+        try:
+            privkey = construct.PRIVATEKEYBLOB.parse(data)
+            return RSAPrivateKey(
+                public_exponent=privkey.pubexponent,
+                modulus=privkey.modulus,
+                private_exponent=privkey.D,
+                p=privkey.P,
+                q=privkey.Q,
+                d_mod_p1=privkey.Dp,
+                d_mod_q1=privkey.Dq,
+                q_inv_mod_p=privkey.Iq,
+            )
+        except construct.ConstructError as e:
+            raise ValueError(f"Failed to parse Private Key BLOB: {e}")
+
+    @classmethod
+    def from_XML(cls, data: str, fallback=False) -> Union["RSAPrivateKey", "RSAPublicKey"]:
+        """
+        Generates RSAPrivateKey from data stored in serialized .NET XML resource.
+        (see RSA.FromXMLString() from .NET API documentation)
+
+        :param data: .NET Microsoft XML resource data
+        :param fallback: Whether to fallback to creating a RSAPublicKey if only the public exponent and modulus exists.
+            (useful if you don't know/care if the XML data contains a public or private key)
+
+        :raises ValueError: on failure
+        """
+        fields = _parse_rsa_xml(data)
+        if fallback and not any(key in fields for key in ("D", "P", "Q", "DP", "DQ", "InverseQ")):
+            return RSAPublicKey.from_XML(data)
+        return RSAPrivateKey(
+            public_exponent=fields.get("Exponent", None),
+            modulus=fields.get("Modulus", None),
+            private_exponent=fields.get("D", None),
+            p=fields.get("P", None),
+            q=fields.get("Q", None),
+            d_mod_p1=fields.get("DP", None),
+            d_mod_q1=fields.get("DQ", None),
+            q_inv_mod_p=fields.get("InverseQ", None),
+        )
+
+    def as_formatted_dict(self, flat=False) -> dict:
+        """
+        Display of RSAPrivateKey tends to create really wide output.
+        Reformatting results to equivalent output you would get with:
+            `openssl rsa -in key.pem -text -noout`
+        """
+        # NOTE: Not using openssl's field names since they are less descriptive.
+        fields = [
+            ("Modulus (n)", self.modulus),
+            ("Public Exponent (e)", self.public_exponent),
+            ("Private Exponent (d)", self.private_exponent),
+            ("p", self.p),
+            ("q", self.q),
+            ("d mod (p-1)", self.d_mod_p1),
+            ("d mod (q-1)", self.d_mod_q1),
+            ("(inverse of q) mod p", self.q_inv_mod_p),
+        ]
+
+        value = ""
+        for field, _value in fields:
+            if _value is not None:
+                value += f"{field}:\n{textwrap.indent(_int_dump(_value), '    ')}\n"
+
+        return {"tags": self.tags, "value": value or None}
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+
+        # x509 specifies hashes and serial for deterministic IDs in most cases, but we will never have that
+        # As such we are using our own namespace to generate a deterministic ID instead of forcing it to be a UUIDv4
+        # We only use the properties for the public key to make this ID so that we can avoid duplicating the public + private key data when both are present
+        namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
+        params = {
+            "id": "x509-certificate--" + str(uuid.uuid5(namespace, f"{self.public_exponent}//{self.modulus}"))
+        }
+
+        if self.public_exponent:
+            params["subject_public_key_exponent"] = self.public_exponent
+
+        if self.modulus:
+            params["subject_public_key_modulus"] = str(self.modulus)
+
+        extensions = stix_extensions.rsa_private_key_extension(self.private_exponent, self.p, self.q, self.d_mod_p1, self.d_mod_q1, self.q_inv_mod_p)
+
+        if extensions:
+            params["extensions"] = extensions
+
+        result.add_linked(stix.X509Certificate(**params))
+        result.create_tag_note(self, result.linked_stix[-1])
+
+        return result        
+
+@attr.s(**config)
+class RSAPublicKey(Metadata):
+    """
+    RSA public key containing: public_exponent, modulus
+    """
+    public_exponent: int = None
+    modulus: int = None
+
+    @classmethod
+    def from_DER(cls, data: bytes) -> "RSAPublicKey":
+        """
+        Generates RSAPublicKey from data in ASN.1 DER format.
+
+        :param data: RSA key data in ASN.1 DER format
+
+        :raises ValueError: on failure
+        """
+        try:
+            keyinfo, _ = asn1_decoder.decode(data, asn1Spec=rfc2459.SubjectPublicKeyInfo())
+            pubkey_obj = keyinfo.getComponentByName("subjectPublicKey")
+            key_data = bitarray(pubkey_obj.asBinary()).tobytes()
+            pubkey, _ = asn1_decoder.decode(key_data, asn1Spec=rfc2437.RSAPublicKey())
+            return RSAPublicKey(
+                public_exponent=int(pubkey.getComponentByName("publicExponent")),
+                modulus=int(pubkey.getComponentByName("modulus")),
+            )
+        except PyAsn1Error as e:
+            raise ValueError(f"Failed to extract RSA public key: {e}")
+
+    @classmethod
+    def from_PEM(
+            cls, data: str,
+            start_marker="-----BEGIN PUBLIC KEY-----",
+            end_marker="-----END PUBLIC KEY-----"
+    ) -> "RSAPublicKey":
+        """
+        Generates RSAPublicKey from data in ASN.1 PEM format.
+
+        :param data: RSA key data in ASN.1 PEM format
+        :param start_marker: Marks the beginning of the public key in PEM format.
+        :param end_marker: Marks the end of the public key in PEM format.
+
+        :raises ValueError: on failure
+        """
+        with io.StringIO(data) as fo:
+            der = pem.readPemFromFile(fo, startMarker=start_marker, endMarker=end_marker)
+            return cls.from_DER(der)
+
+    @classmethod
+    def from_BLOB(cls, data: bytes) -> "RSAPublicKey":
+        """
+        Generates RSAPublicKey from data stored in a Microsoft PUBLICKEYBLOB format.
+
+        :param data: RSA key data in Microsoft Blob format
+
+        :raises ValueError: on failure
+        """
+        try:
+            pubkey = construct.PUBLICKEYBLOB.parse(data)
+            return RSAPublicKey(
+                public_exponent=pubkey.pubexponent,
+                modulus=pubkey.modulus,
+            )
+        except construct.ConstructError as e:
+            raise ValueError(f"Failed to parse Public Key BLOB: {e}")
+
+    @classmethod
+    def from_XML(cls, data: str) -> "RSAPublicKey":
+        """
+        Generates RSAPublicKey from data stored in serialized .NET XML resource.
+        (see RSA.FromXMLString() from .NET API documentation)
+
+        :param data: .NET Microsoft XML resource data
+
+        :raises ValueError: on failure
+        """
+        fields = _parse_rsa_xml(data)
+        return RSAPublicKey(
+            public_exponent=fields.get("Exponent", None),
+            modulus=fields.get("Modulus", None),
+        )
+
+    def as_formatted_dict(self, flat=False) -> dict:
+        """
+        Display of RSAPublicKey tends to create really wide output.
+        Reformatting results to equivalent output you would get with:
+            `openssl rsa -in key.pem -text -noout -pubin`
+        """
+        fields = [
+            ("Modulus (n)", self.modulus),
+            ("Public Exponent (e)", self.public_exponent),
+        ]
+
+        value = ""
+        for field, _value in fields:
+            if _value is not None:
+                value += f"{field}:\n{textwrap.indent(_int_dump(_value), '    ')}\n"
+
+        return {"tags": self.tags, "value": value or None}
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+
+        # x509 specifies hashes and serial for deterministic IDs in most cases, but we will never have that
+        # As such we are using our own namespace to generate a deterministic ID instead of forcing it to be a UUIDv4
+        namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
+        params = {
+            "id": "x509-certificate--" + str(uuid.uuid5(namespace, f"{self.public_exponent}//{self.modulus}"))
+        }
+
+        if self.public_exponent:
+            params["subject_public_key_exponent"] = self.public_exponent
+
+        if self.modulus:
+            params["subject_public_key_modulus"] = str(self.modulus)
+
+        result.add_linked(stix.X509Certificate(**params))
+        result.create_tag_note(self, result.linked_stix[-1])
+
+        return result
+
+@attr.s(**config)
+class Service(Metadata):
+    r"""
+    Windows service information
+
+    :var name: The name of the service (lpServiceName)
+    :var display_name: The display name to be used by user interface programs to identify the service. (lpDisplayName)
+    :var description: The description of the service. (lpDescription)
+    :var image: The fully qualified path to the service binary file. (lpBinaryPathName)
+        Path can also include arguments e.g. "d:\myshare\myservice.exe arg1 arg2"
+    :var dll: Path to DLL file used by service, if any.
+
+    e.g.
+        Service(
+            name="WindowsUserManagement",
+            display_name="Windows User Management",
+            description="Provides a common management to access information about windows user."
+            image="%System%\\svohost.exe"
+        )
+    """
+    name: str = None
+    display_name: str = None
+    description: str = None
+    image: str = None
+    dll: str = None
+
+    def post_processing(self, report):
+        """Add file path in image field to report as a file path."""
+        # we use tactic of looking for first .exe in value. This is
+        # not guaranteed to be reliable
+        # TODO: This is here just to keep legacy logic. Determine if this is still appropriate when we remove
+        #   deprecations.
+        if self.image and ".exe" in self.image:
+            report.add(FilePath(self.image[:self.image.find(".exe") + 4]))
+        # TODO: doing this over setting dll as a Path type so we can set it as a "FilePath"
+        if self.dll:
+            report.add(FilePath(self.dll))
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        # Process generally uses a UUIDv4 but we want to deduplicate when the same command is used so we will use a v5
+        namespace = uuid.UUID('27b16a6a-0f3e-44e2-af1f-4b1c590278f4')
+        
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        params = {
+            "id": "process--" + str(uuid.uuid5(namespace, f"{self.image}/{self.name}/{self.display_name}/{self.description}/{self.image}/{self.dll}"))
+        }
+        extension = {}
+
+        if self.name:
+            extension["service_name"] = self.name
+
+        if self.display_name:
+            extension["display_name"] = self.display_name
+
+        if self.description:
+            extension["descriptions"] = [self.description]
+
+        if self.image:
+            params["command_line"] = self.image
+        
+        if self.dll and self.dll != self.image:
+            dir_path = str(pathlib.Path(self.dll).parent)
+
+            if dir_path:
+                result.add_unlinked(stix.Directory(path = dir_path))
+                result.add_unlinked(stix.File(name = self.image, parent_directory_ref = result.unlinked_stix[-1].id))
+                params["image_ref"] = result.unlinked_stix[-1].id
+
+        if extension:
+            params["extensions"] = {"windows-service-ext": extension}
+
+        
+        result.add_linked(stix.Process(**params))
+        result.create_tag_note(self, result.linked_stix[-1])
+
+        return result
+
+# TODO: legacy helpers
+def ServiceName(name: str) -> Service:
+    warnings.warn(
+        "This is a temporary helper that may be removed in a future version. "
+        "Please use Service() instead.", DeprecationWarning
+    )
+    return Service(name=name)
+
+
+def ServiceDescription(description: str) -> Service:
+    warnings.warn(
+        "This is a temporary helper that may be removed in a future version. "
+        "Please use Service() instead.", DeprecationWarning
+    )
+    return Service(description=description)
+
+
+def ServiceDisplayName(display_name: str) -> Service:
+    warnings.warn(
+        "This is a temporary helper that may be removed in a future version. "
+        "Please use Service() instead.", DeprecationWarning
+    )
+    return Service(display_name=display_name)
+
+
+def ServiceDLL(dll: str) -> Service:
+    warnings.warn(
+        "This is a temporary helper that may be removed in a future version. "
+        "Please use Service() instead.", DeprecationWarning
+    )
+    return Service(dll=dll)
+
+
+def ServiceImage(image: str) -> Service:
+    warnings.warn(
+        "This is a temporary helper that may be removed in a future version. "
+        "Please use Service() instead.", DeprecationWarning
+    )
+    return Service(image=image)
+
+
+@attr.s(**config)
+class SSLCertSHA1(Metadata):
+    """
+    SSL Certificate SHA-1 Hash
+
+    e.g.
+        SSLCertSHA1("c29d79df9b5416fd416c31e57cd525dfc23a8f66")
+    """
+    value: str = attr.ib(metadata={"jsonschema": {
+        "type": "string",
+        "pattern": "^[0-9a-fA-F]{40}$",
+    }})
+
+    _SHA1_RE = re.compile("[0-9a-fA-F]{40}")
+
+    @value.validator
+    def _validate(self, attribute, value):
+        if not self._SHA1_RE.match(value):
+            raise ValidationError(f"Invalid SHA1 hash found: {value!r}")
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        result.add_linked(stix.x509Certificate(hashes={"SHA-1": self.value}))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+
+@attr.s(**config)
+class UserAgent(Metadata):
+    """
+    Software identifier used by malware
+
+    e.g.
+        UserAgent("Mozilla/4.0 (compatible; MISE 6.0; Windows NT 5.2)")
+    """
+    value: str
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+        result.add_linked(stix_extensions.ObservedString(purpose="user-agent", value=self.value))
+        result.create_tag_note(self, result.linked_stix[-1])
+        return result
+
+
+
+@attr.s(**config)
+class Version(Metadata):
+    """
+    The version of the malware.
+    To the degree possible this should be based directly on artifacts from the malware.
+
+    e.g.
+        Version("3.1")
+        Version("incrementing XOR encoding")
+    """
+    value: str
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        content = f"Version: {self.value}"
+
+        if self.tags:
+            content += "\n    Version: " + ", ".join(self.tags)
+        
+        return STIXResult(content)
+
+
+@attr.s(**config)
+class File(Metadata):
+    """
+    Represents a file, which is either the original input file, a file dispatched by the parser,
+    or a supplemental file generated by the parser
+
+    :var name: Name of the file.
+    :var description: Description of the file.
+    :var md5: MD5 hash of the file represented as a hex string.
+    :var sha1: SHA1 hash of the file represented as a hex string.
+    :var sha256: SHA256 hash of the file represented as a hex string.
+    :var architecture: Type of architecture of the file (if applicable)
+    :var compile_time: UTC Timestamp the file was compiled as reported (if applicable)
+    :var file_path: Path where the file exists or has been written out to on the local file system.
+    :var data: Raw bytes of the file.
+    :var derivation: Description of how the file was obtained or its categorization.
+        e.g. "decrypted", "deobfuscated", "supplemental"
+    """
+    name: str = None
+    description: str = None
+    md5: str = attr.ib(default=None)
+    sha1: str = attr.ib(default=None)
+    sha256: str = attr.ib(default=None)
+    architecture: str = None
+    compile_time: str = attr.ib(default=None, metadata={"jsonschema": {
+        "type": "string",
+        "format": "date-time",
+    }})
+    file_path: str = None
+    data: bytes = None
+    derivation: str = None
+
+    def __attrs_post_init__(self):
+        if self.data is not None:
+            if not self.md5:
+                self.md5 = hashlib.md5(self.data).hexdigest()
+            if not self.sha1:
+                self.sha1 = hashlib.sha1(self.data).hexdigest()
+            if not self.sha256:
+                self.sha256 = hashlib.sha256(self.data).hexdigest()
+
+    # TODO: Add validation for hashes.
+
+    def as_stix(self, base_object, fixed_timestamp=None) -> STIXResult:
+        hashes = {}
+        result = STIXResult(fixed_timestamp=fixed_timestamp)
+
+        if self.md5:
+            hashes["MD5"] = self.md5
+        if self.sha1:
+            hashes["SHA-1"] = self.sha1
+        if self.sha1:
+            hashes["SHA-256"] = self.sha256
+        
+        params = {
+            "name": self.name
+            , "hashes": hashes
+        }
+
+        if self.data:
+            result.add_unlinked(stix.Artifact(payload_bin=base64.b64encode(self.data)))
+            params["content_ref"] = result.unlinked_stix[0].id
+
+        result.add_linked(stix.File(**params))
+
+        # description is skipped because that is added to the malware-analysis that is later built for the
+        # file by the report writer
+
+        if self.compile_time or self.architecture:
+            result.note_content = f"Compiled on: {self.compile_time}\nFor architecture: {self.architecture}"
+        
+        result.note_labels = self.tags
+        
+        return result
+
+    @classmethod
+    def from_file_object(cls, file_object):
+        return cls(
+            name=file_object.name,
+            description=file_object.description,
+            md5=file_object.md5,
+            sha1=file_object.sha1,
+            sha256=file_object.sha256,
+            architecture=file_object.architecture,
+            compile_time=file_object.compile_time.isoformat() if file_object.compile_time else None,
+            # TODO: Update this when .file_path deprecation is removed.
+            file_path=file_object.file_path if file_object._exists else None,
+            data=file_object.data,
+            derivation=file_object.derivation,
+        ).add_tag(*file_object.tags)
+
+
+# Helper aliases
+InputFile = File  # Original input malware file that triggered parsing.
+ResidualFile = File  # Relevant or related file created during parsing of malware.
+
+
+def SupplementalFile(
+        name: str = None,
+        description: str = None,
+        md5: str = None,
+        sha1: str = None,
+        sha256: str = None,
+        architecture: str = None,
+        compile_time: str = None,
+        file_path: str = None,
+        data: bytes = None
+) -> File:
+    """
+    Helper function for creating a file that supplements the malware sample but isn't
+    something obtained from the sample.
+    e.g. string dump, annotated IDB, etc.
+    """
+    return File(
+        name=name,
+        description=description,
+        md5=md5,
+        sha1=sha1,
+        sha256=sha256,
+        architecture=architecture,
+        compile_time=compile_time,
+        file_path=file_path,
+        data=data,
+        derivation="supplemental",
+    )
+
+
+@attr.s(**config)
+class Report(Element):
+    """
+    Defines the report of all metadata elements.
+
+    :var mwcp_version: The version of MWCP used.
+    :var input_file: The initial file processed.
+    :var parser: The initial parser used to process the file.
+    :var errors: List of error messages that have occurred.
+    :var logs: List of all log messages that have occurred.
+    :var metadata: List of extracted metadata elements.
+    """
+    mwcp_version: str = attr.ib(init=False, factory=lambda: mwcp.__version__)
+    input_file: File = None
+    parser: str = None
+    errors: List[str] = attr.ib(factory=list)
+    logs: List[str] = attr.ib(factory=list)
+    metadata: List[Metadata] = attr.ib(factory=list)
+
+
+@attr.s(**config)
+class StringReport(Element):
+    """
+    Defines a report of decoded strings for a file.
+    """
+    file: File
+    strings: List[DecodedString] = attr.ib(factory=list)
```

### Comparing `mwcp-3.8.0/mwcp/parser.py` & `mwcp-3.9.0/mwcp/parser.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,160 +1,160 @@
-import abc
-import logging
-from typing import TYPE_CHECKING, Union, Tuple, Any
-import warnings
-
-# This is here for type hints and autocomplete in PyCharm
-# noinspection PyUnreachableCode
-if TYPE_CHECKING:
-    from mwcp import FileObject, Report
-
-logger = logging.getLogger(__name__)
-
-
-# A way to create a class properties
-# (Adding ABCMeta so, parsers have the freedom to use it.)
-class ParserMeta(abc.ABCMeta):
-    @property
-    def name(cls):
-        try:
-            return cls._name
-        except AttributeError:
-            return cls.__name__
-
-    @name.setter
-    def name(cls, value):
-        cls._name = value
-
-    @property
-    def source(cls):
-        try:
-            return cls._source
-        except AttributeError:
-            module, _, _ = cls.__module__.partition(".")
-            return module
-
-    @source.setter
-    def source(cls, value):
-        cls._source = value
-
-    def __repr__(cls):
-        return "<{}>".format(cls.name)
-
-
-class Parser(metaclass=ParserMeta):
-    """
-    Interface for all parser objects.
-    Either use this as a base for all component parsers, or
-    inherit this class into a customized base class for all parsers.  This class includes some of the required data
-    used by various other classes.
-    """
-
-    file_object = None  # type: FileObject
-    # This is the description that will be given to the file object during output
-    # if no description is set in the file_object. This must be overwritten by inherited classes.
-    DESCRIPTION = None
-    # This is a tuple of tags that will be added to the file object after identification.
-    TAGS = ()
-
-    # TODO: Deprecate the AUTHOR field?
-    AUTHOR = ""  # Optional
-
-    def __init__(self, file_object, report, dispatcher):
-        """
-        Initializes the Parser.
-
-        :param FileObject file_object: Object containing data about component file.
-        :param mwcp.Report report: Report object to be filled in.
-        :param Dispatcher dispatcher: reference to the dispatcher object
-        """
-        if not self.DESCRIPTION:
-            raise NotImplementedError("Parser class is missing a DESCRIPTION.")
-        self.file_object = file_object
-        self.report = report
-        self.dispatcher = dispatcher
-        self.logger = logging.getLogger(".".join([self.__class__.__module__, self.__class__.__name__]))
-
-    @property
-    def reporter(self) -> "Report":
-        warnings.warn(
-            "reporter has been renamed to report and is now an instance of mwcp.Report",
-            DeprecationWarning
-        )
-        return self.report
-
-    @classmethod
-    def get_logger(cls):
-        return logging.getLogger(".".join([cls.__module__, cls.__name__]))
-
-    @classmethod
-    def iter_subclasses(cls):
-        """Yields all classes that inherit from this class."""
-        for subclass in cls.__subclasses__():
-            yield subclass
-            for _subclass in subclass.iter_subclasses():
-                yield _subclass
-
-    @classmethod
-    def identify(cls, file_object: "FileObject") -> Union[bool, Tuple[bool, Any]]:
-        """
-        Determines if this parser is identified to support the given file_object.
-        This function must be overwritten in order to support identification.
-
-        The passed in file_object may be modified at this time to provide
-        a new file_name or description.
-        (Be aware, that this change will be in affect for future parsers.
-        Therefore, don't change it if you are returning False or the dispatcher is in greedy mode.)
-
-        :param file_object: file object to use for identification
-        :type file_object: dispatcher.FileObject
-
-        :return bool: Boolean indicating if this parser supports the file_object
-            Extra arguments to pass into the run() function can also be provided.
-        """
-        logger.warning("Missing identify() function for: {}.{}".format(cls.__module__, cls.__name__))
-        return True  # Default to True to keep backwards compatibility for legacy parsers.
-
-    @staticmethod
-    def unpack_identify(result) -> Tuple[bool, Any]:
-        """
-        Helper function to normalize identify results to always produce a tuple of identification result and extras.
-        """
-        if isinstance(result, tuple) and isinstance(result[0], bool):
-            identified, *rest = result
-            rest = tuple(rest)
-        else:
-            identified = bool(result)
-            rest = tuple()
-        return (identified, *rest)
-
-    @classmethod
-    def parse(cls, file_object, report, *run_args, dispatcher=None):
-        """
-        Runs parser on given file_object.
-
-        :param FileObject file_object: Object containing data about component file.
-        :param mwcp.Report report: reference to report object used to report new metadata.
-        :param run_args: Extra arguments returned from identify() to pass to run() function.
-        :param Dispatcher dispatcher: reference to the dispatcher object. (if used)
-        :return:
-        """
-        if dispatcher:
-            report.set_file(file_object)
-            parser_object = cls(file_object, report, dispatcher)
-            parser_object.run(*run_args)
-
-        # If dispatcher isn't provided, create a dummy one containing only this parser.
-        # This is necessary to ensure identification is run first.
-        else:
-            from mwcp import Dispatcher  # Must import here to avoid cyclic import.
-
-            dispatcher = Dispatcher(cls.name, cls.source, author=cls.AUTHOR, description=cls.DESCRIPTION, parsers=[cls])
-            dispatcher.parse(file_object, report, *run_args)
-
-    def run(self, *args):
-        """
-        This function can be overwritten. It is called to run the parser.
-        You don't have to overwrite this method if you only want to identify/output the file.
-        :return:
-        """
-        pass
+import abc
+import logging
+from typing import TYPE_CHECKING, Union, Tuple, Any
+import warnings
+
+# This is here for type hints and autocomplete in PyCharm
+# noinspection PyUnreachableCode
+if TYPE_CHECKING:
+    from mwcp import FileObject, Report
+
+logger = logging.getLogger(__name__)
+
+
+# A way to create a class properties
+# (Adding ABCMeta so, parsers have the freedom to use it.)
+class ParserMeta(abc.ABCMeta):
+    @property
+    def name(cls):
+        try:
+            return cls._name
+        except AttributeError:
+            return cls.__name__
+
+    @name.setter
+    def name(cls, value):
+        cls._name = value
+
+    @property
+    def source(cls):
+        try:
+            return cls._source
+        except AttributeError:
+            module, _, _ = cls.__module__.partition(".")
+            return module
+
+    @source.setter
+    def source(cls, value):
+        cls._source = value
+
+    def __repr__(cls):
+        return "<{}>".format(cls.name)
+
+
+class Parser(metaclass=ParserMeta):
+    """
+    Interface for all parser objects.
+    Either use this as a base for all component parsers, or
+    inherit this class into a customized base class for all parsers.  This class includes some of the required data
+    used by various other classes.
+    """
+
+    file_object = None  # type: FileObject
+    # This is the description that will be given to the file object during output
+    # if no description is set in the file_object. This must be overwritten by inherited classes.
+    DESCRIPTION = None
+    # This is a tuple of tags that will be added to the file object after identification.
+    TAGS = ()
+
+    # TODO: Deprecate the AUTHOR field?
+    AUTHOR = ""  # Optional
+
+    def __init__(self, file_object, report, dispatcher):
+        """
+        Initializes the Parser.
+
+        :param FileObject file_object: Object containing data about component file.
+        :param mwcp.Report report: Report object to be filled in.
+        :param Dispatcher dispatcher: reference to the dispatcher object
+        """
+        if not self.DESCRIPTION:
+            raise NotImplementedError("Parser class is missing a DESCRIPTION.")
+        self.file_object = file_object
+        self.report = report
+        self.dispatcher = dispatcher
+        self.logger = logging.getLogger(".".join([self.__class__.__module__, self.__class__.__name__]))
+
+    @property
+    def reporter(self) -> "Report":
+        warnings.warn(
+            "reporter has been renamed to report and is now an instance of mwcp.Report",
+            DeprecationWarning
+        )
+        return self.report
+
+    @classmethod
+    def get_logger(cls):
+        return logging.getLogger(".".join([cls.__module__, cls.__name__]))
+
+    @classmethod
+    def iter_subclasses(cls):
+        """Yields all classes that inherit from this class."""
+        for subclass in cls.__subclasses__():
+            yield subclass
+            for _subclass in subclass.iter_subclasses():
+                yield _subclass
+
+    @classmethod
+    def identify(cls, file_object: "FileObject") -> Union[bool, Tuple[bool, Any]]:
+        """
+        Determines if this parser is identified to support the given file_object.
+        This function must be overwritten in order to support identification.
+
+        The passed in file_object may be modified at this time to provide
+        a new file_name or description.
+        (Be aware, that this change will be in affect for future parsers.
+        Therefore, don't change it if you are returning False or the dispatcher is in greedy mode.)
+
+        :param file_object: file object to use for identification
+        :type file_object: dispatcher.FileObject
+
+        :return bool: Boolean indicating if this parser supports the file_object
+            Extra arguments to pass into the run() function can also be provided.
+        """
+        logger.warning("Missing identify() function for: {}.{}".format(cls.__module__, cls.__name__))
+        return True  # Default to True to keep backwards compatibility for legacy parsers.
+
+    @staticmethod
+    def unpack_identify(result) -> Tuple[bool, Any]:
+        """
+        Helper function to normalize identify results to always produce a tuple of identification result and extras.
+        """
+        if isinstance(result, tuple) and isinstance(result[0], bool):
+            identified, *rest = result
+            rest = tuple(rest)
+        else:
+            identified = bool(result)
+            rest = tuple()
+        return (identified, *rest)
+
+    @classmethod
+    def parse(cls, file_object, report, *run_args, dispatcher=None):
+        """
+        Runs parser on given file_object.
+
+        :param FileObject file_object: Object containing data about component file.
+        :param mwcp.Report report: reference to report object used to report new metadata.
+        :param run_args: Extra arguments returned from identify() to pass to run() function.
+        :param Dispatcher dispatcher: reference to the dispatcher object. (if used)
+        :return:
+        """
+        if dispatcher:
+            report.set_file(file_object)
+            parser_object = cls(file_object, report, dispatcher)
+            parser_object.run(*run_args)
+
+        # If dispatcher isn't provided, create a dummy one containing only this parser.
+        # This is necessary to ensure identification is run first.
+        else:
+            from mwcp import Dispatcher  # Must import here to avoid cyclic import.
+
+            dispatcher = Dispatcher(cls.name, cls.source, author=cls.AUTHOR, description=cls.DESCRIPTION, parsers=[cls])
+            dispatcher.parse(file_object, report, *run_args)
+
+    def run(self, *args):
+        """
+        This function can be overwritten. It is called to run the parser.
+        You don't have to overwrite this method if you only want to identify/output the file.
+        :return:
+        """
+        pass
```

### Comparing `mwcp-3.8.0/mwcp/parsers/foo.py` & `mwcp-3.9.0/mwcp/parsers/foo.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,50 +1,50 @@
-"""This is an example parser used to show the different methods of adding data to the reporter."""
-import logging
-import os
-
-from mwcp import Parser, FileObject, metadata
-
-logger = logging.getLogger(__name__)
-
-
-class Foo(Parser):
-    DESCRIPTION = "Foo"
-
-    @classmethod
-    def identify(cls, file_object):
-        # identifies if the parser can parse the given file.
-        # checking filename to avoid infinite loop.
-        return file_object.name != "fooconfigtest.txt"
-
-    def run(self):
-        # retrieve input file
-        input_file = self.file_object
-
-        # standardized metadata
-        self.report.add(metadata.URL("http://127.0.0.1"))
-
-        # demonstrate access to sample
-        logger.info(f"size of inputfile is {len(input_file.data)} bytes")
-
-        # other, non-standardized metadata
-        # also demonstrate use of pefile object
-        if input_file.pe:
-            self.report.add(metadata.Other(
-                "section0", input_file.pe.sections[0].Name.rstrip(b"\x00")
-            ))
-
-        # Dispatch residual files to also be processed.
-        self.dispatcher.add(FileObject(
-            b"hello world",
-            file_name="fooconfigtest.txt",
-            description="example output file",
-            derivation="extracted and decompressed",
-        ))
-        #  Alternatively we can manually report a residual file without being processed.
-        if False:
-            self.report.add(metadata.File(
-                "fooconfigtest.txt", description="example output file", data=b"hello world"
-            ))
-
-        # demonstrate use of filename()
-        logger.info(f"operating on inputfile {input_file.name}")
+"""This is an example parser used to show the different methods of adding data to the reporter."""
+import logging
+import os
+
+from mwcp import Parser, FileObject, metadata
+
+logger = logging.getLogger(__name__)
+
+
+class Foo(Parser):
+    DESCRIPTION = "Foo"
+
+    @classmethod
+    def identify(cls, file_object):
+        # identifies if the parser can parse the given file.
+        # checking filename to avoid infinite loop.
+        return file_object.name != "fooconfigtest.txt"
+
+    def run(self):
+        # retrieve input file
+        input_file = self.file_object
+
+        # standardized metadata
+        self.report.add(metadata.URL("http://127.0.0.1"))
+
+        # demonstrate access to sample
+        logger.info(f"size of inputfile is {len(input_file.data)} bytes")
+
+        # other, non-standardized metadata
+        # also demonstrate use of pefile object
+        if input_file.pe:
+            self.report.add(metadata.Other(
+                "section0", input_file.pe.sections[0].Name.rstrip(b"\x00")
+            ))
+
+        # Dispatch residual files to also be processed.
+        self.dispatcher.add(FileObject(
+            b"hello world",
+            file_name="fooconfigtest.txt",
+            description="example output file",
+            derivation="extracted and decompressed",
+        ))
+        #  Alternatively we can manually report a residual file without being processed.
+        if False:
+            self.report.add(metadata.File(
+                "fooconfigtest.txt", description="example output file", data=b"hello world"
+            ))
+
+        # demonstrate use of filename()
+        logger.info(f"operating on inputfile {input_file.name}")
```

### Comparing `mwcp-3.8.0/mwcp/registry.py` & `mwcp-3.9.0/mwcp/registry.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,456 +1,455 @@
-"""
-Interface for registering and accessing parsers.
-"""
-import sys
-from collections import namedtuple
-import hashlib
-import importlib
-import importlib.machinery
-import importlib.util
-import logging
-import os
-import pkgutil
-from typing import Optional, Dict, List
-
-import pkg_resources
-
-from ruamel.yaml import YAML
-
-from mwcp.parser import Parser
-from mwcp.dispatcher import Dispatcher
-from mwcp.exceptions import ParserNotFoundError
-
-yaml = YAML()
-logger = logging.getLogger(__name__)
-
-ParserInfo = namedtuple("ParserInfo", ("name", "source", "author", "description"))
-
-
-class Source:
-    """Represents a source of parsers."""
-
-    def __init__(self, name, path, config, is_pkg):
-        self.name = name
-        self.path = path
-        self.config = config
-        self.is_pkg = is_pkg
-        self._package = None
-
-    def __getstate__(self):
-        # Modifying __getstate__ in order to null out _package, since that is not picklable.
-        _dict = self.__dict__
-        _dict["_package"] = None
-        return _dict
-
-    @property
-    def package(self):
-        """Imports and returns the Python package for the source."""
-        if not self._package:
-            # Import source on first call.
-            if self.is_pkg:
-                try:
-                    self._package = importlib.import_module(self.path)
-                except ImportError:
-                    raise ValueError(f"Could not import source: {self.path}")
-            else:
-                self._package = _create_package(self.path)
-        return self._package
-
-
-# Set of parser sources mapped to configuration files.
-# Sources can be a file path or import path to a python package containing parsers.
-# Maps source -> Source object
-_sources: Dict[str, Source] = {}
-# name of the default source (if set)
-_default_source: Optional[str] = None
-
-
-def get_source(source_name: str) -> Source:
-    """
-    Gets Source object for given name.
-    :param source_name:
-    :raises ValueError: If source with given name is not found.
-    """
-    try:
-        return _sources[source_name]
-    except KeyError:
-        raise ValueError(f"Unable to find source with the given name: {source_name}")
-
-
-def is_source(source_name: str) -> bool:
-    """
-    Determines where the given source name is valid and registered.
-    """
-    return source_name in _sources
-
-
-def get_sources() -> List[Source]:
-    """
-    Returns a list of all currently registered parser sources.
-    """
-    return list(_sources.values())
-
-
-def get_default_source() -> Optional[Source]:
-    """
-    Gets currently set default source.
-    Returns None if a default source is not set.
-    """
-    return get_source(_default_source) if _default_source else None
-
-
-def set_default_source(source_name: str):
-    """
-    Sets a default parser source to use if not explicitly defined.
-    If this is not set, all sources will be considered.
-
-    :param source_name: The name of the source to set.
-    :raises ValueError: If given source name is not a registered source.
-    """
-    global _default_source
-    if source_name not in _sources:
-        raise ValueError(f"{source_name} is not a registered parser source.")
-    _default_source = source_name
-
-
-def clear_default_source():
-    """
-    Clears a previously set default source.
-    """
-    global _default_source
-    _default_source = None
-
-
-def clear():
-    """
-    Removes all registered parsers and sources.
-    """
-    global _sources
-    global _default_source
-    _sources = {}
-    _default_source = None
-
-
-def register_entry_points():
-    """
-    Registers parsers found in entry_point: "mwcp.parsers"
-    :return:
-    """
-    for entry in pkg_resources.iter_entry_points("mwcp.parsers"):
-        package = entry.load()
-        register_parser_package(package, source_name=entry.name)
-
-
-def _load_config(config_file_path):
-    """
-    Loads and validates given parser config file path.
-
-    :raises ValueError: If loaded config file is invalid.
-    """
-    with open(config_file_path, "r") as fp:
-        config = yaml.load(fp)
-
-    logger.debug(f"Validating parser config: {config_file_path}")
-    if not isinstance(config, dict):
-        raise ValueError(f"Parser config is not a dictionary: {config_file_path}")
-    config = {str(key): value for key, value in config.items()}  # Force keys to be strings.
-    for key, value in config.items():
-        if "." in key:
-            raise ValueError(f'"." in group name is not allowed: {key}')
-        if isinstance(value, str):
-            if value not in config.keys():
-                raise ValueError(f'Unable to find "{value}" aliased by "{key}"')
-        else:
-            if "description" not in value:
-                raise ValueError(f'Missing "description" field in group: {key}')
-            if "parsers" not in value:
-                raise ValueError(f'Missing "parsers" field in group: {key}')
-            if not isinstance(value["parsers"], list):
-                raise ValueError(f'"parsers" field is not a list in group: {key}')
-    return config
-
-
-def register_parser_directory(directory, config_file_path=None, source_name=None):
-    """
-    Registers parsers found in directory. This function allows you to register one-off parsers
-    that are not part of an installed python package.
-
-    :param str directory: An extra directory to look for one-off parsers.
-    :param config_file_path: Optional path to a parser configuration file used to define parser groups.
-            If not provided, it will attempt to pull from the "config" attribute of the __init__ module.
-    :param source_name: Unique name to give to the source. (uses directory path otherwise)
-
-    :raises ValueError: If loaded config file is invalid.
-    """
-    global _sources
-
-    if not os.path.isdir(directory):
-        raise ValueError(f"Parser directory not found or not a directory: {directory}")
-
-    # Ensure this directory can be converted to a package and pull config_file_path if available.
-    package = _create_package(directory)
-    if not config_file_path:
-        config_file_path = getattr(package, "config", None)
-    config = _load_config(config_file_path) if config_file_path else {}
-
-    if not source_name:
-        source_name = directory
-
-    # NOTE: _sources must be discoverable without modification, so we can't register the package.
-    _sources[source_name] = Source(source_name, directory, config, False)
-
-
-def register_parser_package(package, config_file_path=None, source_name=None):
-    """
-    Registers Python package containing MWCP parsers.
-
-    :param package: An Python package containing submodules that contain MWCP parsers.
-        NOTE: Package must be discoverable in subprocesses without modifying the python path.
-              Please use register_parser_directory() instead if that is not possible.
-    :param config_file_path: Path to parser configuration file used to define parser groups.
-        If not provided, it will attempt to pull from the "config" attribute of the __init__ module.
-    :param source_name: Unique name to give to the source. (uses package name otherwise)
-
-    :raises AttributeError: If config_file_path is not provided and package doesn't have a "config" attribute.
-    :raises ValueError: If loaded config file is invalid.
-    """
-    global _sources
-
-    if not hasattr(package, "__path__"):
-        raise ValueError(f"{package!r} is not a Python package")
-
-    if not config_file_path:
-        config_file_path = getattr(package, "config", None)
-    config = _load_config(config_file_path) if config_file_path else {}
-
-    if not source_name:
-        source_name = package.__name__.lower()
-
-    _sources[source_name] = Source(source_name, package.__name__, config, True)
-
-
-def _create_package(directory):
-    """Creates a Python package object from given directory."""
-    # Create a dummy package for the directory.
-    package_name = hashlib.md5(directory.encode("utf8")).hexdigest()
-    package_init = os.path.join(directory, "__init__.py")
-    # Create __init__.py if it doesn't exist.
-    if not os.path.exists(package_init):
-        logger.info(f"Creating required __init__ module: {package_init}")
-        with open(package_init, "a"):
-            pass
-    try:
-        spec = importlib.util.spec_from_file_location(package_name, package_init)
-        package = importlib.util.module_from_spec(spec)
-        sys.modules[package_name] = package
-        spec.loader.exec_module(package)
-        package.__path__ = [directory]
-    except IOError as e:
-        raise ValueError(f"Could not create package from {directory} with error: {e}")
-    return package
-
-
-def _is_module_available(module_name):
-    """Determines whether given module name is available without importing."""
-    try:
-        return bool(importlib.util.find_spec(module_name))
-    except ModuleNotFoundError:
-        # If we get this error, that means an intermediate package couldn't be found.
-        return False
-
-
-def _import_parser(name: str, source: Source):
-    """Imports Parser class from full name."""
-    logger.debug(f"Generating parser: {name}")
-    if "." not in name:
-        raise ParserNotFoundError(f"Invalid name {name}")
-    # If not, find and import the referenced mwcp.Parser class.
-    module_name, _, class_name = name.rpartition(".")
-    module_fullname = source.package.__name__ + "." + module_name
-
-    logger.debug(f"Checking existence of {module_fullname}")
-    if not _is_module_available(module_fullname):
-        raise ParserNotFoundError(f"{module_fullname} module does not exist")
-
-    logger.debug(f"Importing: {module_fullname}")
-    module = importlib.import_module(module_fullname)
-
-    if not hasattr(module, class_name):
-        raise ParserNotFoundError(f"{class_name} is not in {module_fullname}")
-
-    klass = getattr(module, class_name)
-
-    if not issubclass(klass, Parser):
-        raise ParserNotFoundError(f"{module_fullname}.{class_name} is not a mwcp.Parser class")
-
-    klass.name = name
-    klass.source = source.name
-    logger.debug(f"Created parser: {klass!r}")
-    return klass
-
-
-def _generate_parser_aux(parser_name, group_name, source, _visiting):
-    """
-    Auxiliary function used by _generate_parser() to format the parser_name
-    before running _generate_parser()
-    """
-    orig_parser_name = parser_name
-
-    if parser_name.startswith("."):
-        parser_name = group_name + parser_name
-
-    # Pull out imported source.
-    if ":" in parser_name:
-        source_name, _, parser_name = parser_name.partition(":")
-        if source_name not in _sources:
-            raise RuntimeError(f"Unable to find source: {source_name}")
-        source = _sources[source_name]
-
-    if (parser_name, source.name) in _visiting:
-        raise RuntimeError(f"Detected recursive loop: {group_name} -> {orig_parser_name}")
-
-    try:
-        return _generate_parser(parser_name, source, _visiting=_visiting)
-    except ParserNotFoundError as e:
-        raise RuntimeError(f"Unable to find {parser_name} with error: {e}")
-
-
-def _generate_parser(name: str, source: Source, recursive=True, _visiting=None):
-    """
-    Generates parser for given name.
-
-    :param str name: Name of parser or parser group.
-    :param Source source: Source object containing parser.
-    :param bool recursive: Recursively generate listed sub parsers.
-        (otherwise only top level parsers will be produced)
-    :param _visiting: Used internally for recursive loop detection.
-
-    :returns: Either a Dispatcher object for a group of parsers or a Parser class.
-
-    :raises ParserNotFound: If parser could not be found.
-    """
-    if _visiting is None:
-        _visiting = set()
-
-    _visiting.add((name, source.name))
-
-    try:
-        # First check if parser name is a parser group or alias.
-        config_value = source.config[name]
-    except KeyError:
-        klass = _import_parser(name, source)
-        _visiting.remove((name, source.name))
-        return klass
-
-    # If value is a string, this is an alias.
-    if isinstance(config_value, str):
-        parser = _generate_parser(config_value, source, recursive=recursive, _visiting=_visiting)
-        parser.name = name
-        return parser
-
-    # Otherwise, instantiate a mwcp.Dispatcher class for the parser group.
-    options = dict(config_value)
-    group_name = name
-    parser_names = options.pop("parsers")
-    sub_parsers = []
-    if recursive:
-        for parser_name in parser_names:
-            sub_parsers.append(_generate_parser_aux(parser_name, group_name, source, _visiting))
-
-    # Dereference default parser.
-    default = options.pop("default", None)
-    if default and recursive:
-        options["default"] = _generate_parser_aux(default, group_name, source, _visiting)
-
-    parser = Dispatcher(group_name, source.name, parsers=sub_parsers, **options)
-    logger.debug(f"Created parser group: {parser!r}")
-    _visiting.remove((name, source.name))
-    return parser
-
-
-def _import_all_modules(package):
-    """Recursively imports all modules from a given python package or directory."""
-    for _, name, is_pkg in pkgutil.walk_packages(package.__path__):
-        full_name = f"{package.__name__}.{name}"
-        module = importlib.import_module(full_name)
-        if is_pkg:
-            _import_all_modules(module)
-
-
-def iter_parsers(name: str = None, source: str = None, config_only=True, _recursive=True):
-    """
-    Iterates all registered parsers.
-
-    :param str name: Filters parser based on a particular name. (":" notation is also supported)
-    :param str source: Filters parser based on a particular source name.
-                       (source name is either the name of a python package or path to local directory)
-    :param bool config_only: Whether to only include parsers listed in the parser configuration file.
-                             (ie. ignore component parsers like "Foo.Implant")
-    :param bool _recursive: Whether to generate sub parsers.
-        (This is used internally, don't change it unless you know what you are doing)
-
-    :yields: tuple containing: (Source tuple, parser)
-
-    :raises ValueError: If a parser name or source could not be found.
-    """
-    global _sources
-
-    if name and not source:
-        # If name is using ":" notation, assume it is being organized by "source_name:parser_name"
-        # (os.path.basename is necessary in-case source is a file path containing ":"'s)
-        orig_name = name
-        _, _, name = os.path.basename(name).rpartition(":")
-        source = orig_name[: -(len(name) + 1)]
-    default_source = get_default_source()
-
-    if source:
-        sources = [get_source(source)]
-    elif default_source:
-        sources = [default_source]
-    else:
-        sources = get_sources()
-
-    for source in sources:
-        # Find list of parser names to generate
-        if name:
-            try:
-                parser = _generate_parser(name, source, recursive=_recursive)
-                yield source, parser
-            except ParserNotFoundError as e:
-                logger.debug(f"[{source.name}] {e}")
-                # Parser couldn't be found for this source.
-                continue
-        else:
-            # If parser name is not provided provide all parsers from the given source.
-            for parser_name in source.config.keys():
-                parser = _generate_parser(parser_name, source, recursive=_recursive)
-                yield source, parser
-
-            # Also list all the component parsers if requested.
-            if not config_only:
-                _import_all_modules(source.package)
-                package_prefix = source.package.__name__ + "."
-                for klass in set(Parser.iter_subclasses()):
-                    # Ignore classes without DESCRIPTIONS since they are usually base classes.
-                    if klass.DESCRIPTION and klass.__module__.startswith(package_prefix):
-                        parser_name = f"{klass.__module__[len(package_prefix):]}.{klass.__name__}"
-                        klass.name = parser_name
-                        yield source, klass
-
-
-def get_parser_descriptions(name=None, source=None, config_only=True):
-    """
-    Retrieve list of parser descriptions
-
-    :param str name: Filters parser based on a particular name. (":" notation is also supported)
-    :param str source: Filters parser based on a particular source.
-                       (source is either the name of a python package or path to local directory)
-    :param bool config_only: Whether to only include parsers listed in the parser configuration file.
-                             (ie. ignore component parsers like "Foo.Implant")
-
-    Returns list of tuples per parser. Tuple contains parser name, author, and description.
-    """
-    descriptions = []
-    for _source, parser in iter_parsers(name=name, source=source, config_only=config_only, _recursive=False):
-        descriptions.append(ParserInfo(parser.name, _source.name, parser.AUTHOR, parser.DESCRIPTION))
-    return sorted(descriptions, key=lambda e: tuple(sub.lower() for sub in e))  # Case-insensitive sorting.
+"""
+Interface for registering and accessing parsers.
+"""
+import sys
+from collections import namedtuple
+import hashlib
+import importlib
+import importlib.machinery
+import importlib.util
+import logging
+import os
+import pkgutil
+from typing import Optional, Dict, List
+
+import pkg_resources
+
+from ruamel.yaml import YAML
+
+from mwcp.parser import Parser
+from mwcp.dispatcher import Dispatcher
+from mwcp.exceptions import ParserNotFoundError
+
+yaml = YAML()
+logger = logging.getLogger(__name__)
+
+ParserInfo = namedtuple("ParserInfo", ("name", "source", "author", "description"))
+
+
+class Source:
+    """Represents a source of parsers."""
+
+    def __init__(self, name, path, config, is_pkg):
+        self.name = name
+        self.path = path
+        self.config = config
+        self.is_pkg = is_pkg
+        self._package = None
+
+    def __getstate__(self):
+        # Modifying __getstate__ in order to null out _package, since that is not picklable.
+        _dict = self.__dict__
+        _dict["_package"] = None
+        return _dict
+
+    @property
+    def package(self):
+        """Imports and returns the Python package for the source."""
+        if not self._package:
+            # Import source on first call.
+            if self.is_pkg:
+                try:
+                    self._package = importlib.import_module(self.path)
+                except ImportError:
+                    raise ValueError(f"Could not import source: {self.path}")
+            else:
+                self._package = _create_package(self.path)
+        return self._package
+
+
+# Set of parser sources mapped to configuration files.
+# Sources can be a file path or import path to a python package containing parsers.
+# Maps source -> Source object
+_sources: Dict[str, Source] = {}
+# name of the default source (if set)
+_default_source: Optional[str] = None
+
+
+def get_source(source_name: str) -> Source:
+    """
+    Gets Source object for given name.
+    :param source_name:
+    :raises ValueError: If source with given name is not found.
+    """
+    try:
+        return _sources[source_name]
+    except KeyError:
+        raise ValueError(f"Unable to find source with the given name: {source_name}")
+
+
+def is_source(source_name: str) -> bool:
+    """
+    Determines where the given source name is valid and registered.
+    """
+    return source_name in _sources
+
+
+def get_sources() -> List[Source]:
+    """
+    Returns a list of all currently registered parser sources.
+    """
+    return list(_sources.values())
+
+
+def get_default_source() -> Optional[Source]:
+    """
+    Gets currently set default source.
+    Returns None if a default source is not set.
+    """
+    return get_source(_default_source) if _default_source else None
+
+
+def set_default_source(source_name: str):
+    """
+    Sets a default parser source to use if not explicitly defined.
+    If this is not set, all sources will be considered.
+
+    :param source_name: The name of the source to set.
+    :raises ValueError: If given source name is not a registered source.
+    """
+    global _default_source
+    if source_name not in _sources:
+        raise ValueError(f"{source_name} is not a registered parser source.")
+    _default_source = source_name
+
+
+def clear_default_source():
+    """
+    Clears a previously set default source.
+    """
+    global _default_source
+    _default_source = None
+
+
+def clear():
+    """
+    Removes all registered parsers and sources.
+    """
+    global _sources
+    global _default_source
+    _sources = {}
+    _default_source = None
+
+
+def register_entry_points():
+    """
+    Registers parsers found in entry_point: "mwcp.parsers"
+    :return:
+    """
+    for entry in pkg_resources.iter_entry_points("mwcp.parsers"):
+        package = entry.load()
+        register_parser_package(package, source_name=entry.name)
+
+
+def _load_config(config_file_path):
+    """
+    Loads and validates given parser config file path.
+
+    :raises ValueError: If loaded config file is invalid.
+    """
+    with open(config_file_path, "r") as fp:
+        config = yaml.load(fp)
+
+    logger.debug(f"Validating parser config: {config_file_path}")
+    if not isinstance(config, dict):
+        raise ValueError(f"Parser config is not a dictionary: {config_file_path}")
+    config = {str(key): value for key, value in config.items()}  # Force keys to be strings.
+    for key, value in config.items():
+        if "." in key:
+            raise ValueError(f'"." in group name is not allowed: {key}')
+        # Validate if parser group. Ignore alias strings.
+        if not isinstance(value, str):
+            if "description" not in value:
+                raise ValueError(f'Missing "description" field in group: {key}')
+            if "parsers" not in value:
+                raise ValueError(f'Missing "parsers" field in group: {key}')
+            if not isinstance(value["parsers"], list):
+                raise ValueError(f'"parsers" field is not a list in group: {key}')
+    return config
+
+
+def register_parser_directory(directory, config_file_path=None, source_name=None):
+    """
+    Registers parsers found in directory. This function allows you to register one-off parsers
+    that are not part of an installed python package.
+
+    :param str directory: An extra directory to look for one-off parsers.
+    :param config_file_path: Optional path to a parser configuration file used to define parser groups.
+            If not provided, it will attempt to pull from the "config" attribute of the __init__ module.
+    :param source_name: Unique name to give to the source. (uses directory path otherwise)
+
+    :raises ValueError: If loaded config file is invalid.
+    """
+    global _sources
+
+    if not os.path.isdir(directory):
+        raise ValueError(f"Parser directory not found or not a directory: {directory}")
+
+    # Ensure this directory can be converted to a package and pull config_file_path if available.
+    package = _create_package(directory)
+    if not config_file_path:
+        config_file_path = getattr(package, "config", None)
+    config = _load_config(config_file_path) if config_file_path else {}
+
+    if not source_name:
+        source_name = directory
+
+    # NOTE: _sources must be discoverable without modification, so we can't register the package.
+    _sources[source_name] = Source(source_name, directory, config, False)
+
+
+def register_parser_package(package, config_file_path=None, source_name=None):
+    """
+    Registers Python package containing MWCP parsers.
+
+    :param package: An Python package containing submodules that contain MWCP parsers.
+        NOTE: Package must be discoverable in subprocesses without modifying the python path.
+              Please use register_parser_directory() instead if that is not possible.
+    :param config_file_path: Path to parser configuration file used to define parser groups.
+        If not provided, it will attempt to pull from the "config" attribute of the __init__ module.
+    :param source_name: Unique name to give to the source. (uses package name otherwise)
+
+    :raises AttributeError: If config_file_path is not provided and package doesn't have a "config" attribute.
+    :raises ValueError: If loaded config file is invalid.
+    """
+    global _sources
+
+    if not hasattr(package, "__path__"):
+        raise ValueError(f"{package!r} is not a Python package")
+
+    if not config_file_path:
+        config_file_path = getattr(package, "config", None)
+    config = _load_config(config_file_path) if config_file_path else {}
+
+    if not source_name:
+        source_name = package.__name__.lower()
+
+    _sources[source_name] = Source(source_name, package.__name__, config, True)
+
+
+def _create_package(directory):
+    """Creates a Python package object from given directory."""
+    # Create a dummy package for the directory.
+    package_name = hashlib.md5(directory.encode("utf8")).hexdigest()
+    package_init = os.path.join(directory, "__init__.py")
+    # Create __init__.py if it doesn't exist.
+    if not os.path.exists(package_init):
+        logger.info(f"Creating required __init__ module: {package_init}")
+        with open(package_init, "a"):
+            pass
+    try:
+        spec = importlib.util.spec_from_file_location(package_name, package_init)
+        package = importlib.util.module_from_spec(spec)
+        sys.modules[package_name] = package
+        spec.loader.exec_module(package)
+        package.__path__ = [directory]
+    except IOError as e:
+        raise ValueError(f"Could not create package from {directory} with error: {e}")
+    return package
+
+
+def _is_module_available(module_name):
+    """Determines whether given module name is available without importing."""
+    try:
+        return bool(importlib.util.find_spec(module_name))
+    except ModuleNotFoundError:
+        # If we get this error, that means an intermediate package couldn't be found.
+        return False
+
+
+def _import_parser(name: str, source: Source):
+    """Imports Parser class from full name."""
+    logger.debug(f"Generating parser: {name}")
+    if "." not in name:
+        raise ParserNotFoundError(f"Invalid name {name}")
+    # If not, find and import the referenced mwcp.Parser class.
+    module_name, _, class_name = name.rpartition(".")
+    module_fullname = source.package.__name__ + "." + module_name
+
+    logger.debug(f"Checking existence of {module_fullname}")
+    if not _is_module_available(module_fullname):
+        raise ParserNotFoundError(f"{module_fullname} module does not exist")
+
+    logger.debug(f"Importing: {module_fullname}")
+    module = importlib.import_module(module_fullname)
+
+    if not hasattr(module, class_name):
+        raise ParserNotFoundError(f"{class_name} is not in {module_fullname}")
+
+    klass = getattr(module, class_name)
+
+    if not issubclass(klass, Parser):
+        raise ParserNotFoundError(f"{module_fullname}.{class_name} is not a mwcp.Parser class")
+
+    klass.name = name
+    klass.source = source.name
+    logger.debug(f"Created parser: {klass!r}")
+    return klass
+
+
+def _generate_parser_aux(parser_name, group_name, source, _visiting):
+    """
+    Auxiliary function used by _generate_parser() to format the parser_name
+    before running _generate_parser()
+    """
+    orig_parser_name = parser_name
+
+    if parser_name.startswith("."):
+        parser_name = group_name + parser_name
+
+    # Pull out imported source.
+    if ":" in parser_name:
+        source_name, _, parser_name = parser_name.partition(":")
+        if source_name not in _sources:
+            raise RuntimeError(f"Unable to find source: {source_name}")
+        source = _sources[source_name]
+
+    if (parser_name, source.name) in _visiting:
+        raise RuntimeError(f"Detected recursive loop: {group_name} -> {orig_parser_name}")
+
+    try:
+        return _generate_parser(parser_name, source, _visiting=_visiting)
+    except ParserNotFoundError as e:
+        raise RuntimeError(f"Unable to find {parser_name} with error: {e}")
+
+
+def _generate_parser(name: str, source: Source, recursive=True, _visiting=None):
+    """
+    Generates parser for given name.
+
+    :param str name: Name of parser or parser group.
+    :param Source source: Source object containing parser.
+    :param bool recursive: Recursively generate listed sub parsers.
+        (otherwise only top level parsers will be produced)
+    :param _visiting: Used internally for recursive loop detection.
+
+    :returns: Either a Dispatcher object for a group of parsers or a Parser class.
+
+    :raises ParserNotFound: If parser could not be found.
+    """
+    if _visiting is None:
+        _visiting = set()
+
+    _visiting.add((name, source.name))
+
+    try:
+        # First check if parser name is a parser group or alias.
+        config_value = source.config[name]
+    except KeyError:
+        klass = _import_parser(name, source)
+        _visiting.remove((name, source.name))
+        return klass
+
+    # If value is a string, this is an alias.
+    if isinstance(config_value, str):
+        parser = _generate_parser_aux(config_value, name, source, _visiting)
+        parser.name = name
+        _visiting.remove((name, source.name))
+        return parser
+
+    # Otherwise, instantiate a mwcp.Dispatcher class for the parser group.
+    options = dict(config_value)
+    group_name = name
+    parser_names = options.pop("parsers")
+    sub_parsers = []
+    if recursive:
+        for parser_name in parser_names:
+            sub_parsers.append(_generate_parser_aux(parser_name, group_name, source, _visiting))
+
+    # Dereference default parser.
+    default = options.pop("default", None)
+    if default and recursive:
+        options["default"] = _generate_parser_aux(default, group_name, source, _visiting)
+
+    parser = Dispatcher(group_name, source.name, parsers=sub_parsers, **options)
+    logger.debug(f"Created parser group: {parser!r}")
+    _visiting.remove((name, source.name))
+    return parser
+
+
+def _import_all_modules(package):
+    """Recursively imports all modules from a given python package or directory."""
+    for _, name, is_pkg in pkgutil.walk_packages(package.__path__):
+        full_name = f"{package.__name__}.{name}"
+        module = importlib.import_module(full_name)
+        if is_pkg:
+            _import_all_modules(module)
+
+
+def iter_parsers(name: str = None, source: str = None, config_only=True, _recursive=True):
+    """
+    Iterates all registered parsers.
+
+    :param str name: Filters parser based on a particular name. (":" notation is also supported)
+    :param str source: Filters parser based on a particular source name.
+                       (source name is either the name of a python package or path to local directory)
+    :param bool config_only: Whether to only include parsers listed in the parser configuration file.
+                             (ie. ignore component parsers like "Foo.Implant")
+    :param bool _recursive: Whether to generate sub parsers.
+        (This is used internally, don't change it unless you know what you are doing)
+
+    :yields: tuple containing: (Source tuple, parser)
+
+    :raises ValueError: If a parser name or source could not be found.
+    """
+    global _sources
+
+    if name and not source:
+        # If name is using ":" notation, assume it is being organized by "source_name:parser_name"
+        # (os.path.basename is necessary in-case source is a file path containing ":"'s)
+        orig_name = name
+        _, _, name = os.path.basename(name).rpartition(":")
+        source = orig_name[: -(len(name) + 1)]
+    default_source = get_default_source()
+
+    if source:
+        sources = [get_source(source)]
+    elif default_source:
+        sources = [default_source]
+    else:
+        sources = get_sources()
+
+    for source in sources:
+        # Find list of parser names to generate
+        if name:
+            try:
+                parser = _generate_parser(name, source, recursive=_recursive)
+                yield source, parser
+            except ParserNotFoundError as e:
+                logger.debug(f"[{source.name}] {e}")
+                # Parser couldn't be found for this source.
+                continue
+        else:
+            # If parser name is not provided provide all parsers from the given source.
+            for parser_name in source.config.keys():
+                parser = _generate_parser(parser_name, source, recursive=_recursive)
+                yield source, parser
+
+            # Also list all the component parsers if requested.
+            if not config_only:
+                _import_all_modules(source.package)
+                package_prefix = source.package.__name__ + "."
+                for klass in set(Parser.iter_subclasses()):
+                    # Ignore classes without DESCRIPTIONS since they are usually base classes.
+                    if klass.DESCRIPTION and klass.__module__.startswith(package_prefix):
+                        parser_name = f"{klass.__module__[len(package_prefix):]}.{klass.__name__}"
+                        klass.name = parser_name
+                        yield source, klass
+
+
+def get_parser_descriptions(name=None, source=None, config_only=True):
+    """
+    Retrieve list of parser descriptions
+
+    :param str name: Filters parser based on a particular name. (":" notation is also supported)
+    :param str source: Filters parser based on a particular source.
+                       (source is either the name of a python package or path to local directory)
+    :param bool config_only: Whether to only include parsers listed in the parser configuration file.
+                             (ie. ignore component parsers like "Foo.Implant")
+
+    Returns list of tuples per parser. Tuple contains parser name, author, and description.
+    """
+    descriptions = []
+    for _source, parser in iter_parsers(name=name, source=source, config_only=config_only, _recursive=False):
+        descriptions.append(ParserInfo(parser.name, _source.name, parser.AUTHOR, parser.DESCRIPTION))
+    return sorted(descriptions, key=lambda e: tuple(sub.lower() for sub in e))  # Case-insensitive sorting.
```

### Comparing `mwcp-3.8.0/mwcp/report.py` & `mwcp-3.9.0/mwcp/report.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,940 +1,949 @@
-"""
-Interface for Report class.
-"""
-import base64
-import collections
-import io
-import json
-import logging
-import pathlib
-import re
-import warnings
-from copy import deepcopy
-from typing import Union, Iterable, Optional, Type, Tuple, List, Callable, TypeVar
-
-import pandas
-from anytree import RenderTree
-
-import mwcp
-from mwcp import metadata, FileObject
-from mwcp.metadata import Report as ReportModel, Metadata, File
-from mwcp.report_writers import DataFrameWriter, SimpleTextWriter, MarkdownWriter, HTMLWriter
-from mwcp.stix.report_writer import STIXWriter
-from mwcp.utils import logutil
-from mwcp.utils.stringutils import convert_to_unicode, sanitize_filename
-
-logger = logging.getLogger(__name__)
-
-
-# Maps legacy field names to their metadata.Element or helper function.
-METADATA_MAP = {
-    "address": metadata.Address,
-    "base16_alphabet": metadata.Base16Alphabet,
-    "base32_alphabet": metadata.Base32Alphabet,
-    "base64_alphabet": metadata.Base64Alphabet,
-    "c2_address": metadata.C2Address,
-    "c2_socketaddress": metadata.C2SocketAddress,
-    "c2_url": metadata.C2URL,
-    "credential": metadata.Credential,
-    "directory": metadata.Directory,
-    "email_address": metadata.EmailAddress,
-    "event": metadata.Event,
-    "filename": metadata.FileName,
-    "filepath": metadata.FilePath,
-    "ftp": metadata.FTP,
-    "guid": metadata.UUIDLegacy,
-    "injectionprocess": metadata.InjectionProcess,
-    "interval": metadata.IntervalLegacy,
-    "key": metadata.EncryptionKeyLegacy,
-    "listenport": metadata.ListenPort,
-    "missionid": metadata.MissionID,
-    "mutex": metadata.Mutex,
-    "other": metadata.Other,
-    "outputfile": metadata.File,
-    "password": metadata.Password,
-    "pipe": metadata.Pipe,
-    "port": metadata.Port,
-    "proxy": metadata.Proxy,
-    "proxy_socketaddress": metadata.ProxySocketAddress,
-    "proxy_address": metadata.ProxyAddress,
-    "registrydata": metadata.RegistryData,
-    "registrypath": metadata.RegistryPath,
-    "registrypathdata": metadata.RegistryPathData,
-    "rsa_private_key": metadata.RSAPrivateKey,
-    "rsa_public_key": metadata.RSAPublicKey,
-    "service": metadata.Service,
-    "servicedescription": metadata.ServiceDescription,
-    "servicedisplayname": metadata.ServiceDisplayName,
-    "servicedll": metadata.ServiceDLL,
-    "serviceimage": metadata.ServiceImage,
-    "servicename": metadata.ServiceName,
-    "socketaddress": metadata.SocketAddress,
-    "ssl_cert_sha1": metadata.SSLCertSHA1,
-    "url": metadata.URL,
-    "urlpath": metadata.URLPath,
-    "useragent": metadata.UserAgent,
-    "username": metadata.Username,
-    "version": metadata.Version,
-}
-
-
-LogRecord = collections.namedtuple("LogRecord", ["source", "level", "message"])
-
-
-class ReportLogHandler(logging.Handler):
-    """
-    Custom logging handler used to record log message into the generated Report.
-    """
-
-    def __init__(self, report: "Report"):
-        super().__init__()
-        self._report = report
-
-    def emit(self, record):
-        message = self.format(record)
-        self._report._logs.append(LogRecord(self._report._current_file, record.levelno, message))
-
-
-T = TypeVar("T")
-
-
-class Report:
-    """
-    Interface for building and accessing reportable information during parsing.
-
-    :param input_file: The original input file that started the parsing. (The root file)
-    :param parser: The name of the parser used for parsing.
-    :param include_file_data: Whether to include file data in the generated report.
-        If disabled, only the file path, description, and md5 will be included.
-    :param prefix_output_files: Whether to include a prefix of the first 5 characters
-        of the md5 on output files. This is to help avoid overwriting multiple
-        output files with the same name.
-    :param include_logs: Whether to include error and debug logs in the generated report.
-    :param log_level: If including logs, the logging level to be collected.
-        (Defaults to currently set effective log level)
-    :param log_filter: If including logs, this can be used to pass in a custom filter for the logs.
-        Should be a valid argument for logging.Handler.addFilter()
-    :param external_strings_report: Whether to output reported DecodedString elements into a
-        separate strings report.
-    """
-
-    def __init__(
-            self,
-            input_file: mwcp.FileObject = None,
-            parser: str = None,
-            include_logs: bool = True,
-            include_file_data: bool = False,
-            prefix_output_files: bool = True,
-            output_directory: Union[pathlib.Path, str] = None,
-            log_level: int = None,
-            log_filter: logging.Filter = None,
-            external_strings_report: bool = False,
-    ):
-        if output_directory:
-            output_directory = pathlib.Path(output_directory)
-            output_directory.mkdir(exist_ok=True)
-        self._output_directory = output_directory
-        self._write_output_files = bool(output_directory)
-
-        self._include_logs = include_logs
-        self._include_file_data = include_file_data
-        self._prefix_output_files = prefix_output_files
-        self._external_strings_report = external_strings_report
-
-        self.input_file = input_file
-        self.parser = parser
-        self.tags = set()
-        # Holds logs per file. (This is used by the ReportLogHandler)
-        self._logs: List[LogRecord] = []
-        # Holds metadata per file.
-        self._metadata = collections.defaultdict(list)
-        self._current_file = input_file  # type: FileObject
-        self._history = [input_file]  # type: List[FileObject]
-        self.parsed_files = {}
-        self.finalized = False
-
-        # Setup a log handler to add errors and debug messages to the report.
-        if include_logs:
-            log_handler = ReportLogHandler(self)
-            logging.root.addHandler(log_handler)
-            # Setup a simple format that doesn't contain any runtime variables.
-            log_handler.addFilter(logutil.LevelCharFilter())
-            log_handler.setFormatter(logging.Formatter("[%(level_char)s] %(message)s"))
-            if log_level is not None:
-                log_handler.setLevel(log_level)
-            if log_filter is not None:
-                log_handler.addFilter(log_filter)
-            self._log_handler = log_handler
-        else:
-            self._log_handler = None
-
-    def __enter__(self):
-        return self
-
-    def __exit__(self, exc_type, exc_val, exc_tb):
-        self.finalize()
-
-    def _insert_into_other(self, metadata_dict: dict, key: str, value):
-        """
-        Handles inserting the given key/value pair into the other dictionary
-        based on legacy logic.
-
-        TODO: Remove this when we remove .metadata
-        """
-        other_dict = metadata_dict["other"]
-        if key in other_dict:
-            # this key already exists, we don't want to clobber so
-            # we turn into list?
-            existing_value = other_dict[key]
-            if isinstance(existing_value, list):
-                if value not in existing_value:
-                    existing_value.append(value)
-            elif value != existing_value:
-                other_dict[key] = [existing_value, value]
-        else:
-            # normal insert of single value
-            other_dict[key] = value
-
-    def get_logs(self, source: Optional[FileObject] = None, errors_only=False) -> List[str]:
-        """
-        Gets log messages.
-
-        :param source: Filters only logs from given source file.
-        :param errors_only: Filters only error messages.
-        :return: list of log messages
-        """
-        return [
-            record.message
-            for record in self._logs
-            if (
-                (not source or record.source == source)
-                and (not errors_only or record.level > logging.WARNING)
-            )
-        ]
-
-    @property
-    def logs(self) -> List[str]:
-        """
-        All logs within this report.
-        """
-        return self.get_logs()
-
-    @property
-    def errors(self) -> List[str]:
-        """
-        All error logs within this report.
-        """
-        return self.get_logs(errors_only=True)
-
-    @property
-    def metadata(self) -> dict:
-        """
-        Converts our metadata elements back into the legacy format described in fields.json
-
-        NOTE: This is here for backwards compatibility with the old json format.
-            Please update your code to use the new schema found in as_dict() or as_json()
-        """
-        warnings.warn(
-            "metadata attributes is deprecated. Please access report data using "
-            "as_dict(), as_json(), as_text(), etc.",
-            DeprecationWarning
-        )
-        results = collections.defaultdict(list)
-        # noinspection PyTypeChecker
-        results["other"] = {}  # "other" is the only field that is not a list.
-        for element in self:
-            if isinstance(element, metadata.Path2):
-                if element.is_dir:
-                    results["directory"].append(element.path or element.directory_path)
-                else:
-                    if element.path:
-                        results["filepath"].append(element.path)
-                    if element.name:
-                        results["filename"].append(element.name)
-                    if element.directory_path:
-                        results["directory"].append(element.directory_path)
-
-            elif isinstance(element, metadata.Socket):
-                if element.address:
-                    results["address"].append(element.address)
-                    if element.c2:
-                        results["c2_address"].append(element.address)
-
-                socket_address = [
-                    element.address or "",
-                    str(element.port) if element.port is not None else "",
-                    element.network_protocol or "",
-                ]
-                if element.port is not None:
-                    # noinspection PyDataclass
-                    if not element._from_port:  # user explicitly specified a Socket
-                        results["socketaddress"].append(socket_address)
-                        if element.c2:
-                            results["c2_socketaddress"].append(socket_address)
-
-                    port = socket_address[1:]
-                    if element.listen:
-                        results["listenport"].append(port)
-                    else:
-                        results["port"].append(port)
-
-            elif isinstance(element, metadata.Alphabet):
-                if element.base in (16, 32, 64):
-                    results[f"base{element.base}_alphabet"].append(element.alphabet)
-                else:
-                    # noinspection PyTypeChecker
-                    self._insert_into_other(
-                        results, f"base{element.base}_alphabet", element.alphabet)
-
-            elif isinstance(element, metadata.Command):
-                self._insert_into_other(results, "command", element.value)
-
-            elif isinstance(element, metadata.CryptoAddress):
-                symbol = (element.symbol or "crypto").lower()
-                self._insert_into_other(results, f"{symbol}_address", element.address)
-
-            elif isinstance(element, metadata.URL):
-                if element.url:
-                    results["url"].append(element.url)
-                    if element.socket and element.socket.c2:
-                        results["c2_url"].append(element.url)
-                if element.path:
-                    results["urlpath"].append(element.path)
-                if element.application_protocol == "ftp":
-                    credential = element.credential
-                    # If the credential wasn't included, they probably didn't mean for the url to
-                    # be reported as "ftp" under the legacy schema.
-                    if credential:
-                        ftp = [credential.username, credential.password, element.url]
-                        results["ftp"].append(ftp)
-                if "proxy" in element.tags:
-                    if element.credential and element.socket:
-                        results["proxy"].append([
-                            element.credential.username,
-                            element.credential.password,
-                            element.socket.address or "",
-                            str(element.socket.port),
-                            (element.socket and element.socket.network_protocol) or "",
-                        ])
-                    if element.socket:
-                        if element.socket.address:
-                            results["proxy_address"].append(element.socket.address)
-                        if element.socket.port is not None:
-                            results["proxy_socketaddress"].append([
-                                element.socket.address,
-                                str(element.socket.port),
-                                element.socket.network_protocol,
-                            ])
-
-            elif isinstance(element, metadata.Credential):
-                if element.username and element.password:
-                    results["credential"].append([element.username, element.password])
-                if element.username:
-                    results["username"].append(element.username)
-                if element.password:
-                    results["password"].append(element.password)
-
-            elif isinstance(element, metadata.EmailAddress):
-                results["email_address"].append(str(element.value))
-
-            elif isinstance(element, metadata.Event):
-                results["event"].append(str(element.value))
-
-            elif isinstance(element, (metadata.UUID, metadata.UUIDLegacy)):
-                results["guid"].append(str(element.value))
-
-            elif isinstance(element, metadata.InjectionProcess):
-                results["injectionprocess"].append(str(element.value))
-
-            elif isinstance(element, (metadata.Interval, metadata.IntervalLegacy)):
-                results["interval"].append(str(element.value))
-
-            elif isinstance(element, metadata.EncryptionKey):
-                key = element.key
-                if element._raw_string:
-                    key = key.decode("utf-8")
-                else:
-                    # Display key as hex string for old display.
-                    key = f"0x{key.hex()}"
-                results["key"].append(key)
-                if element.algorithm:
-                    # noinspection PyTypeChecker
-                    self._insert_into_other(results, f"{element.algorithm}_key", key)
-
-            elif isinstance(element, metadata.MissionID):
-                results["missionid"].append(str(element.value))
-
-            elif isinstance(element, metadata.Mutex):
-                results["mutex"].append(str(element.value))
-
-            elif isinstance(element, metadata.Other):
-                value = element.value
-                if isinstance(value, bytes):
-                    value = value.decode("latin1")
-                # noinspection PyTypeChecker
-                self._insert_into_other(results, element.key, value)
-
-            elif isinstance(element, metadata.Pipe):
-                results["pipe"].append(str(element.value))
-
-            elif isinstance(element, metadata.Registry2):
-                if element.data:
-                    results["registrydata"].append(str(element.data))
-                if element.key or element.value:
-                    path = "\\".join([element.key or "", element.value or ""])
-                    results["registrypath"].append(path)
-                    if element.data:
-                        results["registrypathdata"].append([path, str(element.data)])
-
-            elif isinstance(element, metadata.RSAPrivateKey):
-                results["rsa_private_key"].append([
-                    element.public_exponent and hex(element.public_exponent),
-                    element.modulus and hex(element.modulus),
-                    element.private_exponent and hex(element.private_exponent),
-                    element.p and hex(element.p),
-                    element.q and hex(element.q),
-                    element.d_mod_p1 and hex(element.d_mod_p1),
-                    element.d_mod_q1 and hex(element.d_mod_q1),
-                    element.q_inv_mod_p and hex(element.q_inv_mod_p),
-                ])
-
-            elif isinstance(element, metadata.RSAPublicKey):
-                results["rsa_public_key"].append([
-                    element.public_exponent and hex(element.public_exponent),
-                    element.modulus and hex(element.modulus),
-                ])
-
-            elif isinstance(element, metadata.Service):
-                service = [
-                    element.name,
-                    element.display_name,
-                    element.description,
-                    element.image,
-                    element.dll,
-                ]
-                if sum(x is not None for x in service) > 1:
-                    results["service"].append(service)
-                if element.description:
-                    results["servicedescription"].append(element.description)
-                if element.display_name:
-                    results["servicedisplayname"].append(element.display_name)
-                if element.dll:
-                    results["servicedll"].append(element.dll)
-                if element.image:
-                    results["serviceimage"].append(element.image)
-                if element.name:
-                    results["servicename"].append(element.name)
-
-            elif isinstance(element, metadata.SSLCertSHA1):
-                results["ssl_cert_sha1"].append(str(element.value))
-
-            elif isinstance(element, metadata.UserAgent):
-                results["useragent"].append(str(element.value))
-
-            elif isinstance(element, metadata.Version):
-                results["version"].append(str(element.value))
-
-            elif isinstance(element, metadata.File):
-                output_file = [element.name, element.description, element.md5]
-                if self._include_file_data and element.data:
-                    output_file.append(base64.b64encode(element.data).decode())
-                results["outputfile"].append(output_file)
-
-            elif isinstance(element, metadata.DecodedString):
-                self._insert_into_other(results, "decoded_string", element.value)
-
-        # None is not a thing in the legacy schema.
-        # Replace all None's with empty strings.
-        for key, value in results.items():
-            if isinstance(value, list):
-                new_value = []
-                for entry in value:
-                    if entry is None:
-                        entry = ""
-                    elif isinstance(entry, list):
-                        entry = [x if x is not None else "" for x in entry]
-                    new_value.append(entry)
-                results[key] = new_value
-
-        if self.logs and self._include_logs:
-            results["debug"] = self.logs
-
-        # Remove "other" if we didn't end up using it.
-        if not results["other"]:
-            del results["other"]
-
-        return dict(results)
-
-    def _build_report_model(self, source: FileObject = None) -> ReportModel:
-        """
-        Generate metadata.Report object using currently added metadata.
-        """
-        input_file = source or self.input_file
-        metadata_entries = self.get(source=source)
-        report_model = metadata.Report(
-            input_file=metadata.File.from_file_object(input_file) if input_file else None,
-            parser=(input_file.parser and input_file.parser.name) if source else self.parser,
-            errors=self.get_logs(source, errors_only=True),
-            logs=self.get_logs(source),
-            metadata=deepcopy(metadata_entries),
-        ).add_tag(*self.tags)
-        report_model.validate()
-
-        # Remove DecodedString element if external strings report was requested.
-        # (These are included as a supplemental file in the report.)
-        if self._external_strings_report:
-            report_model.metadata = [
-                element for element in report_model.metadata if not isinstance(element, metadata.DecodedString)
-            ]
-
-        # Remove raw file data from report model if requested.
-        if not self._include_file_data:
-            if report_model.input_file:
-                report_model.input_file.data = None
-            for element in report_model.metadata:
-                if isinstance(element, metadata.File):
-                    element.data = None
-
-        return report_model
-
-    @property
-    def _report_model(self) -> Union[ReportModel, List[ReportModel]]:
-        """
-        Returns the report model based on currently added metadata.
-        Results are merged.
-        """
-        return self._build_report_model()
-
-    @property
-    def _report_models(self) -> List[ReportModel]:
-        """
-        Returns a list of report models split between each source file.
-        """
-        return [
-            self._build_report_model(source=file_object)
-            for file_object in sorted(self._metadata.keys(), key=lambda fo: self._history.index(fo))
-        ]
-
-    def as_dict(self) -> dict:
-        """
-        Returns dictionary representation of the report (merged).
-        """
-        return self._report_model.as_dict()
-
-    def as_list(self) -> List[dict]:
-        """
-        Returns a list of dictionaries representing the report split by
-        source file.
-        """
-        return [report_model.as_dict() for report_model in self._report_models]
-
-    def as_dict_legacy(self, include_filename=False) -> dict:
-        """
-        Returns dictionary representation of the report. (LEGACY schema)
-        """
-        result = self.metadata
-        # Include input file information.
-        # (originally part of _parse_file in cli)
-        if include_filename:
-            input_file = metadata.File.from_file_object(self.input_file)
-            result["inputfilename"] = input_file.file_path
-            result["md5"] = input_file.md5
-            result["sha1"] = input_file.sha1
-            result["sha256"] = input_file.sha256
-            result["parser"] = self.parser
-            if input_file.compile_time:
-                result["compiletime"] = input_file.compile_time
-
-        if self.errors:
-            result["errors"] = self.errors
-
-        return result
-
-    def as_json(self, split=False) -> str:
-        """
-        Returns json representation of the report.
-        """
-        if split:
-            return json.dumps(
-                [report_model.as_json_dict() for report_model in self._report_models]
-            )
-        else:
-            return self._report_model.as_json()
-
-    def as_json_dict(self, split=False):
-        """
-        Jsonifies the element and then loads it back as a dictionary.
-        NOTE: This is different from .as_dict() because things like bytes
-        will be converted to a base64 encoded string.
-        """
-        if split:
-            return [report_model.as_json_dict() for report_model in self._report_models]
-        else:
-            return self._report_model.as_json_dict()
-
-    def as_json_legacy(self, include_filename=False) -> str:
-        """
-        Returns json representation of the report. (LEGACY schema)
-        """
-        return json.dumps(self.as_dict_legacy(include_filename=include_filename), indent=4)
-
-    def as_stix(self, writer: STIXWriter):
-        """
-        Updates the reporter with STIX content
-        """
-        for report_model in self._report_models:
-            writer.write(report_model)
-
-    def as_text(self, format="simple", split=False) -> Optional[str]:
-        """
-        Returns a custom text representation of the report.
-
-        :param format: Text format to use.
-        :param split: Whether to split up metadata results by file or to merge all results
-            under the initial input file.
-        """
-        format_map = {
-            "simple": SimpleTextWriter,
-            "markdown": MarkdownWriter,
-            "html": HTMLWriter,
-        }
-        try:
-            writer_class = format_map[format]
-        except KeyError:
-            raise ValueError(f"Invalid report format: {format}")
-
-        stream = io.StringIO()
-        with writer_class(stream) as writer:
-            if split:
-                for report_model in self._report_models:
-                    writer.write(report_model)
-            else:
-                writer.write(self._report_model)
-
-            # Write File tree
-            if self.input_file:
-                writer.h1("File Tree")
-                writer.code_block(self.file_tree())
-
-        return stream.getvalue()
-
-    def as_markdown(self) -> str:
-        return self.as_text("markdown")
-
-    def as_html(self) -> str:
-        return self.as_text("html")
-
-    def as_dataframe(self, split=False) -> pandas.DataFrame:
-        if split:
-            return pandas.concat([
-                DataFrameWriter().write(report_model)
-                for report_model in self._report_models
-            ])
-        else:
-            return DataFrameWriter().write(self._report_model)
-
-    def as_csv(self) -> str:
-        return self.as_dataframe().to_csv()
-
-    def file_tree(self) -> str:
-        """
-        Returns a tree representing the files produced per....
-        (this should just be part of text)
-        :return:
-        """
-        return str(RenderTree(self.input_file))
-
-    def strings(self, source: Union[None, str, FileObject] = None) -> List[str]:
-        """
-        Returns reported decoded string values.
-        """
-        return [element.value for element in self.iter(metadata.DecodedString, source=source)]
-
-    def add_tag(self, *tags: Iterable[str]) -> "Report":
-        """
-        Adds global tag(s) to the report.
-        NOTE: Tags added in this way are included in the overall report and aren't directed towards
-        any specific file (including the original input file).
-
-        :param tags: One or more tags to add to the metadata.
-        :returns: Report object to make it chainable.
-        """
-        for tag in tags:
-            self.tags.add(tag)
-        return self
-
-    def _get_metadata_element(self, field_name: str) -> Union[Metadata, Callable]:
-        """
-        Returns an appropriate metadata.Element or helper function based on given legacy field name.
-
-        :param field_name: legacy field name
-        :return: Either a metadata.Element or helper function to generate a metadata.Element.
-        """
-        try:
-            return METADATA_MAP[field_name]
-        except KeyError:
-            raise KeyError(f"Invalid field name: {field_name}")
-
-    def _convert_metadata_value(self, field_name: str, value):
-        """
-        Does any necessary conversion from legacy to new format.
-        This is here for field conversions that we want to do to keep backwards compatibility,
-        but we want to fail otherwise.
-
-        :param field_name: Field name value comes from.
-        :param value: Single value passed in for value.
-        :return: New converted value.
-        """
-        # Ignore dictionaries for now (the other).
-        if isinstance(value, dict):
-            return value
-
-        if isinstance(value, (list, tuple)):
-            return [self._convert_metadata_value(field_name, x) for x in value]
-
-        # Legacy metadata values did not support bytes at all. Must be strings.
-        if isinstance(value, bytes):
-            value = value.decode("latin1")
-
-        if value == "":
-            return None
-
-        # Convert value for fields that expect hex strings.
-        if (isinstance(value, str)
-                and field_name in ("rsa_private_key", "rsa_public_key")
-                and (value.startswith("0x") or re.search("[A-Fa-f]", value))
-        ):
-            return int(value, 16)
-
-        return value
-
-    def add(self, element: Metadata):
-        """
-        Report a metadata item.
-        Supports both the new and old way of reporting.
-
-        If element fails to validate, a error log message will be displayed
-        instead of throwing an exception. This is so a parser won't completely stop
-        on the first sign a new variant is partially breaking the parser.
-
-        :param element: metadata.Element type to add.
-        :raises mwcp.ValidationError: If given element is not valid.
-        """
-        if self.finalized:
-            raise RuntimeError("Report has already been finalized. Metadata can no longer be added.")
-
-        metadata_list = self._metadata[self._current_file]
-        if element not in metadata_list:
-            element.validate()
-            metadata_list.append(element)
-            element.post_processing(self)
-
-    def set_file(self, file_object: FileObject):
-        """
-        Sets the file currently being parsed.
-        """
-        self._current_file = file_object
-        if file_object not in self._history:
-            self._history.append(file_object)
-
-    def add_metadata(self, field_name_or_element: Union[str, Metadata], value=None):
-        """
-        Report a metadata item.
-        Supports both the new and old way of reporting.
-
-        :param field_name_or_element: Either a metadata.Element or field name for value.
-        :param value: string or list specifying the value of the metadata.
-        :return:
-        """
-        warnings.warn(
-            ".add_metadata() is deprecated in favor of .add() which only supports the new metadata elements.",
-            DeprecationWarning
-        )
-        if isinstance(field_name_or_element, metadata.Metadata):
-            self.add(field_name_or_element)
-            return
-
-        # Convert legacy metadata format into new format using metadata Element objects.
-
-        field_name = convert_to_unicode(field_name_or_element)
-        if value is None or all(not _value for _value in value):
-            logger.debug(f"No values provided for {field_name}, skipping")
-            return
-
-        if field_name == "debug":
-            self.logs.append(value)
-            return
-
-        element_class = self._get_metadata_element(field_name)
-        value = self._convert_metadata_value(field_name, value)
-        if isinstance(value, (list, tuple)):
-            self.add(element_class(*value))
-        elif field_name == "other":
-            for key, _value in value.items():
-                self.add(metadata.Other(key, _value))
-        else:
-            self.add(element_class(value))
-
-    def output_file(self, data: bytes, filename: str = None, description: str = None):
-        warnings.warn(
-            "output_file() is deprecated. Please add a metadata.File object to add() instead.",
-            DeprecationWarning
-        )
-        residual_file = metadata.File(name=filename, description=description, data=data)
-        self.add(residual_file)
-        # In order to be backwards compatible, we have to write out the file here, so we can
-        # return a file path.
-        return self._write_file(residual_file)
-
-    def _write_file(self, file: File) -> Optional[str]:
-        """
-        Writes out the given File metadata object and returns the file path to the written file
-        or None on failure.
-        """
-        if not self._write_output_files:
-            return
-
-        # Create a safe filename that won't have any name collisions.
-        safe_filename = sanitize_filename(file.name)
-        if self._prefix_output_files:
-            safe_filename = f"{file.md5[:5]}_{safe_filename}"
-        full_path = self._output_directory / safe_filename
-
-        try:
-            # TODO: Should we attach the real file path?
-            full_path.write_bytes(file.data)
-            logger.debug(f"Output file: {full_path}")
-            full_path = str(full_path)
-            file.file_path = full_path
-            return full_path
-        except Exception as e:
-            logger.error(f"Failed to write output file {full_path} with error: {e}")
-            return
-
-    def finalize(self):
-        """
-        This should be called after parsing is complete.
-        This performs post-processing tasks such as validation and cleaning up the log handler.
-        """
-        # If external string report enabled, create supplemental file containing
-        # reported DecodedString elements.
-        if self._external_strings_report:
-            for file_object, metadata_list in self._metadata.items():
-                string_report = metadata.StringReport(
-                    file=metadata.File.from_file_object(file_object),
-                    strings=[element for element in metadata_list if isinstance(element, metadata.DecodedString)]
-                )
-                string_report.file.data = None
-                if string_report.strings:
-                    self.add(metadata.SupplementalFile(
-                        name=f"{file_object.name}_strings.json",
-                        description=f"Decoded Strings",
-                        data=string_report.as_json().encode("utf8"),
-                    ))
-                    self.add(metadata.SupplementalFile(
-                        name=f"{file_object.name}_strings.txt",
-                        description=f"Decoded Strings",
-                        data="\n".join(string.value for string in string_report.strings).encode("utf8")
-                    ))
-
-        # TODO: move this to post_processing of File?
-        # Write out residual files to file system if requested.
-        if self._write_output_files:
-            for residual_file in self.iter(metadata.File):
-                self._write_file(residual_file)
-
-        # Remove log handler.
-        if self._log_handler:
-            logging.root.removeHandler(self._log_handler)
-
-        self.finalized = True
-
-    def __iter__(self) -> Iterable[Metadata]:
-        """
-        Iterates the added metadata elements found within the Report.
-        """
-        yield from self.iter()
-
-    def iter(
-            self,
-            *element_type: Type[T],
-            source: Union[None, str, FileObject] = None
-    ) -> Iterable[T]:
-        """
-        Iterates and returns all element instance of the given metadata Element class
-        or tuple of Element classes.
-
-        Iterates all elements if an element_type and source_file is not provided.
-
-        e.g.
-            for residual_file in report.iter(metadata.File):
-                ...
-
-            for element in report.iter(metadata.URL, metadata.Socket):
-                ...
-
-            for residual_file in report.iter(metadata.File, source="5d41402abc4b2a76b9719d911017c592"):
-                ...
-
-            for element in report.iter(metadata.URL, metadata.Socket, source="5d41402abc4b2a76b9719d911017c592"):
-                ...
-        """
-        if source:
-            if isinstance(source, str):
-                for file_object in self._metadata.keys():
-                    if file_object.md5 == source:
-                        source = file_object
-                        break
-                else:
-                    raise ValueError(f"Unable to find file with md5: {source}")
-            metadata_lists = [self._metadata[source]]
-        else:
-            metadata_lists = self._metadata.values()
-
-        yielded = []
-        for metadata_list in metadata_lists:
-            for element in metadata_list:
-                for _element in element.elements():
-                    if not element_type or isinstance(_element, element_type):
-                        # Metadata elements are not hashable, so we need to check equality of each.
-                        if not any(_element == yielded_element for yielded_element in yielded):
-                            yielded.append(_element)
-                            yield _element
-
-    def get(
-            self,
-            *element_type: Type[T],
-            source: Union[None, str, FileObject] = None
-    ) -> List[T]:
-        """
-        Same as .iter(), but wraps results in a list for you.
-
-        e.g.
-            residual_files = report.get(metadata.File)
-            residual_files = report.get(metadata.File, source="5d41402abc4b2a76b9719d911017c592")
-            elements = report.get(metadata.URL, metadata.Socket)
-            elements = report.get(metadata.URL, metadata.Socket, source="5d41402abc4b2a76b9719d911017c592")
-        """
-        return list(self.iter(*element_type, source=source))
-
-    def iter_tagged(self, *tags) -> Iterable[Metadata]:
-        """
-        Iterates metadata elements with specific tags.
-
-        :param *tags: Name of tags to get. Gets all elements that were tagged otherwise.
-        """
-        # If no tags provided, just get all elements that are tagged.
-        if not tags:
-            for element in self:
-                if element.tags:
-                    yield element
-        else:
-            for element in self:
-                if any(tag in element.tags for tag in tags):
-                    yield element
-
-    def get_tagged(self, *tags) -> List[Metadata]:
-        """
-        Same as .iter_tagged(), but wraps the results in a list for you.
-        """
-        return list(self.iter_tagged(*tags))
+"""
+Interface for Report class.
+"""
+import base64
+import collections
+import io
+import json
+import logging
+import pathlib
+import re
+import warnings
+from copy import deepcopy
+from typing import Union, Iterable, Optional, Type, Tuple, List, Callable, TypeVar
+
+import pandas
+from anytree import RenderTree
+
+import mwcp
+from mwcp import config, metadata, FileObject
+from mwcp.metadata import Report as ReportModel, Metadata, File
+from mwcp.report_writers import DataFrameWriter, SimpleTextWriter, MarkdownWriter, HTMLWriter
+from mwcp.stix.report_writer import STIXWriter
+from mwcp.utils import logutil
+from mwcp.utils.stringutils import convert_to_unicode, sanitize_filename
+
+logger = logging.getLogger(__name__)
+
+
+# Maps legacy field names to their metadata.Element or helper function.
+METADATA_MAP = {
+    "address": metadata.Address,
+    "base16_alphabet": metadata.Base16Alphabet,
+    "base32_alphabet": metadata.Base32Alphabet,
+    "base64_alphabet": metadata.Base64Alphabet,
+    "c2_address": metadata.C2Address,
+    "c2_socketaddress": metadata.C2SocketAddress,
+    "c2_url": metadata.C2URL,
+    "credential": metadata.Credential,
+    "directory": metadata.Directory,
+    "email_address": metadata.EmailAddress,
+    "event": metadata.Event,
+    "filename": metadata.FileName,
+    "filepath": metadata.FilePath,
+    "ftp": metadata.FTP,
+    "guid": metadata.UUIDLegacy,
+    "injectionprocess": metadata.InjectionProcess,
+    "interval": metadata.IntervalLegacy,
+    "key": metadata.EncryptionKeyLegacy,
+    "listenport": metadata.ListenPort,
+    "missionid": metadata.MissionID,
+    "mutex": metadata.Mutex,
+    "other": metadata.Other,
+    "outputfile": metadata.File,
+    "password": metadata.Password,
+    "pipe": metadata.Pipe,
+    "port": metadata.Port,
+    "proxy": metadata.Proxy,
+    "proxy_socketaddress": metadata.ProxySocketAddress,
+    "proxy_address": metadata.ProxyAddress,
+    "registrydata": metadata.RegistryData,
+    "registrypath": metadata.RegistryPath,
+    "registrypathdata": metadata.RegistryPathData,
+    "rsa_private_key": metadata.RSAPrivateKey,
+    "rsa_public_key": metadata.RSAPublicKey,
+    "service": metadata.Service,
+    "servicedescription": metadata.ServiceDescription,
+    "servicedisplayname": metadata.ServiceDisplayName,
+    "servicedll": metadata.ServiceDLL,
+    "serviceimage": metadata.ServiceImage,
+    "servicename": metadata.ServiceName,
+    "socketaddress": metadata.SocketAddress,
+    "ssl_cert_sha1": metadata.SSLCertSHA1,
+    "url": metadata.URL,
+    "urlpath": metadata.URLPath,
+    "useragent": metadata.UserAgent,
+    "username": metadata.Username,
+    "version": metadata.Version,
+}
+
+
+LogRecord = collections.namedtuple("LogRecord", ["source", "level", "message"])
+
+
+class ReportLogHandler(logging.Handler):
+    """
+    Custom logging handler used to record log message into the generated Report.
+    """
+
+    def __init__(self, report: "Report"):
+        super().__init__()
+        self._report = report
+
+    def emit(self, record):
+        message = self.format(record)
+        self._report._logs.append(LogRecord(self._report._current_file, record.levelno, message))
+
+
+T = TypeVar("T")
+
+
+class Report:
+    """
+    Interface for building and accessing reportable information during parsing.
+
+    :param input_file: The original input file that started the parsing. (The root file)
+    :param parser: The name of the parser used for parsing.
+    :param include_file_data: Whether to include file data in the generated report.
+        If disabled, only the file path, description, and md5 will be included.
+    :param prefix_output_files: Whether to include a prefix of the first 5 characters
+        of the md5 on output files. This is to help avoid overwriting multiple
+        output files with the same name.
+    :param include_logs: Whether to include error and debug logs in the generated report.
+    :param log_level: If including logs, the logging level to be collected.
+        (Defaults to currently set effective log level)
+    :param log_filter: If including logs, this can be used to pass in a custom filter for the logs.
+        Should be a valid argument for logging.Handler.addFilter()
+    :param external_strings_report: Whether to output reported DecodedString elements into a
+        separate strings report.
+    """
+
+    def __init__(
+            self,
+            input_file: mwcp.FileObject = None,
+            parser: str = None,
+            include_logs: bool = True,
+            include_file_data: bool = False,
+            prefix_output_files: bool = True,
+            output_directory: Union[pathlib.Path, str] = None,
+            log_level: int = None,
+            log_filter: logging.Filter = None,
+            external_strings_report: bool = False,
+    ):
+        if output_directory:
+            output_directory = pathlib.Path(output_directory)
+            output_directory.mkdir(exist_ok=True)
+        self._output_directory = output_directory
+        self._write_output_files = bool(output_directory)
+
+        self._include_logs = include_logs
+        self._include_file_data = include_file_data
+        self._prefix_output_files = prefix_output_files
+        self._external_strings_report = external_strings_report
+
+        self.input_file = input_file
+        self.parser = parser
+        self.tags = set()
+        # Holds logs per file. (This is used by the ReportLogHandler)
+        self._logs: List[LogRecord] = []
+        # Holds metadata per file.
+        self._metadata = collections.defaultdict(list)
+        self._current_file = input_file  # type: FileObject
+        self._history = [input_file]  # type: List[FileObject]
+        self.parsed_files = {}
+        self.finalized = False
+
+        # Setup a log handler to add errors and debug messages to the report.
+        if include_logs:
+            log_handler = ReportLogHandler(self)
+            logging.root.addHandler(log_handler)
+            # Setup a simple format that doesn't contain any runtime variables.
+            log_handler.addFilter(logutil.LevelCharFilter())
+            log_handler.setFormatter(logging.Formatter("[%(level_char)s] %(message)s"))
+            if log_level is not None:
+                log_handler.setLevel(log_level)
+            if log_filter is not None:
+                log_handler.addFilter(log_filter)
+            self._log_handler = log_handler
+        else:
+            self._log_handler = None
+
+    def __enter__(self):
+        return self
+
+    def __exit__(self, exc_type, exc_val, exc_tb):
+        self.finalize()
+
+    def _insert_into_other(self, metadata_dict: dict, key: str, value):
+        """
+        Handles inserting the given key/value pair into the other dictionary
+        based on legacy logic.
+
+        TODO: Remove this when we remove .metadata
+        """
+        other_dict = metadata_dict["other"]
+        if key in other_dict:
+            # this key already exists, we don't want to clobber so
+            # we turn into list?
+            existing_value = other_dict[key]
+            if isinstance(existing_value, list):
+                if value not in existing_value:
+                    existing_value.append(value)
+            elif value != existing_value:
+                other_dict[key] = [existing_value, value]
+        else:
+            # normal insert of single value
+            other_dict[key] = value
+
+    @property
+    def fields(self):
+        warnings.warn(
+            "Usage of the fields attribute is deprecated. ",
+            DeprecationWarning
+        )
+        with open(config.get("FIELDS_PATH"), "rb") as f:
+            return json.load(f)
+
+    def get_logs(self, source: Optional[FileObject] = None, errors_only=False) -> List[str]:
+        """
+        Gets log messages.
+
+        :param source: Filters only logs from given source file.
+        :param errors_only: Filters only error messages.
+        :return: list of log messages
+        """
+        return [
+            record.message
+            for record in self._logs
+            if (
+                (not source or record.source == source)
+                and (not errors_only or record.level > logging.WARNING)
+            )
+        ]
+
+    @property
+    def logs(self) -> List[str]:
+        """
+        All logs within this report.
+        """
+        return self.get_logs()
+
+    @property
+    def errors(self) -> List[str]:
+        """
+        All error logs within this report.
+        """
+        return self.get_logs(errors_only=True)
+
+    @property
+    def metadata(self) -> dict:
+        """
+        Converts our metadata elements back into the legacy format described in fields.json
+
+        NOTE: This is here for backwards compatibility with the old json format.
+            Please update your code to use the new schema found in as_dict() or as_json()
+        """
+        warnings.warn(
+            "metadata attributes is deprecated. Please access report data using "
+            "as_dict(), as_json(), as_text(), etc.",
+            DeprecationWarning
+        )
+        results = collections.defaultdict(list)
+        # noinspection PyTypeChecker
+        results["other"] = {}  # "other" is the only field that is not a list.
+        for element in self:
+            if isinstance(element, metadata.Path2):
+                if element.is_dir:
+                    results["directory"].append(element.path or element.directory_path)
+                else:
+                    if element.path:
+                        results["filepath"].append(element.path)
+                    if element.name:
+                        results["filename"].append(element.name)
+                    if element.directory_path:
+                        results["directory"].append(element.directory_path)
+
+            elif isinstance(element, metadata.Socket):
+                if element.address:
+                    results["address"].append(element.address)
+                    if element.c2:
+                        results["c2_address"].append(element.address)
+
+                socket_address = [
+                    element.address or "",
+                    str(element.port) if element.port is not None else "",
+                    element.network_protocol or "",
+                ]
+                if element.port is not None:
+                    # noinspection PyDataclass
+                    if not element._from_port:  # user explicitly specified a Socket
+                        results["socketaddress"].append(socket_address)
+                        if element.c2:
+                            results["c2_socketaddress"].append(socket_address)
+
+                    port = socket_address[1:]
+                    if element.listen:
+                        results["listenport"].append(port)
+                    else:
+                        results["port"].append(port)
+
+            elif isinstance(element, metadata.Alphabet):
+                if element.base in (16, 32, 64):
+                    results[f"base{element.base}_alphabet"].append(element.alphabet)
+                else:
+                    # noinspection PyTypeChecker
+                    self._insert_into_other(
+                        results, f"base{element.base}_alphabet", element.alphabet)
+
+            elif isinstance(element, metadata.Command):
+                self._insert_into_other(results, "command", element.value)
+
+            elif isinstance(element, metadata.CryptoAddress):
+                symbol = (element.symbol or "crypto").lower()
+                self._insert_into_other(results, f"{symbol}_address", element.address)
+
+            elif isinstance(element, metadata.URL):
+                if element.url:
+                    results["url"].append(element.url)
+                    if element.socket and element.socket.c2:
+                        results["c2_url"].append(element.url)
+                if element.path:
+                    results["urlpath"].append(element.path)
+                if element.application_protocol == "ftp":
+                    credential = element.credential
+                    # If the credential wasn't included, they probably didn't mean for the url to
+                    # be reported as "ftp" under the legacy schema.
+                    if credential:
+                        ftp = [credential.username, credential.password, element.url]
+                        results["ftp"].append(ftp)
+                if "proxy" in element.tags:
+                    if element.credential and element.socket:
+                        results["proxy"].append([
+                            element.credential.username,
+                            element.credential.password,
+                            element.socket.address or "",
+                            str(element.socket.port),
+                            (element.socket and element.socket.network_protocol) or "",
+                        ])
+                    if element.socket:
+                        if element.socket.address:
+                            results["proxy_address"].append(element.socket.address)
+                        if element.socket.port is not None:
+                            results["proxy_socketaddress"].append([
+                                element.socket.address,
+                                str(element.socket.port),
+                                element.socket.network_protocol,
+                            ])
+
+            elif isinstance(element, metadata.Credential):
+                if element.username and element.password:
+                    results["credential"].append([element.username, element.password])
+                if element.username:
+                    results["username"].append(element.username)
+                if element.password:
+                    results["password"].append(element.password)
+
+            elif isinstance(element, metadata.EmailAddress):
+                results["email_address"].append(str(element.value))
+
+            elif isinstance(element, metadata.Event):
+                results["event"].append(str(element.value))
+
+            elif isinstance(element, (metadata.UUID, metadata.UUIDLegacy)):
+                results["guid"].append(str(element.value))
+
+            elif isinstance(element, metadata.InjectionProcess):
+                results["injectionprocess"].append(str(element.value))
+
+            elif isinstance(element, (metadata.Interval, metadata.IntervalLegacy)):
+                results["interval"].append(str(element.value))
+
+            elif isinstance(element, metadata.EncryptionKey):
+                key = element.key
+                if element._raw_string:
+                    key = key.decode("utf-8")
+                else:
+                    # Display key as hex string for old display.
+                    key = f"0x{key.hex()}"
+                results["key"].append(key)
+                if element.algorithm:
+                    # noinspection PyTypeChecker
+                    self._insert_into_other(results, f"{element.algorithm}_key", key)
+
+            elif isinstance(element, metadata.MissionID):
+                results["missionid"].append(str(element.value))
+
+            elif isinstance(element, metadata.Mutex):
+                results["mutex"].append(str(element.value))
+
+            elif isinstance(element, metadata.Other):
+                value = element.value
+                if isinstance(value, bytes):
+                    value = value.decode("latin1")
+                # noinspection PyTypeChecker
+                self._insert_into_other(results, element.key, value)
+
+            elif isinstance(element, metadata.Pipe):
+                results["pipe"].append(str(element.value))
+
+            elif isinstance(element, metadata.Registry2):
+                if element.data:
+                    results["registrydata"].append(str(element.data))
+                if element.key or element.value:
+                    path = "\\".join([element.key or "", element.value or ""])
+                    results["registrypath"].append(path)
+                    if element.data:
+                        results["registrypathdata"].append([path, str(element.data)])
+
+            elif isinstance(element, metadata.RSAPrivateKey):
+                results["rsa_private_key"].append([
+                    element.public_exponent and hex(element.public_exponent),
+                    element.modulus and hex(element.modulus),
+                    element.private_exponent and hex(element.private_exponent),
+                    element.p and hex(element.p),
+                    element.q and hex(element.q),
+                    element.d_mod_p1 and hex(element.d_mod_p1),
+                    element.d_mod_q1 and hex(element.d_mod_q1),
+                    element.q_inv_mod_p and hex(element.q_inv_mod_p),
+                ])
+
+            elif isinstance(element, metadata.RSAPublicKey):
+                results["rsa_public_key"].append([
+                    element.public_exponent and hex(element.public_exponent),
+                    element.modulus and hex(element.modulus),
+                ])
+
+            elif isinstance(element, metadata.Service):
+                service = [
+                    element.name,
+                    element.display_name,
+                    element.description,
+                    element.image,
+                    element.dll,
+                ]
+                if sum(x is not None for x in service) > 1:
+                    results["service"].append(service)
+                if element.description:
+                    results["servicedescription"].append(element.description)
+                if element.display_name:
+                    results["servicedisplayname"].append(element.display_name)
+                if element.dll:
+                    results["servicedll"].append(element.dll)
+                if element.image:
+                    results["serviceimage"].append(element.image)
+                if element.name:
+                    results["servicename"].append(element.name)
+
+            elif isinstance(element, metadata.SSLCertSHA1):
+                results["ssl_cert_sha1"].append(str(element.value))
+
+            elif isinstance(element, metadata.UserAgent):
+                results["useragent"].append(str(element.value))
+
+            elif isinstance(element, metadata.Version):
+                results["version"].append(str(element.value))
+
+            elif isinstance(element, metadata.File):
+                output_file = [element.name, element.description, element.md5]
+                if self._include_file_data and element.data:
+                    output_file.append(base64.b64encode(element.data).decode())
+                results["outputfile"].append(output_file)
+
+            elif isinstance(element, metadata.DecodedString):
+                self._insert_into_other(results, "decoded_string", element.value)
+
+        # None is not a thing in the legacy schema.
+        # Replace all None's with empty strings.
+        for key, value in results.items():
+            if isinstance(value, list):
+                new_value = []
+                for entry in value:
+                    if entry is None:
+                        entry = ""
+                    elif isinstance(entry, list):
+                        entry = [x if x is not None else "" for x in entry]
+                    new_value.append(entry)
+                results[key] = new_value
+
+        if self.logs and self._include_logs:
+            results["debug"] = self.logs
+
+        # Remove "other" if we didn't end up using it.
+        if not results["other"]:
+            del results["other"]
+
+        return dict(results)
+
+    def _build_report_model(self, source: FileObject = None) -> ReportModel:
+        """
+        Generate metadata.Report object using currently added metadata.
+        """
+        input_file = source or self.input_file
+        metadata_entries = self.get(source=source)
+        report_model = metadata.Report(
+            input_file=metadata.File.from_file_object(input_file) if input_file else None,
+            parser=(input_file.parser and input_file.parser.name) if source else self.parser,
+            errors=self.get_logs(source, errors_only=True),
+            logs=self.get_logs(source),
+            metadata=deepcopy(metadata_entries),
+        ).add_tag(*self.tags)
+        report_model.validate()
+
+        # Remove DecodedString element if external strings report was requested.
+        # (These are included as a supplemental file in the report.)
+        if self._external_strings_report:
+            report_model.metadata = [
+                element for element in report_model.metadata if not isinstance(element, metadata.DecodedString)
+            ]
+
+        # Remove raw file data from report model if requested.
+        if not self._include_file_data:
+            if report_model.input_file:
+                report_model.input_file.data = None
+            for element in report_model.metadata:
+                if isinstance(element, metadata.File):
+                    element.data = None
+
+        return report_model
+
+    @property
+    def _report_model(self) -> Union[ReportModel, List[ReportModel]]:
+        """
+        Returns the report model based on currently added metadata.
+        Results are merged.
+        """
+        return self._build_report_model()
+
+    @property
+    def _report_models(self) -> List[ReportModel]:
+        """
+        Returns a list of report models split between each source file.
+        """
+        return [
+            self._build_report_model(source=file_object)
+            for file_object in sorted(self._metadata.keys(), key=lambda fo: self._history.index(fo))
+        ]
+
+    def as_dict(self) -> dict:
+        """
+        Returns dictionary representation of the report (merged).
+        """
+        return self._report_model.as_dict()
+
+    def as_list(self) -> List[dict]:
+        """
+        Returns a list of dictionaries representing the report split by
+        source file.
+        """
+        return [report_model.as_dict() for report_model in self._report_models]
+
+    def as_dict_legacy(self, include_filename=False) -> dict:
+        """
+        Returns dictionary representation of the report. (LEGACY schema)
+        """
+        result = self.metadata
+        # Include input file information.
+        # (originally part of _parse_file in cli)
+        if include_filename:
+            input_file = metadata.File.from_file_object(self.input_file)
+            result["inputfilename"] = input_file.file_path
+            result["md5"] = input_file.md5
+            result["sha1"] = input_file.sha1
+            result["sha256"] = input_file.sha256
+            result["parser"] = self.parser
+            if input_file.compile_time:
+                result["compiletime"] = input_file.compile_time
+
+        if self.errors:
+            result["errors"] = self.errors
+
+        return result
+
+    def as_json(self, split=False) -> str:
+        """
+        Returns json representation of the report.
+        """
+        if split:
+            return json.dumps(
+                [report_model.as_json_dict() for report_model in self._report_models]
+            )
+        else:
+            return self._report_model.as_json()
+
+    def as_json_dict(self, split=False):
+        """
+        Jsonifies the element and then loads it back as a dictionary.
+        NOTE: This is different from .as_dict() because things like bytes
+        will be converted to a base64 encoded string.
+        """
+        if split:
+            return [report_model.as_json_dict() for report_model in self._report_models]
+        else:
+            return self._report_model.as_json_dict()
+
+    def as_json_legacy(self, include_filename=False) -> str:
+        """
+        Returns json representation of the report. (LEGACY schema)
+        """
+        return json.dumps(self.as_dict_legacy(include_filename=include_filename), indent=4)
+
+    def as_stix(self, writer: STIXWriter):
+        """
+        Updates the reporter with STIX content
+        """
+        for report_model in self._report_models:
+            writer.write(report_model)
+
+    def as_text(self, format="simple", split=False) -> Optional[str]:
+        """
+        Returns a custom text representation of the report.
+
+        :param format: Text format to use.
+        :param split: Whether to split up metadata results by file or to merge all results
+            under the initial input file.
+        """
+        format_map = {
+            "simple": SimpleTextWriter,
+            "markdown": MarkdownWriter,
+            "html": HTMLWriter,
+        }
+        try:
+            writer_class = format_map[format]
+        except KeyError:
+            raise ValueError(f"Invalid report format: {format}")
+
+        stream = io.StringIO()
+        with writer_class(stream) as writer:
+            if split:
+                for report_model in self._report_models:
+                    writer.write(report_model)
+            else:
+                writer.write(self._report_model)
+
+            # Write File tree
+            if self.input_file:
+                writer.h1("File Tree")
+                writer.code_block(self.file_tree())
+
+        return stream.getvalue()
+
+    def as_markdown(self) -> str:
+        return self.as_text("markdown")
+
+    def as_html(self) -> str:
+        return self.as_text("html")
+
+    def as_dataframe(self, split=False) -> pandas.DataFrame:
+        if split:
+            return pandas.concat([
+                DataFrameWriter().write(report_model)
+                for report_model in self._report_models
+            ])
+        else:
+            return DataFrameWriter().write(self._report_model)
+
+    def as_csv(self) -> str:
+        return self.as_dataframe().to_csv()
+
+    def file_tree(self) -> str:
+        """
+        Returns a tree representing the files produced per....
+        (this should just be part of text)
+        :return:
+        """
+        return str(RenderTree(self.input_file))
+
+    def strings(self, source: Union[None, str, FileObject] = None) -> List[str]:
+        """
+        Returns reported decoded string values.
+        """
+        return [element.value for element in self.iter(metadata.DecodedString, source=source)]
+
+    def add_tag(self, *tags: Iterable[str]) -> "Report":
+        """
+        Adds global tag(s) to the report.
+        NOTE: Tags added in this way are included in the overall report and aren't directed towards
+        any specific file (including the original input file).
+
+        :param tags: One or more tags to add to the metadata.
+        :returns: Report object to make it chainable.
+        """
+        for tag in tags:
+            self.tags.add(tag)
+        return self
+
+    def _get_metadata_element(self, field_name: str) -> Union[Metadata, Callable]:
+        """
+        Returns an appropriate metadata.Element or helper function based on given legacy field name.
+
+        :param field_name: legacy field name
+        :return: Either a metadata.Element or helper function to generate a metadata.Element.
+        """
+        try:
+            return METADATA_MAP[field_name]
+        except KeyError:
+            raise KeyError(f"Invalid field name: {field_name}")
+
+    def _convert_metadata_value(self, field_name: str, value):
+        """
+        Does any necessary conversion from legacy to new format.
+        This is here for field conversions that we want to do to keep backwards compatibility,
+        but we want to fail otherwise.
+
+        :param field_name: Field name value comes from.
+        :param value: Single value passed in for value.
+        :return: New converted value.
+        """
+        # Ignore dictionaries for now (the other).
+        if isinstance(value, dict):
+            return value
+
+        if isinstance(value, (list, tuple)):
+            return [self._convert_metadata_value(field_name, x) for x in value]
+
+        # Legacy metadata values did not support bytes at all. Must be strings.
+        if isinstance(value, bytes):
+            value = value.decode("latin1")
+
+        if value == "":
+            return None
+
+        # Convert value for fields that expect hex strings.
+        if (isinstance(value, str)
+                and field_name in ("rsa_private_key", "rsa_public_key")
+                and (value.startswith("0x") or re.search("[A-Fa-f]", value))
+        ):
+            return int(value, 16)
+
+        return value
+
+    def add(self, element: Metadata):
+        """
+        Report a metadata item.
+        Supports both the new and old way of reporting.
+
+        If element fails to validate, a error log message will be displayed
+        instead of throwing an exception. This is so a parser won't completely stop
+        on the first sign a new variant is partially breaking the parser.
+
+        :param element: metadata.Element type to add.
+        :raises mwcp.ValidationError: If given element is not valid.
+        """
+        if self.finalized:
+            raise RuntimeError("Report has already been finalized. Metadata can no longer be added.")
+
+        metadata_list = self._metadata[self._current_file]
+        if element not in metadata_list:
+            element.validate()
+            metadata_list.append(element)
+            element.post_processing(self)
+
+    def set_file(self, file_object: FileObject):
+        """
+        Sets the file currently being parsed.
+        """
+        self._current_file = file_object
+        if file_object not in self._history:
+            self._history.append(file_object)
+
+    def add_metadata(self, field_name_or_element: Union[str, Metadata], value=None):
+        """
+        Report a metadata item.
+        Supports both the new and old way of reporting.
+
+        :param field_name_or_element: Either a metadata.Element or field name for value.
+        :param value: string or list specifying the value of the metadata.
+        :return:
+        """
+        warnings.warn(
+            ".add_metadata() is deprecated in favor of .add() which only supports the new metadata elements.",
+            DeprecationWarning
+        )
+        if isinstance(field_name_or_element, metadata.Metadata):
+            self.add(field_name_or_element)
+            return
+
+        # Convert legacy metadata format into new format using metadata Element objects.
+
+        field_name = convert_to_unicode(field_name_or_element)
+        if value is None or all(not _value for _value in value):
+            logger.debug(f"No values provided for {field_name}, skipping")
+            return
+
+        if field_name == "debug":
+            self.logs.append(value)
+            return
+
+        element_class = self._get_metadata_element(field_name)
+        value = self._convert_metadata_value(field_name, value)
+        if isinstance(value, (list, tuple)):
+            self.add(element_class(*value))
+        elif field_name == "other":
+            for key, _value in value.items():
+                self.add(metadata.Other(key, _value))
+        else:
+            self.add(element_class(value))
+
+    def output_file(self, data: bytes, filename: str = None, description: str = None):
+        warnings.warn(
+            "output_file() is deprecated. Please add a metadata.File object to add() instead.",
+            DeprecationWarning
+        )
+        residual_file = metadata.File(name=filename, description=description, data=data)
+        self.add(residual_file)
+        # In order to be backwards compatible, we have to write out the file here, so we can
+        # return a file path.
+        return self._write_file(residual_file)
+
+    def _write_file(self, file: File) -> Optional[str]:
+        """
+        Writes out the given File metadata object and returns the file path to the written file
+        or None on failure.
+        """
+        if not self._write_output_files:
+            return
+
+        # Create a safe filename that won't have any name collisions.
+        safe_filename = sanitize_filename(file.name)
+        if self._prefix_output_files:
+            safe_filename = f"{file.md5[:5]}_{safe_filename}"
+        full_path = self._output_directory / safe_filename
+
+        try:
+            # TODO: Should we attach the real file path?
+            full_path.write_bytes(file.data)
+            logger.debug(f"Output file: {full_path}")
+            full_path = str(full_path)
+            file.file_path = full_path
+            return full_path
+        except Exception as e:
+            logger.error(f"Failed to write output file {full_path} with error: {e}")
+            return
+
+    def finalize(self):
+        """
+        This should be called after parsing is complete.
+        This performs post-processing tasks such as validation and cleaning up the log handler.
+        """
+        # If external string report enabled, create supplemental file containing
+        # reported DecodedString elements.
+        if self._external_strings_report:
+            for file_object, metadata_list in self._metadata.items():
+                string_report = metadata.StringReport(
+                    file=metadata.File.from_file_object(file_object),
+                    strings=[element for element in metadata_list if isinstance(element, metadata.DecodedString)]
+                )
+                string_report.file.data = None
+                if string_report.strings:
+                    self.add(metadata.SupplementalFile(
+                        name=f"{file_object.name}_strings.json",
+                        description=f"Decoded Strings",
+                        data=string_report.as_json().encode("utf8"),
+                    ))
+                    self.add(metadata.SupplementalFile(
+                        name=f"{file_object.name}_strings.txt",
+                        description=f"Decoded Strings",
+                        data="\n".join(string.value for string in string_report.strings).encode("utf8")
+                    ))
+
+        # TODO: move this to post_processing of File?
+        # Write out residual files to file system if requested.
+        if self._write_output_files:
+            for residual_file in self.iter(metadata.File):
+                self._write_file(residual_file)
+
+        # Remove log handler.
+        if self._log_handler:
+            logging.root.removeHandler(self._log_handler)
+
+        self.finalized = True
+
+    def __iter__(self) -> Iterable[Metadata]:
+        """
+        Iterates the added metadata elements found within the Report.
+        """
+        yield from self.iter()
+
+    def iter(
+            self,
+            *element_type: Type[T],
+            source: Union[None, str, FileObject] = None
+    ) -> Iterable[T]:
+        """
+        Iterates and returns all element instance of the given metadata Element class
+        or tuple of Element classes.
+
+        Iterates all elements if an element_type and source_file is not provided.
+
+        e.g.
+            for residual_file in report.iter(metadata.File):
+                ...
+
+            for element in report.iter(metadata.URL, metadata.Socket):
+                ...
+
+            for residual_file in report.iter(metadata.File, source="5d41402abc4b2a76b9719d911017c592"):
+                ...
+
+            for element in report.iter(metadata.URL, metadata.Socket, source="5d41402abc4b2a76b9719d911017c592"):
+                ...
+        """
+        if source:
+            if isinstance(source, str):
+                for file_object in self._metadata.keys():
+                    if file_object.md5 == source:
+                        source = file_object
+                        break
+                else:
+                    raise ValueError(f"Unable to find file with md5: {source}")
+            metadata_lists = [self._metadata[source]]
+        else:
+            metadata_lists = self._metadata.values()
+
+        yielded = []
+        for metadata_list in metadata_lists:
+            for element in metadata_list:
+                for _element in element.elements():
+                    if not element_type or isinstance(_element, element_type):
+                        # Metadata elements are not hashable, so we need to check equality of each.
+                        if not any(_element == yielded_element for yielded_element in yielded):
+                            yielded.append(_element)
+                            yield _element
+
+    def get(
+            self,
+            *element_type: Type[T],
+            source: Union[None, str, FileObject] = None
+    ) -> List[T]:
+        """
+        Same as .iter(), but wraps results in a list for you.
+
+        e.g.
+            residual_files = report.get(metadata.File)
+            residual_files = report.get(metadata.File, source="5d41402abc4b2a76b9719d911017c592")
+            elements = report.get(metadata.URL, metadata.Socket)
+            elements = report.get(metadata.URL, metadata.Socket, source="5d41402abc4b2a76b9719d911017c592")
+        """
+        return list(self.iter(*element_type, source=source))
+
+    def iter_tagged(self, *tags) -> Iterable[Metadata]:
+        """
+        Iterates metadata elements with specific tags.
+
+        :param *tags: Name of tags to get. Gets all elements that were tagged otherwise.
+        """
+        # If no tags provided, just get all elements that are tagged.
+        if not tags:
+            for element in self:
+                if element.tags:
+                    yield element
+        else:
+            for element in self:
+                if any(tag in element.tags for tag in tags):
+                    yield element
+
+    def get_tagged(self, *tags) -> List[Metadata]:
+        """
+        Same as .iter_tagged(), but wraps the results in a list for you.
+        """
+        return list(self.iter_tagged(*tags))
```

### Comparing `mwcp-3.8.0/mwcp/report_writers.py` & `mwcp-3.9.0/mwcp/report_writers.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,376 +1,376 @@
-import abc
-import collections
-import html
-import re
-import textwrap
-from typing import List, Union
-
-import pandas
-import tabulate
-
-from mwcp import metadata
-
-
-def _camel_case_to_title(name: str):
-    """
-    Converts CamelCase name to a formated title:
-
-    >>> _camel_case_to_title("SocketURLAddress")
-    "Socket URL Address"
-    """
-    # Remove any "2" suffixes. These are here for transitions to new schemas.
-    name = name.rstrip("2")
-    return re.sub(
-        "([a-z])([A-Z])", "\g<1> \g<2>",
-        re.sub("([A-Z][a-z])", " \g<1>", name).strip()
-    )
-
-
-class ReportWriter(metaclass=abc.ABCMeta):
-    name = None
-
-    def __enter__(self):
-        return self
-
-    def __exit__(self, exc_type, exc_val, exc_tb):
-        pass
-
-    @abc.abstractmethod
-    def write(self, report: metadata.Report):
-        ...
-
-
-class DataFrameWriter(ReportWriter):
-    """
-    Base class for report writers that use a dataframe
-    """
-
-    def write(self, report: metadata.Report) -> pandas.DataFrame:
-        rows = []
-
-        # Every row is going to contain the original input file md5 to use as an index.
-        md5 = report.input_file.md5
-
-        # Add input file info.
-        category = "Input File"
-        rows.extend([
-            [md5, 0, category, "parser", report.parser],
-            [md5, 0, category, "filename", report.input_file.name],
-            [md5, 0, category, "description", report.input_file.description],
-            [md5, 0, category, "architecture", report.input_file.architecture],
-            [md5, 0, category, "compile_time", report.input_file.compile_time],
-            [md5, 0, category, "derivation", report.input_file.derivation],
-        ])
-        # Split tags into their own rows.
-        for tag in report.input_file.tags:
-            rows.append([md5, 0, category, "tag", tag])
-
-        for meta_index, element in enumerate(report.metadata, start=1):
-            category = _camel_case_to_title(element.__class__.__name__)
-            row_dict = element.as_dict(flat=True)
-
-            # Flatten "Other"
-            if category == "Other":
-                row_dict[row_dict["key"]] = row_dict["value"]
-                del row_dict["key"]
-                del row_dict["value"]
-
-            for key, value in row_dict.items():
-                # Split tags into their own rows.
-                if key == "tags":
-                    for tag in sorted(value):
-                        rows.append([md5, meta_index, category, "tag", tag])
-                else:
-                    rows.append([md5, meta_index, category, key, value])
-
-        df = pandas.DataFrame(rows, columns=["MD5", "MetaIndex", "Category", "Field", "Value"])
-        # Set index so dataframe is multi-indexed by metadata element.
-        df.set_index(["MD5", "MetaIndex", "Category", "Field"], inplace=True)
-        return df
-
-
-class MarkupWriter(ReportWriter):
-    """
-    Base class for report writers that use a markup language.
-    """
-    # Table format used when generating tables.
-    _tablefmt = None
-    MAX_COL_WIDTH = 100
-    MAX_COL_INT_WIDTH = 50
-
-    def __init__(self, stream):
-        self._stream = stream
-
-    def _format_cell_value(self, value):
-        """
-        Converts given cell value into formatted value appropriate for a table cell.
-        Returns formatted value or passes back original value if no formatting is necessary.
-        """
-        # Convert sets into sorted lists to ensure deterministic behaviour.
-        if isinstance(value, set):
-            value = sorted(set)
-
-        # Present lists of strings as comma delimited string.
-        if isinstance(value, list) and all(isinstance(item, str) for item in value):
-            value = ", ".join(value)
-
-        # Wrap really long values to multiple lines.
-        if value:
-            max_width = self.MAX_COL_WIDTH
-            # As a special case, we are going to force huge integers (such as in RSAPrivateKey)
-            # to be wrapped at a smaller width threshold.
-            if isinstance(value, int):
-                max_width = self.MAX_COL_INT_WIDTH
-
-            col_width = max(len(line) for line in str(value).splitlines())
-            if col_width > max_width:
-                # For simple format, we don't have any borders showing different cells, so we are going
-                # to indent subsequence lines to make it more obvious it is part of the same cell.
-                indent = "  " if isinstance(self, SimpleTextWriter) else ""
-                value = textwrap.fill(
-                    str(value),
-                    width=max_width,
-                    subsequent_indent=indent,
-                    tabsize=4,
-                    replace_whitespace=False,
-                )
-
-        return value
-
-    def table(self, tabular_data: Union[List[dict], List[list]], headers=None, **options):
-        """
-        Writes out tabular data as a table using tabulate library.
-
-        :param tabular_data: A list of dicts or lists to represent tabular data.
-        :param headers: Header option passed to tabulate. If not provided and tabular data
-            contains dictionaries, it will use the keys.
-        :param **options: Extra arguments to pass along to tabulate.
-        """
-        if tabular_data:
-            if not headers and isinstance(tabular_data[0], dict):
-                headers = "keys"
-
-            for i, entry in enumerate(tabular_data):
-                # Reformat cells as appropriate.
-                if isinstance(entry, dict):
-                    tabular_data[i] = {key: self._format_cell_value(value) for key, value in entry.items()}
-                elif isinstance(entry, list):
-                    # noinspection PyTypeChecker
-                    tabular_data[i] = [self._format_cell_value(value) for value in entry]
-                else:
-                    raise ValueError(f"Invalid tabular data: {entry!r}")
-
-        self._stream.write(tabulate.tabulate(tabular_data, headers=headers, tablefmt=self._tablefmt, **options))
-        self._stream.write("\n\n")
-
-    def _write_table(self, elements: List[metadata.Element]):
-        tabular_data = []
-        includes_tags = False
-        for element in elements:
-            entry = element.as_formatted_dict(flat=True)
-
-            # Strip empty values (but keep tags in order to ensure it is first)
-            entry = {
-                key: value
-                for key, value in entry.items()
-                if (value or value == 0 or key == "tags")
-            }
-
-            if entry["tags"]:
-                includes_tags = True
-
-            # Convert key names into more friendly titles.
-            for key in list(entry.keys()):
-                entry[key.replace("_", " ").replace(".", " / ").title()] = entry.pop(key)
-
-            tabular_data.append(entry)
-
-        # Decide if we should remove tags if no entries have tags.
-        if not includes_tags:
-            for entry in tabular_data:
-                del entry["Tags"]
-
-        if isinstance(elements[0], metadata.Version):
-            # tabulate may incorrectly see these versions as floats.
-            self.table(tabular_data, disable_numparse=True)
-        else:
-            self.table(tabular_data)
-
-    def write(self, report: metadata.Report):
-        """
-        Writes report using a markup language.
-        Each metadata type will be written out in its own table with some
-        special cases.
-        """
-        # First write input file as a pivoted table.
-        input_file = report.input_file
-        if input_file:
-            self.h1(f"File: {input_file.name}")
-            tabular_data = [
-                ["Parser", report.parser],
-                ["File Path", input_file.file_path],
-                ["Description", input_file.description],
-                ["Architecture", input_file.architecture],
-                ["MD5", input_file.md5],
-                ["SHA1", input_file.sha1],
-                ["SHA256", input_file.sha256],
-                ["Compile Time", input_file.compile_time],
-            ]
-            if input_file.derivation:
-                tabular_data.append(["Derivation", input_file.derivation])
-            if input_file.tags:
-                tabular_data.append(["Tags", ", ".join(input_file.tags)])
-            # For this view, we will include the global report tags in this table as well.
-            if report.tags:
-                tabular_data.append(["Report Tags", ", ".join(report.tags)])
-
-            self.table(tabular_data, headers=["Field", "Value"])
-
-        # Consolidate metadata elements by their type.
-        metadata_dict = collections.defaultdict(list)
-        for element in report.metadata:
-            metadata_dict[element.__class__].append(element)
-
-        # Write all metadata elements in alphabetical order.
-        # (Except for Other and ResidualFile which we will write at the end.)
-        for element_class, elements in sorted(metadata_dict.items(), key=lambda tup: tup[0].__name__):
-            if element_class in (metadata.Other, metadata.File):
-                continue
-            table_name = _camel_case_to_title(element_class.__name__)
-            # Remove the " Legacy" part for legacy metadata fields.
-            # NOTE: This can potentially lead to two different tables with the same header.
-            #   But that would only happen if we are running a parser with a mixture of old and new.
-            #   Developer should be proactive in completely updating the parsers in a set if they see this.
-            if table_name.endswith(" Legacy"):
-                table_name = table_name[:-len(" Legacy")]
-            self.h2(table_name)
-            self._write_table(elements)
-
-        # Write Miscellaneous data
-        misc_elements = metadata_dict.get(metadata.Other, [])
-        if misc_elements:
-            self.h2("Miscellaneous")
-            self._write_table(misc_elements)
-
-        # TODO: Use as_formatted_dict() instead?
-        # Write out output/residual files. (Customized columns)
-        residual_files = metadata_dict.get(metadata.File, [])
-        if residual_files:
-            self.h2("Residual Files")
-            include_tags = any(residual_file.tags for residual_file in residual_files)
-            tabular_data = []
-            for residual_file in residual_files:
-                row = [
-                    residual_file.name,
-                    residual_file.description,
-                    residual_file.derivation,
-                    residual_file.md5,
-                    residual_file.architecture,
-                    residual_file.compile_time
-                ]
-                if include_tags:
-                    row = [", ".join(residual_file.tags)] + row
-                tabular_data.append(row)
-            headers = ["Filename", "Description", "Derivation", "MD5", "Arch", "Compile Time"]
-            if include_tags:
-                headers = ["Tags"] + headers
-            self.table(tabular_data, headers=headers)
-
-        # Finally write out log messages.
-        if report.errors:
-            self.h2("Errors")
-            self.code_block("\n".join(report.errors))
-        if report.logs:
-            self.h2("Logs")
-            self.code_block("\n".join(report.logs))
-
-    @abc.abstractmethod
-    def h1(self, text: str):
-        ...
-
-    @abc.abstractmethod
-    def h2(self, text: str):
-        ...
-
-    @abc.abstractmethod
-    def h3(self, text: str):
-        ...
-
-    @abc.abstractmethod
-    def code_block(self, text: str):
-        ...
-
-
-class MarkdownWriter(MarkupWriter):
-    name = "markdown"
-    _tablefmt = "pipe"
-
-    def _format_cell_value(self, value):
-        value = super()._format_cell_value(value)
-        # We need to replace newlines with <br> since tabulate doesn't do that for us.
-        if isinstance(value, str):
-            value = value.replace("\n", "<br>")
-        return value
-
-    def h1(self, text: str):
-        self._stream.write(f"# {text}\n")
-
-    def h2(self, text: str):
-        self._stream.write(f"## {text}\n")
-
-    def h3(self, text: str):
-        self._stream.write(f"### {text}\n")
-
-    def code_block(self, text: str):
-        if not text.endswith("\n"):
-            text = text + "\n"
-        self._stream.write(f"```\n{text}```\n\n")
-
-
-class HTMLWriter(MarkupWriter):
-    name = "html"
-    # NOTE: Using unsafehtml format so we can escape the values ourselves.
-    _tablefmt = "unsafehtml"
-
-    def _format_cell_value(self, value):
-        value = super()._format_cell_value(value)
-        if isinstance(value, str):
-            value = html.escape(value)
-            # If we have newlines in the value, wrap it in <pre>
-            # in order to preserve whitespace.
-            if "\n" in value:
-                value = f"<pre>{value}</pre>"
-        return value
-
-    def h1(self, text: str):
-        self._stream.write(f"<h1>{html.escape(text)}</h1>\n")
-
-    def h2(self, text: str):
-        self._stream.write(f"<h2>{html.escape(text)}</h2>\n")
-
-    def h3(self, text: str):
-        self._stream.write(f"<h3>{html.escape(text)}</h3>\n")
-
-    def code_block(self, text: str):
-        if not text.endswith("\n"):
-            text = text + "\n"
-        self._stream.write(f"<pre>\n{html.escape(text)}</pre>\n\n")
-
-
-class SimpleTextWriter(MarkupWriter):
-    name = "simple"
-    _tablefmt = "simple"
-
-    def h1(self, text: str):
-        self._stream.write(f"----- {text} -----\n")
-
-    def h2(self, text: str):
-        self._stream.write(f"---- {text} ----\n")
-
-    def h3(self, text: str):
-        self._stream.write(f"--- {text} ---\n")
-
-    def code_block(self, text: str):
-        if not text.endswith("\n"):
-            text = text + "\n"
-        self._stream.write(text + "\n")
+import abc
+import collections
+import html
+import re
+import textwrap
+from typing import List, Union
+
+import pandas
+import tabulate
+
+from mwcp import metadata
+
+
+def _camel_case_to_title(name: str):
+    """
+    Converts CamelCase name to a formated title:
+
+    >>> _camel_case_to_title("SocketURLAddress")
+    "Socket URL Address"
+    """
+    # Remove any "2" suffixes. These are here for transitions to new schemas.
+    name = name.rstrip("2")
+    return re.sub(
+        "([a-z])([A-Z])", "\g<1> \g<2>",
+        re.sub("([A-Z][a-z])", " \g<1>", name).strip()
+    )
+
+
+class ReportWriter(metaclass=abc.ABCMeta):
+    name = None
+
+    def __enter__(self):
+        return self
+
+    def __exit__(self, exc_type, exc_val, exc_tb):
+        pass
+
+    @abc.abstractmethod
+    def write(self, report: metadata.Report):
+        ...
+
+
+class DataFrameWriter(ReportWriter):
+    """
+    Base class for report writers that use a dataframe
+    """
+
+    def write(self, report: metadata.Report) -> pandas.DataFrame:
+        rows = []
+
+        # Every row is going to contain the original input file md5 to use as an index.
+        md5 = report.input_file.md5
+
+        # Add input file info.
+        category = "Input File"
+        rows.extend([
+            [md5, 0, category, "parser", report.parser],
+            [md5, 0, category, "filename", report.input_file.name],
+            [md5, 0, category, "description", report.input_file.description],
+            [md5, 0, category, "architecture", report.input_file.architecture],
+            [md5, 0, category, "compile_time", report.input_file.compile_time],
+            [md5, 0, category, "derivation", report.input_file.derivation],
+        ])
+        # Split tags into their own rows.
+        for tag in report.input_file.tags:
+            rows.append([md5, 0, category, "tag", tag])
+
+        for meta_index, element in enumerate(report.metadata, start=1):
+            category = _camel_case_to_title(element.__class__.__name__)
+            row_dict = element.as_dict(flat=True)
+
+            # Flatten "Other"
+            if category == "Other":
+                row_dict[row_dict["key"]] = row_dict["value"]
+                del row_dict["key"]
+                del row_dict["value"]
+
+            for key, value in row_dict.items():
+                # Split tags into their own rows.
+                if key == "tags":
+                    for tag in sorted(value):
+                        rows.append([md5, meta_index, category, "tag", tag])
+                else:
+                    rows.append([md5, meta_index, category, key, value])
+
+        df = pandas.DataFrame(rows, columns=["MD5", "MetaIndex", "Category", "Field", "Value"])
+        # Set index so dataframe is multi-indexed by metadata element.
+        df.set_index(["MD5", "MetaIndex", "Category", "Field"], inplace=True)
+        return df
+
+
+class MarkupWriter(ReportWriter):
+    """
+    Base class for report writers that use a markup language.
+    """
+    # Table format used when generating tables.
+    _tablefmt = None
+    MAX_COL_WIDTH = 100
+    MAX_COL_INT_WIDTH = 50
+
+    def __init__(self, stream):
+        self._stream = stream
+
+    def _format_cell_value(self, value):
+        """
+        Converts given cell value into formatted value appropriate for a table cell.
+        Returns formatted value or passes back original value if no formatting is necessary.
+        """
+        # Convert sets into sorted lists to ensure deterministic behaviour.
+        if isinstance(value, set):
+            value = sorted(set)
+
+        # Present lists of strings as comma delimited string.
+        if isinstance(value, list) and all(isinstance(item, str) for item in value):
+            value = ", ".join(value)
+
+        # Wrap really long values to multiple lines.
+        if value:
+            max_width = self.MAX_COL_WIDTH
+            # As a special case, we are going to force huge integers (such as in RSAPrivateKey)
+            # to be wrapped at a smaller width threshold.
+            if isinstance(value, int):
+                max_width = self.MAX_COL_INT_WIDTH
+
+            col_width = max(len(line) for line in str(value).splitlines())
+            if col_width > max_width:
+                # For simple format, we don't have any borders showing different cells, so we are going
+                # to indent subsequence lines to make it more obvious it is part of the same cell.
+                indent = "  " if isinstance(self, SimpleTextWriter) else ""
+                value = textwrap.fill(
+                    str(value),
+                    width=max_width,
+                    subsequent_indent=indent,
+                    tabsize=4,
+                    replace_whitespace=False,
+                )
+
+        return value
+
+    def table(self, tabular_data: Union[List[dict], List[list]], headers=None, **options):
+        """
+        Writes out tabular data as a table using tabulate library.
+
+        :param tabular_data: A list of dicts or lists to represent tabular data.
+        :param headers: Header option passed to tabulate. If not provided and tabular data
+            contains dictionaries, it will use the keys.
+        :param **options: Extra arguments to pass along to tabulate.
+        """
+        if tabular_data:
+            if not headers and isinstance(tabular_data[0], dict):
+                headers = "keys"
+
+            for i, entry in enumerate(tabular_data):
+                # Reformat cells as appropriate.
+                if isinstance(entry, dict):
+                    tabular_data[i] = {key: self._format_cell_value(value) for key, value in entry.items()}
+                elif isinstance(entry, list):
+                    # noinspection PyTypeChecker
+                    tabular_data[i] = [self._format_cell_value(value) for value in entry]
+                else:
+                    raise ValueError(f"Invalid tabular data: {entry!r}")
+
+        self._stream.write(tabulate.tabulate(tabular_data, headers=headers, tablefmt=self._tablefmt, **options))
+        self._stream.write("\n\n")
+
+    def _write_table(self, elements: List[metadata.Element]):
+        tabular_data = []
+        includes_tags = False
+        for element in elements:
+            entry = element.as_formatted_dict(flat=True)
+
+            # Strip empty values (but keep tags in order to ensure it is first)
+            entry = {
+                key: value
+                for key, value in entry.items()
+                if (value or value == 0 or key == "tags")
+            }
+
+            if entry["tags"]:
+                includes_tags = True
+
+            # Convert key names into more friendly titles.
+            for key in list(entry.keys()):
+                entry[key.replace("_", " ").replace(".", " / ").title()] = entry.pop(key)
+
+            tabular_data.append(entry)
+
+        # Decide if we should remove tags if no entries have tags.
+        if not includes_tags:
+            for entry in tabular_data:
+                del entry["Tags"]
+
+        if isinstance(elements[0], metadata.Version):
+            # tabulate may incorrectly see these versions as floats.
+            self.table(tabular_data, disable_numparse=True)
+        else:
+            self.table(tabular_data)
+
+    def write(self, report: metadata.Report):
+        """
+        Writes report using a markup language.
+        Each metadata type will be written out in its own table with some
+        special cases.
+        """
+        # First write input file as a pivoted table.
+        input_file = report.input_file
+        if input_file:
+            self.h1(f"File: {input_file.name}")
+            tabular_data = [
+                ["Parser", report.parser],
+                ["File Path", input_file.file_path],
+                ["Description", input_file.description],
+                ["Architecture", input_file.architecture],
+                ["MD5", input_file.md5],
+                ["SHA1", input_file.sha1],
+                ["SHA256", input_file.sha256],
+                ["Compile Time", input_file.compile_time],
+            ]
+            if input_file.derivation:
+                tabular_data.append(["Derivation", input_file.derivation])
+            if input_file.tags:
+                tabular_data.append(["Tags", ", ".join(input_file.tags)])
+            # For this view, we will include the global report tags in this table as well.
+            if report.tags:
+                tabular_data.append(["Report Tags", ", ".join(report.tags)])
+
+            self.table(tabular_data, headers=["Field", "Value"])
+
+        # Consolidate metadata elements by their type.
+        metadata_dict = collections.defaultdict(list)
+        for element in report.metadata:
+            metadata_dict[element.__class__].append(element)
+
+        # Write all metadata elements in alphabetical order.
+        # (Except for Other and ResidualFile which we will write at the end.)
+        for element_class, elements in sorted(metadata_dict.items(), key=lambda tup: tup[0].__name__):
+            if element_class in (metadata.Other, metadata.File):
+                continue
+            table_name = _camel_case_to_title(element_class.__name__)
+            # Remove the " Legacy" part for legacy metadata fields.
+            # NOTE: This can potentially lead to two different tables with the same header.
+            #   But that would only happen if we are running a parser with a mixture of old and new.
+            #   Developer should be proactive in completely updating the parsers in a set if they see this.
+            if table_name.endswith(" Legacy"):
+                table_name = table_name[:-len(" Legacy")]
+            self.h2(table_name)
+            self._write_table(elements)
+
+        # Write Miscellaneous data
+        misc_elements = metadata_dict.get(metadata.Other, [])
+        if misc_elements:
+            self.h2("Miscellaneous")
+            self._write_table(misc_elements)
+
+        # TODO: Use as_formatted_dict() instead?
+        # Write out output/residual files. (Customized columns)
+        residual_files = metadata_dict.get(metadata.File, [])
+        if residual_files:
+            self.h2("Residual Files")
+            include_tags = any(residual_file.tags for residual_file in residual_files)
+            tabular_data = []
+            for residual_file in residual_files:
+                row = [
+                    residual_file.name,
+                    residual_file.description,
+                    residual_file.derivation,
+                    residual_file.md5,
+                    residual_file.architecture,
+                    residual_file.compile_time
+                ]
+                if include_tags:
+                    row = [", ".join(residual_file.tags)] + row
+                tabular_data.append(row)
+            headers = ["Filename", "Description", "Derivation", "MD5", "Arch", "Compile Time"]
+            if include_tags:
+                headers = ["Tags"] + headers
+            self.table(tabular_data, headers=headers)
+
+        # Finally write out log messages.
+        if report.errors:
+            self.h2("Errors")
+            self.code_block("\n".join(report.errors))
+        if report.logs:
+            self.h2("Logs")
+            self.code_block("\n".join(report.logs))
+
+    @abc.abstractmethod
+    def h1(self, text: str):
+        ...
+
+    @abc.abstractmethod
+    def h2(self, text: str):
+        ...
+
+    @abc.abstractmethod
+    def h3(self, text: str):
+        ...
+
+    @abc.abstractmethod
+    def code_block(self, text: str):
+        ...
+
+
+class MarkdownWriter(MarkupWriter):
+    name = "markdown"
+    _tablefmt = "pipe"
+
+    def _format_cell_value(self, value):
+        value = super()._format_cell_value(value)
+        # We need to replace newlines with <br> since tabulate doesn't do that for us.
+        if isinstance(value, str):
+            value = value.replace("\n", "<br>")
+        return value
+
+    def h1(self, text: str):
+        self._stream.write(f"# {text}\n")
+
+    def h2(self, text: str):
+        self._stream.write(f"## {text}\n")
+
+    def h3(self, text: str):
+        self._stream.write(f"### {text}\n")
+
+    def code_block(self, text: str):
+        if not text.endswith("\n"):
+            text = text + "\n"
+        self._stream.write(f"```\n{text}```\n\n")
+
+
+class HTMLWriter(MarkupWriter):
+    name = "html"
+    # NOTE: Using unsafehtml format so we can escape the values ourselves.
+    _tablefmt = "unsafehtml"
+
+    def _format_cell_value(self, value):
+        value = super()._format_cell_value(value)
+        if isinstance(value, str):
+            value = html.escape(value)
+            # If we have newlines in the value, wrap it in <pre>
+            # in order to preserve whitespace.
+            if "\n" in value:
+                value = f"<pre>{value}</pre>"
+        return value
+
+    def h1(self, text: str):
+        self._stream.write(f"<h1>{html.escape(text)}</h1>\n")
+
+    def h2(self, text: str):
+        self._stream.write(f"<h2>{html.escape(text)}</h2>\n")
+
+    def h3(self, text: str):
+        self._stream.write(f"<h3>{html.escape(text)}</h3>\n")
+
+    def code_block(self, text: str):
+        if not text.endswith("\n"):
+            text = text + "\n"
+        self._stream.write(f"<pre>\n{html.escape(text)}</pre>\n\n")
+
+
+class SimpleTextWriter(MarkupWriter):
+    name = "simple"
+    _tablefmt = "simple"
+
+    def h1(self, text: str):
+        self._stream.write(f"----- {text} -----\n")
+
+    def h2(self, text: str):
+        self._stream.write(f"---- {text} ----\n")
+
+    def h3(self, text: str):
+        self._stream.write(f"--- {text} ---\n")
+
+    def code_block(self, text: str):
+        if not text.endswith("\n"):
+            text = text + "\n"
+        self._stream.write(text + "\n")
```

### Comparing `mwcp-3.8.0/mwcp/stix/extensions.py` & `mwcp-3.9.0/mwcp/stix/extensions.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,121 +1,121 @@
-"""
-Provides support for STIX 2.1 extensions that have not yet been added to the STIX Python library as top level objects.
-"""
-
-from collections import OrderedDict
-
-from stix2.v21 import _Observable
-from stix2.properties import (
-    DictionaryProperty, HexProperty, IDProperty, ListProperty, OpenVocabProperty,
-    ReferenceProperty, StringProperty, TypeProperty
-)
-from stix2.v21.common import GranularMarking
-
-OBSERVED_STRING_PURPOSE_OV = [
-    "campaign-id",
-    "pipe",
-    "user-agent",
-    "uuid",
-]
-
-
-class ObservedString(_Observable):
-    """
-    This STIX SCO is an extension and used to track unique strings observed in content so it can be easily deduplicated, shared and searched for
-    """
-
-    __EXTENSION_DETAILS = {"extension-definition--8b1aa84c-5532-4c69-a8e7-b6170facfd3d": {"extension_type": "new-sco"}}
-
-    _type = "observed-string"
-    _properties = OrderedDict([
-        ('type', TypeProperty(_type, spec_version="2.1")),
-        ('spec_version', StringProperty(fixed="2.1")),
-        ('id', IDProperty(_type, spec_version="2.1")),
-        ('value', StringProperty(required=True)),
-        ('purpose', OpenVocabProperty(OBSERVED_STRING_PURPOSE_OV, required=True)),
-        ('object_marking_refs', ListProperty(ReferenceProperty(valid_types="marking-definition", spec_version="2.1"))),
-        ('granular_markings', ListProperty(GranularMarking)),
-        # This uses a Dictionary instead of an Extension property because ExtensionProperty does not support fixed values
-        ('extensions', DictionaryProperty(fixed=__EXTENSION_DETAILS)), 
-    ])
-
-    _id_contributing_properties = ["value", "purpose"]
-
-
-class CryptoCurrencyAddress(_Observable):
-    """
-    This STIX SCO is an extension and used to track cryptocurrecy addresses
-    """
-
-    __EXTENSION_DETAILS = {"extension-definition--4b12a3b5-0d80-464b-914d-dcbfbd980e64": {"extension_type": "new-sco"}}
-
-    _type = "crypto-currency-address"
-    _properties = OrderedDict([
-        ('type', TypeProperty(_type, spec_version="2.1")),
-        ('spec_version', StringProperty(fixed="2.1")),
-        ('id', IDProperty(_type, spec_version="2.1")),
-        ('address', StringProperty(required=True)),
-        ('currency_type', StringProperty()),
-        ('object_marking_refs', ListProperty(ReferenceProperty(valid_types="marking-definition", spec_version="2.1"))),
-        ('granular_markings', ListProperty(GranularMarking)),
-        # This uses a Dictionary instead of an Extension property because ExtensionProperty does not support fixed values
-        ('extensions', DictionaryProperty(fixed=__EXTENSION_DETAILS)), 
-    ])
-
-    _id_contributing_properties = ["address", "currency_type"]
-
-
-class SymmetricEncryption(_Observable):
-    """
-    This STIX SCO is used to supply information about encryption keys found in Files or other sources
-    """
-
-    __EXTENSION_DETAILS = {"extension-definition--fb989191-187f-4c11-81cd-4a699a00835d": {"extension_type": "new-sco"}}
-
-    _type = "symmetric-encryption"
-    _properties = OrderedDict([
-        ('type', TypeProperty(_type, spec_version="2.1")),
-        ('spec_version', StringProperty(fixed="2.1")),
-        ('id', IDProperty(_type, spec_version="2.1")),
-        ('key_hex', HexProperty()),
-        ('iv_hex', HexProperty()),
-        ('algorithm', StringProperty()),
-        ('mode', StringProperty()),
-        ('object_marking_refs', ListProperty(ReferenceProperty(valid_types="marking-definition", spec_version="2.1"))),
-        ('granular_markings', ListProperty(GranularMarking)),
-        # This uses a Dictionary instead of an Extension property because ExtensionProperty does not support fixed values
-        ('extensions', DictionaryProperty(fixed=__EXTENSION_DETAILS)), 
-    ])
-
-    _id_contributing_properties = ["key_hex", "iv_hex", "mode", "algorithm"]
-
-    def _check_object_constraints(self):
-        super()._check_object_constraints()
-        self._check_at_least_one_property(["key_hex", "iv_hex", "mode", "algorithm"])
-
-
-def rsa_private_key_extension(private_exponent, p, q, d_mod_p1, d_mod_q1, q_inv_mod_p) -> dict:
-    """
-    This takes the parameters for the x509 certificate rsa private key extension returns an extension dictionary that includes these
-    This is not an object as it produces a property extension instead of a SCO
-    """
-    properties = {}
-
-    if private_exponent:
-        properties["private_exponent"] = private_exponent
-    if p:
-        properties["p"] = str(p)
-    if q:
-        properties["q"] = str(q)
-    if d_mod_p1:
-        properties["d_mod_p1"] = str(d_mod_p1)
-    if d_mod_q1:
-        properties["d_mod_q1"] = str(d_mod_q1)
-    if q_inv_mod_p:
-        properties["q_inv_mod_p"] = str(q_inv_mod_p)
-
-    if len(properties) > 0:
-        properties["extension_type"] = "property-extension"
-        return {"extension-definition--b84c95f5-d48d-4e4a-b723-7d209a02deb9": properties}
-
-    return {}
+"""
+Provides support for STIX 2.1 extensions that have not yet been added to the STIX Python library as top level objects.
+"""
+
+from collections import OrderedDict
+
+from stix2.v21 import _Observable
+from stix2.properties import (
+    DictionaryProperty, HexProperty, IDProperty, ListProperty, OpenVocabProperty,
+    ReferenceProperty, StringProperty, TypeProperty
+)
+from stix2.v21.common import GranularMarking
+
+OBSERVED_STRING_PURPOSE_OV = [
+    "campaign-id",
+    "pipe",
+    "user-agent",
+    "uuid",
+]
+
+
+class ObservedString(_Observable):
+    """
+    This STIX SCO is an extension and used to track unique strings observed in content so it can be easily deduplicated, shared and searched for
+    """
+
+    __EXTENSION_DETAILS = {"extension-definition--8b1aa84c-5532-4c69-a8e7-b6170facfd3d": {"extension_type": "new-sco"}}
+
+    _type = "observed-string"
+    _properties = OrderedDict([
+        ('type', TypeProperty(_type, spec_version="2.1")),
+        ('spec_version', StringProperty(fixed="2.1")),
+        ('id', IDProperty(_type, spec_version="2.1")),
+        ('value', StringProperty(required=True)),
+        ('purpose', OpenVocabProperty(OBSERVED_STRING_PURPOSE_OV, required=True)),
+        ('object_marking_refs', ListProperty(ReferenceProperty(valid_types="marking-definition", spec_version="2.1"))),
+        ('granular_markings', ListProperty(GranularMarking)),
+        # This uses a Dictionary instead of an Extension property because ExtensionProperty does not support fixed values
+        ('extensions', DictionaryProperty(fixed=__EXTENSION_DETAILS)), 
+    ])
+
+    _id_contributing_properties = ["value", "purpose"]
+
+
+class CryptoCurrencyAddress(_Observable):
+    """
+    This STIX SCO is an extension and used to track cryptocurrecy addresses
+    """
+
+    __EXTENSION_DETAILS = {"extension-definition--4b12a3b5-0d80-464b-914d-dcbfbd980e64": {"extension_type": "new-sco"}}
+
+    _type = "crypto-currency-address"
+    _properties = OrderedDict([
+        ('type', TypeProperty(_type, spec_version="2.1")),
+        ('spec_version', StringProperty(fixed="2.1")),
+        ('id', IDProperty(_type, spec_version="2.1")),
+        ('address', StringProperty(required=True)),
+        ('currency_type', StringProperty()),
+        ('object_marking_refs', ListProperty(ReferenceProperty(valid_types="marking-definition", spec_version="2.1"))),
+        ('granular_markings', ListProperty(GranularMarking)),
+        # This uses a Dictionary instead of an Extension property because ExtensionProperty does not support fixed values
+        ('extensions', DictionaryProperty(fixed=__EXTENSION_DETAILS)), 
+    ])
+
+    _id_contributing_properties = ["address", "currency_type"]
+
+
+class SymmetricEncryption(_Observable):
+    """
+    This STIX SCO is used to supply information about encryption keys found in Files or other sources
+    """
+
+    __EXTENSION_DETAILS = {"extension-definition--fb989191-187f-4c11-81cd-4a699a00835d": {"extension_type": "new-sco"}}
+
+    _type = "symmetric-encryption"
+    _properties = OrderedDict([
+        ('type', TypeProperty(_type, spec_version="2.1")),
+        ('spec_version', StringProperty(fixed="2.1")),
+        ('id', IDProperty(_type, spec_version="2.1")),
+        ('key_hex', HexProperty()),
+        ('iv_hex', HexProperty()),
+        ('algorithm', StringProperty()),
+        ('mode', StringProperty()),
+        ('object_marking_refs', ListProperty(ReferenceProperty(valid_types="marking-definition", spec_version="2.1"))),
+        ('granular_markings', ListProperty(GranularMarking)),
+        # This uses a Dictionary instead of an Extension property because ExtensionProperty does not support fixed values
+        ('extensions', DictionaryProperty(fixed=__EXTENSION_DETAILS)), 
+    ])
+
+    _id_contributing_properties = ["key_hex", "iv_hex", "mode", "algorithm"]
+
+    def _check_object_constraints(self):
+        super()._check_object_constraints()
+        self._check_at_least_one_property(["key_hex", "iv_hex", "mode", "algorithm"])
+
+
+def rsa_private_key_extension(private_exponent, p, q, d_mod_p1, d_mod_q1, q_inv_mod_p) -> dict:
+    """
+    This takes the parameters for the x509 certificate rsa private key extension returns an extension dictionary that includes these
+    This is not an object as it produces a property extension instead of a SCO
+    """
+    properties = {}
+
+    if private_exponent:
+        properties["private_exponent"] = private_exponent
+    if p:
+        properties["p"] = str(p)
+    if q:
+        properties["q"] = str(q)
+    if d_mod_p1:
+        properties["d_mod_p1"] = str(d_mod_p1)
+    if d_mod_q1:
+        properties["d_mod_q1"] = str(d_mod_q1)
+    if q_inv_mod_p:
+        properties["q_inv_mod_p"] = str(q_inv_mod_p)
+
+    if len(properties) > 0:
+        properties["extension_type"] = "property-extension"
+        return {"extension-definition--b84c95f5-d48d-4e4a-b723-7d209a02deb9": properties}
+
+    return {}
```

### Comparing `mwcp-3.8.0/mwcp/stix/objects.py` & `mwcp-3.9.0/mwcp/stix/objects.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,45 +1,45 @@
-"""
-This provides helper objects that can be used to generate STIX content
-"""
-
-
-class STIXResult:
-    """
-    Provides a means to return STIX 2.1 content
-
-    :var linked_stix: An array of STIX objects that should be linked to a parent malware analysis object
-    :var unlinked_stix: An array of STIX objects that should not be linked to a parent malware analysis object.
-         This can include relationship objects, objects connected by relationship objects,
-         and objects with embedded references like Notes
-    :var note_content: The content of the note which will be attached to the STIX file object being analyzed by the
-        malware analysis
-    :var note_labels: The labels of the note which will be attached to the STIX file object being analyzed by the
-        malware analysis
-    """
-
-    def __init__(self, note_content: str = "", fixed_timestamp: str = None):
-        self.linked_stix = []
-        self.unlinked_stix = []
-        self.note_content = note_content
-        self.note_labels = []
-        self.fixed_timestamp = fixed_timestamp
-
-    def add_linked(self, stix_content):
-        self.linked_stix.append(stix_content)
-
-    def add_unlinked(self, stix_content):
-        self.unlinked_stix.append(stix_content)
-
-    def create_tag_note(self, metadata, stix_content):
-        note = metadata.as_stix_tags(stix_content, self.fixed_timestamp)
-        if note:
-            self.unlinked_stix.append(note)
-
-    def merge(self, other):
-        self.linked_stix.extend(other.linked_stix)
-        self.unlinked_stix.extend(other.unlinked_stix)
-
-        if self.note_content == "":
-            self.note_content = other.note_content
-        elif other.note_content != "":
+"""
+This provides helper objects that can be used to generate STIX content
+"""
+
+
+class STIXResult:
+    """
+    Provides a means to return STIX 2.1 content
+
+    :var linked_stix: An array of STIX objects that should be linked to a parent malware analysis object
+    :var unlinked_stix: An array of STIX objects that should not be linked to a parent malware analysis object.
+         This can include relationship objects, objects connected by relationship objects,
+         and objects with embedded references like Notes
+    :var note_content: The content of the note which will be attached to the STIX file object being analyzed by the
+        malware analysis
+    :var note_labels: The labels of the note which will be attached to the STIX file object being analyzed by the
+        malware analysis
+    """
+
+    def __init__(self, note_content: str = "", fixed_timestamp: str = None):
+        self.linked_stix = []
+        self.unlinked_stix = []
+        self.note_content = note_content
+        self.note_labels = []
+        self.fixed_timestamp = fixed_timestamp
+
+    def add_linked(self, stix_content):
+        self.linked_stix.append(stix_content)
+
+    def add_unlinked(self, stix_content):
+        self.unlinked_stix.append(stix_content)
+
+    def create_tag_note(self, metadata, stix_content):
+        note = metadata.as_stix_tags(stix_content, self.fixed_timestamp)
+        if note:
+            self.unlinked_stix.append(note)
+
+    def merge(self, other):
+        self.linked_stix.extend(other.linked_stix)
+        self.unlinked_stix.extend(other.unlinked_stix)
+
+        if self.note_content == "":
+            self.note_content = other.note_content
+        elif other.note_content != "":
             self.note_content += "\n" + other.note_content
```

### Comparing `mwcp-3.8.0/mwcp/stix/report_writer.py` & `mwcp-3.9.0/mwcp/stix/report_writer.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,151 +1,151 @@
-"""
-This serves as the STIX Report Writer.  This expands on the same report every time write is called.
-A STIX package is generated and returned as a string when serialize is called
-"""
-
-from stix2 import v21 as stix
-from stix2.v21 import _Observable
-
-import mwcp
-from mwcp import metadata
-from mwcp.file_object import FileObject
-from mwcp.report_writers import ReportWriter
-
-
-class STIXWriter(ReportWriter):
-    """
-    Used to create a STIX Bundle that represents one or more MWCP Reports.
-    Write must be called by each report that should be included in the final result.
-    Serialize is called once this process is completed to return the STIX Bundle as a string.
-    """
-    def __init__(self, fixed_timestamp: str = None):
-        # used to ensure we deduplicate objects prior to loading them into the bundle
-        self._all_objects = {}
-        # applies a fixed timestamp to all SDOs and SROs for their created and updated times
-        self.fixed_timestamp = fixed_timestamp
-
-    def write(self, report: metadata.Report):
-        linked_ids = set()
-        analysis_data = {
-            "product": "mwcp",
-            "version": mwcp.__version__,
-            "result_name": report.parser,
-            "allow_custom": True,
-            "created": self.fixed_timestamp,
-            "modified": self.fixed_timestamp
-        }
-
-        note_content = ["Description: " + str(report.input_file.description)]
-
-        # we need to turn the FileObj into a metadata.File to fetch STIX content
-        file_result = report.input_file.as_stix(None, self.fixed_timestamp)
-        
-        for item in file_result.linked_stix:
-            self._add_stix_object(item)
-
-        for item in file_result.unlinked_stix:
-            self._add_stix_object(item)
-
-        # the file should always be the first STIX object written
-        base_file = file_result.linked_stix[0]
-
-        analysis_data["sample_ref"] = base_file.id
-
-        if file_result.note_content:
-            note_content.append(file_result.note_content)
-
-        for element in report.metadata:
-            result = element.as_stix(base_file, self.fixed_timestamp)
-
-            # Content is loaded to the master note for the File
-            if result.note_content:
-                note_content.append(result.note_content)
-
-            # Linked items will be added the result set for the Malware Analysis
-            for item in result.linked_stix:
-                linked_ids.add(item.id)
-                self._add_stix_object(item)
-
-            # Unlinked items are added to the final result, but are not linked within the Malware Analysis.
-            # Links should happen via relationships or embedded STIX relationships within the objects
-            for item in result.unlinked_stix:
-                self._add_stix_object(item)
-
-        # make a single large Note for all Other data which was collected and not otherwise applied
-        if len(note_content) > 0:
-            note_params = {
-                "content": "\n".join(note_content),
-                "object_refs": [base_file.id],
-                "created": self.fixed_timestamp,
-                "modified": self.fixed_timestamp,
-                "allow_custom": True
-            }
-
-            if len(file_result.note_labels) > 0:
-                file_result.note_labels.sort()
-                note_params["labels"] = file_result.note_labels
-
-            note = stix.Note(**note_params)
-            self._add_stix_object(note)
-
-        # the malware analysis must be made last since we need the IDs for everything that came out of it
-        if len(linked_ids) > 0:
-            refs = list(linked_ids)
-            refs.sort()
-            analysis_data["analysis_sco_refs"] = refs
-        else:
-            analysis_data["result"] = "unknown"
-
-        if report.tags:
-            tags = list(report.tags)
-            tags.sort()
-            analysis_data["labels"] = tags
-            
-        malware_analysis = stix.MalwareAnalysis(**analysis_data)
-        self._add_stix_object(malware_analysis)
-
-    def serialize(self) -> str:
-        # Consolidate Notes down to avoid needless duplication
-        note_lookup = {}
-        to_remove = []
-        for idx, item in self._all_objects.items():
-            if item.type == "note":
-                if hasattr(item, "abstract"):
-                    key = item.abstract + item.content
-                else:
-                    key = item.content
-
-                if hasattr(item, "labels"):
-                    key += " / ".join(item.labels)
-
-                if key in note_lookup:
-                    existing = note_lookup[key]
-                    for ref in item.object_refs:
-                        if ref not in existing.object_refs:
-                            existing.object_refs.append(ref)
-                    to_remove.append(idx)
-                else:
-                    note_lookup[key] = item
-
-        # remove the duplicate notes
-        # done outside of the initial loop to avoid messing with for
-        for idx in to_remove:
-            self._all_objects.pop(idx)
-
-        values = self._all_objects.values()
-        if len(values) > 0:
-            package = stix.Bundle(objects=values, allow_custom=True)
-        else:
-            package = stix.Bundle()
-
-        return package.serialize(indent=4)
-
-    def _add_stix_object(self, stix_object: _Observable):
-        """
-        Adds a STIX object to the all objects dictionary and replaces the existing element if the new version has more details
-        """
-        if stix_object.id in self._all_objects:
-            if len(stix_object.serialize()) > len(self._all_objects[stix_object.id].serialize()):
-                self._all_objects[stix_object.id] = stix_object
-        else:
-            self._all_objects[stix_object.id] = stix_object
+"""
+This serves as the STIX Report Writer.  This expands on the same report every time write is called.
+A STIX package is generated and returned as a string when serialize is called
+"""
+
+from stix2 import v21 as stix
+from stix2.v21 import _Observable
+
+import mwcp
+from mwcp import metadata
+from mwcp.file_object import FileObject
+from mwcp.report_writers import ReportWriter
+
+
+class STIXWriter(ReportWriter):
+    """
+    Used to create a STIX Bundle that represents one or more MWCP Reports.
+    Write must be called by each report that should be included in the final result.
+    Serialize is called once this process is completed to return the STIX Bundle as a string.
+    """
+    def __init__(self, fixed_timestamp: str = None):
+        # used to ensure we deduplicate objects prior to loading them into the bundle
+        self._all_objects = {}
+        # applies a fixed timestamp to all SDOs and SROs for their created and updated times
+        self.fixed_timestamp = fixed_timestamp
+
+    def write(self, report: metadata.Report):
+        linked_ids = set()
+        analysis_data = {
+            "product": "mwcp",
+            "version": mwcp.__version__,
+            "result_name": report.parser,
+            "allow_custom": True,
+            "created": self.fixed_timestamp,
+            "modified": self.fixed_timestamp
+        }
+
+        note_content = ["Description: " + str(report.input_file.description)]
+
+        # we need to turn the FileObj into a metadata.File to fetch STIX content
+        file_result = report.input_file.as_stix(None, self.fixed_timestamp)
+        
+        for item in file_result.linked_stix:
+            self._add_stix_object(item)
+
+        for item in file_result.unlinked_stix:
+            self._add_stix_object(item)
+
+        # the file should always be the first STIX object written
+        base_file = file_result.linked_stix[0]
+
+        analysis_data["sample_ref"] = base_file.id
+
+        if file_result.note_content:
+            note_content.append(file_result.note_content)
+
+        for element in report.metadata:
+            result = element.as_stix(base_file, self.fixed_timestamp)
+
+            # Content is loaded to the master note for the File
+            if result.note_content:
+                note_content.append(result.note_content)
+
+            # Linked items will be added the result set for the Malware Analysis
+            for item in result.linked_stix:
+                linked_ids.add(item.id)
+                self._add_stix_object(item)
+
+            # Unlinked items are added to the final result, but are not linked within the Malware Analysis.
+            # Links should happen via relationships or embedded STIX relationships within the objects
+            for item in result.unlinked_stix:
+                self._add_stix_object(item)
+
+        # make a single large Note for all Other data which was collected and not otherwise applied
+        if len(note_content) > 0:
+            note_params = {
+                "content": "\n".join(note_content),
+                "object_refs": [base_file.id],
+                "created": self.fixed_timestamp,
+                "modified": self.fixed_timestamp,
+                "allow_custom": True
+            }
+
+            if len(file_result.note_labels) > 0:
+                file_result.note_labels.sort()
+                note_params["labels"] = file_result.note_labels
+
+            note = stix.Note(**note_params)
+            self._add_stix_object(note)
+
+        # the malware analysis must be made last since we need the IDs for everything that came out of it
+        if len(linked_ids) > 0:
+            refs = list(linked_ids)
+            refs.sort()
+            analysis_data["analysis_sco_refs"] = refs
+        else:
+            analysis_data["result"] = "unknown"
+
+        if report.tags:
+            tags = list(report.tags)
+            tags.sort()
+            analysis_data["labels"] = tags
+            
+        malware_analysis = stix.MalwareAnalysis(**analysis_data)
+        self._add_stix_object(malware_analysis)
+
+    def serialize(self) -> str:
+        # Consolidate Notes down to avoid needless duplication
+        note_lookup = {}
+        to_remove = []
+        for idx, item in self._all_objects.items():
+            if item.type == "note":
+                if hasattr(item, "abstract"):
+                    key = item.abstract + item.content
+                else:
+                    key = item.content
+
+                if hasattr(item, "labels"):
+                    key += " / ".join(item.labels)
+
+                if key in note_lookup:
+                    existing = note_lookup[key]
+                    for ref in item.object_refs:
+                        if ref not in existing.object_refs:
+                            existing.object_refs.append(ref)
+                    to_remove.append(idx)
+                else:
+                    note_lookup[key] = item
+
+        # remove the duplicate notes
+        # done outside of the initial loop to avoid messing with for
+        for idx in to_remove:
+            self._all_objects.pop(idx)
+
+        values = self._all_objects.values()
+        if len(values) > 0:
+            package = stix.Bundle(objects=values, allow_custom=True)
+        else:
+            package = stix.Bundle()
+
+        return package.serialize(indent=4)
+
+    def _add_stix_object(self, stix_object: _Observable):
+        """
+        Adds a STIX object to the all objects dictionary and replaces the existing element if the new version has more details
+        """
+        if stix_object.id in self._all_objects:
+            if len(stix_object.serialize()) > len(self._all_objects[stix_object.id].serialize()):
+                self._all_objects[stix_object.id] = stix_object
+        else:
+            self._all_objects[stix_object.id] = stix_object
```

### Comparing `mwcp-3.8.0/mwcp/tester.py` & `mwcp-3.9.0/mwcp/tester.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,628 +1,628 @@
-"""
-Test case support for DC3-MWCP. Parser output is stored in a json file per parser. To run test cases,
-parser is re-run and compared to previous results.
-"""
-
-import json
-import multiprocessing as mp
-import logging
-import os
-import pathlib
-import sys
-import traceback
-from timeit import default_timer
-
-try:
-    import pkg_resources
-except ImportError:
-    pkg_resources = None
-
-import mwcp
-from mwcp import config
-from mwcp.utils.stringutils import convert_to_unicode
-from mwcp.utils import multi_proc
-
-logger = logging.getLogger(__name__)
-
-# Constants
-DEFAULT_EXCLUDE_FIELDS = (u"debug",)
-INPUT_FILE_PATH = u"inputfilename"  # MUST BE UNICODE
-FILE_EXTENSION = ".json"
-
-# Setting encoding to utf8 is a hotfix for a larger issue
-encode_params = {"encoding": "utf8", "errors": "replace"}
-
-
-def multiproc_test_wrapper(args):
-    """Wrapper function for running tests in multiple processes."""
-    test_case = args[0]
-    try:
-        return test_case.run(*args[1:])
-    except KeyboardInterrupt:
-        return
-
-
-class Tester(object):
-    """DC3-MWCP Tester class"""
-
-    def __init__(
-        self, parser_names=None, nprocs=None, field_names=None, ignore_field_names=DEFAULT_EXCLUDE_FIELDS,
-    ):
-        """
-
-        Run tests and compare produced results to expected results.
-
-        :param [str] parser_names:
-                A list of parser names to run tests for. If the list is empty (default),
-                then test cases for all parsers will be run.
-        :param [str] field_names:
-                A restricted list of fields (metadata key values) that should be compared
-                during testing. If the list is empty (default), then all fields, except those in
-                ignore_field_names will be compared.
-        :param int nprocs: Number of processes to use. (defaults to (3*num_cores)/4)
-        """
-        self.field_names = field_names or []
-        self.ignore_field_names = ignore_field_names
-        self._test_cases = None
-        self._results = []  # Cached results.
-        self._processed = False
-        self._nprocs = nprocs or (3 * mp.cpu_count()) // 4
-        if not parser_names or parser_names == [None]:
-            parser_names = [f"{source.name}:{parser.name}" for source, parser in mwcp.iter_parsers()]
-        self.parser_names = parser_names
-
-    def __iter__(self):
-        return self._iter_results()
-
-    def _iter_results(self):
-        # First yield any cached results.
-        for result in self._results:
-            yield result
-
-        # Run tests in multiprocessing pool (if not already run)
-        if not self._processed:
-            self._processed = True
-            pool = multi_proc.TPool(processes=self._nprocs)
-            test_iter = pool.imap_unordered(multiproc_test_wrapper, [(test_case,) for test_case in self.test_cases])
-            pool.close()
-
-            try:
-                for result in test_iter:
-                    self._results.append(result)
-                    yield result
-            except KeyboardInterrupt:
-                pool.terminate()
-                raise
-
-    @property
-    def test_cases(self):
-        """Returns test cases."""
-        if self._test_cases is None:
-            self._test_cases = []
-            for parser_name in self.parser_names:
-                # We want to iterate parsers in case parser_name represents a set of parsers from different sources.
-                found = False
-                for source, parser in mwcp.iter_parsers(parser_name):
-                    found = True
-                    full_parser_name = "{}:{}".format(source.name, parser.name)
-                    results_file_path = self.get_results_filepath(full_parser_name)
-                    if os.path.isfile(results_file_path):
-                        for expected_results in self.read_results_file(results_file_path):
-                            self._test_cases.append(
-                                TestCase(
-                                    full_parser_name,
-                                    expected_results,
-                                    field_names=self.field_names,
-                                    ignore_field_names=self.ignore_field_names,
-                                )
-                            )
-                    else:
-                        # Warn user if they are missing a test file for a parser group.
-                        logger.warning("Test case file not found: {}".format(results_file_path))
-
-                if not found and parser_name:
-                    # Add a failed results if we have an orphan test.
-                    self._results.append(TestResult(parser=parser_name, passed=False, errors=["Parser not found."]))
-        return self._test_cases
-
-    @property
-    def total(self):
-        """Returns total number of results."""
-        return len(self._results) + len(self.test_cases)
-
-    def gen_results(self, parser_name, input_file_path):
-        """
-        Generate JSON results for the given file using the given parser name.
-        """
-        report = mwcp.run(parser_name, input_file_path)
-        results = report.metadata
-        results[INPUT_FILE_PATH] = convert_to_unicode(input_file_path)
-        return report, results
-
-    def _list_test_files(self, results_list):
-        """
-        Returns a list of the input file paths for the given results_list.
-        """
-        return [results[INPUT_FILE_PATH] for results in results_list]
-
-    def get_results_filepath(self, name, source=None):
-        """
-        Returns the results file path based on the parser name provided and the
-        set testcase directory.
-        """
-        for source, parser in mwcp.iter_parsers(name, source=source):
-            file_name = parser.name + FILE_EXTENSION
-            # Use hardcoded testcase directory if set.
-            testcase_dir = mwcp.config.get("TESTCASE_DIR")
-            if testcase_dir:
-                return os.path.join(testcase_dir, file_name)
-
-            if source.is_pkg:
-                # Dynamically pull based on parser's top level module.
-                test_dir = pkg_resources.resource_filename(source.path, "tests")
-            else:
-                # If source is a directory, assume there is a "tests" folder within it.
-                test_dir = os.path.join(source.path, "tests")
-
-            return os.path.normpath(os.path.join(test_dir, file_name))
-
-        raise ValueError("Invalid parser: {}".format(name))
-
-    def read_results_file(self, results_file_path):
-        """
-        Parses and validates the JSON results file and returns the parsed results_dict.
-        """
-        if not os.path.exists(results_file_path):
-            results = []
-        else:
-            with open(results_file_path) as results_file:
-                results = json.load(results_file)
-
-        # The results file results_dict is expected to be a list of metadata dictionaries
-        if not isinstance(results, list) or not all(isinstance(a, dict) for a in results):
-            raise ValueError("Results file is invalid: {}".format(results_file_path))
-
-        # Resolve input file paths.
-        for testcase in results:
-            # NOTE: Using PureWindowsPath to help convert a Windows path using \
-            #   into / path.
-            #   This helps in-case the test case was originally made with a Windows machine
-            #   but is being tested on Linux.
-            input_file_path = pathlib.PureWindowsPath(testcase[INPUT_FILE_PATH]).as_posix()
-            # expand environment variables
-            input_file_path = os.path.expandvars(input_file_path)
-            # resolve variables
-            input_file_path = input_file_path.format(MALWARE_REPO=mwcp.config.get("MALWARE_REPO", ""))
-            # make relative paths relative to json file
-            input_file_path = os.path.join(os.path.dirname(results_file_path), input_file_path)
-            input_file_path = os.path.abspath(input_file_path)
-            testcase[INPUT_FILE_PATH] = input_file_path
-
-        return results
-
-    def write_results_file(self, results_list, file_path):
-        """
-        Saves the JSON results list to the given file path.
-        :param list[dict] results_list: JSON results list to save
-        :param str file_path: Path to save the results JSON file.
-        """
-        # Replace references to the malware repo with a variable.
-        malware_repo = mwcp.config.get("MALWARE_REPO", None)
-        if malware_repo:
-            for results in results_list:
-                # TODO: Refactor this
-                input_file_path = results[INPUT_FILE_PATH]
-                if input_file_path.startswith(malware_repo):
-                    input_file_path = "{MALWARE_REPO}" + input_file_path[len(malware_repo) :]
-                results[INPUT_FILE_PATH] = input_file_path
-
-        # Write updated data to results file
-        # NOTE: We need to use dumps instead of dump to avoid TypeError.
-        with open(file_path, "w", encoding="utf8") as results_file:
-            results_file.write(str(json.dumps(results_list, indent=4, sort_keys=True)))
-
-    def update_tests(self, force=False):
-        """
-        Updates existing test cases by rerunning parsers.
-
-        :param bool force: Whether to force adding the test case even if errors are encountered
-        """
-        orig_level = logging.root.level
-        logging.root.setLevel(logging.INFO)  # Force info level logs so test cases stay consistent.
-        try:
-            for parser_name in self.parser_names:
-                logger.info(f"Updating test for parser: {parser_name}")
-                results_file_path = self.get_results_filepath(parser_name)
-                if not os.path.isfile(results_file_path):
-                    logger.warning(f"No test case file found for parser: {results_file_path}")
-                    continue
-                results_list = self.read_results_file(results_file_path)
-                for index, file_path in enumerate(self._list_test_files(results_list)):
-                    report, new_results = self.gen_results(parser_name, file_path)
-                    if not new_results:
-                        logger.warning("Empty results for {} in {}, not updating.".format(file_path, results_file_path))
-                        continue
-                    if report.errors and not force:
-                        logger.warning("Results for {} has errors, not updating.".format(file_path))
-                        continue
-
-                    logger.info("Updating results for {} in {}".format(file_path, results_file_path))
-                    results_list[index] = new_results
-
-                self.write_results_file(results_list, results_file_path)
-        finally:
-            logging.root.setLevel(orig_level)
-
-    def add_test(self, file_path, force=False, update=False):
-        """
-        Adds test case for given file path.
-
-        :param str file_path: Path to input file to add.
-        :param bool force: Whether to force adding the test case even if errors are encountered
-        :param bool update: Whether to allow updating the test case if a test for this file already exists.
-        """
-        orig_level = logging.root.level
-        logging.root.setLevel(logging.INFO)  # Force info level logs so test cases stay consistent.
-        try:
-            for parser_name in self.parser_names:
-                results_file_path = self.get_results_filepath(parser_name)
-                results_list = self.read_results_file(results_file_path)
-                input_files = self._list_test_files(results_list)
-
-                if file_path in input_files and not update:
-                    logger.warning("Test case for {} already exists in {}".format(file_path, results_file_path))
-                    continue
-
-                report, new_results = self.gen_results(parser_name, file_path)
-                if not new_results:
-                    logger.warning("Empty results for {} in {}, not adding.".format(file_path, results_file_path))
-                    continue
-                if report.errors and not force:
-                    logger.warning("Results for {} has errors, not adding.".format(file_path))
-                    continue
-
-                if file_path in input_files:
-                    logger.info("Updating results for {} in {}".format(file_path, results_file_path))
-                    index = input_files.index(file_path)
-                    results_list[index] = new_results
-                else:
-                    logger.info("Adding results for {} in {}".format(file_path, results_file_path))
-                    results_list.append(new_results)
-
-                self.write_results_file(results_list, results_file_path)
-        finally:
-            logging.root.setLevel(orig_level)
-
-    def remove_test(self, file_path):
-        """Removes test case for given file path."""
-        for parser_name in self.parser_names:
-            results_file_path = self.get_results_filepath(parser_name)
-            results_list = []
-            removed = False
-            for results in self.read_results_file(results_file_path):
-                if results[INPUT_FILE_PATH] == file_path:
-                    logger.info("Removed results for {} in {}".format(file_path, results_file_path))
-                    removed = True
-                else:
-                    results_list.append(results)
-
-            if removed:
-                self.write_results_file(results_list, results_file_path)
-
-
-class TestCase(object):
-    def __init__(self, parser, expected_results, field_names=None, ignore_field_names=DEFAULT_EXCLUDE_FIELDS):
-        self.input_file_path = expected_results[INPUT_FILE_PATH]
-        self.filename = os.path.basename(self.input_file_path)
-        self.parser = parser
-        self.parser_source, _, self.parser_name = parser.rpartition(":")
-        self.expected_results = expected_results
-        self._field_names = field_names or []
-        self._ignore_field_names = ignore_field_names or []
-
-    def run(self):
-        """Run test case."""
-        start_time = default_timer()
-
-        # Clear any existing loggers to ensure the only logs present are in
-        # the report.
-        logging.root.handlers.clear()
-
-        report = mwcp.run(self.parser, self.input_file_path, log_level=logging.INFO)
-        results = report.metadata
-        results[INPUT_FILE_PATH] = convert_to_unicode(self.input_file_path)
-
-        comparer_results = self._compare_results(self.expected_results, results)
-        passed = all(comparer.passed for comparer in comparer_results)
-
-        done_time = default_timer()
-        run_time = done_time - start_time
-
-        return TestResult(
-            parser=self.parser,
-            input_file_path=self.input_file_path,
-            passed=passed,
-            errors=report.errors,
-            debug=report.logs or None,
-            results=comparer_results,
-            run_time=run_time,
-        )
-
-    def _compare_results(self, results_a, results_b):
-        """
-        Compare two result sets. If the field names list is not empty,
-        then only the fields (metadata key values) in the list will be compared.
-        ignore_field_names fields are not compared unless included in field_names.
-        """
-        results = []
-
-        # Cursory check to remove FILE_INPUT_PATH key from results since it is
-        # a custom added field for test cases
-        if INPUT_FILE_PATH in results_a:
-            results_a = dict(results_a)
-            del results_a[INPUT_FILE_PATH]
-        if INPUT_FILE_PATH in results_b:
-            results_b = dict(results_b)
-            del results_b[INPUT_FILE_PATH]
-
-        # Begin comparing results
-        if self._field_names:
-            for field_name in self._field_names:
-                try:
-                    comparer = self._compare_results_field(results_a, results_b, field_name)
-                except:
-                    comparer = ResultComparer(field_name)
-                    logger.error(traceback.format_exc())
-                results.append(comparer)
-        else:
-            for ignore_field in self._ignore_field_names:
-                results_a.pop(ignore_field, None)
-                results_b.pop(ignore_field, None)
-            all_field_names = set(results_a.keys()).union(list(results_b.keys()))
-            for field_name in all_field_names:
-                try:
-                    comparer = self._compare_results_field(results_a, results_b, field_name)
-                except:
-                    comparer = ResultComparer(field_name)
-                    logger.error(traceback.format_exc())
-                results.append(comparer)
-
-        return results
-
-    def _compare_results_field(self, results_a, results_b, field_name):
-        """
-        Compare the values for a single results field in the two passed in results.
-
-        Args:
-            results_a (dict): MWCP generated result for a given file using a given parser.
-            results_b (dict): MWCP generated result for a given file using a given parser.
-        """
-
-        # Check if provided field_name is a valid key (based on fields.json)
-        try:
-            field_name_u = convert_to_unicode(field_name)
-        except:
-            raise Exception("Failed to convert field name '{}' to unicode.".format(field_name))
-
-        # Stolen from Reporter/Runner.
-        # TODO: Look into refactoring to use pytest entirely?
-        with open(config.get("FIELDS_PATH"), "rb") as f:
-            fields = json.load(f)
-
-        try:
-            field_type = fields[field_name_u]["type"]
-        except:
-            raise Exception("Key error. Field name '{}' was not identified as a standardized field.".format(field_name))
-
-        # Establish value to send for comparison
-        value_a = None
-        value_b = None
-        if field_name_u in results_a:
-            value_a = results_a[field_name_u]
-        if field_name_u in results_b:
-            value_b = results_b[field_name_u]
-
-        # Now compare results based on field type (see "fields.json" for more
-        # details)
-        if field_type == "listofstrings":
-            comparer = ListOfStringsComparer(field_name_u)
-            comparer.compare(value_a, value_b)
-        elif field_type == "listofstringtuples":
-            comparer = ListOfStringTuplesComparer(field_name_u)
-            comparer.compare(value_a, value_b)
-        elif field_type == "dictofstrings":
-            comparer = DictOfStringsComparer(field_name_u)
-            comparer.compare(value_a, value_b)
-        else:
-            raise Exception("Unhandled field type '{}' found for field name '{}'.".format(field_type, field_name))
-
-        return comparer
-
-
-class TestResult(object):
-    def __init__(self, parser, passed, input_file_path=None, errors=None, debug=None, results=None, run_time=None):
-        self.parser = parser
-        self.parser_source, _, self.parser_name = parser.rpartition(":")
-        self.input_file_path = input_file_path or "N/A"
-        self.filename = os.path.basename(input_file_path) if input_file_path else "N/A"
-        self.passed = passed
-        self.errors = errors or []
-        self.debug = debug or []
-        self.results = results or []
-        self.run_time = run_time or 0
-
-    def print(self, failed_tests=True, passed_tests=True, json_format=False):
-        """
-        print test result based on provided parameters.
-
-        :param bool failed_tests: Whether to show failed tests.
-        :param bool passed_tests: Whether to show passed tests.
-        :param bool json_format: Whether to format results as json.
-        """
-        # TODO: Do we need the json option?
-        if json_format:
-            passed = self.passed
-            if (passed and passed_tests) or (not passed and failed_tests):
-                print(json.dumps(self, indent=4, cls=MyEncoder))
-        else:
-            separator = ""
-
-            filtered_output = ""
-            passed = self.passed
-            if passed and passed_tests:
-                filtered_output += "Parser Name = {}\n".format(self.parser)
-                if self.input_file_path and self.input_file_path != "N/A":
-                    filtered_output += "Input Filename = {}\n".format(self.input_file_path)
-                filtered_output += "Tests Passed = {}\n".format(self.passed)
-            elif not passed and failed_tests:
-                filtered_output += "Parser Name = {}\n".format(self.parser)
-                if self.input_file_path and self.input_file_path != "N/A":
-                    filtered_output += "Input Filename = {}\n".format(self.input_file_path)
-                filtered_output += "Tests Passed = {}\n".format(self.passed)
-                filtered_output += "Errors = {}".format("\n" if self.errors else "None\n")
-                if self.errors:
-                    for entry in self.errors:
-                        filtered_output += "\t{0}\n".format(entry)
-                filtered_output += "Debug Logs = {}".format("\n" if self.debug else "None\n")
-                if self.debug:
-                    for entry in self.debug:
-                        filtered_output += "\t{0}\n".format(entry)
-                if self.results:
-                    filtered_output += "Results =\n"
-                    for result in self.results:
-                        if not result.passed:
-                            filtered_output += "{0}\n".format(result)
-
-            if filtered_output:
-                filtered_output += "{0}\n".format(separator)
-                print(filtered_output.encode("ascii", "backslashreplace").decode())
-
-
-####################################################
-# Comparer classes for various MWCP field types
-####################################################
-
-
-class ResultComparer(object):
-    def __init__(self, field):
-        self.field = field
-        self.passed = False
-        self.missing = []  # Entries found in test case but not new results
-        self.unexpected = []  # Entries found in new results but not test case
-
-    def compare(self, test_case_results=None, new_results=None):
-        """Compare two result sets and document any differences."""
-
-        self.missing = []
-        self.unexpected = []
-
-        self.field_compare(test_case_results, new_results)
-
-        self.passed = not bool(self.missing or self.unexpected)
-
-    def field_compare(self, test_case_results, new_results):
-        """Field specific compare function."""
-        # Override in child classes
-        raise NotImplementedError()
-
-    def get_report(self, json=False, tabs=1):
-        """
-        If json parameter is False, get report as a unicode string.
-        If json parameter is True, get report as a dictionary.
-        """
-
-        if json:
-            return self.__dict__
-        else:
-            tab = tabs * "\t"
-            tab_1 = tab + "\t"
-            tab_2 = tab_1 + "\t"
-            report = tab + "{}:\n".format(self.field)
-            report += tab_1 + "Passed: {}\n".format(self.passed)
-            if self.missing:
-                report += tab_1 + "Missing From New Results:\n"
-                for item in self.missing:
-                    report += tab_2 + "{}\n".format(convert_to_unicode(item))
-            if self.unexpected:
-                report += tab_1 + "Unexpected New Results:\n"
-                for item in self.unexpected:
-                    report += tab_2 + "{}\n".format(convert_to_unicode(item))
-
-            return report
-
-    def __bytes__(self):
-        return self.get_report().encode("utf8")
-
-    def __unicode__(self):
-        return self.get_report()
-
-    def __str__(self):
-        if sys.version_info >= (3, 0):
-            return self.__unicode__()
-        else:
-            return self.__bytes__()
-
-    def __repr__(self):
-        return self.__str__()
-
-
-class ListOfStringsComparer(ResultComparer):
-    def field_compare(self, test_case_results, new_results):
-        """Compare each string in a list of strings."""
-        list_test = [] if not test_case_results else test_case_results
-        list_new = [] if not new_results else new_results
-
-        self.missing += list(map(repr, set(list_test) - set(list_new)))
-        self.unexpected += list(map(repr, set(list_new) - set(list_test)))
-
-
-class ListOfStringTuplesComparer(ResultComparer):
-    def field_compare(self, test_case_results, new_results):
-        """Compare each tuple of strings in a list of tuples."""
-        set_list_test = []
-        set_list_new = []
-        if test_case_results:
-            set_list_test = [set(x) for x in test_case_results]
-        if new_results:
-            set_list_new = [set(x) for x in new_results]
-
-        for set_test in set_list_test:
-            if set_test not in set_list_new:
-                # Append the list entry here instead of the set to preserve the
-                # entries ordering
-                self.missing.append(repr(test_case_results[set_list_test.index(set_test)]))
-
-        for set_new in set_list_new:
-            if set_new not in set_list_test:
-                # Append the list entry here instead of the set to preserve the
-                # entries ordering
-                self.unexpected.append(repr(new_results[set_list_new.index(set_new)]))
-
-
-class DictOfStringsComparer(ResultComparer):
-    def field_compare(self, test_case_results, new_results):
-        """Compare each key value pair in a dictionary of strings."""
-        dict_test = {} if not test_case_results else test_case_results
-        dict_new = {} if not new_results else new_results
-
-        for key in dict_test:
-            if key not in dict_new:
-                self.missing.append(u"{}: {!r}".format(key, dict_test[key]))
-            elif set(dict_test[key]) != set(dict_new[key]):
-                self.missing.append(u"{}: {!r}".format(key, dict_test[key]))
-
-        for key in dict_new:
-            if key not in dict_test:
-                self.unexpected.append(u"{}: {!r}".format(key, dict_new[key]))
-            elif set(dict_new[key]) != set(dict_test[key]):
-                self.unexpected.append(u"{}: {!r}".format(key, dict_new[key]))
-
-
-####################################################
-# JSON encoders
-####################################################
-
-
-class MyEncoder(json.JSONEncoder):
-    def default(self, o):
-        return o.__dict__
+"""
+Test case support for DC3-MWCP. Parser output is stored in a json file per parser. To run test cases,
+parser is re-run and compared to previous results.
+"""
+
+import json
+import multiprocessing as mp
+import logging
+import os
+import pathlib
+import sys
+import traceback
+from timeit import default_timer
+
+try:
+    import pkg_resources
+except ImportError:
+    pkg_resources = None
+
+import mwcp
+from mwcp import config
+from mwcp.utils.stringutils import convert_to_unicode
+from mwcp.utils import multi_proc
+
+logger = logging.getLogger(__name__)
+
+# Constants
+DEFAULT_EXCLUDE_FIELDS = (u"debug",)
+INPUT_FILE_PATH = u"inputfilename"  # MUST BE UNICODE
+FILE_EXTENSION = ".json"
+
+# Setting encoding to utf8 is a hotfix for a larger issue
+encode_params = {"encoding": "utf8", "errors": "replace"}
+
+
+def multiproc_test_wrapper(args):
+    """Wrapper function for running tests in multiple processes."""
+    test_case = args[0]
+    try:
+        return test_case.run(*args[1:])
+    except KeyboardInterrupt:
+        return
+
+
+class Tester(object):
+    """DC3-MWCP Tester class"""
+
+    def __init__(
+        self, parser_names=None, nprocs=None, field_names=None, ignore_field_names=DEFAULT_EXCLUDE_FIELDS,
+    ):
+        """
+
+        Run tests and compare produced results to expected results.
+
+        :param [str] parser_names:
+                A list of parser names to run tests for. If the list is empty (default),
+                then test cases for all parsers will be run.
+        :param [str] field_names:
+                A restricted list of fields (metadata key values) that should be compared
+                during testing. If the list is empty (default), then all fields, except those in
+                ignore_field_names will be compared.
+        :param int nprocs: Number of processes to use. (defaults to (3*num_cores)/4)
+        """
+        self.field_names = field_names or []
+        self.ignore_field_names = ignore_field_names
+        self._test_cases = None
+        self._results = []  # Cached results.
+        self._processed = False
+        self._nprocs = nprocs or (3 * mp.cpu_count()) // 4
+        if not parser_names or parser_names == [None]:
+            parser_names = [f"{source.name}:{parser.name}" for source, parser in mwcp.iter_parsers()]
+        self.parser_names = parser_names
+
+    def __iter__(self):
+        return self._iter_results()
+
+    def _iter_results(self):
+        # First yield any cached results.
+        for result in self._results:
+            yield result
+
+        # Run tests in multiprocessing pool (if not already run)
+        if not self._processed:
+            self._processed = True
+            pool = multi_proc.TPool(processes=self._nprocs)
+            test_iter = pool.imap_unordered(multiproc_test_wrapper, [(test_case,) for test_case in self.test_cases])
+            pool.close()
+
+            try:
+                for result in test_iter:
+                    self._results.append(result)
+                    yield result
+            except KeyboardInterrupt:
+                pool.terminate()
+                raise
+
+    @property
+    def test_cases(self):
+        """Returns test cases."""
+        if self._test_cases is None:
+            self._test_cases = []
+            for parser_name in self.parser_names:
+                # We want to iterate parsers in case parser_name represents a set of parsers from different sources.
+                found = False
+                for source, parser in mwcp.iter_parsers(parser_name):
+                    found = True
+                    full_parser_name = "{}:{}".format(source.name, parser.name)
+                    results_file_path = self.get_results_filepath(full_parser_name)
+                    if os.path.isfile(results_file_path):
+                        for expected_results in self.read_results_file(results_file_path):
+                            self._test_cases.append(
+                                TestCase(
+                                    full_parser_name,
+                                    expected_results,
+                                    field_names=self.field_names,
+                                    ignore_field_names=self.ignore_field_names,
+                                )
+                            )
+                    else:
+                        # Warn user if they are missing a test file for a parser group.
+                        logger.warning("Test case file not found: {}".format(results_file_path))
+
+                if not found and parser_name:
+                    # Add a failed results if we have an orphan test.
+                    self._results.append(TestResult(parser=parser_name, passed=False, errors=["Parser not found."]))
+        return self._test_cases
+
+    @property
+    def total(self):
+        """Returns total number of results."""
+        return len(self._results) + len(self.test_cases)
+
+    def gen_results(self, parser_name, input_file_path):
+        """
+        Generate JSON results for the given file using the given parser name.
+        """
+        report = mwcp.run(parser_name, input_file_path)
+        results = report.metadata
+        results[INPUT_FILE_PATH] = convert_to_unicode(input_file_path)
+        return report, results
+
+    def _list_test_files(self, results_list):
+        """
+        Returns a list of the input file paths for the given results_list.
+        """
+        return [results[INPUT_FILE_PATH] for results in results_list]
+
+    def get_results_filepath(self, name, source=None):
+        """
+        Returns the results file path based on the parser name provided and the
+        set testcase directory.
+        """
+        for source, parser in mwcp.iter_parsers(name, source=source):
+            file_name = parser.name + FILE_EXTENSION
+            # Use hardcoded testcase directory if set.
+            testcase_dir = mwcp.config.get("TESTCASE_DIR")
+            if testcase_dir:
+                return os.path.join(testcase_dir, file_name)
+
+            if source.is_pkg:
+                # Dynamically pull based on parser's top level module.
+                test_dir = pkg_resources.resource_filename(source.path, "tests")
+            else:
+                # If source is a directory, assume there is a "tests" folder within it.
+                test_dir = os.path.join(source.path, "tests")
+
+            return os.path.normpath(os.path.join(test_dir, file_name))
+
+        raise ValueError("Invalid parser: {}".format(name))
+
+    def read_results_file(self, results_file_path):
+        """
+        Parses and validates the JSON results file and returns the parsed results_dict.
+        """
+        if not os.path.exists(results_file_path):
+            results = []
+        else:
+            with open(results_file_path) as results_file:
+                results = json.load(results_file)
+
+        # The results file results_dict is expected to be a list of metadata dictionaries
+        if not isinstance(results, list) or not all(isinstance(a, dict) for a in results):
+            raise ValueError("Results file is invalid: {}".format(results_file_path))
+
+        # Resolve input file paths.
+        for testcase in results:
+            # NOTE: Using PureWindowsPath to help convert a Windows path using \
+            #   into / path.
+            #   This helps in-case the test case was originally made with a Windows machine
+            #   but is being tested on Linux.
+            input_file_path = pathlib.PureWindowsPath(testcase[INPUT_FILE_PATH]).as_posix()
+            # expand environment variables
+            input_file_path = os.path.expandvars(input_file_path)
+            # resolve variables
+            input_file_path = input_file_path.format(MALWARE_REPO=mwcp.config.get("MALWARE_REPO", ""))
+            # make relative paths relative to json file
+            input_file_path = os.path.join(os.path.dirname(results_file_path), input_file_path)
+            input_file_path = os.path.abspath(input_file_path)
+            testcase[INPUT_FILE_PATH] = input_file_path
+
+        return results
+
+    def write_results_file(self, results_list, file_path):
+        """
+        Saves the JSON results list to the given file path.
+        :param list[dict] results_list: JSON results list to save
+        :param str file_path: Path to save the results JSON file.
+        """
+        # Replace references to the malware repo with a variable.
+        malware_repo = mwcp.config.get("MALWARE_REPO", None)
+        if malware_repo:
+            for results in results_list:
+                # TODO: Refactor this
+                input_file_path = results[INPUT_FILE_PATH]
+                if input_file_path.startswith(malware_repo):
+                    input_file_path = "{MALWARE_REPO}" + input_file_path[len(malware_repo) :]
+                results[INPUT_FILE_PATH] = input_file_path
+
+        # Write updated data to results file
+        # NOTE: We need to use dumps instead of dump to avoid TypeError.
+        with open(file_path, "w", encoding="utf8") as results_file:
+            results_file.write(str(json.dumps(results_list, indent=4, sort_keys=True)))
+
+    def update_tests(self, force=False):
+        """
+        Updates existing test cases by rerunning parsers.
+
+        :param bool force: Whether to force adding the test case even if errors are encountered
+        """
+        orig_level = logging.root.level
+        logging.root.setLevel(logging.INFO)  # Force info level logs so test cases stay consistent.
+        try:
+            for parser_name in self.parser_names:
+                logger.info(f"Updating test for parser: {parser_name}")
+                results_file_path = self.get_results_filepath(parser_name)
+                if not os.path.isfile(results_file_path):
+                    logger.warning(f"No test case file found for parser: {results_file_path}")
+                    continue
+                results_list = self.read_results_file(results_file_path)
+                for index, file_path in enumerate(self._list_test_files(results_list)):
+                    report, new_results = self.gen_results(parser_name, file_path)
+                    if not new_results:
+                        logger.warning("Empty results for {} in {}, not updating.".format(file_path, results_file_path))
+                        continue
+                    if report.errors and not force:
+                        logger.warning("Results for {} has errors, not updating.".format(file_path))
+                        continue
+
+                    logger.info("Updating results for {} in {}".format(file_path, results_file_path))
+                    results_list[index] = new_results
+
+                self.write_results_file(results_list, results_file_path)
+        finally:
+            logging.root.setLevel(orig_level)
+
+    def add_test(self, file_path, force=False, update=False):
+        """
+        Adds test case for given file path.
+
+        :param str file_path: Path to input file to add.
+        :param bool force: Whether to force adding the test case even if errors are encountered
+        :param bool update: Whether to allow updating the test case if a test for this file already exists.
+        """
+        orig_level = logging.root.level
+        logging.root.setLevel(logging.INFO)  # Force info level logs so test cases stay consistent.
+        try:
+            for parser_name in self.parser_names:
+                results_file_path = self.get_results_filepath(parser_name)
+                results_list = self.read_results_file(results_file_path)
+                input_files = self._list_test_files(results_list)
+
+                if file_path in input_files and not update:
+                    logger.warning("Test case for {} already exists in {}".format(file_path, results_file_path))
+                    continue
+
+                report, new_results = self.gen_results(parser_name, file_path)
+                if not new_results:
+                    logger.warning("Empty results for {} in {}, not adding.".format(file_path, results_file_path))
+                    continue
+                if report.errors and not force:
+                    logger.warning("Results for {} has errors, not adding.".format(file_path))
+                    continue
+
+                if file_path in input_files:
+                    logger.info("Updating results for {} in {}".format(file_path, results_file_path))
+                    index = input_files.index(file_path)
+                    results_list[index] = new_results
+                else:
+                    logger.info("Adding results for {} in {}".format(file_path, results_file_path))
+                    results_list.append(new_results)
+
+                self.write_results_file(results_list, results_file_path)
+        finally:
+            logging.root.setLevel(orig_level)
+
+    def remove_test(self, file_path):
+        """Removes test case for given file path."""
+        for parser_name in self.parser_names:
+            results_file_path = self.get_results_filepath(parser_name)
+            results_list = []
+            removed = False
+            for results in self.read_results_file(results_file_path):
+                if results[INPUT_FILE_PATH] == file_path:
+                    logger.info("Removed results for {} in {}".format(file_path, results_file_path))
+                    removed = True
+                else:
+                    results_list.append(results)
+
+            if removed:
+                self.write_results_file(results_list, results_file_path)
+
+
+class TestCase(object):
+    def __init__(self, parser, expected_results, field_names=None, ignore_field_names=DEFAULT_EXCLUDE_FIELDS):
+        self.input_file_path = expected_results[INPUT_FILE_PATH]
+        self.filename = os.path.basename(self.input_file_path)
+        self.parser = parser
+        self.parser_source, _, self.parser_name = parser.rpartition(":")
+        self.expected_results = expected_results
+        self._field_names = field_names or []
+        self._ignore_field_names = ignore_field_names or []
+
+    def run(self):
+        """Run test case."""
+        start_time = default_timer()
+
+        # Clear any existing loggers to ensure the only logs present are in
+        # the report.
+        logging.root.handlers.clear()
+
+        report = mwcp.run(self.parser, self.input_file_path, log_level=logging.INFO)
+        results = report.metadata
+        results[INPUT_FILE_PATH] = convert_to_unicode(self.input_file_path)
+
+        comparer_results = self._compare_results(self.expected_results, results)
+        passed = all(comparer.passed for comparer in comparer_results)
+
+        done_time = default_timer()
+        run_time = done_time - start_time
+
+        return TestResult(
+            parser=self.parser,
+            input_file_path=self.input_file_path,
+            passed=passed,
+            errors=report.errors,
+            debug=report.logs or None,
+            results=comparer_results,
+            run_time=run_time,
+        )
+
+    def _compare_results(self, results_a, results_b):
+        """
+        Compare two result sets. If the field names list is not empty,
+        then only the fields (metadata key values) in the list will be compared.
+        ignore_field_names fields are not compared unless included in field_names.
+        """
+        results = []
+
+        # Cursory check to remove FILE_INPUT_PATH key from results since it is
+        # a custom added field for test cases
+        if INPUT_FILE_PATH in results_a:
+            results_a = dict(results_a)
+            del results_a[INPUT_FILE_PATH]
+        if INPUT_FILE_PATH in results_b:
+            results_b = dict(results_b)
+            del results_b[INPUT_FILE_PATH]
+
+        # Begin comparing results
+        if self._field_names:
+            for field_name in self._field_names:
+                try:
+                    comparer = self._compare_results_field(results_a, results_b, field_name)
+                except:
+                    comparer = ResultComparer(field_name)
+                    logger.error(traceback.format_exc())
+                results.append(comparer)
+        else:
+            for ignore_field in self._ignore_field_names:
+                results_a.pop(ignore_field, None)
+                results_b.pop(ignore_field, None)
+            all_field_names = set(results_a.keys()).union(list(results_b.keys()))
+            for field_name in all_field_names:
+                try:
+                    comparer = self._compare_results_field(results_a, results_b, field_name)
+                except:
+                    comparer = ResultComparer(field_name)
+                    logger.error(traceback.format_exc())
+                results.append(comparer)
+
+        return results
+
+    def _compare_results_field(self, results_a, results_b, field_name):
+        """
+        Compare the values for a single results field in the two passed in results.
+
+        Args:
+            results_a (dict): MWCP generated result for a given file using a given parser.
+            results_b (dict): MWCP generated result for a given file using a given parser.
+        """
+
+        # Check if provided field_name is a valid key (based on fields.json)
+        try:
+            field_name_u = convert_to_unicode(field_name)
+        except:
+            raise Exception("Failed to convert field name '{}' to unicode.".format(field_name))
+
+        # Stolen from Reporter/Runner.
+        # TODO: Look into refactoring to use pytest entirely?
+        with open(config.get("FIELDS_PATH"), "rb") as f:
+            fields = json.load(f)
+
+        try:
+            field_type = fields[field_name_u]["type"]
+        except:
+            raise Exception("Key error. Field name '{}' was not identified as a standardized field.".format(field_name))
+
+        # Establish value to send for comparison
+        value_a = None
+        value_b = None
+        if field_name_u in results_a:
+            value_a = results_a[field_name_u]
+        if field_name_u in results_b:
+            value_b = results_b[field_name_u]
+
+        # Now compare results based on field type (see "fields.json" for more
+        # details)
+        if field_type == "listofstrings":
+            comparer = ListOfStringsComparer(field_name_u)
+            comparer.compare(value_a, value_b)
+        elif field_type == "listofstringtuples":
+            comparer = ListOfStringTuplesComparer(field_name_u)
+            comparer.compare(value_a, value_b)
+        elif field_type == "dictofstrings":
+            comparer = DictOfStringsComparer(field_name_u)
+            comparer.compare(value_a, value_b)
+        else:
+            raise Exception("Unhandled field type '{}' found for field name '{}'.".format(field_type, field_name))
+
+        return comparer
+
+
+class TestResult(object):
+    def __init__(self, parser, passed, input_file_path=None, errors=None, debug=None, results=None, run_time=None):
+        self.parser = parser
+        self.parser_source, _, self.parser_name = parser.rpartition(":")
+        self.input_file_path = input_file_path or "N/A"
+        self.filename = os.path.basename(input_file_path) if input_file_path else "N/A"
+        self.passed = passed
+        self.errors = errors or []
+        self.debug = debug or []
+        self.results = results or []
+        self.run_time = run_time or 0
+
+    def print(self, failed_tests=True, passed_tests=True, json_format=False):
+        """
+        print test result based on provided parameters.
+
+        :param bool failed_tests: Whether to show failed tests.
+        :param bool passed_tests: Whether to show passed tests.
+        :param bool json_format: Whether to format results as json.
+        """
+        # TODO: Do we need the json option?
+        if json_format:
+            passed = self.passed
+            if (passed and passed_tests) or (not passed and failed_tests):
+                print(json.dumps(self, indent=4, cls=MyEncoder))
+        else:
+            separator = ""
+
+            filtered_output = ""
+            passed = self.passed
+            if passed and passed_tests:
+                filtered_output += "Parser Name = {}\n".format(self.parser)
+                if self.input_file_path and self.input_file_path != "N/A":
+                    filtered_output += "Input Filename = {}\n".format(self.input_file_path)
+                filtered_output += "Tests Passed = {}\n".format(self.passed)
+            elif not passed and failed_tests:
+                filtered_output += "Parser Name = {}\n".format(self.parser)
+                if self.input_file_path and self.input_file_path != "N/A":
+                    filtered_output += "Input Filename = {}\n".format(self.input_file_path)
+                filtered_output += "Tests Passed = {}\n".format(self.passed)
+                filtered_output += "Errors = {}".format("\n" if self.errors else "None\n")
+                if self.errors:
+                    for entry in self.errors:
+                        filtered_output += "\t{0}\n".format(entry)
+                filtered_output += "Debug Logs = {}".format("\n" if self.debug else "None\n")
+                if self.debug:
+                    for entry in self.debug:
+                        filtered_output += "\t{0}\n".format(entry)
+                if self.results:
+                    filtered_output += "Results =\n"
+                    for result in self.results:
+                        if not result.passed:
+                            filtered_output += "{0}\n".format(result)
+
+            if filtered_output:
+                filtered_output += "{0}\n".format(separator)
+                print(filtered_output.encode("ascii", "backslashreplace").decode())
+
+
+####################################################
+# Comparer classes for various MWCP field types
+####################################################
+
+
+class ResultComparer(object):
+    def __init__(self, field):
+        self.field = field
+        self.passed = False
+        self.missing = []  # Entries found in test case but not new results
+        self.unexpected = []  # Entries found in new results but not test case
+
+    def compare(self, test_case_results=None, new_results=None):
+        """Compare two result sets and document any differences."""
+
+        self.missing = []
+        self.unexpected = []
+
+        self.field_compare(test_case_results, new_results)
+
+        self.passed = not bool(self.missing or self.unexpected)
+
+    def field_compare(self, test_case_results, new_results):
+        """Field specific compare function."""
+        # Override in child classes
+        raise NotImplementedError()
+
+    def get_report(self, json=False, tabs=1):
+        """
+        If json parameter is False, get report as a unicode string.
+        If json parameter is True, get report as a dictionary.
+        """
+
+        if json:
+            return self.__dict__
+        else:
+            tab = tabs * "\t"
+            tab_1 = tab + "\t"
+            tab_2 = tab_1 + "\t"
+            report = tab + "{}:\n".format(self.field)
+            report += tab_1 + "Passed: {}\n".format(self.passed)
+            if self.missing:
+                report += tab_1 + "Missing From New Results:\n"
+                for item in self.missing:
+                    report += tab_2 + "{}\n".format(convert_to_unicode(item))
+            if self.unexpected:
+                report += tab_1 + "Unexpected New Results:\n"
+                for item in self.unexpected:
+                    report += tab_2 + "{}\n".format(convert_to_unicode(item))
+
+            return report
+
+    def __bytes__(self):
+        return self.get_report().encode("utf8")
+
+    def __unicode__(self):
+        return self.get_report()
+
+    def __str__(self):
+        if sys.version_info >= (3, 0):
+            return self.__unicode__()
+        else:
+            return self.__bytes__()
+
+    def __repr__(self):
+        return self.__str__()
+
+
+class ListOfStringsComparer(ResultComparer):
+    def field_compare(self, test_case_results, new_results):
+        """Compare each string in a list of strings."""
+        list_test = [] if not test_case_results else test_case_results
+        list_new = [] if not new_results else new_results
+
+        self.missing += list(map(repr, set(list_test) - set(list_new)))
+        self.unexpected += list(map(repr, set(list_new) - set(list_test)))
+
+
+class ListOfStringTuplesComparer(ResultComparer):
+    def field_compare(self, test_case_results, new_results):
+        """Compare each tuple of strings in a list of tuples."""
+        set_list_test = []
+        set_list_new = []
+        if test_case_results:
+            set_list_test = [set(x) for x in test_case_results]
+        if new_results:
+            set_list_new = [set(x) for x in new_results]
+
+        for set_test in set_list_test:
+            if set_test not in set_list_new:
+                # Append the list entry here instead of the set to preserve the
+                # entries ordering
+                self.missing.append(repr(test_case_results[set_list_test.index(set_test)]))
+
+        for set_new in set_list_new:
+            if set_new not in set_list_test:
+                # Append the list entry here instead of the set to preserve the
+                # entries ordering
+                self.unexpected.append(repr(new_results[set_list_new.index(set_new)]))
+
+
+class DictOfStringsComparer(ResultComparer):
+    def field_compare(self, test_case_results, new_results):
+        """Compare each key value pair in a dictionary of strings."""
+        dict_test = {} if not test_case_results else test_case_results
+        dict_new = {} if not new_results else new_results
+
+        for key in dict_test:
+            if key not in dict_new:
+                self.missing.append(u"{}: {!r}".format(key, dict_test[key]))
+            elif set(dict_test[key]) != set(dict_new[key]):
+                self.missing.append(u"{}: {!r}".format(key, dict_test[key]))
+
+        for key in dict_new:
+            if key not in dict_test:
+                self.unexpected.append(u"{}: {!r}".format(key, dict_new[key]))
+            elif set(dict_new[key]) != set(dict_test[key]):
+                self.unexpected.append(u"{}: {!r}".format(key, dict_new[key]))
+
+
+####################################################
+# JSON encoders
+####################################################
+
+
+class MyEncoder(json.JSONEncoder):
+    def default(self, o):
+        return o.__dict__
```

### Comparing `mwcp-3.8.0/mwcp/testing.py` & `mwcp-3.9.0/mwcp/testing.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,347 +1,347 @@
-"""
-Utilities for managing parser tests (and the malware repository)
-"""
-
-import collections
-import hashlib
-import json
-import logging
-import pathlib
-import re
-import shutil
-from dataclasses import dataclass
-from typing import Iterable, Union, List
-
-import pkg_resources
-
-import mwcp
-from mwcp import registry
-
-logger = logging.getLogger(__name__)
-
-
-@dataclass
-class TestCase:
-    name: str
-    md5: str
-    results_path: pathlib.Path
-
-    def update(self, force=False) -> bool:
-        """
-        Updates test case based on currently generated results.
-
-        :param force: Whether to force adding the test case even if errors are encountered
-        :returns: Whether update was successful.
-        """
-        results_path = self.results_path
-        with open(results_path, "r") as fo:
-            old_results = json.load(fo)
-        parser_name = old_results["parser"]
-
-        file_path = get_path_in_malware_repo(md5=self.md5)
-        if not file_path.exists():
-            logger.warning(f"Unable to update {self.name}. Missing {file_path}")
-            return False
-
-        report = mwcp.run(parser_name, data=file_path.read_bytes(), log_level=logging.INFO)
-        if report.errors and not force:
-            logger.warning(f"Results for {self.name} has the following errors, not updating:")
-            logger.warning("\n".join(report.errors))
-            return False
-
-        # Don't bother updating if it only updates the mwcp version.
-        new_results = report.as_json_dict()
-        new_results["mwcp_version"] = old_results["mwcp_version"]
-        if new_results == old_results:
-            return True
-
-        logger.info(f"Updating results for {file_path} in {results_path}")
-        results_path.write_text(report.as_json())
-        return True
-
-
-def get_path_in_malware_repo(file_path: Union[str, pathlib.Path] = None, md5: str = None) -> pathlib.Path:
-    """
-    Gets file path for a file in the malware_repo based on the given md5 or md5 of the given file_path.
-
-    :param file_path: Path to file to hash in order to obtain the equivalent file path in the malware repo.
-    :param md5: All or partial md5 of sample to get from malware repo.
-
-    :raises ValueError: If sample doesn't exists in malware repo.
-    """
-    malware_repo = mwcp.config.get("MALWARE_REPO")
-    if not malware_repo:
-        raise ValueError("Malware Repository not set.")
-    if file_path:
-        with open(file_path, "rb") as fo:
-            md5 = hashlib.md5(fo.read()).hexdigest()
-    if not md5:
-        raise ValueError(f"Missing file_path or md5 parameter.")
-
-    # If md5 is partial, try to figure out which md5 we want by iterating the directory.
-    if len(md5) < 4:
-        raise ValueError(f"Unable to determine md5 from '{md5}'. Must be at least 4 characters.")
-
-    if len(md5) < 32:
-        sub_dir = pathlib.Path(malware_repo, md5[:4])
-        if not sub_dir.exists():
-            raise ValueError(f"Failed to find sample starting with the md5 '{md5}'.")
-        file_paths = []
-        for file_path in sub_dir.iterdir():
-            if file_path.name.startswith(md5):
-                file_paths.append(file_path)
-        if not file_paths:
-            raise ValueError(f"Failed to find sample starting with the md5 '{md5}'.")
-        if len(file_paths) > 1:
-            md5s = "\t\n".join(file_path.name for file_path in file_paths)
-            raise ValueError(f"Found multiple samples starting with  the md5 '{md5}': \n\t{md5s}")
-        return file_paths[0]
-
-    return pathlib.Path(malware_repo, md5[:4], md5)
-
-
-def add_to_malware_repo(file_path: Union[str, pathlib.Path]) -> pathlib.Path:
-    """
-    Adds the given file path to the malware repo.
-    Returns resulting destination path.
-    """
-    file_path = pathlib.Path(file_path)
-    dest_file_path = get_path_in_malware_repo(file_path)
-
-    if dest_file_path.exists():
-        logger.info(f"File already exists in malware repo: {dest_file_path}")
-        return dest_file_path
-
-    dest_file_path.parent.mkdir(parents=True, exist_ok=True)
-
-    logger.info(f"Copying {file_path} to {dest_file_path}")
-    shutil.copy(file_path, dest_file_path)
-    return dest_file_path
-
-
-def _get_testcase_dir_from_source(source: registry.Source) -> pathlib.Path:
-    """
-    Returns the testcase directory for the given source.
-    """
-    if source.is_pkg:
-        # Dynamically pull based on top level module.
-        return pathlib.Path(pkg_resources.resource_filename(source.path, "tests"))
-
-    # If source is a directory, assume there is a "tests" folder within it.
-    return pathlib.Path(source.path, "tests")
-
-
-def get_testcase_dir(source: registry.Source) -> pathlib.Path:
-    """
-    Returns the testcase directory for the given parser name or source.
-    """
-    # Use hardcoded testcase directory if set.
-    testcase_dir = mwcp.config.get("TESTCASE_DIR")
-    if testcase_dir:
-        return pathlib.Path(testcase_dir, source.name)
-
-    return _get_testcase_dir_from_source(source)
-
-
-def iter_test_cases(source: registry.Source = None, parsers: List[str] = None) -> Iterable[TestCase]:
-    """
-    Iterates the test cases discovered from a specific or all registered sources.
-
-    :param source: Optional source to obtain test cases for.
-    :param parsers: List of parser names for tests cases.
-    :yields: tests cases
-    """
-    # If parser names provided, iterate test cases just for those parsers.
-    if parsers:
-        cache = set()
-        for parser_name in parsers:
-            if source:
-                for test_case in iter_test_cases(source):
-                    if parser_name in test_case.name:
-                        yield test_case
-            else:
-                for source, parser in mwcp.iter_parsers(parser_name):
-                    if source not in cache:
-                        cache.add(source)
-                        for test_case in iter_test_cases(source):
-                            if parser_name in test_case.name:
-                                yield test_case
-        return
-
-    testcase_dirs = []
-    # First see if user provided a global testcase directory that overrides all sources.
-    # Test case directories are organized into sub directories based on source name.
-    testcase_dir = mwcp.config.get("TESTCASE_DIR")
-    if testcase_dir:
-        testcase_dir = pathlib.Path(testcase_dir)
-        for source_dir in testcase_dir.iterdir():
-            if source_dir.is_dir() and registry.is_source(source_dir.name):
-                testcase_dirs.append((source_dir.name, source_dir))
-
-        # If we don't find any testcase directories, user probably provided a directory
-        # not structured as expected.
-        # In this case, let's just recursively look for all .json files.
-        if not testcase_dirs:
-            for file_path in testcase_dir.glob("**/[!_]*.json"):
-                with open(file_path, "r") as fp:
-                    data = json.load(fp)
-                try:
-                    yield TestCase(data["parser"], data["input_file"]["md5"], file_path)
-                except (KeyError, TypeError):
-                    logger.warning(f"Failed to collect testcase file: {file_path}")
-            return
-
-    # Otherwise we need to pull test case directories based on location of source.
-    else:
-        sources = [source] if source else registry.get_sources()
-        for source in sources:
-            testcase_dirs.append((source.name, _get_testcase_dir_from_source(source)))
-
-    for source_name, testcase_dir in testcase_dirs:
-        if not testcase_dir.exists():
-            logger.warning(f"Missing test case directory: {testcase_dir}")
-            continue
-        for file_path in testcase_dir.glob("[!_]*/[!_]*.json"):
-            parser_name = file_path.parent.name
-            md5 = file_path.stem
-            if not re.match("[a-f0-9]{32}", md5):
-                continue
-            yield TestCase(f"{source_name}:{parser_name}", md5, file_path)
-
-
-def iter_failed_tests() -> Iterable[TestCase]:
-    """
-    Iterates the previously failed test cases.
-    """
-    lastfailed_file = mwcp.config.pytest_cache_dir / "v" / "cache" / "lastfailed"
-    if lastfailed_file.exists():
-        with open(lastfailed_file, "r") as fo:
-            data = json.load(fo)
-        for key, enabled in data.items():
-            if enabled:
-                identifier = re.search("\[(.*)\]", key).group(1)
-                parser_name, found, md5 = identifier.partition("-")
-                if found:
-                    for test_case in iter_test_cases():
-                        if test_case.name == parser_name and test_case.md5 == md5:
-                            yield test_case
-                            break
-
-
-def iter_md5s(parser_name: str) -> Iterable[str]:
-    """
-    Obtains the md5 hashes for the test cases for a given parser name
-
-    :param parser_name: Name of parser (case-sensitive)
-    :yields: md5 hashes
-    """
-    for test_case in iter_test_cases(parsers=[parser_name]):
-        _, _, test_case_name = test_case.name.partition(":")
-        if test_case_name == parser_name:
-            yield test_case.md5
-
-
-def download(md5: str, output_dir: pathlib.Path = None):
-    """
-    Downloads test sample for given md5.
-
-    :param md5: Full or partial md5 hash.
-    :param output_dir: Directory to write file. (defaults to current directory)
-    :return: Path of downloaded file.
-
-    :raise IOError: If file could not be found.
-    """
-    if not output_dir:
-        output_dir = pathlib.Path(".")
-        
-    try:
-        file_path = get_path_in_malware_repo(md5=md5)
-    except ValueError as e:
-        raise IOError(e)
-
-    if not file_path.exists():
-        raise IOError(f"Unable to find sample at {file_path}")
-
-    output_path = output_dir / file_path.name
-    logger.debug(f"Downloading {file_path}...")
-    with open(output_path, "wb") as fo:
-        fo.write(file_path.read_bytes())
-    return output_path
-
-
-def add_tests(file_path: Union[str, pathlib.Path], parsers: List[str] = None, force=False, update=True) -> bool:
-    """
-    Adds a test case for the given parser and md5 for malware sample.
-
-    :param file_path: Input file to run given parsers on to create tests.
-    :param parsers: List of parser names to create test cases for.
-        (Or None to use all registered parsers)
-    :param force: Whether to force adding the test case even if errors are encountered
-    :param update: Whether to allow updating the test case if a test for this file already exists.
-
-    :returns: Whether we were able successfully add all test cases.
-    """
-    file_path = pathlib.Path(file_path)
-    file_data = file_path.read_bytes()
-    md5 = hashlib.md5(file_data).hexdigest()
-
-    add_to_malware_repo(file_path)
-
-    # Run on all parsers if not provided.
-    if not parsers:
-        parsers = [None]
-
-    success = True
-    for parser_name in parsers:
-        for source, parser in mwcp.iter_parsers(parser_name):
-            testcase_dir = get_testcase_dir(source)
-            results_path = testcase_dir / parser.name / f"{md5}.json"
-            results_path.parent.mkdir(exist_ok=True)
-            full_parser_name = f"{source.name}:{parser.name}"
-
-            if results_path.exists() and not update:
-                logger.warning(
-                    f"Test case for {file_path} already exists in {results_path}"
-                )
-                continue
-
-            report = mwcp.run(full_parser_name, data=file_data, log_level=logging.INFO)
-
-            if report.errors and not force:
-                logger.warning(
-                    f"Results for {file_path} with parser {full_parser_name} "
-                    f"has the following errors, not adding:"
-                )
-                logger.warning("\n".join(report.errors))
-                success = False
-                continue
-
-            logger.info(f"Adding results for {file_path} in {results_path}")
-            results_path.write_text(report.as_json())
-
-    return success
-
-
-def remove_tests(file_path: Union[str, pathlib.Path], parsers: List[str] = None):
-    """
-    Removes the test case for the given parser and md5 of malware sample.
-
-    :param file_path: Input file to run given parsers on to create tests.
-    :param parsers: List of parser names to remove test cases for.
-        (Or None to use all registered parsers)
-    """
-    file_path = pathlib.Path(file_path)
-    file_data = file_path.read_bytes()
-    md5 = hashlib.md5(file_data).hexdigest()
-
-    if not parsers:
-        parsers = [None]
-
-    for parser_name in parsers:
-        for source, parser in mwcp.iter_parsers(parser_name):
-            testcase_dir = get_testcase_dir(source)
-            results_path = testcase_dir / parser.name / f"{md5}.json"
-
-            if results_path.exists():
-                logger.info(f"Removing test case: {results_path}")
-                results_path.unlink()
+"""
+Utilities for managing parser tests (and the malware repository)
+"""
+
+import collections
+import hashlib
+import json
+import logging
+import pathlib
+import re
+import shutil
+from dataclasses import dataclass
+from typing import Iterable, Union, List
+
+import pkg_resources
+
+import mwcp
+from mwcp import registry
+
+logger = logging.getLogger(__name__)
+
+
+@dataclass
+class TestCase:
+    name: str
+    md5: str
+    results_path: pathlib.Path
+
+    def update(self, force=False) -> bool:
+        """
+        Updates test case based on currently generated results.
+
+        :param force: Whether to force adding the test case even if errors are encountered
+        :returns: Whether update was successful.
+        """
+        results_path = self.results_path
+        with open(results_path, "r") as fo:
+            old_results = json.load(fo)
+        parser_name = old_results["parser"]
+
+        file_path = get_path_in_malware_repo(md5=self.md5)
+        if not file_path.exists():
+            logger.warning(f"Unable to update {self.name}. Missing {file_path}")
+            return False
+
+        report = mwcp.run(parser_name, data=file_path.read_bytes(), log_level=logging.INFO)
+        if report.errors and not force:
+            logger.warning(f"Results for {self.name} has the following errors, not updating:")
+            logger.warning("\n".join(report.errors))
+            return False
+
+        # Don't bother updating if it only updates the mwcp version.
+        new_results = report.as_json_dict()
+        new_results["mwcp_version"] = old_results["mwcp_version"]
+        if new_results == old_results:
+            return True
+
+        logger.info(f"Updating results for {file_path} in {results_path}")
+        results_path.write_text(report.as_json())
+        return True
+
+
+def get_path_in_malware_repo(file_path: Union[str, pathlib.Path] = None, md5: str = None) -> pathlib.Path:
+    """
+    Gets file path for a file in the malware_repo based on the given md5 or md5 of the given file_path.
+
+    :param file_path: Path to file to hash in order to obtain the equivalent file path in the malware repo.
+    :param md5: All or partial md5 of sample to get from malware repo.
+
+    :raises ValueError: If sample doesn't exists in malware repo.
+    """
+    malware_repo = mwcp.config.get("MALWARE_REPO")
+    if not malware_repo:
+        raise ValueError(f"MALWARE_REPO field not set in '{mwcp.config.user_path}'. Try running `mwcp config` to set this.")
+    if file_path:
+        with open(file_path, "rb") as fo:
+            md5 = hashlib.md5(fo.read()).hexdigest()
+    if not md5:
+        raise ValueError(f"Missing file_path or md5 parameter.")
+
+    # If md5 is partial, try to figure out which md5 we want by iterating the directory.
+    if len(md5) < 4:
+        raise ValueError(f"Unable to determine md5 from '{md5}'. Must be at least 4 characters.")
+
+    if len(md5) < 32:
+        sub_dir = pathlib.Path(malware_repo, md5[:4])
+        if not sub_dir.exists():
+            raise ValueError(f"Failed to find sample starting with the md5 '{md5}'.")
+        file_paths = []
+        for file_path in sub_dir.iterdir():
+            if file_path.name.startswith(md5):
+                file_paths.append(file_path)
+        if not file_paths:
+            raise ValueError(f"Failed to find sample starting with the md5 '{md5}'.")
+        if len(file_paths) > 1:
+            md5s = "\t\n".join(file_path.name for file_path in file_paths)
+            raise ValueError(f"Found multiple samples starting with  the md5 '{md5}': \n\t{md5s}")
+        return file_paths[0]
+
+    return pathlib.Path(malware_repo, md5[:4], md5)
+
+
+def add_to_malware_repo(file_path: Union[str, pathlib.Path]) -> pathlib.Path:
+    """
+    Adds the given file path to the malware repo.
+    Returns resulting destination path.
+    """
+    file_path = pathlib.Path(file_path)
+    dest_file_path = get_path_in_malware_repo(file_path)
+
+    if dest_file_path.exists():
+        logger.info(f"File already exists in malware repo: {dest_file_path}")
+        return dest_file_path
+
+    dest_file_path.parent.mkdir(parents=True, exist_ok=True)
+
+    logger.info(f"Copying {file_path} to {dest_file_path}")
+    shutil.copy(file_path, dest_file_path)
+    return dest_file_path
+
+
+def _get_testcase_dir_from_source(source: registry.Source) -> pathlib.Path:
+    """
+    Returns the testcase directory for the given source.
+    """
+    if source.is_pkg:
+        # Dynamically pull based on top level module.
+        return pathlib.Path(pkg_resources.resource_filename(source.path, "tests"))
+
+    # If source is a directory, assume there is a "tests" folder within it.
+    return pathlib.Path(source.path, "tests")
+
+
+def get_testcase_dir(source: registry.Source) -> pathlib.Path:
+    """
+    Returns the testcase directory for the given parser name or source.
+    """
+    # Use hardcoded testcase directory if set.
+    testcase_dir = mwcp.config.get("TESTCASE_DIR")
+    if testcase_dir:
+        return pathlib.Path(testcase_dir, source.name)
+
+    return _get_testcase_dir_from_source(source)
+
+
+def iter_test_cases(source: registry.Source = None, parsers: List[str] = None) -> Iterable[TestCase]:
+    """
+    Iterates the test cases discovered from a specific or all registered sources.
+
+    :param source: Optional source to obtain test cases for.
+    :param parsers: List of parser names for tests cases.
+    :yields: tests cases
+    """
+    # If parser names provided, iterate test cases just for those parsers.
+    if parsers:
+        cache = set()
+        for parser_name in parsers:
+            if source:
+                for test_case in iter_test_cases(source):
+                    if parser_name in test_case.name:
+                        yield test_case
+            else:
+                for source, parser in mwcp.iter_parsers(parser_name):
+                    if source not in cache:
+                        cache.add(source)
+                        for test_case in iter_test_cases(source):
+                            if parser_name in test_case.name:
+                                yield test_case
+        return
+
+    testcase_dirs = []
+    # First see if user provided a global testcase directory that overrides all sources.
+    # Test case directories are organized into sub directories based on source name.
+    testcase_dir = mwcp.config.get("TESTCASE_DIR")
+    if testcase_dir:
+        testcase_dir = pathlib.Path(testcase_dir)
+        for source_dir in testcase_dir.iterdir():
+            if source_dir.is_dir() and registry.is_source(source_dir.name):
+                testcase_dirs.append((source_dir.name, source_dir))
+
+        # If we don't find any testcase directories, user probably provided a directory
+        # not structured as expected.
+        # In this case, let's just recursively look for all .json files.
+        if not testcase_dirs:
+            for file_path in testcase_dir.glob("**/[!_]*.json"):
+                with open(file_path, "r") as fp:
+                    data = json.load(fp)
+                try:
+                    yield TestCase(data["parser"], data["input_file"]["md5"], file_path)
+                except (KeyError, TypeError):
+                    logger.warning(f"Failed to collect testcase file: {file_path}")
+            return
+
+    # Otherwise we need to pull test case directories based on location of source.
+    else:
+        sources = [source] if source else registry.get_sources()
+        for source in sources:
+            testcase_dirs.append((source.name, _get_testcase_dir_from_source(source)))
+
+    for source_name, testcase_dir in testcase_dirs:
+        if not testcase_dir.exists():
+            logger.warning(f"Missing test case directory: {testcase_dir}")
+            continue
+        for file_path in testcase_dir.glob("[!_]*/[!_]*.json"):
+            parser_name = file_path.parent.name
+            md5 = file_path.stem
+            if not re.match("[a-f0-9]{32}", md5):
+                continue
+            yield TestCase(f"{source_name}:{parser_name}", md5, file_path)
+
+
+def iter_failed_tests() -> Iterable[TestCase]:
+    """
+    Iterates the previously failed test cases.
+    """
+    lastfailed_file = mwcp.config.pytest_cache_dir / "v" / "cache" / "lastfailed"
+    if lastfailed_file.exists():
+        with open(lastfailed_file, "r") as fo:
+            data = json.load(fo)
+        for key, enabled in data.items():
+            if enabled:
+                identifier = re.search("\[(.*)\]", key).group(1)
+                parser_name, found, md5 = identifier.partition("-")
+                if found:
+                    for test_case in iter_test_cases():
+                        if test_case.name == parser_name and test_case.md5 == md5:
+                            yield test_case
+                            break
+
+
+def iter_md5s(parser_name: str) -> Iterable[str]:
+    """
+    Obtains the md5 hashes for the test cases for a given parser name
+
+    :param parser_name: Name of parser (case-sensitive)
+    :yields: md5 hashes
+    """
+    for test_case in iter_test_cases(parsers=[parser_name]):
+        _, _, test_case_name = test_case.name.partition(":")
+        if test_case_name == parser_name:
+            yield test_case.md5
+
+
+def download(md5: str, output_dir: pathlib.Path = None):
+    """
+    Downloads test sample for given md5.
+
+    :param md5: Full or partial md5 hash.
+    :param output_dir: Directory to write file. (defaults to current directory)
+    :return: Path of downloaded file.
+
+    :raise IOError: If file could not be found.
+    """
+    if not output_dir:
+        output_dir = pathlib.Path(".")
+        
+    try:
+        file_path = get_path_in_malware_repo(md5=md5)
+    except ValueError as e:
+        raise IOError(e)
+
+    if not file_path.exists():
+        raise IOError(f"Unable to find sample at {file_path}")
+
+    output_path = output_dir / file_path.name
+    logger.debug(f"Downloading {file_path}...")
+    with open(output_path, "wb") as fo:
+        fo.write(file_path.read_bytes())
+    return output_path
+
+
+def add_tests(file_path: Union[str, pathlib.Path], parsers: List[str] = None, force=False, update=True) -> bool:
+    """
+    Adds a test case for the given parser and md5 for malware sample.
+
+    :param file_path: Input file to run given parsers on to create tests.
+    :param parsers: List of parser names to create test cases for.
+        (Or None to use all registered parsers)
+    :param force: Whether to force adding the test case even if errors are encountered
+    :param update: Whether to allow updating the test case if a test for this file already exists.
+
+    :returns: Whether we were able successfully add all test cases.
+    """
+    file_path = pathlib.Path(file_path)
+    file_data = file_path.read_bytes()
+    md5 = hashlib.md5(file_data).hexdigest()
+
+    add_to_malware_repo(file_path)
+
+    # Run on all parsers if not provided.
+    if not parsers:
+        parsers = [None]
+
+    success = True
+    for parser_name in parsers:
+        for source, parser in mwcp.iter_parsers(parser_name):
+            testcase_dir = get_testcase_dir(source)
+            results_path = testcase_dir / parser.name / f"{md5}.json"
+            results_path.parent.mkdir(exist_ok=True)
+            full_parser_name = f"{source.name}:{parser.name}"
+
+            if results_path.exists() and not update:
+                logger.warning(
+                    f"Test case for {file_path} already exists in {results_path}"
+                )
+                continue
+
+            report = mwcp.run(full_parser_name, data=file_data, log_level=logging.INFO)
+
+            if report.errors and not force:
+                logger.warning(
+                    f"Results for {file_path} with parser {full_parser_name} "
+                    f"has the following errors, not adding:"
+                )
+                logger.warning("\n".join(report.errors))
+                success = False
+                continue
+
+            logger.info(f"Adding results for {file_path} in {results_path}")
+            results_path.write_text(report.as_json())
+
+    return success
+
+
+def remove_tests(file_path: Union[str, pathlib.Path], parsers: List[str] = None):
+    """
+    Removes the test case for the given parser and md5 of malware sample.
+
+    :param file_path: Input file to run given parsers on to create tests.
+    :param parsers: List of parser names to remove test cases for.
+        (Or None to use all registered parsers)
+    """
+    file_path = pathlib.Path(file_path)
+    file_data = file_path.read_bytes()
+    md5 = hashlib.md5(file_data).hexdigest()
+
+    if not parsers:
+        parsers = [None]
+
+    for parser_name in parsers:
+        for source, parser in mwcp.iter_parsers(parser_name):
+            testcase_dir = get_testcase_dir(source)
+            results_path = testcase_dir / parser.name / f"{md5}.json"
+
+            if results_path.exists():
+                logger.info(f"Removing test case: {results_path}")
+                results_path.unlink()
```

### Comparing `mwcp-3.8.0/mwcp/tests/construct_html.html` & `mwcp-3.9.0/mwcp/tests/construct_html.html`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,374 +1,374 @@
-
-<html>
-<head>
-<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
-<meta name=Generator content="Microsoft Word 14 (filtered)">
-<style>
-<!--
- /* Font Definitions */
- @font-face
-	{font-family:Courier;
-	panose-1:2 7 4 9 2 2 5 2 4 4;}
-@font-face
-	{font-family:"Cambria Math";
-	panose-1:2 4 5 3 5 4 6 3 2 4;}
-@font-face
-	{font-family:Calibri;
-	panose-1:2 15 5 2 2 2 4 3 2 4;}
- /* Style Definitions */
- p.MsoNormal, li.MsoNormal, div.MsoNormal
-	{margin:0in;
-	margin-bottom:.0001pt;
-	font-size:11.0pt;
-	font-family:"Times New Roman","serif";}
-h1
-	{mso-style-link:"Heading 1 Char";
-	margin:0in;
-	margin-bottom:.0001pt;
-	page-break-after:avoid;
-	font-size:16.0pt;
-	font-family:"Calibri","sans-serif";
-	color:#943634;}
-h3
-	{mso-style-link:"Heading 3 Char";
-	margin-top:10.0pt;
-	margin-right:0in;
-	margin-bottom:0in;
-	margin-left:0in;
-	margin-bottom:.0001pt;
-	page-break-after:avoid;
-	font-size:11.0pt;
-	font-family:"Times New Roman","serif";}
-p.MsoNoSpacing, li.MsoNoSpacing, div.MsoNoSpacing
-	{mso-style-link:"No Spacing Char";
-	margin:0in;
-	margin-bottom:.0001pt;
-	font-size:11.0pt;
-	font-family:"Calibri","sans-serif";}
-span.Heading1Char
-	{mso-style-name:"Heading 1 Char";
-	mso-style-link:"Heading 1";
-	color:#943634;
-	font-weight:bold;}
-span.Heading3Char
-	{mso-style-name:"Heading 3 Char";
-	mso-style-link:"Heading 3";
-	font-family:"Times New Roman","serif";
-	font-weight:bold;}
-span.NoSpacingChar
-	{mso-style-name:"No Spacing Char";
-	mso-style-link:"No Spacing";
-	font-family:"Calibri","sans-serif";}
-.MsoChpDefault
-	{font-family:"Calibri","sans-serif";}
-.MsoPapDefault
-	{margin-bottom:10.0pt;
-	line-height:115%;}
-@page WordSection1
-	{size:8.5in 11.0in;
-	margin:1.0in 1.0in 1.0in 1.0in;}
-div.WordSection1
-	{page:WordSection1;}
--->
-</style>
-</head>
-<body lang=EN-US>
-<div class=WordSection1>
-
-<!-- Hex Dump -->
-<p class=MsoNormal style='background:#FFFFFF'>
-    <span style='font-size:8.0pt;font-family:"Courier New"'>
-        &nbsp;offset&nbsp;|&nbsp;&nbsp;0&nbsp;&nbsp;1&nbsp;&nbsp;2&nbsp;&nbsp;3&nbsp;&nbsp;4&nbsp;&nbsp;5&nbsp;&nbsp;6&nbsp;&nbsp;7&nbsp;&nbsp;8&nbsp;&nbsp;9&nbsp;&nbsp;a&nbsp;&nbsp;b&nbsp;&nbsp;c&nbsp;&nbsp;d&nbsp;&nbsp;e&nbsp;&nbsp;f&nbsp;|&nbsp;0123456789abcdef<br/>
-        &nbsp;------ |  -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --  | ----------------
-        <br/>&nbsp;000000&nbsp;|&nbsp;01&nbsp;00&nbsp;00&nbsp;00&nbsp;7D&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;<span style="background:#00ff00;color:#000000">F4&nbsp;01&nbsp;00&nbsp;00&nbsp;</span><span style="background:#0000ff;color:#ffffff">32&nbsp;00&nbsp;00</span>&nbsp;|&nbsp;....}....<span style="background:#00ff00;color:#000000">....</span><span style="background:#0000ff;color:#ffffff">2..</span>
-        <br/>&nbsp;000010&nbsp;|&nbsp;<span style="background:#0000ff;color:#ffffff">00&nbsp;</span><span style="background:#00ffff;color:#000000">E8&nbsp;03&nbsp;00&nbsp;00&nbsp;</span>00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;|&nbsp;<span style="background:#0000ff;color:#ffffff">.</span><span style="background:#00ffff;color:#000000">....</span>...........
-        <br/>&nbsp;000020&nbsp;|&nbsp;00&nbsp;00&nbsp;01&nbsp;01&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;01&nbsp;00&nbsp;00&nbsp;00&nbsp;<span style="background:#ff0000;color:#ffffff">C0&nbsp;A8&nbsp;01&nbsp;0D</span>&nbsp;|&nbsp;............<span style="background:#ff0000;color:#ffffff">....</span>
-        <br/>&nbsp;000030&nbsp;|&nbsp;<span style="background:#ffff00;color:#000000">C0&nbsp;A8&nbsp;01&nbsp;0D&nbsp;C0&nbsp;A8&nbsp;01&nbsp;0D&nbsp;C0&nbsp;A8&nbsp;01&nbsp;0D&nbsp;C0&nbsp;A8&nbsp;01&nbsp;0D</span>&nbsp;|&nbsp;<span style="background:#ffff00;color:#000000">................</span>
-        <br/>&nbsp;000040&nbsp;|&nbsp;FF&nbsp;FF&nbsp;01&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;<span style="background:#ff00ff;color:#ffffff">2D&nbsp;3D&nbsp;3D&nbsp;20&nbsp;4C&nbsp;6F&nbsp;76&nbsp;65</span>&nbsp;|&nbsp;........<span style="background:#ff00ff;color:#ffffff">-==.Love</span>
-        <br/>&nbsp;000050&nbsp;|&nbsp;<span style="background:#ff00ff;color:#ffffff">20&nbsp;41&nbsp;56&nbsp;20&nbsp;3D&nbsp;3D&nbsp;2D&nbsp;</span>3A&nbsp;00&nbsp;<span style="background:#008000;color:#ffffff">01&nbsp;00&nbsp;00&nbsp;00&nbsp;</span><span style="background:#000080;color:#ffffff">64&nbsp;0A&nbsp;00</span>&nbsp;|&nbsp;<span style="background:#ff00ff;color:#ffffff">.AV.==-</span>:.<span style="background:#008000;color:#ffffff">....</span><span style="background:#000080;color:#ffffff">d..</span>
-        <br/>&nbsp;000060&nbsp;|&nbsp;<span style="background:#000080;color:#ffffff">00&nbsp;</span><span style="background:#008080;color:#ffffff">C4&nbsp;07&nbsp;00&nbsp;00&nbsp;</span><span style="background:#00ff80;color:#000000">4C&nbsp;69&nbsp;6E&nbsp;75&nbsp;78&nbsp;20&nbsp;33&nbsp;2E&nbsp;31&nbsp;33&nbsp;2E</span>&nbsp;|&nbsp;<span style="background:#000080;color:#ffffff">.</span><span style="background:#008080;color:#ffffff">....</span><span style="background:#00ff80;color:#000000">Linux.3.13.</span>
-        <br/>&nbsp;000070&nbsp;|&nbsp;<span style="background:#00ff80;color:#000000">30&nbsp;2D&nbsp;39&nbsp;33&nbsp;2D&nbsp;67&nbsp;65&nbsp;6E&nbsp;65&nbsp;72&nbsp;69&nbsp;63&nbsp;00&nbsp;</span><span style="background:#0080ff;color:#ffffff">31&nbsp;3A&nbsp;47</span>&nbsp;|&nbsp;<span style="background:#00ff80;color:#000000">0-93-generic.</span><span style="background:#0080ff;color:#ffffff">1:G</span>
-        <br/>&nbsp;000080&nbsp;|&nbsp;<span style="background:#0080ff;color:#ffffff">32&nbsp;2E&nbsp;34&nbsp;30&nbsp;00&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;<span style="background:#0080ff;color:#ffffff">2.40.</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
-    </span>
-</p>
-
-<!-- Variable Table -->
-<p class=MsoNormal>&nbsp;</p>
-    <table class=MsoNormalTable border=1 cellspacing=0 cellpadding=0
-     style='margin-left:5.4pt;border-collapse:collapse;border:none'>
-     <tr>
-      <td width=175 valign=top style='width:131.05pt;border:solid windowtext 1.0pt;
-      background:#244061;padding:0in 5.4pt 0in 5.4pt'>
-      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
-      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Offset</span></b></p>
-      </td>
-      <td width=238 valign=top style='width:178.7pt;border:solid windowtext 1.0pt;
-      border-left:none;background:#244061;padding:0in 5.4pt 0in 5.4pt'>
-      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
-      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Name</span></b></p>
-      </td>
-      <td width=218 valign=top style='width:163.65pt;border:solid windowtext 1.0pt;
-      border-left:none;background:#244061;padding:0in 5.4pt 0in 5.4pt'>
-      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
-      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Value</span></b></p>
-      </td>
-     </tr>
-
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000009</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#00ff00;color:#000000">
-                        Hardcoded Value 1
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        0x1f4
-                    </span>
-                </p>
-            </td>
-        </tr>
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">00000d</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#0000ff;color:#ffffff">
-                        Hardcoded Value 2
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        0x32
-                    </span>
-                </p>
-            </td>
-        </tr>
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000011</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#00ffff;color:#000000">
-                        Hardcoded Value 3
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        0x3e8
-                    </span>
-                </p>
-            </td>
-        </tr>
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">00002c</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#ff0000;color:#ffffff">
-                        Compromised Host IP
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        192.168.1.13
-                    </span>
-                </p>
-            </td>
-        </tr>
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000030</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#ffff00;color:#000000">
-                        Unknown IP Addresses
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        - first: <br/>&nbsp;&nbsp;&nbsp;&nbsp;a: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;192<br/>&nbsp;&nbsp;&nbsp;&nbsp;b: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;168<br/>&nbsp;&nbsp;second: <br/>&nbsp;&nbsp;&nbsp;&nbsp;inner2: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\x01\r<br/>- first: <br/>&nbsp;&nbsp;&nbsp;&nbsp;a: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;192<br/>&nbsp;&nbsp;&nbsp;&nbsp;b: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;168<br/>&nbsp;&nbsp;second: <br/>&nbsp;&nbsp;&nbsp;&nbsp;inner2: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\x01\r<br/>- first: <br/>&nbsp;&nbsp;&nbsp;&nbsp;a: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;192<br/>&nbsp;&nbsp;&nbsp;&nbsp;b: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;168<br/>&nbsp;&nbsp;second: <br/>&nbsp;&nbsp;&nbsp;&nbsp;inner2: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\x01\r<br/>- first: <br/>&nbsp;&nbsp;&nbsp;&nbsp;a: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;192<br/>&nbsp;&nbsp;&nbsp;&nbsp;b: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;168<br/>&nbsp;&nbsp;second: <br/>&nbsp;&nbsp;&nbsp;&nbsp;inner2: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\x01\r
-                    </span>
-                </p>
-            </td>
-        </tr>
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000048</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#ff00ff;color:#ffffff">
-                        Unknown Indicator
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        -== Love AV ==-
-                    </span>
-                </p>
-            </td>
-        </tr>
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000059</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#008000;color:#ffffff">
-                        Number of CPUs
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        1
-                    </span>
-                </p>
-            </td>
-        </tr>
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">00005d</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#000080;color:#ffffff">
-                        CPU Mhz
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        2660
-                    </span>
-                </p>
-            </td>
-        </tr>
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000061</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#008080;color:#ffffff">
-                        Total Memory (MB)
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        1988
-                    </span>
-                </p>
-            </td>
-        </tr>
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000065</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#00ff80;color:#000000">
-                        Compromised System Kernel
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        Linux 3.13.0-93-generic
-                    </span>
-                </p>
-            </td>
-        </tr>
-        <tr>
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">00007d</span>
-                </p>
-            </td>
-
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:#0080ff;color:#ffffff">
-                        Possible Trojan Version
-                    </span>
-                </p>
-            </td>
-
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        1:G2.40
-                    </span>
-                </p>
-            </td>
-        </tr>
-
-    </table>
-</div>
-</body>
+
+<html>
+<head>
+<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
+<meta name=Generator content="Microsoft Word 14 (filtered)">
+<style>
+<!--
+ /* Font Definitions */
+ @font-face
+	{font-family:Courier;
+	panose-1:2 7 4 9 2 2 5 2 4 4;}
+@font-face
+	{font-family:"Cambria Math";
+	panose-1:2 4 5 3 5 4 6 3 2 4;}
+@font-face
+	{font-family:Calibri;
+	panose-1:2 15 5 2 2 2 4 3 2 4;}
+ /* Style Definitions */
+ p.MsoNormal, li.MsoNormal, div.MsoNormal
+	{margin:0in;
+	margin-bottom:.0001pt;
+	font-size:11.0pt;
+	font-family:"Times New Roman","serif";}
+h1
+	{mso-style-link:"Heading 1 Char";
+	margin:0in;
+	margin-bottom:.0001pt;
+	page-break-after:avoid;
+	font-size:16.0pt;
+	font-family:"Calibri","sans-serif";
+	color:#943634;}
+h3
+	{mso-style-link:"Heading 3 Char";
+	margin-top:10.0pt;
+	margin-right:0in;
+	margin-bottom:0in;
+	margin-left:0in;
+	margin-bottom:.0001pt;
+	page-break-after:avoid;
+	font-size:11.0pt;
+	font-family:"Times New Roman","serif";}
+p.MsoNoSpacing, li.MsoNoSpacing, div.MsoNoSpacing
+	{mso-style-link:"No Spacing Char";
+	margin:0in;
+	margin-bottom:.0001pt;
+	font-size:11.0pt;
+	font-family:"Calibri","sans-serif";}
+span.Heading1Char
+	{mso-style-name:"Heading 1 Char";
+	mso-style-link:"Heading 1";
+	color:#943634;
+	font-weight:bold;}
+span.Heading3Char
+	{mso-style-name:"Heading 3 Char";
+	mso-style-link:"Heading 3";
+	font-family:"Times New Roman","serif";
+	font-weight:bold;}
+span.NoSpacingChar
+	{mso-style-name:"No Spacing Char";
+	mso-style-link:"No Spacing";
+	font-family:"Calibri","sans-serif";}
+.MsoChpDefault
+	{font-family:"Calibri","sans-serif";}
+.MsoPapDefault
+	{margin-bottom:10.0pt;
+	line-height:115%;}
+@page WordSection1
+	{size:8.5in 11.0in;
+	margin:1.0in 1.0in 1.0in 1.0in;}
+div.WordSection1
+	{page:WordSection1;}
+-->
+</style>
+</head>
+<body lang=EN-US>
+<div class=WordSection1>
+
+<!-- Hex Dump -->
+<p class=MsoNormal style='background:#FFFFFF'>
+    <span style='font-size:8.0pt;font-family:"Courier New"'>
+        &nbsp;offset&nbsp;|&nbsp;&nbsp;0&nbsp;&nbsp;1&nbsp;&nbsp;2&nbsp;&nbsp;3&nbsp;&nbsp;4&nbsp;&nbsp;5&nbsp;&nbsp;6&nbsp;&nbsp;7&nbsp;&nbsp;8&nbsp;&nbsp;9&nbsp;&nbsp;a&nbsp;&nbsp;b&nbsp;&nbsp;c&nbsp;&nbsp;d&nbsp;&nbsp;e&nbsp;&nbsp;f&nbsp;|&nbsp;0123456789abcdef<br/>
+        &nbsp;------ |  -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --  | ----------------
+        <br/>&nbsp;000000&nbsp;|&nbsp;01&nbsp;00&nbsp;00&nbsp;00&nbsp;7D&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;<span style="background:#00ff00;color:#000000">F4&nbsp;01&nbsp;00&nbsp;00&nbsp;</span><span style="background:#0000ff;color:#ffffff">32&nbsp;00&nbsp;00</span>&nbsp;|&nbsp;....}....<span style="background:#00ff00;color:#000000">....</span><span style="background:#0000ff;color:#ffffff">2..</span>
+        <br/>&nbsp;000010&nbsp;|&nbsp;<span style="background:#0000ff;color:#ffffff">00&nbsp;</span><span style="background:#00ffff;color:#000000">E8&nbsp;03&nbsp;00&nbsp;00&nbsp;</span>00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;|&nbsp;<span style="background:#0000ff;color:#ffffff">.</span><span style="background:#00ffff;color:#000000">....</span>...........
+        <br/>&nbsp;000020&nbsp;|&nbsp;00&nbsp;00&nbsp;01&nbsp;01&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;01&nbsp;00&nbsp;00&nbsp;00&nbsp;<span style="background:#ff0000;color:#ffffff">C0&nbsp;A8&nbsp;01&nbsp;0D</span>&nbsp;|&nbsp;............<span style="background:#ff0000;color:#ffffff">....</span>
+        <br/>&nbsp;000030&nbsp;|&nbsp;<span style="background:#ffff00;color:#000000">C0&nbsp;A8&nbsp;01&nbsp;0D&nbsp;C0&nbsp;A8&nbsp;01&nbsp;0D&nbsp;C0&nbsp;A8&nbsp;01&nbsp;0D&nbsp;C0&nbsp;A8&nbsp;01&nbsp;0D</span>&nbsp;|&nbsp;<span style="background:#ffff00;color:#000000">................</span>
+        <br/>&nbsp;000040&nbsp;|&nbsp;FF&nbsp;FF&nbsp;01&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;00&nbsp;<span style="background:#ff00ff;color:#ffffff">2D&nbsp;3D&nbsp;3D&nbsp;20&nbsp;4C&nbsp;6F&nbsp;76&nbsp;65</span>&nbsp;|&nbsp;........<span style="background:#ff00ff;color:#ffffff">-==.Love</span>
+        <br/>&nbsp;000050&nbsp;|&nbsp;<span style="background:#ff00ff;color:#ffffff">20&nbsp;41&nbsp;56&nbsp;20&nbsp;3D&nbsp;3D&nbsp;2D&nbsp;</span>3A&nbsp;00&nbsp;<span style="background:#008000;color:#ffffff">01&nbsp;00&nbsp;00&nbsp;00&nbsp;</span><span style="background:#000080;color:#ffffff">64&nbsp;0A&nbsp;00</span>&nbsp;|&nbsp;<span style="background:#ff00ff;color:#ffffff">.AV.==-</span>:.<span style="background:#008000;color:#ffffff">....</span><span style="background:#000080;color:#ffffff">d..</span>
+        <br/>&nbsp;000060&nbsp;|&nbsp;<span style="background:#000080;color:#ffffff">00&nbsp;</span><span style="background:#008080;color:#ffffff">C4&nbsp;07&nbsp;00&nbsp;00&nbsp;</span><span style="background:#00ff80;color:#000000">4C&nbsp;69&nbsp;6E&nbsp;75&nbsp;78&nbsp;20&nbsp;33&nbsp;2E&nbsp;31&nbsp;33&nbsp;2E</span>&nbsp;|&nbsp;<span style="background:#000080;color:#ffffff">.</span><span style="background:#008080;color:#ffffff">....</span><span style="background:#00ff80;color:#000000">Linux.3.13.</span>
+        <br/>&nbsp;000070&nbsp;|&nbsp;<span style="background:#00ff80;color:#000000">30&nbsp;2D&nbsp;39&nbsp;33&nbsp;2D&nbsp;67&nbsp;65&nbsp;6E&nbsp;65&nbsp;72&nbsp;69&nbsp;63&nbsp;00&nbsp;</span><span style="background:#0080ff;color:#ffffff">31&nbsp;3A&nbsp;47</span>&nbsp;|&nbsp;<span style="background:#00ff80;color:#000000">0-93-generic.</span><span style="background:#0080ff;color:#ffffff">1:G</span>
+        <br/>&nbsp;000080&nbsp;|&nbsp;<span style="background:#0080ff;color:#ffffff">32&nbsp;2E&nbsp;34&nbsp;30&nbsp;00&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;<span style="background:#0080ff;color:#ffffff">2.40.</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
+    </span>
+</p>
+
+<!-- Variable Table -->
+<p class=MsoNormal>&nbsp;</p>
+    <table class=MsoNormalTable border=1 cellspacing=0 cellpadding=0
+     style='margin-left:5.4pt;border-collapse:collapse;border:none'>
+     <tr>
+      <td width=175 valign=top style='width:131.05pt;border:solid windowtext 1.0pt;
+      background:#244061;padding:0in 5.4pt 0in 5.4pt'>
+      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
+      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Offset</span></b></p>
+      </td>
+      <td width=238 valign=top style='width:178.7pt;border:solid windowtext 1.0pt;
+      border-left:none;background:#244061;padding:0in 5.4pt 0in 5.4pt'>
+      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
+      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Name</span></b></p>
+      </td>
+      <td width=218 valign=top style='width:163.65pt;border:solid windowtext 1.0pt;
+      border-left:none;background:#244061;padding:0in 5.4pt 0in 5.4pt'>
+      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
+      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Value</span></b></p>
+      </td>
+     </tr>
+
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000009</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#00ff00;color:#000000">
+                        Hardcoded Value 1
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        0x1f4
+                    </span>
+                </p>
+            </td>
+        </tr>
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">00000d</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#0000ff;color:#ffffff">
+                        Hardcoded Value 2
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        0x32
+                    </span>
+                </p>
+            </td>
+        </tr>
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000011</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#00ffff;color:#000000">
+                        Hardcoded Value 3
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        0x3e8
+                    </span>
+                </p>
+            </td>
+        </tr>
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">00002c</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#ff0000;color:#ffffff">
+                        Compromised Host IP
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        192.168.1.13
+                    </span>
+                </p>
+            </td>
+        </tr>
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000030</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#ffff00;color:#000000">
+                        Unknown IP Addresses
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        - first: <br/>&nbsp;&nbsp;&nbsp;&nbsp;a: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;192<br/>&nbsp;&nbsp;&nbsp;&nbsp;b: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;168<br/>&nbsp;&nbsp;second: <br/>&nbsp;&nbsp;&nbsp;&nbsp;inner2: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\x01\r<br/>- first: <br/>&nbsp;&nbsp;&nbsp;&nbsp;a: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;192<br/>&nbsp;&nbsp;&nbsp;&nbsp;b: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;168<br/>&nbsp;&nbsp;second: <br/>&nbsp;&nbsp;&nbsp;&nbsp;inner2: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\x01\r<br/>- first: <br/>&nbsp;&nbsp;&nbsp;&nbsp;a: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;192<br/>&nbsp;&nbsp;&nbsp;&nbsp;b: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;168<br/>&nbsp;&nbsp;second: <br/>&nbsp;&nbsp;&nbsp;&nbsp;inner2: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\x01\r<br/>- first: <br/>&nbsp;&nbsp;&nbsp;&nbsp;a: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;192<br/>&nbsp;&nbsp;&nbsp;&nbsp;b: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;168<br/>&nbsp;&nbsp;second: <br/>&nbsp;&nbsp;&nbsp;&nbsp;inner2: <br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\x01\r
+                    </span>
+                </p>
+            </td>
+        </tr>
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000048</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#ff00ff;color:#ffffff">
+                        Unknown Indicator
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        -== Love AV ==-
+                    </span>
+                </p>
+            </td>
+        </tr>
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000059</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#008000;color:#ffffff">
+                        Number of CPUs
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        1
+                    </span>
+                </p>
+            </td>
+        </tr>
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">00005d</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#000080;color:#ffffff">
+                        CPU Mhz
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        2660
+                    </span>
+                </p>
+            </td>
+        </tr>
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000061</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#008080;color:#ffffff">
+                        Total Memory (MB)
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        1988
+                    </span>
+                </p>
+            </td>
+        </tr>
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">000065</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#00ff80;color:#000000">
+                        Compromised System Kernel
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        Linux 3.13.0-93-generic
+                    </span>
+                </p>
+            </td>
+        </tr>
+        <tr>
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">00007d</span>
+                </p>
+            </td>
+
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:#0080ff;color:#ffffff">
+                        Possible Trojan Version
+                    </span>
+                </p>
+            </td>
+
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        1:G2.40
+                    </span>
+                </p>
+            </td>
+        </tr>
+
+    </table>
+</div>
+</body>
 </html>
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_cli/csv_cli.csv` & `mwcp-3.9.0/mwcp/tests/test_cli/csv_cli.csv`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,33 +1,33 @@
-MD5,MetaIndex,Category,Field,Value
-fb843efb2ffec987db12e72ca75c9ea2,0,Input File,parser,foo
-fb843efb2ffec987db12e72ca75c9ea2,0,Input File,filename,test.txt
-fb843efb2ffec987db12e72ca75c9ea2,0,Input File,description,Foo
-fb843efb2ffec987db12e72ca75c9ea2,0,Input File,architecture,
-fb843efb2ffec987db12e72ca75c9ea2,0,Input File,compile_time,
-fb843efb2ffec987db12e72ca75c9ea2,0,Input File,derivation,
-fb843efb2ffec987db12e72ca75c9ea2,1,URL,url,http://127.0.0.1
-fb843efb2ffec987db12e72ca75c9ea2,1,URL,address,127.0.0.1
-fb843efb2ffec987db12e72ca75c9ea2,1,URL,port,
-fb843efb2ffec987db12e72ca75c9ea2,1,URL,network_protocol,
-fb843efb2ffec987db12e72ca75c9ea2,1,URL,c2,
-fb843efb2ffec987db12e72ca75c9ea2,1,URL,listen,
-fb843efb2ffec987db12e72ca75c9ea2,1,URL,path,
-fb843efb2ffec987db12e72ca75c9ea2,1,URL,query,
-fb843efb2ffec987db12e72ca75c9ea2,1,URL,application_protocol,http
-fb843efb2ffec987db12e72ca75c9ea2,1,URL,credential,
-fb843efb2ffec987db12e72ca75c9ea2,2,Socket,address,127.0.0.1
-fb843efb2ffec987db12e72ca75c9ea2,2,Socket,port,
-fb843efb2ffec987db12e72ca75c9ea2,2,Socket,network_protocol,
-fb843efb2ffec987db12e72ca75c9ea2,2,Socket,c2,
-fb843efb2ffec987db12e72ca75c9ea2,2,Socket,listen,
-fb843efb2ffec987db12e72ca75c9ea2,3,File,name,fooconfigtest.txt
-fb843efb2ffec987db12e72ca75c9ea2,3,File,description,example output file
-fb843efb2ffec987db12e72ca75c9ea2,3,File,md5,5eb63bbbe01eeed093cb22bb8f5acdc3
-fb843efb2ffec987db12e72ca75c9ea2,3,File,sha1,2aae6c35c94fcfb415dbe95f408b9ce91ee846ed
-fb843efb2ffec987db12e72ca75c9ea2,3,File,sha256,b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9
-fb843efb2ffec987db12e72ca75c9ea2,3,File,architecture,
-fb843efb2ffec987db12e72ca75c9ea2,3,File,compile_time,
-fb843efb2ffec987db12e72ca75c9ea2,3,File,file_path,
-fb843efb2ffec987db12e72ca75c9ea2,3,File,data,
-fb843efb2ffec987db12e72ca75c9ea2,3,File,derivation,extracted and decompressed
-
+MD5,MetaIndex,Category,Field,Value
+fb843efb2ffec987db12e72ca75c9ea2,0,Input File,parser,foo
+fb843efb2ffec987db12e72ca75c9ea2,0,Input File,filename,test.txt
+fb843efb2ffec987db12e72ca75c9ea2,0,Input File,description,Foo
+fb843efb2ffec987db12e72ca75c9ea2,0,Input File,architecture,
+fb843efb2ffec987db12e72ca75c9ea2,0,Input File,compile_time,
+fb843efb2ffec987db12e72ca75c9ea2,0,Input File,derivation,
+fb843efb2ffec987db12e72ca75c9ea2,1,URL,url,http://127.0.0.1
+fb843efb2ffec987db12e72ca75c9ea2,1,URL,address,127.0.0.1
+fb843efb2ffec987db12e72ca75c9ea2,1,URL,port,
+fb843efb2ffec987db12e72ca75c9ea2,1,URL,network_protocol,
+fb843efb2ffec987db12e72ca75c9ea2,1,URL,c2,
+fb843efb2ffec987db12e72ca75c9ea2,1,URL,listen,
+fb843efb2ffec987db12e72ca75c9ea2,1,URL,path,
+fb843efb2ffec987db12e72ca75c9ea2,1,URL,query,
+fb843efb2ffec987db12e72ca75c9ea2,1,URL,application_protocol,http
+fb843efb2ffec987db12e72ca75c9ea2,1,URL,credential,
+fb843efb2ffec987db12e72ca75c9ea2,2,Socket,address,127.0.0.1
+fb843efb2ffec987db12e72ca75c9ea2,2,Socket,port,
+fb843efb2ffec987db12e72ca75c9ea2,2,Socket,network_protocol,
+fb843efb2ffec987db12e72ca75c9ea2,2,Socket,c2,
+fb843efb2ffec987db12e72ca75c9ea2,2,Socket,listen,
+fb843efb2ffec987db12e72ca75c9ea2,3,File,name,fooconfigtest.txt
+fb843efb2ffec987db12e72ca75c9ea2,3,File,description,example output file
+fb843efb2ffec987db12e72ca75c9ea2,3,File,md5,5eb63bbbe01eeed093cb22bb8f5acdc3
+fb843efb2ffec987db12e72ca75c9ea2,3,File,sha1,2aae6c35c94fcfb415dbe95f408b9ce91ee846ed
+fb843efb2ffec987db12e72ca75c9ea2,3,File,sha256,b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9
+fb843efb2ffec987db12e72ca75c9ea2,3,File,architecture,
+fb843efb2ffec987db12e72ca75c9ea2,3,File,compile_time,
+fb843efb2ffec987db12e72ca75c9ea2,3,File,file_path,
+fb843efb2ffec987db12e72ca75c9ea2,3,File,data,
+fb843efb2ffec987db12e72ca75c9ea2,3,File,derivation,extracted and decompressed
+
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_cli.py` & `mwcp-3.9.0/mwcp/tests/test_cli.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,314 +1,314 @@
-"""
-Tests the CLI tools.
-"""
-
-import hashlib
-import json
-import os
-import re
-import sys
-
-from click.testing import CliRunner
-import pytest
-import pathlib
-
-import mwcp
-from mwcp import cli
-
-
-@pytest.fixture(autouse=True)
-def reset():
-    """Ensures registry and config is reset for each test."""
-    mwcp.clear_registry()
-    mwcp.config.clear()
-
-
-def test_parse(tmp_path, datadir):
-    """Test running a parser"""
-    runner = CliRunner(mix_stderr=False)
-
-    with runner.isolated_filesystem(tmp_path):
-
-        test_file = "test.txt"
-        with open(test_file, "wb") as fp:
-            fp.write(b"This is some test data!")
-
-        # Run the foo parser on the test input file.
-        ret = runner.invoke(cli.main, ["parse", "foo", test_file])
-        print(ret.stdout)
-        print(ret.stderr, file=sys.stderr)
-        assert ret.exit_code == 0
-
-        expected = (datadir / "parse.txt").read_text("utf-8")
-        assert ret.stdout == expected
-
-        output_file = pathlib.Path(f"{test_file}_mwcp_output", "5eb63_fooconfigtest.txt")
-        assert output_file.exists()
-
-        # Test the "--no-output-files" flag.
-        output_file.unlink()
-        assert not output_file.exists()
-        ret = runner.invoke(cli.main, ["parse", "--no-output-files", "foo", test_file])
-        assert ret.exit_code == 0
-        # We should still not have the output file
-        assert not output_file.exists()
-
-        # Test the json formatting
-        ret = runner.invoke(cli.main, ["parse", "--no-output-files", "-f", "json", "foo", test_file])
-        print(ret.stdout)
-        print(ret.stderr, file=sys.stderr)
-        assert ret.exit_code == 0
-
-        expected = (datadir / "parse.json").read_text("utf-8").replace("MWCP_VERSION", mwcp.__version__)
-        assert ret.stdout == expected
-
-
-def test_list(tmp_path, make_sample_parser):
-    """
-    Tests displaying a list of parsers.
-
-    (This is also where we test the parser registration flags.)
-    """
-    runner = CliRunner(mix_stderr=False)
-
-    with runner.isolated_filesystem(tmp_path):
-
-        # First ensure our foo parser is registered via entry_points.
-        ret = runner.invoke(cli.main, ["list", "--json"])
-        print(ret.stderr, file=sys.stderr)
-        assert ret.exit_code == 0
-
-        results = json.loads(ret.stdout, encoding="utf8")
-        assert len(results) > 1
-        for name, source_name, author, description in results:
-            if name == u"foo" and source_name == u"mwcp":
-                assert author == u"DC3"
-                assert description == u"example parser that works on any file"
-                break
-        else:
-            pytest.fail("Sample parser was not listed.")
-
-        parser_file, config_file = make_sample_parser()
-        parser_dir = parser_file.dirname
-
-        # Now try adding the Sample parser using the --parser-dir flag.
-        ret = runner.invoke(cli.main, [
-            "--parser-dir", str(parser_dir),
-            "--parser-config", str(config_file),
-            "list", "--json",
-        ])
-        print(ret.stderr, file=sys.stderr)
-        assert ret.exit_code == 0
-
-        # FIXME: This breaks if user has set up a PARSER_SOURCE in the configuration file.
-        results = json.loads(ret.stdout, encoding="utf8")
-        assert len(results) > 1
-        for name, source_name, author, description in results:
-            if source_name == str(parser_dir):
-                assert name == u"Sample"
-                assert author == u"Mr. Tester"
-                assert description == u"A test parser"
-                break
-        else:
-            pytest.fail("Sample parser from parser directory was not listed.")
-
-        # If we set --parser-source we should only get our registered parser from the directory.
-        ret = runner.invoke(cli.main, [
-            "--parser-dir", str(parser_dir),
-            "--parser-config", str(config_file),
-            "--parser-source", str(parser_dir),
-            "list", "--json"
-        ])
-        print(ret.stderr, file=sys.stderr)
-        assert ret.exit_code == 0
-
-        results = json.loads(ret.stdout, encoding="utf8")
-        assert results == [
-            [u"Sample", str(parser_dir), u"Mr. Tester", u"A test parser"]
-        ]
-
-        # Now try adding the config_file path to the __init__.py file in order to avoid having
-        # to manually use the --parser-config flag.
-        init_file = pathlib.Path(parser_dir) / "__init__.py"
-        init_file.write_text(f"config = {str(config_file)!r}", "utf8")
-        ret = runner.invoke(cli.main, [
-            "--parser-dir", str(parser_dir),
-            "--parser-source", str(parser_dir),
-            "list", "--json",
-        ])
-        print(ret.stderr, file=sys.stderr)
-        assert ret.exit_code == 0
-
-        results = json.loads(ret.stdout, encoding="utf8")
-        assert results == [
-            [u"Sample", str(parser_dir), u"Mr. Tester", u"A test parser"]
-        ]
-
-
-def test_csv_legacy(tmp_path, datadir):
-    """Tests the csv feature."""
-    input_files = ["file1.exe", "file2.exe"]
-    results = [
-        {
-            "other": {"field1": "value1", "field2": ["value2", "value3"]},
-            "outputfile": [["out_name", "out_desc", "out_md5"], ["out_name2", "out_desc2", "out_md52"]],
-            "address": ["https://google.com", "ftp://amazon.com"]
-        },
-        {
-            "a": ["b", "c"],
-        }
-    ]
-    csv_file = tmp_path / "test.csv"
-
-    cli._write_csv(input_files, results, str(csv_file))
-
-    expected = (datadir / "csv_legacy.csv").read_text("utf-8")
-    actual = csv_file.read_text("utf-8")
-    actual = re.sub('\n[^"]*?,', "\n[TIMESTAMP],", actual)
-    assert actual == expected
-
-
-def test_csv_cli(tmp_path, datadir):
-    """Tests the csv feature on the command line."""
-    runner = CliRunner(mix_stderr=False)
-
-    with runner.isolated_filesystem(tmp_path):
-
-        with open("test.txt", "wb") as fp:
-            fp.write(b"This is some test data!")
-
-        ret = runner.invoke(cli.main, [
-            "parse", "foo", "test.txt",
-            "--no-output-files",
-            "--format", "csv",
-        ], catch_exceptions=False)
-        print(ret.stdout)
-        print(ret.stderr, file=sys.stderr)
-        assert ret.exit_code == 0
-
-        expected = (datadir / "csv_cli.csv").read_text()
-        assert ret.stdout == expected
-
-
-def test_add_testcase(tmp_path, datadir):
-    """Tests adding a parser testcase."""
-    runner = CliRunner(mix_stderr=False)
-
-    malware_repo = tmp_path / "malware_repo"
-    malware_repo.mkdir()
-    test_case_dir = tmp_path / "testcases"
-    test_case_dir.mkdir()
-    (test_case_dir / "mwcp").mkdir()  # directory for parser source must also be created
-    test_file = tmp_path / "test.txt"
-    test_file.write_bytes(b"This is some test data!")
-
-    # Add a test case for our foo parser.
-    ret = runner.invoke(cli.main, [
-        "test", "foo",
-        "--testcase-dir", str(test_case_dir),
-        "--malware-repo", str(malware_repo),
-        "--add", str(test_file),
-    ], catch_exceptions=False)
-    print(ret.stdout)
-    print(ret.stderr, file=sys.stderr)
-    assert ret.exit_code == 0
-
-    # Ensure test file got placed in the right location.
-    test_sample = malware_repo / "fb84" / "fb843efb2ffec987db12e72ca75c9ea2"
-    assert test_sample.exists()
-    assert test_sample.read_bytes() == test_file.read_bytes()
-
-    # Ensure the test case was created correctly.
-    test_case_file = test_case_dir / "mwcp" / "foo" / "fb843efb2ffec987db12e72ca75c9ea2.json"
-    assert test_case_file.exists()
-    expected = (datadir / "fb843efb2ffec987db12e72ca75c9ea2.json").read_text().replace("MWCP_VERSION", mwcp.__version__)
-    assert test_case_file.read_text() == expected
-
-    # Now test that it ignores a second add of the same file.
-    ret = runner.invoke(cli.main, [
-        "test", "foo",
-        "--testcase-dir", str(test_case_dir),
-        "--malware-repo", str(malware_repo),
-        "--add", str(test_file),
-    ], catch_exceptions=False)
-    print(ret.stdout)
-    print(ret.stderr, file=sys.stderr)
-    assert ret.exit_code == 0
-    assert ret.stderr.splitlines()[-1] == (
-        f"[-] (MainProcess:mwcp.testing): Test case for {test_file} already exists in {test_case_file}"
-    )
-    assert test_case_file.read_text() == expected
-
-    # Now test force updating the results.
-    ret = runner.invoke(cli.main, [
-        "test", "foo",
-        "--testcase-dir", str(test_case_dir),
-        "--malware-repo", str(malware_repo),
-        "--update",
-        "--add", str(test_file),
-    ], catch_exceptions=False)
-    print(ret.stdout)
-    print(ret.stderr, file=sys.stderr)
-    assert ret.exit_code == 0
-    # Since it would be too hard to dynamically change what the parser does, just ensure
-    # we get the right stderr and the testcase hasn't changed.
-    assert ret.stderr.splitlines()[-1] == (
-        f"[+] (MainProcess:mwcp.testing): Adding results for {test_file} in {test_case_file}"
-    )
-    assert test_case_file.read_text() == expected
-
-    # Now test the deletion of the test case.
-    ret = runner.invoke(cli.main, [
-        "test", "foo",
-        "--testcase-dir", str(test_case_dir),
-        "--malware-repo", str(malware_repo),
-        "--delete", str(test_file),
-    ], catch_exceptions=False)
-    print(ret.stdout)
-    print(ret.stderr, file=sys.stderr)
-    assert ret.exit_code == 0
-
-    # Make sure we did NOT remove the file from the malware repo.
-    assert test_sample.exists()
-    assert test_sample.read_bytes() == test_file.read_bytes()
-
-    # Check that the test case has been removed.
-    assert not test_case_file.exists()
-
-
-def test_add_filelist_testcase(tmp_path):
-    """Tests bulk adding testcases with --add-filelist flag."""
-    runner = CliRunner(mix_stderr=False)
-
-    malware_repo = tmp_path / "malware_repo"
-    malware_repo.mkdir()
-    test_case_dir = tmp_path / "testcases"
-    test_case_dir.mkdir()
-    (test_case_dir / "mwcp").mkdir()  # directory for parser source must also be created
-
-    # Create a file list of paths.
-    filelist = []
-    for i in range(10):
-        file = tmp_path / f"file_{i}"
-        data = f"this is file {i}".encode("utf8")
-        file.write_bytes(data)
-        filelist.append((str(file), hashlib.md5(data).hexdigest()))
-
-    filelist_txt = tmp_path / "filelist.txt"
-    filelist_txt.write_text(u"\n".join(file_path for file_path, _ in filelist), "utf8")
-
-    # Add a test case for our sample parser.
-    ret = runner.invoke(cli.main, [
-        "test", "foo",
-        "--testcase-dir", str(test_case_dir),
-        "--malware-repo", str(malware_repo),
-        "--add-filelist", str(filelist_txt),
-    ], catch_exceptions=False)
-    print(ret.stdout)
-    print(ret.stderr, file=sys.stderr)
-    assert ret.exit_code == 0
-
-    # Ensure a sample and test case was added for each file.
-    for _, md5 in filelist:
-        assert (malware_repo / md5[:4] / md5).exists()
-        assert (test_case_dir / "mwcp" / "foo" / f"{md5}.json").exists()
+"""
+Tests the CLI tools.
+"""
+
+import hashlib
+import json
+import os
+import re
+import sys
+
+from click.testing import CliRunner
+import pytest
+import pathlib
+
+import mwcp
+from mwcp import cli
+
+
+@pytest.fixture(autouse=True)
+def reset():
+    """Ensures registry and config is reset for each test."""
+    mwcp.clear_registry()
+    mwcp.config.clear()
+
+
+def test_parse(tmp_path, datadir):
+    """Test running a parser"""
+    runner = CliRunner(mix_stderr=False)
+
+    with runner.isolated_filesystem(tmp_path):
+
+        test_file = "test.txt"
+        with open(test_file, "wb") as fp:
+            fp.write(b"This is some test data!")
+
+        # Run the foo parser on the test input file.
+        ret = runner.invoke(cli.main, ["parse", "foo", test_file])
+        print(ret.stdout)
+        print(ret.stderr, file=sys.stderr)
+        assert ret.exit_code == 0
+
+        expected = (datadir / "parse.txt").read_text("utf-8")
+        assert ret.stdout == expected
+
+        output_file = pathlib.Path(f"{test_file}_mwcp_output", "5eb63_fooconfigtest.txt")
+        assert output_file.exists()
+
+        # Test the "--no-output-files" flag.
+        output_file.unlink()
+        assert not output_file.exists()
+        ret = runner.invoke(cli.main, ["parse", "--no-output-files", "foo", test_file])
+        assert ret.exit_code == 0
+        # We should still not have the output file
+        assert not output_file.exists()
+
+        # Test the json formatting
+        ret = runner.invoke(cli.main, ["parse", "--no-output-files", "-f", "json", "foo", test_file])
+        print(ret.stdout)
+        print(ret.stderr, file=sys.stderr)
+        assert ret.exit_code == 0
+
+        expected = (datadir / "parse.json").read_text("utf-8").replace("MWCP_VERSION", mwcp.__version__)
+        assert ret.stdout == expected
+
+
+def test_list(tmp_path, make_sample_parser):
+    """
+    Tests displaying a list of parsers.
+
+    (This is also where we test the parser registration flags.)
+    """
+    runner = CliRunner(mix_stderr=False)
+
+    with runner.isolated_filesystem(tmp_path):
+
+        # First ensure our foo parser is registered via entry_points.
+        ret = runner.invoke(cli.main, ["list", "--json"])
+        print(ret.stderr, file=sys.stderr)
+        assert ret.exit_code == 0
+
+        results = json.loads(ret.stdout, encoding="utf8")
+        assert len(results) > 1
+        for name, source_name, author, description in results:
+            if name == u"foo" and source_name == u"dc3":
+                assert author == u"DC3"
+                assert description == u"example parser that works on any file"
+                break
+        else:
+            pytest.fail("Sample parser was not listed.")
+
+        parser_file, config_file = make_sample_parser()
+        parser_dir = parser_file.dirname
+
+        # Now try adding the Sample parser using the --parser-dir flag.
+        ret = runner.invoke(cli.main, [
+            "--parser-dir", str(parser_dir),
+            "--parser-config", str(config_file),
+            "list", "--json",
+        ])
+        print(ret.stderr, file=sys.stderr)
+        assert ret.exit_code == 0
+
+        # FIXME: This breaks if user has set up a PARSER_SOURCE in the configuration file.
+        results = json.loads(ret.stdout, encoding="utf8")
+        assert len(results) > 1
+        for name, source_name, author, description in results:
+            if source_name == str(parser_dir):
+                assert name == u"Sample"
+                assert author == u"Mr. Tester"
+                assert description == u"A test parser"
+                break
+        else:
+            pytest.fail("Sample parser from parser directory was not listed.")
+
+        # If we set --parser-source we should only get our registered parser from the directory.
+        ret = runner.invoke(cli.main, [
+            "--parser-dir", str(parser_dir),
+            "--parser-config", str(config_file),
+            "--parser-source", str(parser_dir),
+            "list", "--json"
+        ])
+        print(ret.stderr, file=sys.stderr)
+        assert ret.exit_code == 0
+
+        results = json.loads(ret.stdout, encoding="utf8")
+        assert results == [
+            [u"Sample", str(parser_dir), u"Mr. Tester", u"A test parser"]
+        ]
+
+        # Now try adding the config_file path to the __init__.py file in order to avoid having
+        # to manually use the --parser-config flag.
+        init_file = pathlib.Path(parser_dir) / "__init__.py"
+        init_file.write_text(f"config = {str(config_file)!r}", "utf8")
+        ret = runner.invoke(cli.main, [
+            "--parser-dir", str(parser_dir),
+            "--parser-source", str(parser_dir),
+            "list", "--json",
+        ])
+        print(ret.stderr, file=sys.stderr)
+        assert ret.exit_code == 0
+
+        results = json.loads(ret.stdout, encoding="utf8")
+        assert results == [
+            [u"Sample", str(parser_dir), u"Mr. Tester", u"A test parser"]
+        ]
+
+
+def test_csv_legacy(tmp_path, datadir):
+    """Tests the csv feature."""
+    input_files = ["file1.exe", "file2.exe"]
+    results = [
+        {
+            "other": {"field1": "value1", "field2": ["value2", "value3"]},
+            "outputfile": [["out_name", "out_desc", "out_md5"], ["out_name2", "out_desc2", "out_md52"]],
+            "address": ["https://google.com", "ftp://amazon.com"]
+        },
+        {
+            "a": ["b", "c"],
+        }
+    ]
+    csv_file = tmp_path / "test.csv"
+
+    cli._write_csv(input_files, results, str(csv_file))
+
+    expected = (datadir / "csv_legacy.csv").read_text("utf-8")
+    actual = csv_file.read_text("utf-8")
+    actual = re.sub('\n[^"]*?,', "\n[TIMESTAMP],", actual)
+    assert actual == expected
+
+
+def test_csv_cli(tmp_path, datadir):
+    """Tests the csv feature on the command line."""
+    runner = CliRunner(mix_stderr=False)
+
+    with runner.isolated_filesystem(tmp_path):
+
+        with open("test.txt", "wb") as fp:
+            fp.write(b"This is some test data!")
+
+        ret = runner.invoke(cli.main, [
+            "parse", "foo", "test.txt",
+            "--no-output-files",
+            "--format", "csv",
+        ], catch_exceptions=False)
+        print(ret.stdout)
+        print(ret.stderr, file=sys.stderr)
+        assert ret.exit_code == 0
+
+        expected = (datadir / "csv_cli.csv").read_text()
+        assert ret.stdout == expected
+
+
+def test_add_testcase(tmp_path, datadir):
+    """Tests adding a parser testcase."""
+    runner = CliRunner(mix_stderr=False)
+
+    malware_repo = tmp_path / "malware_repo"
+    malware_repo.mkdir()
+    test_case_dir = tmp_path / "testcases"
+    test_case_dir.mkdir()
+    (test_case_dir / "dc3").mkdir()  # directory for parser source must also be created
+    test_file = tmp_path / "test.txt"
+    test_file.write_bytes(b"This is some test data!")
+
+    # Add a test case for our foo parser.
+    ret = runner.invoke(cli.main, [
+        "test", "foo",
+        "--testcase-dir", str(test_case_dir),
+        "--malware-repo", str(malware_repo),
+        "--add", str(test_file),
+    ], catch_exceptions=False)
+    print(ret.stdout)
+    print(ret.stderr, file=sys.stderr)
+    assert ret.exit_code == 0
+
+    # Ensure test file got placed in the right location.
+    test_sample = malware_repo / "fb84" / "fb843efb2ffec987db12e72ca75c9ea2"
+    assert test_sample.exists()
+    assert test_sample.read_bytes() == test_file.read_bytes()
+
+    # Ensure the test case was created correctly.
+    test_case_file = test_case_dir / "dc3" / "foo" / "fb843efb2ffec987db12e72ca75c9ea2.json"
+    assert test_case_file.exists()
+    expected = (datadir / "fb843efb2ffec987db12e72ca75c9ea2.json").read_text().replace("MWCP_VERSION", mwcp.__version__)
+    assert test_case_file.read_text() == expected
+
+    # Now test that it ignores a second add of the same file.
+    ret = runner.invoke(cli.main, [
+        "test", "foo",
+        "--testcase-dir", str(test_case_dir),
+        "--malware-repo", str(malware_repo),
+        "--add", str(test_file),
+    ], catch_exceptions=False)
+    print(ret.stdout)
+    print(ret.stderr, file=sys.stderr)
+    assert ret.exit_code == 0
+    assert ret.stderr.splitlines()[-1] == (
+        f"[-] (MainProcess:mwcp.testing): Test case for {test_file} already exists in {test_case_file}"
+    )
+    assert test_case_file.read_text() == expected
+
+    # Now test force updating the results.
+    ret = runner.invoke(cli.main, [
+        "test", "foo",
+        "--testcase-dir", str(test_case_dir),
+        "--malware-repo", str(malware_repo),
+        "--update",
+        "--add", str(test_file),
+    ], catch_exceptions=False)
+    print(ret.stdout)
+    print(ret.stderr, file=sys.stderr)
+    assert ret.exit_code == 0
+    # Since it would be too hard to dynamically change what the parser does, just ensure
+    # we get the right stderr and the testcase hasn't changed.
+    assert ret.stderr.splitlines()[-1] == (
+        f"[+] (MainProcess:mwcp.testing): Adding results for {test_file} in {test_case_file}"
+    )
+    assert test_case_file.read_text() == expected
+
+    # Now test the deletion of the test case.
+    ret = runner.invoke(cli.main, [
+        "test", "foo",
+        "--testcase-dir", str(test_case_dir),
+        "--malware-repo", str(malware_repo),
+        "--delete", str(test_file),
+    ], catch_exceptions=False)
+    print(ret.stdout)
+    print(ret.stderr, file=sys.stderr)
+    assert ret.exit_code == 0
+
+    # Make sure we did NOT remove the file from the malware repo.
+    assert test_sample.exists()
+    assert test_sample.read_bytes() == test_file.read_bytes()
+
+    # Check that the test case has been removed.
+    assert not test_case_file.exists()
+
+
+def test_add_filelist_testcase(tmp_path):
+    """Tests bulk adding testcases with --add-filelist flag."""
+    runner = CliRunner(mix_stderr=False)
+
+    malware_repo = tmp_path / "malware_repo"
+    malware_repo.mkdir()
+    test_case_dir = tmp_path / "testcases"
+    test_case_dir.mkdir()
+    (test_case_dir / "dc3").mkdir()  # directory for parser source must also be created
+
+    # Create a file list of paths.
+    filelist = []
+    for i in range(10):
+        file = tmp_path / f"file_{i}"
+        data = f"this is file {i}".encode("utf8")
+        file.write_bytes(data)
+        filelist.append((str(file), hashlib.md5(data).hexdigest()))
+
+    filelist_txt = tmp_path / "filelist.txt"
+    filelist_txt.write_text(u"\n".join(file_path for file_path, _ in filelist), "utf8")
+
+    # Add a test case for our sample parser.
+    ret = runner.invoke(cli.main, [
+        "test", "foo",
+        "--testcase-dir", str(test_case_dir),
+        "--malware-repo", str(malware_repo),
+        "--add-filelist", str(filelist_txt),
+    ], catch_exceptions=False)
+    print(ret.stdout)
+    print(ret.stderr, file=sys.stderr)
+    assert ret.exit_code == 0
+
+    # Ensure a sample and test case was added for each file.
+    for _, md5 in filelist:
+        assert (malware_repo / md5[:4] / md5).exists()
+        assert (test_case_dir / "dc3" / "foo" / f"{md5}.json").exists()
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_construct.py` & `mwcp-3.9.0/mwcp/tests/test_construct.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,100 +1,100 @@
-"""Tests our construct helpers."""
-
-import doctest
-import os
-import sys
-
-import pytest
-
-from mwcp.utils import construct
-
-
-@pytest.mark.xfail(
-    raises=ValueError,
-    reason="Doctest is producing a 'wrapper loop when unwrapping obj_' error"
-)
-def test_helpers():
-    """Tests that the doctests for the helpers work."""
-    helper_modules = [
-        construct.helpers,
-        construct.datetime_,
-        construct.network,
-        construct.windows_enums,
-        construct.windows_structures
-    ]
-    for module in helper_modules:
-        results = doctest.testmod(module)
-        assert not results.failed
-
-
-def test_html():
-    """Tests the html construct."""
-    # Test doctests
-    results = doctest.testmod(construct.construct_html)
-    assert not results.failed
-
-    # Test with an example
-    EMBED_SPEC = construct.Struct(
-        'a' / construct.IP4Address,
-        'b' / construct.IP4Address,
-        'c' / construct.IP4Address,
-        'd' / construct.IP4Address
-    )
-
-    address_struct = construct.Struct(
-        'first' / construct.Struct('a' / construct.Byte, 'b' / construct.Byte),
-        'second' / construct.Struct('inner2' / construct.Bytes(2))
-        # 'internal' / IP4Address
-    )
-
-    PACKET = construct.Struct(
-        construct.Padding(0x9),
-        'Hardcoded Value 1' / construct.HexString(construct.Int32ul),
-        'Hardcoded Value 2' / construct.HexString(construct.Int32ul),
-        'Hardcoded Value 3' / construct.HexString(construct.Int32ul),
-        construct.Padding(0x17),
-        'Compromised Host IP' / construct.IP4Address,  # Use IP adapter
-        # 'Unknown IP Addresses' / construct.Switch(
-        #     this['Hardcoded Value 1'],
-        #     {
-        #         '0x1f4' : EMBED_SPEC
-        #     },
-        # ),
-        'Unknown IP Addresses' / address_struct[4],
-        # 'Unknown IP Addresses' / IP4Address[4],
-        construct.Padding(8),
-        'Unknown Indicator' / construct.String(0xF),
-        construct.Padding(2),
-        'Number of CPUs' / construct.Int32ul,
-        'CPU Mhz' / construct.Int32ul,
-        'Total Memory (MB)' / construct.Int32ul,
-        'Compromised System Kernel' / construct.CString(),
-        'Possible Trojan Version' / construct.CString()
-    )
-
-    data = (b'\x01\x00\x00\x00}\x00\x00\x00\x00\xf4\x01\x00\x002\x00\x00\x00\xe8'
-            b'\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01'
-            b'\x01\x00\x00\x00\x00\x01\x00\x00\x00\xc0\xa8\x01\r\xc0\xa8\x01\r\xc0'
-            b'\xa8\x01\r\xc0\xa8\x01\r\xc0\xa8\x01\r\xff\xff\x01\x00\x00\x00\x00\x00'
-            b'-== Love AV ==-:\x00\x01\x00\x00\x00d\n\x00\x00\xc4\x07\x00\x00'
-            b'Linux 3.13.0-93-generic\x001:G2.40\x00')
-
-    html_data = construct.html_hex(PACKET, data, depth=1)
-
-    with open(os.path.join(os.path.dirname(__file__), 'construct_html.html'), 'r') as fo:
-        expected_html_data = fo.read()
-
-    assert html_data == expected_html_data
-
-
-def test_base64():
-    """Test the Base64 Adapter with bug associated with unicode encoding on build"""
-    spec = construct.Base64(construct.CString("utf-16le"))
-    data = b'Y\x00W\x00J\x00j\x00Z\x00A\x00=\x00=\x00\x00\x00'
-    assert spec.parse(data) == b"abcd"
-    assert spec.build(b"abcd") == data
-
-    spec = construct.Base64(construct.CString("utf-8"))
-    data = b'YWJjZA==\x00'
-    assert spec.parse(data) == b"abcd"
-    assert spec.build(b"abcd") == data
+"""Tests our construct helpers."""
+
+import doctest
+import os
+import sys
+
+import pytest
+
+from mwcp.utils import construct
+
+
+@pytest.mark.xfail(
+    raises=ValueError,
+    reason="Doctest is producing a 'wrapper loop when unwrapping obj_' error"
+)
+def test_helpers():
+    """Tests that the doctests for the helpers work."""
+    helper_modules = [
+        construct.helpers,
+        construct.datetime_,
+        construct.network,
+        construct.windows_enums,
+        construct.windows_structures
+    ]
+    for module in helper_modules:
+        results = doctest.testmod(module)
+        assert not results.failed
+
+
+def test_html():
+    """Tests the html construct."""
+    # Test doctests
+    results = doctest.testmod(construct.construct_html)
+    assert not results.failed
+
+    # Test with an example
+    EMBED_SPEC = construct.Struct(
+        'a' / construct.IP4Address,
+        'b' / construct.IP4Address,
+        'c' / construct.IP4Address,
+        'd' / construct.IP4Address
+    )
+
+    address_struct = construct.Struct(
+        'first' / construct.Struct('a' / construct.Byte, 'b' / construct.Byte),
+        'second' / construct.Struct('inner2' / construct.Bytes(2))
+        # 'internal' / IP4Address
+    )
+
+    PACKET = construct.Struct(
+        construct.Padding(0x9),
+        'Hardcoded Value 1' / construct.HexString(construct.Int32ul),
+        'Hardcoded Value 2' / construct.HexString(construct.Int32ul),
+        'Hardcoded Value 3' / construct.HexString(construct.Int32ul),
+        construct.Padding(0x17),
+        'Compromised Host IP' / construct.IP4Address,  # Use IP adapter
+        # 'Unknown IP Addresses' / construct.Switch(
+        #     this['Hardcoded Value 1'],
+        #     {
+        #         '0x1f4' : EMBED_SPEC
+        #     },
+        # ),
+        'Unknown IP Addresses' / address_struct[4],
+        # 'Unknown IP Addresses' / IP4Address[4],
+        construct.Padding(8),
+        'Unknown Indicator' / construct.String(0xF),
+        construct.Padding(2),
+        'Number of CPUs' / construct.Int32ul,
+        'CPU Mhz' / construct.Int32ul,
+        'Total Memory (MB)' / construct.Int32ul,
+        'Compromised System Kernel' / construct.CString(),
+        'Possible Trojan Version' / construct.CString()
+    )
+
+    data = (b'\x01\x00\x00\x00}\x00\x00\x00\x00\xf4\x01\x00\x002\x00\x00\x00\xe8'
+            b'\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01'
+            b'\x01\x00\x00\x00\x00\x01\x00\x00\x00\xc0\xa8\x01\r\xc0\xa8\x01\r\xc0'
+            b'\xa8\x01\r\xc0\xa8\x01\r\xc0\xa8\x01\r\xff\xff\x01\x00\x00\x00\x00\x00'
+            b'-== Love AV ==-:\x00\x01\x00\x00\x00d\n\x00\x00\xc4\x07\x00\x00'
+            b'Linux 3.13.0-93-generic\x001:G2.40\x00')
+
+    html_data = construct.html_hex(PACKET, data, depth=1)
+
+    with open(os.path.join(os.path.dirname(__file__), 'construct_html.html'), 'r') as fo:
+        expected_html_data = fo.read()
+
+    assert html_data == expected_html_data
+
+
+def test_base64():
+    """Test the Base64 Adapter with bug associated with unicode encoding on build"""
+    spec = construct.Base64(construct.CString("utf-16le"))
+    data = b'Y\x00W\x00J\x00j\x00Z\x00A\x00=\x00=\x00\x00\x00'
+    assert spec.parse(data) == b"abcd"
+    assert spec.build(b"abcd") == data
+
+    spec = construct.Base64(construct.CString("utf-8"))
+    data = b'YWJjZA==\x00'
+    assert spec.parse(data) == b"abcd"
+    assert spec.build(b"abcd") == data
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_custombase64.py` & `mwcp-3.9.0/mwcp/tests/test_custombase64.py`

 * *Ordering differences only*

 * *Files 8% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-"""Tests mwcp.utils.custombase64"""
-
-from mwcp.utils import custombase64
-
-
-def test_base64():
-    custom_alphabet = b'EFGHQRSTUVWefghijklmnopIJKLMNOPABCDqrstuvwxyXYZabcdz0123456789+/='
-    assert custombase64.b64encode(b'hello world', custom_alphabet) == b'LSoXMS8BO29dMSj='
-    assert custombase64.b64decode(b'LSoXMS8BO29dMSj=', custom_alphabet) == b'hello world'
-
-
-def test_base32():
-    custom_alphabet = b'FGHIJQ345RSTUVWXYKLMABCDENOPZ267='
-    assert custombase64.b32encode(b'hello world', custom_alphabet) == b'VGLCEPIXJGPC6ZMUUY======'
-    assert custombase64.b32decode(b'VGLCEPIXJGPC6ZMUUY======', custom_alphabet) == b'hello world'
-
-
-def test_base16():
-    custom_alphabet = b'78BDE0123F459A6C'
-    assert custombase64.b16encode(b'hello world', custom_alphabet) == b'131019191CB7221C2B191E'
-    assert custombase64.b16decode(b'131019191CB7221C2B191E', custom_alphabet) == b'hello world'
+"""Tests mwcp.utils.custombase64"""
+
+from mwcp.utils import custombase64
+
+
+def test_base64():
+    custom_alphabet = b'EFGHQRSTUVWefghijklmnopIJKLMNOPABCDqrstuvwxyXYZabcdz0123456789+/='
+    assert custombase64.b64encode(b'hello world', custom_alphabet) == b'LSoXMS8BO29dMSj='
+    assert custombase64.b64decode(b'LSoXMS8BO29dMSj=', custom_alphabet) == b'hello world'
+
+
+def test_base32():
+    custom_alphabet = b'FGHIJQ345RSTUVWXYKLMABCDENOPZ267='
+    assert custombase64.b32encode(b'hello world', custom_alphabet) == b'VGLCEPIXJGPC6ZMUUY======'
+    assert custombase64.b32decode(b'VGLCEPIXJGPC6ZMUUY======', custom_alphabet) == b'hello world'
+
+
+def test_base16():
+    custom_alphabet = b'78BDE0123F459A6C'
+    assert custombase64.b16encode(b'hello world', custom_alphabet) == b'131019191CB7221C2B191E'
+    assert custombase64.b16decode(b'131019191CB7221C2B191E', custom_alphabet) == b'hello world'
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_disassembly/Sample.py` & `mwcp-3.9.0/mwcp/tests/test_disassembly/Sample.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,61 +1,61 @@
-"""
-Sample parser that uses dragodis disassembly library.
-(This is a conversion from the kordesii "Sample" parser.)
-"""
-
-import dragodis
-import rugosa
-
-from mwcp import metadata, Parser
-
-
-class Implant(Parser):
-    DESCRIPTION = "Sample Implant"
-
-    @classmethod
-    def identify(cls, file_object):
-        return file_object.md5 == "e1b6be6c0c2db8b3d4dca56062ca6301"
-
-    @staticmethod
-    def xor_decrypt(key, enc_data):
-        return bytes((x ^ key) for x in enc_data)
-
-    def find_strings(self, dis: dragodis.Disassembler):
-        """
-        Extracts and reports DecodedString objects for the parameters following xor encryption function:
-
-            void encrypt(char *s, char key)
-            {
-                while (*s)
-                    *s++ ^= key;
-            }
-        """
-        emulator = rugosa.Emulator(dis)
-        pattern = rugosa.re.compile(br"\x8b\x45\x08\x0f\xbe\x08")
-        for encrypt_func in pattern.find_functions(dis):
-            self.logger.info("Found XOR encrypt function at: 0x%x", encrypt_func.start)
-            for call_ea in encrypt_func.calls_to:
-                self.logger.debug("Tracing 0x%08x", call_ea)
-                # Extract arguments for call to xor function.
-                context = emulator.context_at(call_ea)
-                enc_str_ptr, key = context.get_function_arg_values()
-
-                enc_string_data = rugosa.get_terminated_bytes(dis, enc_str_ptr)
-                dec_string_data = self.xor_decrypt(key, enc_string_data)
-                string = rugosa.DecodedString(
-                    dec_data=dec_string_data,
-                    enc_data=enc_string_data,
-                    # data is encrypted in-place, so include string pointer as decoded source.
-                    dec_source=enc_str_ptr,
-                )
-                # Annotate underlying disassembler with decrypted data.
-                string.patch(dis, rename=False)
-
-                # Report decoded string.
-                self.report.add(metadata.DecodedString(
-                    str(string), encryption_key=metadata.EncryptionKey(bytes([key]), "xor")
-                ))
-
-    def run(self):
-        with self.file_object.disassembly(report=self.report) as dis:
-            self.find_strings(dis)
+"""
+Sample parser that uses dragodis disassembly library.
+(This is a conversion from the kordesii "Sample" parser.)
+"""
+
+import dragodis
+import rugosa
+
+from mwcp import metadata, Parser
+
+
+class Implant(Parser):
+    DESCRIPTION = "Sample Implant"
+
+    @classmethod
+    def identify(cls, file_object):
+        return file_object.md5 == "e1b6be6c0c2db8b3d4dca56062ca6301"
+
+    @staticmethod
+    def xor_decrypt(key, enc_data):
+        return bytes((x ^ key) for x in enc_data)
+
+    def find_strings(self, dis: dragodis.Disassembler):
+        """
+        Extracts and reports DecodedString objects for the parameters following xor encryption function:
+
+            void encrypt(char *s, char key)
+            {
+                while (*s)
+                    *s++ ^= key;
+            }
+        """
+        emulator = rugosa.Emulator(dis)
+        pattern = rugosa.re.compile(br"\x8b\x45\x08\x0f\xbe\x08")
+        for encrypt_func in pattern.find_functions(dis):
+            self.logger.info("Found XOR encrypt function at: 0x%x", encrypt_func.start)
+            for call_ea in encrypt_func.calls_to:
+                self.logger.debug("Tracing 0x%08x", call_ea)
+                # Extract arguments for call to xor function.
+                context = emulator.context_at(call_ea)
+                enc_str_ptr, key = context.get_function_arg_values()
+
+                enc_string_data = rugosa.get_terminated_bytes(dis, enc_str_ptr)
+                dec_string_data = self.xor_decrypt(key, enc_string_data)
+                string = rugosa.DecodedString(
+                    dec_data=dec_string_data,
+                    enc_data=enc_string_data,
+                    # data is encrypted in-place, so include string pointer as decoded source.
+                    dec_source=enc_str_ptr,
+                )
+                # Annotate underlying disassembler with decrypted data.
+                string.patch(dis, rename=False)
+
+                # Report decoded string.
+                self.report.add(metadata.DecodedString(
+                    str(string), encryption_key=metadata.EncryptionKey(bytes([key]), "xor")
+                ))
+
+    def run(self):
+        with self.file_object.disassembly(report=self.report) as dis:
+            self.find_strings(dis)
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_disassembly/strings.c` & `mwcp-3.9.0/mwcp/tests/test_disassembly/strings.c`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,76 +1,76 @@
-#include <stdio.h>
-#include <string.h>
-
-char string01[] = "Idmmn!Vnsme ";
-char string02[] = "Vgqv\"qvpkle\"ukvj\"ig{\"2z20";
-char string03[] = "Wkf#rvj`h#aqltm#el{#ivnsp#lufq#wkf#obyz#gld-";
-char string04[] = "Keo$mw$wpvkjc$ej`$ehwk$cmraw$wle`a*";
-char string05[] = "Dfla%gpwkv%mji`v%lk%rjji%fijqm+";
-char string06[] = "Egru&ghb&biau&cgen&ngrc&rnc&irnct(";
-char string13[] = "\\cv}3g{v3pargv3qfg3w|}4g3qavrx3g{v3t\x7fr``=";
-char string17[] = "C\x7frer7c\x7fr7q{xxs7zve|7~d7cry7~yt\x7frd9";
-char string1a[] = "+()./,-\"#*";
-char string23[] = "`QFBWFsQL@FPPb";
-char string27[] = "tSUdFS";
-char string40[] = "\x01\x13\x10n\x0e\x05\x14";
-char string46[] = "-\",5 , v,tr4v,trv4t,v\x7f,ttt";
-char string73[] = "@AKJDGBA@KJGDBJKAGDC";
-char string75[] = "!\x1d\x10U\x05\x14\x06\x01U\x02\x1c\x19\x19U\x19\x1a\x1a\x1eU\x17\x07\x1c\x12\x1d\x01\x10\x07U\x01\x1a\x18\x1a\x07\x07\x1a\x02[";
-char string77[] = "4\x16\x05\x04W\x16\x19\x13W\x15\x02\x04\x04\x12\x04W\x04\x03\x16\x1b\x1b\x12\x13W\x1e\x19W\x04\x16\x19\x13W\x13\x05\x1e\x11\x03\x04Y";
-char string7a[] = ".\x12\x1fZ\x10\x1b\x19\x11\x1f\x0eZ\x12\x0f\x14\x1dZ\x15\x14Z\x0e\x12\x1fZ\x18\x1b\x19\x11Z\x15\x1cZ\x0e\x12\x1fZ\r\x13\x1e\x1fZ\x19\x12\x1b\x13\x08T";
-char string7f[] = "LMFOGHKNLMGFOHKFGNLKHNMLOKGNKGHFGLHKGLMHKGOFNMLHKGFNLMJNMLIJFGNMLOJIMLNGFJHNM";;
-
-
-
-void encrypt(char *s, char key)
-{
-	while (*s)
-		*s++ ^= key;
-}
-
-void decrypt()
-{
-	encrypt(&string01[0], 0x01);
-	encrypt(&string02[0], 0x02);
-	encrypt(&string03[0], 0x03);
-	encrypt(&string04[0], 0x04);
-	encrypt(&string05[0], 0x05);
-	encrypt(&string06[0], 0x06);
-	encrypt(&string13[0], 0x13);
-	encrypt(&string17[0], 0x17);
-	encrypt(&string1a[0], 0x1a);
-	encrypt(&string23[0], 0x23);
-	encrypt(&string27[0], 0x27);
-	encrypt(&string40[0], 0x40);
-	encrypt(&string46[0], 0x46);
-	encrypt(&string73[0], 0x73);
-	encrypt(&string75[0], 0x75);
-	encrypt(&string77[0], 0x77);
-	encrypt(&string7a[0], 0x7a);
-	encrypt(&string7f[0], 0x7f);
-}
-
-int main()
-{
-	decrypt();
-	printf("%s\n", string01);
-	printf("%s\n", string02);
-	printf("%s\n", string03);
-	printf("%s\n", string04);
-	printf("%s\n", string05);
-	printf("%s\n", string06);
-	printf("%s\n", string13);
-	printf("%s\n", string17);
-	printf("%s\n", string1a);
-	printf("%s\n", string23);
-	printf("%s\n", string27);
-	printf("%s\n", string40);
-	printf("%s\n", string46);
-	printf("%s\n", string73);
-	printf("%s\n", string75);
-	printf("%s\n", string77);
-	printf("%s\n", string7a);
-	printf("%s\n", string7f);
-
-    return 0;
-}
+#include <stdio.h>
+#include <string.h>
+
+char string01[] = "Idmmn!Vnsme ";
+char string02[] = "Vgqv\"qvpkle\"ukvj\"ig{\"2z20";
+char string03[] = "Wkf#rvj`h#aqltm#el{#ivnsp#lufq#wkf#obyz#gld-";
+char string04[] = "Keo$mw$wpvkjc$ej`$ehwk$cmraw$wle`a*";
+char string05[] = "Dfla%gpwkv%mji`v%lk%rjji%fijqm+";
+char string06[] = "Egru&ghb&biau&cgen&ngrc&rnc&irnct(";
+char string13[] = "\\cv}3g{v3pargv3qfg3w|}4g3qavrx3g{v3t\x7fr``=";
+char string17[] = "C\x7frer7c\x7fr7q{xxs7zve|7~d7cry7~yt\x7frd9";
+char string1a[] = "+()./,-\"#*";
+char string23[] = "`QFBWFsQL@FPPb";
+char string27[] = "tSUdFS";
+char string40[] = "\x01\x13\x10n\x0e\x05\x14";
+char string46[] = "-\",5 , v,tr4v,trv4t,v\x7f,ttt";
+char string73[] = "@AKJDGBA@KJGDBJKAGDC";
+char string75[] = "!\x1d\x10U\x05\x14\x06\x01U\x02\x1c\x19\x19U\x19\x1a\x1a\x1eU\x17\x07\x1c\x12\x1d\x01\x10\x07U\x01\x1a\x18\x1a\x07\x07\x1a\x02[";
+char string77[] = "4\x16\x05\x04W\x16\x19\x13W\x15\x02\x04\x04\x12\x04W\x04\x03\x16\x1b\x1b\x12\x13W\x1e\x19W\x04\x16\x19\x13W\x13\x05\x1e\x11\x03\x04Y";
+char string7a[] = ".\x12\x1fZ\x10\x1b\x19\x11\x1f\x0eZ\x12\x0f\x14\x1dZ\x15\x14Z\x0e\x12\x1fZ\x18\x1b\x19\x11Z\x15\x1cZ\x0e\x12\x1fZ\r\x13\x1e\x1fZ\x19\x12\x1b\x13\x08T";
+char string7f[] = "LMFOGHKNLMGFOHKFGNLKHNMLOKGNKGHFGLHKGLMHKGOFNMLHKGFNLMJNMLIJFGNMLOJIMLNGFJHNM";;
+
+
+
+void encrypt(char *s, char key)
+{
+	while (*s)
+		*s++ ^= key;
+}
+
+void decrypt()
+{
+	encrypt(&string01[0], 0x01);
+	encrypt(&string02[0], 0x02);
+	encrypt(&string03[0], 0x03);
+	encrypt(&string04[0], 0x04);
+	encrypt(&string05[0], 0x05);
+	encrypt(&string06[0], 0x06);
+	encrypt(&string13[0], 0x13);
+	encrypt(&string17[0], 0x17);
+	encrypt(&string1a[0], 0x1a);
+	encrypt(&string23[0], 0x23);
+	encrypt(&string27[0], 0x27);
+	encrypt(&string40[0], 0x40);
+	encrypt(&string46[0], 0x46);
+	encrypt(&string73[0], 0x73);
+	encrypt(&string75[0], 0x75);
+	encrypt(&string77[0], 0x77);
+	encrypt(&string7a[0], 0x7a);
+	encrypt(&string7f[0], 0x7f);
+}
+
+int main()
+{
+	decrypt();
+	printf("%s\n", string01);
+	printf("%s\n", string02);
+	printf("%s\n", string03);
+	printf("%s\n", string04);
+	printf("%s\n", string05);
+	printf("%s\n", string06);
+	printf("%s\n", string13);
+	printf("%s\n", string17);
+	printf("%s\n", string1a);
+	printf("%s\n", string23);
+	printf("%s\n", string27);
+	printf("%s\n", string40);
+	printf("%s\n", string46);
+	printf("%s\n", string73);
+	printf("%s\n", string75);
+	printf("%s\n", string77);
+	printf("%s\n", string7a);
+	printf("%s\n", string7f);
+
+    return 0;
+}
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_disassembly/strings.exe` & `mwcp-3.9.0/mwcp/tests/test_disassembly/strings.exe`

 * *Files identical despite different names*

### Comparing `mwcp-3.8.0/mwcp/tests/test_disassembly.py` & `mwcp-3.9.0/mwcp/tests/test_disassembly.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,67 +1,67 @@
-"""
-Tests components that use Dragodis disassembly.
-"""
-
-import os
-
-import pytest
-
-import mwcp
-from mwcp import metadata
-from mwcp.tests.test_parsers import _test_parser
-
-dragodis = pytest.importorskip("dragodis", reason="Dragodis not installed")
-
-
-@pytest.mark.parametrize("backend", ["ida", "ghidra"])
-def test_disassembly(datadir, backend):
-    """Tests basic disassembly"""
-    strings_exe = datadir / "strings.exe"
-
-    input_file = mwcp.FileObject.from_path(strings_exe)
-    try:
-        with input_file.disassembly(backend) as dis:
-            insn = dis.get_instruction(0x401000)
-            assert insn.mnemonic == "push"
-    except dragodis.NotInstalledError as e:
-        pytest.skip(e)
-
-
-@pytest.mark.parametrize("backend", ["ida", "ghidra"])
-def test_file_object_disassembly(datadir, backend):
-    """Tests disassembler project file gets reported when using FileObject.disassembly()"""
-    strings_exe = datadir / "strings.exe"
-
-    input_file = mwcp.FileObject.from_path(strings_exe)
-    report = mwcp.Report(input_file, "FooParser")
-    with report:
-        try:
-            with input_file.disassembly(backend, report=report) as dis:
-                line = dis.get_line(0x401000)
-                line.set_comment("test comment")
-        except dragodis.NotInstalledError as e:
-            pytest.skip(e)
-    # After we leave disassembly context, we should see the project file in the report.
-    files = report.get(metadata.File)
-    assert len(files) == 1
-    project_file = files[0]
-    assert project_file.data
-    if backend == "ida":
-        assert project_file.name == "strings.exe.idb"
-    else:
-        assert project_file.name == "strings.exe_ghidra.zip"
-    assert project_file.derivation == "supplemental"
-
-
-@pytest.mark.parametrize("backend", ["ida", "ghidra"])
-def test_Sample(pytestconfig, datadir, backend):
-    """Tests running the Sample parser."""
-    mwcp.register_parser_directory(str(datadir), source_name="test")
-    os.environ["DRAGODIS_DISASSEMBLER"] = backend
-    input_file_path = datadir / "strings.exe"
-    results_path = datadir / "strings.json"
-
-    try:
-        _test_parser(pytestconfig, input_file_path, results_path)
-    except dragodis.NotInstalledError as e:
-        pytest.skip(e)
+"""
+Tests components that use Dragodis disassembly.
+"""
+
+import os
+
+import pytest
+
+import mwcp
+from mwcp import metadata
+from mwcp.tests.test_parsers import _test_parser
+
+dragodis = pytest.importorskip("dragodis", reason="Dragodis not installed")
+
+
+@pytest.mark.parametrize("backend", ["ida", "ghidra"])
+def test_disassembly(datadir, backend):
+    """Tests basic disassembly"""
+    strings_exe = datadir / "strings.exe"
+
+    input_file = mwcp.FileObject.from_path(strings_exe)
+    try:
+        with input_file.disassembly(backend) as dis:
+            insn = dis.get_instruction(0x401000)
+            assert insn.mnemonic == "push"
+    except dragodis.NotInstalledError as e:
+        pytest.skip(e)
+
+
+@pytest.mark.parametrize("backend", ["ida", "ghidra"])
+def test_file_object_disassembly(datadir, backend):
+    """Tests disassembler project file gets reported when using FileObject.disassembly()"""
+    strings_exe = datadir / "strings.exe"
+
+    input_file = mwcp.FileObject.from_path(strings_exe)
+    report = mwcp.Report(input_file, "FooParser")
+    with report:
+        try:
+            with input_file.disassembly(backend, report=report) as dis:
+                line = dis.get_line(0x401000)
+                line.set_comment("test comment")
+        except dragodis.NotInstalledError as e:
+            pytest.skip(e)
+    # After we leave disassembly context, we should see the project file in the report.
+    files = report.get(metadata.File)
+    assert len(files) == 1
+    project_file = files[0]
+    assert project_file.data
+    if backend == "ida":
+        assert project_file.name == "strings.exe.idb"
+    else:
+        assert project_file.name == "strings.exe_ghidra.zip"
+    assert project_file.derivation == "supplemental"
+
+
+@pytest.mark.parametrize("backend", ["ida", "ghidra"])
+def test_Sample(pytestconfig, datadir, backend):
+    """Tests running the Sample parser."""
+    mwcp.register_parser_directory(str(datadir), source_name="test")
+    os.environ["DRAGODIS_DISASSEMBLER"] = backend
+    input_file_path = datadir / "strings.exe"
+    results_path = datadir / "strings.json"
+
+    try:
+        _test_parser(pytestconfig, input_file_path, results_path)
+    except dragodis.NotInstalledError as e:
+        pytest.skip(e)
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_legacy_reporter/report.txt` & `mwcp-3.9.0/mwcp/tests/test_legacy_reporter/report.txt`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,26 +1,26 @@
----- Credential ----
-Username    Password
-----------  ----------
-admin       pass
-
----- Socket ----
-Address        Port  Network Protocol
------------  ------  ------------------
-192.168.1.1      80  tcp
-
----- URL ----
-Tags    Address        Port  Network Protocol    Username    Password
-------  -----------  ------  ------------------  ----------  ----------
-proxy   192.168.1.1      80  tcp                 admin       pass
-
----- Miscellaneous ----
-Key    Value
------  --------------
-foo    bar
-biz    b'baz\x00\x01'
-
----- Residual Files ----
-Filename    Description          Derivation    MD5                               Arch    Compile Time
-----------  -------------------  ------------  --------------------------------  ------  --------------
-file_1.exe  example output file                8d777f385d3dfec8815d20f7496026dc
-
+---- Credential ----
+Username    Password
+----------  ----------
+admin       pass
+
+---- Socket ----
+Address        Port  Network Protocol
+-----------  ------  ------------------
+192.168.1.1      80  tcp
+
+---- URL ----
+Tags    Address        Port  Network Protocol    Username    Password
+------  -----------  ------  ------------------  ----------  ----------
+proxy   192.168.1.1      80  tcp                 admin       pass
+
+---- Miscellaneous ----
+Key    Value
+-----  --------------
+foo    bar
+biz    b'baz\x00\x01'
+
+---- Residual Files ----
+Filename    Description          Derivation    MD5                               Arch    Compile Time
+----------  -------------------  ------------  --------------------------------  ------  --------------
+file_1.exe  example output file                8d777f385d3dfec8815d20f7496026dc
+
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_legacy_reporter.py` & `mwcp-3.9.0/mwcp/tests/test_legacy_reporter.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,149 +1,140 @@
-# coding=utf-8
-"""
-Tests the legacy features of mwcp.Reporter object.
-
-These features are now replaced by test_report.py and test_runner.py
-"""
-
-import os
-import json
-
-import pytest
-
-import mwcp
-# from mwcp.reporter import STANDARD_FIELD_ORDER, INFO_FIELD_ORDER
-
-
-def test_managed_tempdir(tmpdir):
-    runner = mwcp.Runner(temp_directory=str(tmpdir))
-    managed_tempdir = runner.managed_tempdir
-    assert os.path.exists(managed_tempdir)
-    assert managed_tempdir.startswith(os.path.join(str(tmpdir), 'mwcp-managed_tempdir-'))
-
-
-@pytest.mark.parametrize('key,value,expected', [
-    ('filepath', br'C:\dir\file.txt', {
-        'filepath': [r'C:\dir\file.txt'],
-        'filename': ['file.txt'],
-        'directory': [r'C:\dir']
-    }),
-    ('servicedll', br'C:\Windows\Temp\1.tmp', {
-        'servicedll': [r'C:\Windows\Temp\1.tmp'],
-        'filepath': [r'C:\Windows\Temp\1.tmp'],
-        'filename': ['1.tmp'],
-        'directory': [r'C:\Windows\Temp']
-    }),
-    ('c2_url', b'http://[fe80::20c:1234:5678:9abc]:80/badness', {
-        'c2_url': ['http://[fe80::20c:1234:5678:9abc]:80/badness'],
-        'url': ['http://[fe80::20c:1234:5678:9abc]:80/badness'],
-        'urlpath': ['/badness'],
-        'c2_socketaddress': [['fe80::20c:1234:5678:9abc', '80', '']],
-        'socketaddress': [['fe80::20c:1234:5678:9abc', '80', '']],
-        'c2_address': ['fe80::20c:1234:5678:9abc'],
-        'address': ['fe80::20c:1234:5678:9abc'],
-        'port': [['80', '']]
-    }),
-    ('url', b'http://127.0.0.1/really/bad?hostname=pwned', {
-        'url': ['http://127.0.0.1/really/bad?hostname=pwned'],
-        'urlpath': ['/really/bad'],
-        'address': ['127.0.0.1']
-    }),
-    ('proxy', (b'admin', b'pass', b'192.168.1.1', b'80', 'tcp'), {
-        'proxy': [['admin', 'pass', '192.168.1.1', '80', 'tcp']],
-        'proxy_socketaddress': [['192.168.1.1', '80', 'tcp']],
-        'socketaddress': [['192.168.1.1', '80', 'tcp']],
-        'proxy_address': ['192.168.1.1'],
-        'address': ['192.168.1.1'],
-        'port': [['80', 'tcp']],
-        'credential': [['admin', 'pass']],
-        'password': ['pass'],
-        'username': ['admin']
-    }),
-    ('rsa_private_key', ('0x7', '0xbb', '0x17', '0x11', '0xb', '0x7', '0x3', '0xe'), {
-        'rsa_private_key': [['0x7', '0xbb', '0x17', '0x11', '0xb', '0x7', '0x3', '0xe']]
-    }),
-    # Test auto padding.
-    ('rsa_private_key', ('0x7', '0xbb', '0x17', '0x11', '0xb'), {
-        'rsa_private_key': [['0x7', '0xbb', '0x17', '0x11', '0xb', '', '', '']]
-    }),
-    ('other', {b'foo': b'bar', 'biz': 'baz'}, {
-        'other': {
-            'foo': 'bar',
-            'biz': 'baz'
-        }
-    })
-])
-def test_add_metadata(key, value, expected):
-    report = mwcp.Report()
-    with report:
-        report.add_metadata(key, value)
-    assert report.metadata == expected
-
-
-def test_other_add_metadata():
-    """Tests that adding multiple 'other' keys of same will convert to a list."""
-    report = mwcp.Report()
-    with report:
-        report.add_metadata('other', {b'foo': b'bar', 'biz': 'baz'})
-        assert report.metadata == {'other': {'foo': 'bar', 'biz': 'baz'}}
-        report.add_metadata('other', {b'foo': b'boop'})
-        assert report.metadata == {'other': {'foo': ['bar', 'boop'], 'biz': 'baz'}}
-
-
-def test_output_file(tmpdir):
-    test_file = tmpdir / '9c91e_foo.txt'
-    report = mwcp.Report(output_directory=str(tmpdir))
-    with report:
-        assert report.output_file(b'This is data!', 'foo.txt', description='A foo file') == str(test_file)
-
-        assert test_file.exists()
-        assert test_file.read_binary() == b'This is data!'
-        assert report.metadata['outputfile'] == [
-            ['foo.txt', 'A foo file', '9c91e665b5b7ba5a3066c92dd02d3d7c']
-        ]
-
-        # Add file with same name to test name collision code.
-        test_file = tmpdir / '4d8cf_foo.txt'
-        assert report.output_file(b'More data!', 'foo.txt', description='Another foo file') == str(test_file)
-
-        assert test_file.exists()
-        assert test_file.read_binary() == b'More data!'
-        assert report.metadata['outputfile'] == [
-            ['foo.txt', 'A foo file', '9c91e665b5b7ba5a3066c92dd02d3d7c'],
-            ['foo.txt', 'Another foo file', '4d8cfa4b19f5f971b0e6d79250cb1321'],
-        ]
-
-    # Test file sanitization
-    test_file = tmpdir / '6f1ed_hello.txt'
-    report = mwcp.Report(output_directory=str(tmpdir))
-    with report:
-        assert report.output_file(b'blah', u'hllo!!\x08.txt') == str(test_file)
-
-        assert test_file.exists()
-        assert test_file.read_binary() == b'blah'
-        assert report.metadata['outputfile'] == [
-            [u'hllo!!\x08.txt', '', '6f1ed002ab5595859014ebf0951522d9']
-        ]
-
-
-def test_print_report(datadir):
-    """Tests the text report generation."""
-    report = mwcp.Report()
-    with report:
-        report.add_metadata('proxy', (b'admin', b'pass', b'192.168.1.1', b'80', 'tcp'))
-        report.add_metadata('other', {b'foo': 'bar', 'biz': b'baz\x00\x01'})
-        report.output_file(b'data', 'file_1.exe', 'example output file')
-
-    print(report.as_text())
-    assert report.as_text() == (datadir / "report.txt").read_text()
-
-
-# TODO: Deal with field ordering?
-# def test_standard_field_order():
-#     """Tests that STANDARD_FIELD_ORDER is updated to the field.json file."""
-#     with open(mwcp.config.get("FIELDS_PATH"), "rb") as f:
-#         fields = json.load(f)
-#
-#     ignore_fields = INFO_FIELD_ORDER + ["debug", "other", "outputfile"]
-#
-#     assert sorted(STANDARD_FIELD_ORDER) == sorted(set(fields.keys()) - set(ignore_fields))
+# coding=utf-8
+"""
+Tests the legacy features of mwcp.Reporter object.
+
+These features are now replaced by test_report.py and test_runner.py
+"""
+
+import os
+
+import pytest
+
+import mwcp
+
+
+@pytest.mark.parametrize('key,value,expected', [
+    ('filepath', br'C:\dir\file.txt', {
+        'filepath': [r'C:\dir\file.txt'],
+        'filename': ['file.txt'],
+        'directory': [r'C:\dir']
+    }),
+    ('servicedll', br'C:\Windows\Temp\1.tmp', {
+        'servicedll': [r'C:\Windows\Temp\1.tmp'],
+        'filepath': [r'C:\Windows\Temp\1.tmp'],
+        'filename': ['1.tmp'],
+        'directory': [r'C:\Windows\Temp']
+    }),
+    ('c2_url', b'http://[fe80::20c:1234:5678:9abc]:80/badness', {
+        'c2_url': ['http://[fe80::20c:1234:5678:9abc]:80/badness'],
+        'url': ['http://[fe80::20c:1234:5678:9abc]:80/badness'],
+        'urlpath': ['/badness'],
+        'c2_socketaddress': [['fe80::20c:1234:5678:9abc', '80', '']],
+        'socketaddress': [['fe80::20c:1234:5678:9abc', '80', '']],
+        'c2_address': ['fe80::20c:1234:5678:9abc'],
+        'address': ['fe80::20c:1234:5678:9abc'],
+        'port': [['80', '']]
+    }),
+    ('url', b'http://127.0.0.1/really/bad?hostname=pwned', {
+        'url': ['http://127.0.0.1/really/bad?hostname=pwned'],
+        'urlpath': ['/really/bad'],
+        'address': ['127.0.0.1']
+    }),
+    ('proxy', (b'admin', b'pass', b'192.168.1.1', b'80', 'tcp'), {
+        'proxy': [['admin', 'pass', '192.168.1.1', '80', 'tcp']],
+        'proxy_socketaddress': [['192.168.1.1', '80', 'tcp']],
+        'socketaddress': [['192.168.1.1', '80', 'tcp']],
+        'proxy_address': ['192.168.1.1'],
+        'address': ['192.168.1.1'],
+        'port': [['80', 'tcp']],
+        'credential': [['admin', 'pass']],
+        'password': ['pass'],
+        'username': ['admin']
+    }),
+    ('rsa_private_key', ('0x7', '0xbb', '0x17', '0x11', '0xb', '0x7', '0x3', '0xe'), {
+        'rsa_private_key': [['0x7', '0xbb', '0x17', '0x11', '0xb', '0x7', '0x3', '0xe']]
+    }),
+    # Test auto padding.
+    ('rsa_private_key', ('0x7', '0xbb', '0x17', '0x11', '0xb'), {
+        'rsa_private_key': [['0x7', '0xbb', '0x17', '0x11', '0xb', '', '', '']]
+    }),
+    ('other', {b'foo': b'bar', 'biz': 'baz'}, {
+        'other': {
+            'foo': 'bar',
+            'biz': 'baz'
+        }
+    })
+])
+def test_add_metadata(key, value, expected):
+    report = mwcp.Report()
+    with report:
+        report.add_metadata(key, value)
+    assert report.metadata == expected
+
+
+def test_other_add_metadata():
+    """Tests that adding multiple 'other' keys of same will convert to a list."""
+    report = mwcp.Report()
+    with report:
+        report.add_metadata('other', {b'foo': b'bar', 'biz': 'baz'})
+        assert report.metadata == {'other': {'foo': 'bar', 'biz': 'baz'}}
+        report.add_metadata('other', {b'foo': b'boop'})
+        assert report.metadata == {'other': {'foo': ['bar', 'boop'], 'biz': 'baz'}}
+
+
+def test_output_file(tmpdir):
+    test_file = tmpdir / '9c91e_foo.txt'
+    report = mwcp.Report(output_directory=str(tmpdir))
+    with report:
+        assert report.output_file(b'This is data!', 'foo.txt', description='A foo file') == str(test_file)
+
+        assert test_file.exists()
+        assert test_file.read_binary() == b'This is data!'
+        assert report.metadata['outputfile'] == [
+            ['foo.txt', 'A foo file', '9c91e665b5b7ba5a3066c92dd02d3d7c']
+        ]
+
+        # Add file with same name to test name collision code.
+        test_file = tmpdir / '4d8cf_foo.txt'
+        assert report.output_file(b'More data!', 'foo.txt', description='Another foo file') == str(test_file)
+
+        assert test_file.exists()
+        assert test_file.read_binary() == b'More data!'
+        assert report.metadata['outputfile'] == [
+            ['foo.txt', 'A foo file', '9c91e665b5b7ba5a3066c92dd02d3d7c'],
+            ['foo.txt', 'Another foo file', '4d8cfa4b19f5f971b0e6d79250cb1321'],
+        ]
+
+    # Test file sanitization
+    test_file = tmpdir / '6f1ed_hello.txt'
+    report = mwcp.Report(output_directory=str(tmpdir))
+    with report:
+        assert report.output_file(b'blah', u'hllo!!\x08.txt') == str(test_file)
+
+        assert test_file.exists()
+        assert test_file.read_binary() == b'blah'
+        assert report.metadata['outputfile'] == [
+            [u'hllo!!\x08.txt', '', '6f1ed002ab5595859014ebf0951522d9']
+        ]
+
+
+def test_print_report(datadir):
+    """Tests the text report generation."""
+    report = mwcp.Report()
+    with report:
+        report.add_metadata('proxy', (b'admin', b'pass', b'192.168.1.1', b'80', 'tcp'))
+        report.add_metadata('other', {b'foo': 'bar', 'biz': b'baz\x00\x01'})
+        report.output_file(b'data', 'file_1.exe', 'example output file')
+
+    print(report.as_text())
+    assert report.as_text() == (datadir / "report.txt").read_text()
+
+
+# TODO: Deal with field ordering?
+# def test_standard_field_order():
+#     """Tests that STANDARD_FIELD_ORDER is updated to the field.json file."""
+#     with open(mwcp.config.get("FIELDS_PATH"), "rb") as f:
+#         fields = json.load(f)
+#
+#     ignore_fields = INFO_FIELD_ORDER + ["debug", "other", "outputfile"]
+#
+#     assert sorted(STANDARD_FIELD_ORDER) == sorted(set(fields.keys()) - set(ignore_fields))
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_metadata.py` & `mwcp-3.9.0/mwcp/tests/test_metadata.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,159 +1,159 @@
-"""
-Tests mwcp.metadata elements.
-"""
-import json
-import logging
-import pathlib
-import textwrap
-
-import pytest
-
-import mwcp
-from mwcp import metadata
-
-
-def test_tags():
-    p = metadata.Path2("C:\\hello\\world.txt")
-
-    # test single
-    assert p.add_tag("download") is p
-    assert p.tags == ["download"]
-
-    # test multiple
-    assert p.add_tag("download", "APT9000", "text document") is p
-    assert p.tags == ["APT9000", "download", "text document"]
-
-
-def test_serialization():
-    # Test simple metadata.
-    p = metadata.Path2("C:\\hello\\world.txt").add_tag("download")
-    p_dict = p.as_dict()
-    assert p_dict == {
-        'type': 'path',
-        'tags': ['download'],
-        'path': r"C:\hello\world.txt",
-        'posix': False,
-        'is_dir': None,
-        'file_system': None,
-    }
-    # language=json
-    assert p.as_json() == textwrap.dedent(r"""
-        {
-            "type": "path",
-            "tags": [
-                "download"
-            ],
-            "path": "C:\\hello\\world.txt",
-            "is_dir": null,
-            "posix": false,
-            "file_system": null
-        }
-    """).strip()
-    assert metadata.Path2.from_dict(p_dict) == p
-    assert metadata.Metadata.from_dict(p_dict) == p
-
-    # Test nested metadata.
-    u = metadata.URL("http://google.com")
-    u_dict = u.as_dict()
-    assert u_dict == {
-        'type': 'url',
-        'tags': [],
-        'url': 'http://google.com',
-        'application_protocol': 'http',
-        'credential': None,
-        'path': None,
-        'query': '',
-        'socket': {
-            'type': 'socket',
-            'tags': [],
-            'address': 'google.com',
-            'c2': None,
-            'listen': None,
-            'network_protocol': None,
-            'port': None
-        },
-      }
-    # language=json
-    assert u.as_json() == textwrap.dedent(r"""
-        {
-            "type": "url",
-            "tags": [],
-            "url": "http://google.com",
-            "socket": {
-                "type": "socket",
-                "tags": [],
-                "address": "google.com",
-                "port": null,
-                "network_protocol": null,
-                "c2": null,
-                "listen": null
-            },
-            "path": null,
-            "query": "",
-            "application_protocol": "http",
-            "credential": null
-        }
-    """).strip()
-    assert metadata.URL.from_dict(u_dict) == u
-    assert metadata.Metadata.from_dict(u_dict) == u
-
-
-def test_schema(tmp_path):
-    """
-    Tests schema generation to ensure schema.json is up to date.
-    """
-    schema_json = pathlib.Path(mwcp.__file__).parent / "config" / "schema.json"
-    with schema_json.open("r") as fo:
-        schema = json.load(fo)
-    assert mwcp.schema() == schema, "Schema out of date. Run mwcp/tools/update_schema.py"
-
-
-def test_schema_validation(report, metadata_items):
-    pytest.importorskip("jsonschema")
-    import jsonschema
-
-    logger = logging.getLogger(__name__)
-
-    with report:
-        for item in metadata_items:
-            jsonschema.validate(item.as_json_dict(), item.schema())
-            report.add(item)
-
-        # Add some log messages in for good measure.
-        logger.info("Test info log")
-        logger.error("Test error log")
-        logger.debug("Test debug log")
-
-    jsonschema.validate(report.as_json_dict(), mwcp.schema())
-
-
-def test_path_alternative_constructors():
-    """
-    Tests alternative constructors for path.
-    """
-    path = metadata.Path2.from_segments("C:", "hello", "world.txt")
-    assert path.path == "C:\\hello\\world.txt"
-    path = metadata.Path2.from_segments("C:", "hello", "world.txt", posix=True)
-    assert path.path == "C:/hello/world.txt"
-    path = metadata.Path2.from_segments("world.txt")
-    assert path.path == "world.txt"
-    assert path.posix is False
-
-    path = metadata.Path2.from_pathlib_path(pathlib.PureWindowsPath("C:\\hello\\world.txt"))
-    assert path.path == "C:\\hello\\world.txt"
-    assert path.posix is False
-    path = metadata.Path2.from_pathlib_path(pathlib.PurePosixPath("/home/user/test.txt"))
-    assert path.path == "/home/user/test.txt"
-    assert path.posix is True
-
-
-def test_path_absolute_segment_issue():
-    """
-    Tests issue with absolute path causing previous segments being excluded in Path2.from_segments()
-    """
-    assert metadata.Path2.from_segments("hello", "\\world").path == r"hello\world"
-    assert metadata.Path2.from_segments("\\hello", "\\world").path == r"\hello\world"
-    assert metadata.Path2.from_segments("C:\\hello", "\\world").path == r"C:\hello\world"
-    assert metadata.Path2.from_segments("hello", "\\world", posix=True).path == r"hello/\world"
-    assert metadata.Path2.from_segments("hello", "/\\world", posix=True).path == r"hello/\world"
-    assert metadata.Path2.from_segments("/hello", "/world", posix=True).path == r"/hello/world"
+"""
+Tests mwcp.metadata elements.
+"""
+import json
+import logging
+import pathlib
+import textwrap
+
+import pytest
+
+import mwcp
+from mwcp import metadata
+
+
+def test_tags():
+    p = metadata.Path2("C:\\hello\\world.txt")
+
+    # test single
+    assert p.add_tag("download") is p
+    assert p.tags == ["download"]
+
+    # test multiple
+    assert p.add_tag("download", "APT9000", "text document") is p
+    assert p.tags == ["APT9000", "download", "text document"]
+
+
+def test_serialization():
+    # Test simple metadata.
+    p = metadata.Path2("C:\\hello\\world.txt").add_tag("download")
+    p_dict = p.as_dict()
+    assert p_dict == {
+        'type': 'path',
+        'tags': ['download'],
+        'path': r"C:\hello\world.txt",
+        'posix': False,
+        'is_dir': None,
+        'file_system': None,
+    }
+    # language=json
+    assert p.as_json() == textwrap.dedent(r"""
+        {
+            "type": "path",
+            "tags": [
+                "download"
+            ],
+            "path": "C:\\hello\\world.txt",
+            "is_dir": null,
+            "posix": false,
+            "file_system": null
+        }
+    """).strip()
+    assert metadata.Path2.from_dict(p_dict) == p
+    assert metadata.Metadata.from_dict(p_dict) == p
+
+    # Test nested metadata.
+    u = metadata.URL("http://google.com")
+    u_dict = u.as_dict()
+    assert u_dict == {
+        'type': 'url',
+        'tags': [],
+        'url': 'http://google.com',
+        'application_protocol': 'http',
+        'credential': None,
+        'path': None,
+        'query': '',
+        'socket': {
+            'type': 'socket',
+            'tags': [],
+            'address': 'google.com',
+            'c2': None,
+            'listen': None,
+            'network_protocol': None,
+            'port': None
+        },
+      }
+    # language=json
+    assert u.as_json() == textwrap.dedent(r"""
+        {
+            "type": "url",
+            "tags": [],
+            "url": "http://google.com",
+            "socket": {
+                "type": "socket",
+                "tags": [],
+                "address": "google.com",
+                "port": null,
+                "network_protocol": null,
+                "c2": null,
+                "listen": null
+            },
+            "path": null,
+            "query": "",
+            "application_protocol": "http",
+            "credential": null
+        }
+    """).strip()
+    assert metadata.URL.from_dict(u_dict) == u
+    assert metadata.Metadata.from_dict(u_dict) == u
+
+
+def test_schema(tmp_path):
+    """
+    Tests schema generation to ensure schema.json is up to date.
+    """
+    schema_json = pathlib.Path(mwcp.__file__).parent / "config" / "schema.json"
+    with schema_json.open("r") as fo:
+        schema = json.load(fo)
+    assert mwcp.schema() == schema, "Schema out of date. Run mwcp/tools/update_schema.py"
+
+
+def test_schema_validation(report, metadata_items):
+    pytest.importorskip("jsonschema")
+    import jsonschema
+
+    logger = logging.getLogger(__name__)
+
+    with report:
+        for item in metadata_items:
+            jsonschema.validate(item.as_json_dict(), item.schema())
+            report.add(item)
+
+        # Add some log messages in for good measure.
+        logger.info("Test info log")
+        logger.error("Test error log")
+        logger.debug("Test debug log")
+
+    jsonschema.validate(report.as_json_dict(), mwcp.schema())
+
+
+def test_path_alternative_constructors():
+    """
+    Tests alternative constructors for path.
+    """
+    path = metadata.Path2.from_segments("C:", "hello", "world.txt")
+    assert path.path == "C:\\hello\\world.txt"
+    path = metadata.Path2.from_segments("C:", "hello", "world.txt", posix=True)
+    assert path.path == "C:/hello/world.txt"
+    path = metadata.Path2.from_segments("world.txt")
+    assert path.path == "world.txt"
+    assert path.posix is False
+
+    path = metadata.Path2.from_pathlib_path(pathlib.PureWindowsPath("C:\\hello\\world.txt"))
+    assert path.path == "C:\\hello\\world.txt"
+    assert path.posix is False
+    path = metadata.Path2.from_pathlib_path(pathlib.PurePosixPath("/home/user/test.txt"))
+    assert path.path == "/home/user/test.txt"
+    assert path.posix is True
+
+
+def test_path_absolute_segment_issue():
+    """
+    Tests issue with absolute path causing previous segments being excluded in Path2.from_segments()
+    """
+    assert metadata.Path2.from_segments("hello", "\\world").path == r"hello\world"
+    assert metadata.Path2.from_segments("\\hello", "\\world").path == r"\hello\world"
+    assert metadata.Path2.from_segments("C:\\hello", "\\world").path == r"C:\hello\world"
+    assert metadata.Path2.from_segments("hello", "\\world", posix=True).path == r"hello/\world"
+    assert metadata.Path2.from_segments("hello", "/\\world", posix=True).path == r"hello/\world"
+    assert metadata.Path2.from_segments("/hello", "/world", posix=True).path == r"/hello/world"
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_parsers.py` & `mwcp-3.9.0/mwcp/tests/test_parsers.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,236 +1,236 @@
-import json
-
-import pytest
-
-try:
-    import dragodis
-except ImportError:
-    dragodis = None
-
-import mwcp
-import mwcp.metadata
-from mwcp import testing
-
-
-def _setup(config):
-    """
-    Registers parsers and loads configuration.
-    """
-    mwcp.register_entry_points()
-    mwcp.config.load()
-
-    # Set any configuration passed in through command line of pytest.
-    testcase_dir = config.option.testcase_dir if "testcase_dir" in config.option else None
-    malware_repo = config.option.malware_repo if "malware_repo" in config.option else None
-    if testcase_dir:
-        mwcp.config["TESTCASE_DIR"] = testcase_dir
-    if malware_repo:
-        mwcp.config["MALWARE_REPO"] = malware_repo
-
-
-@pytest.fixture(scope="session", autouse=True)
-def setup(request):
-    _setup(request.config)
-
-
-def pytest_generate_tests(metafunc):
-    """
-    Generates the test cases for parametrization of parser tests.
-    Add "md5" and "results_path" to your fixtures.
-    """
-    if not ("md5" in metafunc.fixturenames and "results_path" in metafunc.fixturenames):
-        return
-
-    _setup(metafunc.config)
-
-    params = []
-    for test_case in testing.iter_test_cases():
-        params.append(pytest.param(
-            test_case.md5, test_case.results_path, id=f"{test_case.name}-{test_case.md5}"
-        ))
-    metafunc.parametrize("md5,results_path", params)
-
-
-def _fixup_test_cases(expected_results, actual_results):
-    """
-    Fixes up test cases to handle differences in schema
-    and remove extraneous differences that don't affect the overall parse results.
-    """
-    # Expected results are allowed to include logs to provide better insight when the
-    # test case was first created. However, we don't want to include them in the test since
-    # logs can easily change over time.
-    expected_results["logs"] = []
-    expected_results["errors"] = []
-
-    # Remove mwcp version since we don't want to be updating our tests cases every time
-    # there is a new version.
-    expected_results_version = expected_results.pop("mwcp_version")
-    actual_results_version = actual_results.pop("mwcp_version")
-
-    # Version 3.3.2 introduced "mode" property in encryption_key. Remove property for older tests.
-    if expected_results_version < "3.3.2":
-        for item in actual_results["metadata"]:
-            if item["type"] == "encryption_key":
-                del item["mode"]
-
-    # Version 3.3.3 set "residual_file" and "input_file" types to just "file".
-    if expected_results_version < "3.3.3":
-        actual_results["input_file"]["type"] = "input_file"
-        for item in actual_results["metadata"]:
-            if item["type"] == "file":
-                item["type"] = "residual_file"
-
-    # Version 3.3.3 also changed the types for legacy interval and uuid to
-    # "interval_legacy" and "uuid_legacy" respectively.
-    if expected_results_version < "3.3.3":
-        for item in actual_results["metadata"]:
-            if item["type"].endswith("_legacy"):
-                item["type"] = item["type"][:-len("_legacy")]
-
-    # Version 3.3.3 no longer automatically adds tcp into a socket for url,
-    # therefore just clear the network_protocol when it's set to tcp for
-    # older versions
-    if expected_results_version < "3.3.3":
-        for item in actual_results["metadata"] + expected_results["metadata"]:
-            if item["type"] == "socket" and item["network_protocol"] == "tcp":
-                item["network_protocol"] = None
-
-            elif item["type"] == "url" and item["socket"] and item["socket"]["network_protocol"] == "tcp":
-                item["socket"]["network_protocol"] = None
-
-        # Deduplicate both lists of metadata dictionary items since changing "tcp" to None will likely
-        # create some.
-        for item in list(actual_results["metadata"]):
-            while actual_results["metadata"].count(item) > 1:
-                actual_results["metadata"].remove(item)
-
-        for item in list(expected_results["metadata"]):
-            while expected_results["metadata"].count(item) > 1:
-                expected_results["metadata"].remove(item)
-
-    # Version 3.5.0 adds "value_format" to Other metadata elements
-    # and allows for new value types.
-    if expected_results_version < "3.5.0":
-        for item in actual_results["metadata"]:
-            if item["type"] == "other":
-                del item["value_format"]
-                # If we get an integer or boolean, that was meant to be automatically
-                # converted to a string.
-                if isinstance(item["value"], (int, bool)):
-                    item["value"] = str(item["value"])
-
-    # TODO: File recursion to be reintroduced in 3.6.2
-    # Version 3.6.0 adds "duplicate" tags to files already parsed and will not include
-    # the duplicate residual files that are extracted from such files.
-    # To best handle backwards compatibility we are just going to dedup all residual files
-    # based on md5.
-    # if expected_results_version < "3.6.0":
-    #     # Find and remove files with "duplicate" tag.
-    #     for item in list(actual_results["metadata"]):
-    #         if item["type"] in ("file", "residual_file") and "duplicate" in item["tags"]:
-    #             actual_results["metadata"].remove(item)
-    #
-    #     # Find and remove all duplicate residual files from expected results,
-    #     # since they may not exist in new results due to skipped processing.
-    #     seen_md5s = set()
-    #     for item in list(expected_results["metadata"]):
-    #         if item["type"] in ("file", "residual_file"):
-    #             if item["md5"] in seen_md5s:
-    #                 expected_results["metadata"].remove(item)
-    #             else:
-    #                 seen_md5s.add(item["md5"])
-
-    # Version 3.6.0 changes schema for Registry.
-    # "path" has been removed.
-    # "key" has been replaced with a "hive"/"subkey" combo.
-    # Update registry entries in expected results to account for new schema.
-    if expected_results_version < "3.6.0":
-        for item in expected_results["metadata"]:
-            if item["type"] == "registry":
-                reg = mwcp.metadata.Registry2.from_path(item["path"] or "", data=item["data"]).add_tag(*item["tags"])
-                item.update(reg.as_json_dict())
-                del item["path"]
-                del item["key"]
-
-    # Version 3.7.0 changes schema for Path
-    # "directory_path", and "name" as been removed in exchange for just a "path" element.
-    # Update path entries in expected results to account for new schema.
-    if expected_results_version < "3.7.0":
-        for item in expected_results["metadata"]:
-            if item["type"] == "path":
-                # Recreate path using backwards compatibility wrapper.
-                if item["path"] is not None:
-                    path = mwcp.metadata.Path(
-                        path=item["path"],
-                        is_dir=item["is_dir"],
-                        file_system=item["file_system"],
-                    )
-                else:
-                    path = mwcp.metadata.Path(
-                        directory_path=item["directory_path"],
-                        name=item["name"],
-                        is_dir=item["is_dir"],
-                        file_system=item["file_system"],
-                    )
-                path.add_tag(*item["tags"])
-                item.update(path.as_json_dict())
-                del item["directory_path"]
-                del item["name"]
-
-        # "derivation" field was also added. Remove it for older test cases.
-        del actual_results["input_file"]["derivation"]
-        for item in actual_results["metadata"]:
-            if item["type"] in ("file", "residual_file"):
-                del item["derivation"]
-
-    # For now, we are going to remove any supplemental generated files created by IDA or Ghidra.
-    # These are not deterministic, changing the md5 on each run. Plus the backend disassembler
-    # could be different based what the user setup as their default backend disassembler.
-    if expected_results_version >= "3.7.0":
-        # TODO: make this check less hardcoded.
-        is_supplemental = lambda item: (
-            item["type"] == "file"
-            and item["description"] in ("IDA Project File", "Ghidra Project File")
-        )
-        expected_results["metadata"] = [item for item in expected_results["metadata"] if not is_supplemental(item)]
-        actual_results["metadata"] = [item for item in actual_results["metadata"] if not is_supplemental(item)]
-
-    # The order the metadata comes in doesn't matter and shouldn't fail the test.
-    # (Using custom repr to ensure dictionary keys are sorted before repr is applied.)
-    custom_repr = lambda d: repr(dict(sorted(d.items())) if isinstance(d, dict) else d)
-    expected_results["metadata"] = sorted(expected_results["metadata"], key=custom_repr)
-    actual_results["metadata"] = sorted(actual_results["metadata"], key=custom_repr)
-
-
-def _test_parser(pytestconfig, input_file_path, results_path):
-    # Grab expected results.
-    with open(results_path, "r") as fo:
-        expected_results = json.load(fo)
-
-    # Get full parser name from expected results.
-    parser_name = expected_results["parser"]
-    md5 = expected_results["input_file"]["md5"]
-
-    # NOTE: Reading bytes of input file instead of passing in file path to ensure everything gets run in-memory
-    #   and no residual artifacts (like idbs) are created in the malware repo.
-    report = mwcp.run(parser_name, data=input_file_path.read_bytes(), include_logs=False)
-
-    actual_results = report.as_json_dict()
-
-    _fixup_test_cases(expected_results, actual_results)
-
-    # Convert results back to json text to improve comparison report on failure.
-    # But avoid doing this if we detect we are in PyCharm. This is because PyCharm's built in comparison
-    # tool displays better on the raw dictionary instead of the string.
-    if not hasattr(pytestconfig, "_teamcityReporting"):
-        actual_results = json.dumps(actual_results, indent=4, sort_keys=True)
-        expected_results = json.dumps(expected_results, indent=4, sort_keys=True)
-
-    assert actual_results == expected_results, \
-        f"Parser Test Failed \n\tparser = {parser_name}\n\tmd5 = {md5}\n\ttest_case = {results_path}"
-
-
-@pytest.mark.parsers  # Custom mark
-def test_parser(pytestconfig, md5, results_path):
-    input_file_path = testing.get_path_in_malware_repo(md5=md5)
-    _test_parser(pytestconfig, input_file_path, results_path)
+import json
+
+import pytest
+
+try:
+    import dragodis
+except ImportError:
+    dragodis = None
+
+import mwcp
+import mwcp.metadata
+from mwcp import testing
+
+
+def _setup(config):
+    """
+    Registers parsers and loads configuration.
+    """
+    mwcp.register_entry_points()
+    mwcp.config.load()
+
+    # Set any configuration passed in through command line of pytest.
+    testcase_dir = config.option.testcase_dir if "testcase_dir" in config.option else None
+    malware_repo = config.option.malware_repo if "malware_repo" in config.option else None
+    if testcase_dir:
+        mwcp.config["TESTCASE_DIR"] = testcase_dir
+    if malware_repo:
+        mwcp.config["MALWARE_REPO"] = malware_repo
+
+
+@pytest.fixture(scope="session", autouse=True)
+def setup(request):
+    _setup(request.config)
+
+
+def pytest_generate_tests(metafunc):
+    """
+    Generates the test cases for parametrization of parser tests.
+    Add "md5" and "results_path" to your fixtures.
+    """
+    if not ("md5" in metafunc.fixturenames and "results_path" in metafunc.fixturenames):
+        return
+
+    _setup(metafunc.config)
+
+    params = []
+    for test_case in testing.iter_test_cases():
+        params.append(pytest.param(
+            test_case.md5, test_case.results_path, id=f"{test_case.name}-{test_case.md5}"
+        ))
+    metafunc.parametrize("md5,results_path", params)
+
+
+def _fixup_test_cases(expected_results, actual_results):
+    """
+    Fixes up test cases to handle differences in schema
+    and remove extraneous differences that don't affect the overall parse results.
+    """
+    # Expected results are allowed to include logs to provide better insight when the
+    # test case was first created. However, we don't want to include them in the test since
+    # logs can easily change over time.
+    expected_results["logs"] = []
+    expected_results["errors"] = []
+
+    # Remove mwcp version since we don't want to be updating our tests cases every time
+    # there is a new version.
+    expected_results_version = expected_results.pop("mwcp_version")
+    actual_results_version = actual_results.pop("mwcp_version")
+
+    # Version 3.3.2 introduced "mode" property in encryption_key. Remove property for older tests.
+    if expected_results_version < "3.3.2":
+        for item in actual_results["metadata"]:
+            if item["type"] == "encryption_key":
+                del item["mode"]
+
+    # Version 3.3.3 set "residual_file" and "input_file" types to just "file".
+    if expected_results_version < "3.3.3":
+        actual_results["input_file"]["type"] = "input_file"
+        for item in actual_results["metadata"]:
+            if item["type"] == "file":
+                item["type"] = "residual_file"
+
+    # Version 3.3.3 also changed the types for legacy interval and uuid to
+    # "interval_legacy" and "uuid_legacy" respectively.
+    if expected_results_version < "3.3.3":
+        for item in actual_results["metadata"]:
+            if item["type"].endswith("_legacy"):
+                item["type"] = item["type"][:-len("_legacy")]
+
+    # Version 3.3.3 no longer automatically adds tcp into a socket for url,
+    # therefore just clear the network_protocol when it's set to tcp for
+    # older versions
+    if expected_results_version < "3.3.3":
+        for item in actual_results["metadata"] + expected_results["metadata"]:
+            if item["type"] == "socket" and item["network_protocol"] == "tcp":
+                item["network_protocol"] = None
+
+            elif item["type"] == "url" and item["socket"] and item["socket"]["network_protocol"] == "tcp":
+                item["socket"]["network_protocol"] = None
+
+        # Deduplicate both lists of metadata dictionary items since changing "tcp" to None will likely
+        # create some.
+        for item in list(actual_results["metadata"]):
+            while actual_results["metadata"].count(item) > 1:
+                actual_results["metadata"].remove(item)
+
+        for item in list(expected_results["metadata"]):
+            while expected_results["metadata"].count(item) > 1:
+                expected_results["metadata"].remove(item)
+
+    # Version 3.5.0 adds "value_format" to Other metadata elements
+    # and allows for new value types.
+    if expected_results_version < "3.5.0":
+        for item in actual_results["metadata"]:
+            if item["type"] == "other":
+                del item["value_format"]
+                # If we get an integer or boolean, that was meant to be automatically
+                # converted to a string.
+                if isinstance(item["value"], (int, bool)):
+                    item["value"] = str(item["value"])
+
+    # TODO: File recursion to be reintroduced in 3.6.2
+    # Version 3.6.0 adds "duplicate" tags to files already parsed and will not include
+    # the duplicate residual files that are extracted from such files.
+    # To best handle backwards compatibility we are just going to dedup all residual files
+    # based on md5.
+    # if expected_results_version < "3.6.0":
+    #     # Find and remove files with "duplicate" tag.
+    #     for item in list(actual_results["metadata"]):
+    #         if item["type"] in ("file", "residual_file") and "duplicate" in item["tags"]:
+    #             actual_results["metadata"].remove(item)
+    #
+    #     # Find and remove all duplicate residual files from expected results,
+    #     # since they may not exist in new results due to skipped processing.
+    #     seen_md5s = set()
+    #     for item in list(expected_results["metadata"]):
+    #         if item["type"] in ("file", "residual_file"):
+    #             if item["md5"] in seen_md5s:
+    #                 expected_results["metadata"].remove(item)
+    #             else:
+    #                 seen_md5s.add(item["md5"])
+
+    # Version 3.6.0 changes schema for Registry.
+    # "path" has been removed.
+    # "key" has been replaced with a "hive"/"subkey" combo.
+    # Update registry entries in expected results to account for new schema.
+    if expected_results_version < "3.6.0":
+        for item in expected_results["metadata"]:
+            if item["type"] == "registry":
+                reg = mwcp.metadata.Registry2.from_path(item["path"] or "", data=item["data"]).add_tag(*item["tags"])
+                item.update(reg.as_json_dict())
+                del item["path"]
+                del item["key"]
+
+    # Version 3.7.0 changes schema for Path
+    # "directory_path", and "name" as been removed in exchange for just a "path" element.
+    # Update path entries in expected results to account for new schema.
+    if expected_results_version < "3.7.0":
+        for item in expected_results["metadata"]:
+            if item["type"] == "path":
+                # Recreate path using backwards compatibility wrapper.
+                if item["path"] is not None:
+                    path = mwcp.metadata.Path(
+                        path=item["path"],
+                        is_dir=item["is_dir"],
+                        file_system=item["file_system"],
+                    )
+                else:
+                    path = mwcp.metadata.Path(
+                        directory_path=item["directory_path"],
+                        name=item["name"],
+                        is_dir=item["is_dir"],
+                        file_system=item["file_system"],
+                    )
+                path.add_tag(*item["tags"])
+                item.update(path.as_json_dict())
+                del item["directory_path"]
+                del item["name"]
+
+        # "derivation" field was also added. Remove it for older test cases.
+        del actual_results["input_file"]["derivation"]
+        for item in actual_results["metadata"]:
+            if item["type"] in ("file", "residual_file"):
+                del item["derivation"]
+
+    # For now, we are going to remove any supplemental generated files created by IDA or Ghidra.
+    # These are not deterministic, changing the md5 on each run. Plus the backend disassembler
+    # could be different based what the user setup as their default backend disassembler.
+    if expected_results_version >= "3.7.0":
+        # TODO: make this check less hardcoded.
+        is_supplemental = lambda item: (
+            item["type"] == "file"
+            and item["description"] in ("IDA Project File", "Ghidra Project File")
+        )
+        expected_results["metadata"] = [item for item in expected_results["metadata"] if not is_supplemental(item)]
+        actual_results["metadata"] = [item for item in actual_results["metadata"] if not is_supplemental(item)]
+
+    # The order the metadata comes in doesn't matter and shouldn't fail the test.
+    # (Using custom repr to ensure dictionary keys are sorted before repr is applied.)
+    custom_repr = lambda d: repr(dict(sorted(d.items())) if isinstance(d, dict) else d)
+    expected_results["metadata"] = sorted(expected_results["metadata"], key=custom_repr)
+    actual_results["metadata"] = sorted(actual_results["metadata"], key=custom_repr)
+
+
+def _test_parser(pytestconfig, input_file_path, results_path):
+    # Grab expected results.
+    with open(results_path, "r") as fo:
+        expected_results = json.load(fo)
+
+    # Get full parser name from expected results.
+    parser_name = expected_results["parser"]
+    md5 = expected_results["input_file"]["md5"]
+
+    # NOTE: Reading bytes of input file instead of passing in file path to ensure everything gets run in-memory
+    #   and no residual artifacts (like idbs) are created in the malware repo.
+    report = mwcp.run(parser_name, data=input_file_path.read_bytes(), include_logs=False, recursive=False)
+
+    actual_results = report.as_json_dict()
+
+    _fixup_test_cases(expected_results, actual_results)
+
+    # Convert results back to json text to improve comparison report on failure.
+    # But avoid doing this if we detect we are in PyCharm. This is because PyCharm's built in comparison
+    # tool displays better on the raw dictionary instead of the string.
+    if not hasattr(pytestconfig, "_teamcityReporting"):
+        actual_results = json.dumps(actual_results, indent=4, sort_keys=True)
+        expected_results = json.dumps(expected_results, indent=4, sort_keys=True)
+
+    assert actual_results == expected_results, \
+        f"Parser Test Failed \n\tparser = {parser_name}\n\tmd5 = {md5}\n\ttest_case = {results_path}"
+
+
+@pytest.mark.parsers  # Custom mark
+def test_parser(pytestconfig, md5, results_path):
+    input_file_path = testing.get_path_in_malware_repo(md5=md5)
+    _test_parser(pytestconfig, input_file_path, results_path)
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_pecon.py` & `mwcp-3.9.0/mwcp/tests/test_pecon.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,59 +1,59 @@
-"""
-These are pytest test cases for pecon.
-"""
-
-from mwcp.utils import pecon
-
-
-default_pe = (
-    b'MZ\x90\x00\x03\x00\x00\x00\x04\x00\x00\x00\xff\xff\x00\x00\xb8\x00\x00\x00'
-    b'\x00\x00\x00\x00@\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\xe0\x00\x00\x00\xc3\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00PE\x00\x00L\x01\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xe0\x00\x0f\x01\x0b\x01'
-    b'\x01G\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x10\x00\x00\x00\x02\x00\x00\x01'
-    b'\x00\x00\x00\x00\x00\x00\x00\x05\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x02\x00\x00\x00\x00\x00\x00\x03\x00\x00\x00\x00\x00\x10\x00\x00\x10\x00'
-    b'\x00\x00\x00\x10\x00\x00\x10\x00\x00\x00\x00\x00\x00\x10\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-)
-
-
-def test_reconstruction():
-    """Tests basic PE reconstruction"""
-    pe = pecon.PE()
-
-    # Test accessing some random fields.
-    assert pe.DosHeader.e_magic == b'MZ'
-    assert pe.SectionTable == []
-    assert pe.OptionalHeader.FileAlignment == 512
-    assert pe.OptionalHeader.DataDirectory.imports.VirtualAddress == 0
-
-    # Test building
-    pe_data = pe.build()
-    assert pe_data == default_pe
-
-
-def test_parsing():
-    """Tests parsing and then rebuilding existing PE file."""
-    pe = pecon.PE(default_pe)
-
-    assert pe.build() == default_pe
-
-    pe.DosHeader.e_magic = b'ZM'
-    assert pe.build() == b'ZM' + default_pe[2:]
+"""
+These are pytest test cases for pecon.
+"""
+
+from mwcp.utils import pecon
+
+
+default_pe = (
+    b'MZ\x90\x00\x03\x00\x00\x00\x04\x00\x00\x00\xff\xff\x00\x00\xb8\x00\x00\x00'
+    b'\x00\x00\x00\x00@\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\xe0\x00\x00\x00\xc3\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00PE\x00\x00L\x01\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xe0\x00\x0f\x01\x0b\x01'
+    b'\x01G\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x10\x00\x00\x00\x02\x00\x00\x01'
+    b'\x00\x00\x00\x00\x00\x00\x00\x05\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x02\x00\x00\x00\x00\x00\x00\x03\x00\x00\x00\x00\x00\x10\x00\x00\x10\x00'
+    b'\x00\x00\x00\x10\x00\x00\x10\x00\x00\x00\x00\x00\x00\x10\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+)
+
+
+def test_reconstruction():
+    """Tests basic PE reconstruction"""
+    pe = pecon.PE()
+
+    # Test accessing some random fields.
+    assert pe.DosHeader.e_magic == b'MZ'
+    assert pe.SectionTable == []
+    assert pe.OptionalHeader.FileAlignment == 512
+    assert pe.OptionalHeader.DataDirectory.imports.VirtualAddress == 0
+
+    # Test building
+    pe_data = pe.build()
+    assert pe_data == default_pe
+
+
+def test_parsing():
+    """Tests parsing and then rebuilding existing PE file."""
+    pe = pecon.PE(default_pe)
+
+    assert pe.build() == default_pe
+
+    pe.DosHeader.e_magic = b'ZM'
+    assert pe.build() == b'ZM' + default_pe[2:]
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_report/report.json` & `mwcp-3.9.0/mwcp/tests/test_report/report.json`

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

 * *Files 26% similar despite different names*

```diff
@@ -1,762 +1,734 @@
-00000000: 7b0d 0a20 2020 2022 7479 7065 223a 2022  {..    "type": "
-00000010: 7265 706f 7274 222c 0d0a 2020 2020 2274  report",..    "t
-00000020: 6167 7322 3a20 5b0d 0a20 2020 2020 2020  ags": [..       
-00000030: 2022 7461 6767 696e 6722 2c0d 0a20 2020   "tagging",..   
-00000040: 2020 2020 2022 7465 7374 220d 0a20 2020       "test"..   
-00000050: 205d 2c0d 0a20 2020 2022 6d77 6370 5f76   ],..    "mwcp_v
-00000060: 6572 7369 6f6e 223a 2022 4d57 4350 5f56  ersion": "MWCP_V
-00000070: 4552 5349 4f4e 222c 0d0a 2020 2020 2269  ERSION",..    "i
-00000080: 6e70 7574 5f66 696c 6522 3a20 7b0d 0a20  nput_file": {.. 
-00000090: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
-000000a0: 6669 6c65 222c 0d0a 2020 2020 2020 2020  file",..        
-000000b0: 2274 6167 7322 3a20 5b5d 2c0d 0a20 2020  "tags": [],..   
-000000c0: 2020 2020 2022 6e61 6d65 223a 2022 696e       "name": "in
-000000d0: 7075 745f 6669 6c65 2e62 696e 222c 0d0a  put_file.bin",..
-000000e0: 2020 2020 2020 2020 2264 6573 6372 6970          "descrip
-000000f0: 7469 6f6e 223a 206e 756c 6c2c 0d0a 2020  tion": null,..  
-00000100: 2020 2020 2020 226d 6435 223a 2022 3165        "md5": "1e
-00000110: 3530 3231 3061 3032 3032 3439 3766 6237  50210a0202497fb7
-00000120: 3962 6333 3862 3661 6465 3663 3334 222c  9bc38b6ade6c34",
-00000130: 0d0a 2020 2020 2020 2020 2273 6861 3122  ..        "sha1"
-00000140: 3a20 2262 6166 3334 3535 3166 6563 6234  : "baf34551fecb4
-00000150: 3861 6363 3364 6138 3638 6562 3835 6531  8acc3da868eb85e1
-00000160: 6236 6461 6339 6465 3335 3622 2c0d 0a20  b6dac9de356",.. 
-00000170: 2020 2020 2020 2022 7368 6132 3536 223a         "sha256":
-00000180: 2022 3133 3037 3939 3065 3662 6135 6361   "1307990e6ba5ca
-00000190: 3134 3565 6233 3565 3939 3138 3261 3962  145eb35e99182a9b
-000001a0: 6563 3436 3533 3162 6335 3464 6466 3635  ec46531bc54ddf65
-000001b0: 3661 3630 3263 3738 3066 6130 3234 3064  6a602c780fa0240d
-000001c0: 6565 222c 0d0a 2020 2020 2020 2020 2261  ee",..        "a
-000001d0: 7263 6869 7465 6374 7572 6522 3a20 6e75  rchitecture": nu
-000001e0: 6c6c 2c0d 0a20 2020 2020 2020 2022 636f  ll,..        "co
-000001f0: 6d70 696c 655f 7469 6d65 223a 206e 756c  mpile_time": nul
-00000200: 6c2c 0d0a 2020 2020 2020 2020 2266 696c  l,..        "fil
-00000210: 655f 7061 7468 223a 2022 433a 2f69 6e70  e_path": "C:/inp
-00000220: 7574 5f66 696c 652e 6269 6e22 2c0d 0a20  ut_file.bin",.. 
-00000230: 2020 2020 2020 2022 6461 7461 223a 206e         "data": n
-00000240: 756c 6c2c 0d0a 2020 2020 2020 2020 2264  ull,..        "d
-00000250: 6572 6976 6174 696f 6e22 3a20 6e75 6c6c  erivation": null
-00000260: 0d0a 2020 2020 7d2c 0d0a 2020 2020 2270  ..    },..    "p
-00000270: 6172 7365 7222 3a20 2246 6f6f 5061 7273  arser": "FooPars
-00000280: 6572 222c 0d0a 2020 2020 2265 7272 6f72  er",..    "error
-00000290: 7322 3a20 5b0d 0a20 2020 2020 2020 2022  s": [..        "
-000002a0: 5b21 5d20 5465 7374 2065 7272 6f72 206c  [!] Test error l
-000002b0: 6f67 220d 0a20 2020 205d 2c0d 0a20 2020  og"..    ],..   
-000002c0: 2022 6c6f 6773 223a 205b 0d0a 2020 2020   "logs": [..    
-000002d0: 2020 2020 225b 2b5d 2054 6573 7420 696e      "[+] Test in
-000002e0: 666f 206c 6f67 222c 0d0a 2020 2020 2020  fo log",..      
-000002f0: 2020 225b 215d 2054 6573 7420 6572 726f    "[!] Test erro
-00000300: 7220 6c6f 6722 2c0d 0a20 2020 2020 2020  r log",..       
-00000310: 2022 5b2a 5d20 5465 7374 2064 6562 7567   "[*] Test debug
-00000320: 206c 6f67 220d 0a20 2020 205d 2c0d 0a20   log"..    ],.. 
-00000330: 2020 2022 6d65 7461 6461 7461 223a 205b     "metadata": [
-00000340: 0d0a 2020 2020 2020 2020 7b0d 0a20 2020  ..        {..   
-00000350: 2020 2020 2020 2020 2022 7479 7065 223a           "type":
-00000360: 2022 7061 7468 222c 0d0a 2020 2020 2020   "path",..      
-00000370: 2020 2020 2020 2274 6167 7322 3a20 5b5d        "tags": []
-00000380: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-00000390: 7061 7468 223a 2022 433a 5c5c 7769 6e64  path": "C:\\wind
-000003a0: 6f77 735c 5c74 656d 705c 5c31 5c5c 6c6f  ows\\temp\\1\\lo
-000003b0: 675c 5c6b 6579 6462 2e74 7874 222c 0d0a  g\\keydb.txt",..
-000003c0: 2020 2020 2020 2020 2020 2020 2269 735f              "is_
-000003d0: 6469 7222 3a20 6661 6c73 652c 0d0a 2020  dir": false,..  
-000003e0: 2020 2020 2020 2020 2020 2270 6f73 6978            "posix
-000003f0: 223a 2066 616c 7365 2c0d 0a20 2020 2020  ": false,..     
-00000400: 2020 2020 2020 2022 6669 6c65 5f73 7973         "file_sys
-00000410: 7465 6d22 3a20 6e75 6c6c 0d0a 2020 2020  tem": null..    
-00000420: 2020 2020 7d2c 0d0a 2020 2020 2020 2020      },..        
-00000430: 7b0d 0a20 2020 2020 2020 2020 2020 2022  {..            "
-00000440: 7479 7065 223a 2022 7061 7468 222c 0d0a  type": "path",..
-00000450: 2020 2020 2020 2020 2020 2020 2274 6167              "tag
-00000460: 7322 3a20 5b5d 2c0d 0a20 2020 2020 2020  s": [],..       
-00000470: 2020 2020 2022 7061 7468 223a 2022 2541       "path": "%A
-00000480: 5050 4441 5441 255c 5c66 6f6f 222c 0d0a  PPDATA%\\foo",..
-00000490: 2020 2020 2020 2020 2020 2020 2269 735f              "is_
-000004a0: 6469 7222 3a20 7472 7565 2c0d 0a20 2020  dir": true,..   
-000004b0: 2020 2020 2020 2020 2022 706f 7369 7822           "posix"
-000004c0: 3a20 6661 6c73 652c 0d0a 2020 2020 2020  : false,..      
-000004d0: 2020 2020 2020 2266 696c 655f 7379 7374        "file_syst
-000004e0: 656d 223a 206e 756c 6c0d 0a20 2020 2020  em": null..     
-000004f0: 2020 207d 2c0d 0a20 2020 2020 2020 207b     },..        {
-00000500: 0d0a 2020 2020 2020 2020 2020 2020 2274  ..            "t
-00000510: 7970 6522 3a20 2270 6174 6822 2c0d 0a20  ype": "path",.. 
-00000520: 2020 2020 2020 2020 2020 2022 7461 6773             "tags
-00000530: 223a 205b 5d2c 0d0a 2020 2020 2020 2020  ": [],..        
-00000540: 2020 2020 2270 6174 6822 3a20 2243 3a5c      "path": "C:\
-00000550: 5c66 6f6f 5c5c 6261 722e 7478 7422 2c0d  \foo\\bar.txt",.
-00000560: 0a20 2020 2020 2020 2020 2020 2022 6973  .            "is
-00000570: 5f64 6972 223a 2066 616c 7365 2c0d 0a20  _dir": false,.. 
-00000580: 2020 2020 2020 2020 2020 2022 706f 7369             "posi
-00000590: 7822 3a20 6661 6c73 652c 0d0a 2020 2020  x": false,..    
-000005a0: 2020 2020 2020 2020 2266 696c 655f 7379          "file_sy
-000005b0: 7374 656d 223a 206e 756c 6c0d 0a20 2020  stem": null..   
-000005c0: 2020 2020 207d 2c0d 0a20 2020 2020 2020       },..       
-000005d0: 207b 0d0a 2020 2020 2020 2020 2020 2020   {..            
-000005e0: 2274 7970 6522 3a20 2270 6174 6822 2c0d  "type": "path",.
-000005f0: 0a20 2020 2020 2020 2020 2020 2022 7461  .            "ta
-00000600: 6773 223a 205b 5d2c 0d0a 2020 2020 2020  gs": [],..      
-00000610: 2020 2020 2020 2270 6174 6822 3a20 226d        "path": "m
-00000620: 616c 7761 7265 2e65 7865 222c 0d0a 2020  alware.exe",..  
-00000630: 2020 2020 2020 2020 2020 2269 735f 6469            "is_di
-00000640: 7222 3a20 6661 6c73 652c 0d0a 2020 2020  r": false,..    
-00000650: 2020 2020 2020 2020 2270 6f73 6978 223a          "posix":
-00000660: 206e 756c 6c2c 0d0a 2020 2020 2020 2020   null,..        
-00000670: 2020 2020 2266 696c 655f 7379 7374 656d      "file_system
-00000680: 223a 206e 756c 6c0d 0a20 2020 2020 2020  ": null..       
-00000690: 207d 2c0d 0a20 2020 2020 2020 207b 0d0a   },..        {..
-000006a0: 2020 2020 2020 2020 2020 2020 2274 7970              "typ
-000006b0: 6522 3a20 2261 6c70 6861 6265 7422 2c0d  e": "alphabet",.
-000006c0: 0a20 2020 2020 2020 2020 2020 2022 7461  .            "ta
-000006d0: 6773 223a 205b 5d2c 0d0a 2020 2020 2020  gs": [],..      
-000006e0: 2020 2020 2020 2261 6c70 6861 6265 7422        "alphabet"
-000006f0: 3a20 2230 3132 3334 3536 3738 3941 4243  : "0123456789ABC
-00000700: 4445 4622 2c0d 0a20 2020 2020 2020 2020  DEF",..         
-00000710: 2020 2022 6261 7365 223a 2031 360d 0a20     "base": 16.. 
-00000720: 2020 2020 2020 207d 2c0d 0a20 2020 2020         },..     
-00000730: 2020 207b 0d0a 2020 2020 2020 2020 2020     {..          
-00000740: 2020 2274 7970 6522 3a20 2261 6c70 6861    "type": "alpha
-00000750: 6265 7422 2c0d 0a20 2020 2020 2020 2020  bet",..         
-00000760: 2020 2022 7461 6773 223a 205b 5d2c 0d0a     "tags": [],..
-00000770: 2020 2020 2020 2020 2020 2020 2261 6c70              "alp
-00000780: 6861 6265 7422 3a20 2241 4243 4445 4647  habet": "ABCDEFG
-00000790: 4849 4a4b 4c4d 4e4f 5051 5253 5455 5657  HIJKLMNOPQRSTUVW
-000007a0: 5859 5a32 3334 3536 373d 222c 0d0a 2020  XYZ234567=",..  
-000007b0: 2020 2020 2020 2020 2020 2262 6173 6522            "base"
-000007c0: 3a20 3332 0d0a 2020 2020 2020 2020 7d2c  : 32..        },
-000007d0: 0d0a 2020 2020 2020 2020 7b0d 0a20 2020  ..        {..   
-000007e0: 2020 2020 2020 2020 2022 7479 7065 223a           "type":
-000007f0: 2022 616c 7068 6162 6574 222c 0d0a 2020   "alphabet",..  
-00000800: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
-00000810: 3a20 5b5d 2c0d 0a20 2020 2020 2020 2020  : [],..         
-00000820: 2020 2022 616c 7068 6162 6574 223a 2022     "alphabet": "
-00000830: 4142 4344 4546 4748 494a 4b4c 4d4e 4f50  ABCDEFGHIJKLMNOP
-00000840: 5152 5354 5556 5758 595a 6162 6364 6566  QRSTUVWXYZabcdef
-00000850: 6768 696a 6b6c 6d6e 6f70 7172 7374 7576  ghijklmnopqrstuv
-00000860: 7778 797a 3031 3233 3435 3637 3839 2b2f  wxyz0123456789+/
-00000870: 3d22 2c0d 0a20 2020 2020 2020 2020 2020  =",..           
-00000880: 2022 6261 7365 223a 2036 340d 0a20 2020   "base": 64..   
-00000890: 2020 2020 207d 2c0d 0a20 2020 2020 2020       },..       
-000008a0: 207b 0d0a 2020 2020 2020 2020 2020 2020   {..            
-000008b0: 2274 7970 6522 3a20 2263 6f6d 6d61 6e64  "type": "command
-000008c0: 222c 0d0a 2020 2020 2020 2020 2020 2020  ",..            
-000008d0: 2274 6167 7322 3a20 5b5d 2c0d 0a20 2020  "tags": [],..   
-000008e0: 2020 2020 2020 2020 2022 7661 6c75 6522           "value"
-000008f0: 3a20 2263 6d64 2e65 7865 202f 6320 6e6f  : "cmd.exe /c no
-00000900: 7465 7061 642e 6578 6522 0d0a 2020 2020  tepad.exe"..    
-00000910: 2020 2020 7d2c 0d0a 2020 2020 2020 2020      },..        
-00000920: 7b0d 0a20 2020 2020 2020 2020 2020 2022  {..            "
-00000930: 7479 7065 223a 2022 6372 6564 656e 7469  type": "credenti
-00000940: 616c 222c 0d0a 2020 2020 2020 2020 2020  al",..          
-00000950: 2020 2274 6167 7322 3a20 5b5d 2c0d 0a20    "tags": [],.. 
-00000960: 2020 2020 2020 2020 2020 2022 7573 6572             "user
-00000970: 6e61 6d65 223a 2022 6164 6d69 6e22 2c0d  name": "admin",.
-00000980: 0a20 2020 2020 2020 2020 2020 2022 7061  .            "pa
-00000990: 7373 776f 7264 223a 2022 3132 3334 3536  ssword": "123456
-000009a0: 220d 0a20 2020 2020 2020 207d 2c0d 0a20  "..        },.. 
-000009b0: 2020 2020 2020 207b 0d0a 2020 2020 2020         {..      
-000009c0: 2020 2020 2020 2274 7970 6522 3a20 2263        "type": "c
-000009d0: 7265 6465 6e74 6961 6c22 2c0d 0a20 2020  redential",..   
-000009e0: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
-000009f0: 205b 5d2c 0d0a 2020 2020 2020 2020 2020   [],..          
-00000a00: 2020 2275 7365 726e 616d 6522 3a20 226d    "username": "m
-00000a10: 7275 7365 7222 2c0d 0a20 2020 2020 2020  ruser",..       
-00000a20: 2020 2020 2022 7061 7373 776f 7264 223a       "password":
-00000a30: 206e 756c 6c0d 0a20 2020 2020 2020 207d   null..        }
-00000a40: 2c0d 0a20 2020 2020 2020 207b 0d0a 2020  ,..        {..  
-00000a50: 2020 2020 2020 2020 2020 2274 7970 6522            "type"
-00000a60: 3a20 2263 7265 6465 6e74 6961 6c22 2c0d  : "credential",.
-00000a70: 0a20 2020 2020 2020 2020 2020 2022 7461  .            "ta
-00000a80: 6773 223a 205b 5d2c 0d0a 2020 2020 2020  gs": [],..      
-00000a90: 2020 2020 2020 2275 7365 726e 616d 6522        "username"
-00000aa0: 3a20 6e75 6c6c 2c0d 0a20 2020 2020 2020  : null,..       
-00000ab0: 2020 2020 2022 7061 7373 776f 7264 223a       "password":
-00000ac0: 2022 7365 6372 6574 7322 0d0a 2020 2020   "secrets"..    
-00000ad0: 2020 2020 7d2c 0d0a 2020 2020 2020 2020      },..        
-00000ae0: 7b0d 0a20 2020 2020 2020 2020 2020 2022  {..            "
-00000af0: 7479 7065 223a 2022 6372 7970 746f 5f61  type": "crypto_a
-00000b00: 6464 7265 7373 222c 0d0a 2020 2020 2020  ddress",..      
-00000b10: 2020 2020 2020 2274 6167 7322 3a20 5b5d        "tags": []
-00000b20: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-00000b30: 6164 6472 6573 7322 3a20 2231 3471 5669  address": "14qVi
-00000b40: 4c4a 6664 4761 5034 4565 486e 4479 4a62  LJfdGaP4EeHnDyJb
-00000b50: 4547 5179 736e 4370 776b 3367 6422 2c0d  EGQysnCpwk3gd",.
-00000b60: 0a20 2020 2020 2020 2020 2020 2022 7379  .            "sy
-00000b70: 6d62 6f6c 223a 2022 4254 4322 0d0a 2020  mbol": "BTC"..  
-00000b80: 2020 2020 2020 7d2c 0d0a 2020 2020 2020        },..      
-00000b90: 2020 7b0d 0a20 2020 2020 2020 2020 2020    {..           
-00000ba0: 2022 7479 7065 223a 2022 736f 636b 6574   "type": "socket
-00000bb0: 222c 0d0a 2020 2020 2020 2020 2020 2020  ",..            
-00000bc0: 2274 6167 7322 3a20 5b5d 2c0d 0a20 2020  "tags": [],..   
-00000bd0: 2020 2020 2020 2020 2022 6164 6472 6573           "addres
-00000be0: 7322 3a20 2262 6164 2e63 6f6d 222c 0d0a  s": "bad.com",..
-00000bf0: 2020 2020 2020 2020 2020 2020 2270 6f72              "por
-00000c00: 7422 3a20 3231 2c0d 0a20 2020 2020 2020  t": 21,..       
-00000c10: 2020 2020 2022 6e65 7477 6f72 6b5f 7072       "network_pr
-00000c20: 6f74 6f63 6f6c 223a 2022 7463 7022 2c0d  otocol": "tcp",.
-00000c30: 0a20 2020 2020 2020 2020 2020 2022 6332  .            "c2
-00000c40: 223a 206e 756c 6c2c 0d0a 2020 2020 2020  ": null,..      
-00000c50: 2020 2020 2020 226c 6973 7465 6e22 3a20        "listen": 
-00000c60: 6e75 6c6c 0d0a 2020 2020 2020 2020 7d2c  null..        },
-00000c70: 0d0a 2020 2020 2020 2020 7b0d 0a20 2020  ..        {..   
-00000c80: 2020 2020 2020 2020 2022 7479 7065 223a           "type":
-00000c90: 2022 736f 636b 6574 222c 0d0a 2020 2020   "socket",..    
-00000ca0: 2020 2020 2020 2020 2274 6167 7322 3a20          "tags": 
-00000cb0: 5b5d 2c0d 0a20 2020 2020 2020 2020 2020  [],..           
-00000cc0: 2022 6164 6472 6573 7322 3a20 6e75 6c6c   "address": null
-00000cd0: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-00000ce0: 706f 7274 223a 2031 3633 352c 0d0a 2020  port": 1635,..  
-00000cf0: 2020 2020 2020 2020 2020 226e 6574 776f            "netwo
-00000d00: 726b 5f70 726f 746f 636f 6c22 3a20 2275  rk_protocol": "u
-00000d10: 6470 222c 0d0a 2020 2020 2020 2020 2020  dp",..          
-00000d20: 2020 2263 3222 3a20 6e75 6c6c 2c0d 0a20    "c2": null,.. 
-00000d30: 2020 2020 2020 2020 2020 2022 6c69 7374             "list
-00000d40: 656e 223a 206e 756c 6c0d 0a20 2020 2020  en": null..     
-00000d50: 2020 207d 2c0d 0a20 2020 2020 2020 207b     },..        {
-00000d60: 0d0a 2020 2020 2020 2020 2020 2020 2274  ..            "t
-00000d70: 7970 6522 3a20 2273 6f63 6b65 7422 2c0d  ype": "socket",.
-00000d80: 0a20 2020 2020 2020 2020 2020 2022 7461  .            "ta
-00000d90: 6773 223a 205b 5d2c 0d0a 2020 2020 2020  gs": [],..      
-00000da0: 2020 2020 2020 2261 6464 7265 7373 223a        "address":
-00000db0: 206e 756c 6c2c 0d0a 2020 2020 2020 2020   null,..        
-00000dc0: 2020 2020 2270 6f72 7422 3a20 3435 3638      "port": 4568
-00000dd0: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-00000de0: 6e65 7477 6f72 6b5f 7072 6f74 6f63 6f6c  network_protocol
-00000df0: 223a 2022 7463 7022 2c0d 0a20 2020 2020  ": "tcp",..     
-00000e00: 2020 2020 2020 2022 6332 223a 206e 756c         "c2": nul
-00000e10: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
-00000e20: 226c 6973 7465 6e22 3a20 7472 7565 0d0a  "listen": true..
-00000e30: 2020 2020 2020 2020 7d2c 0d0a 2020 2020          },..    
-00000e40: 2020 2020 7b0d 0a20 2020 2020 2020 2020      {..         
-00000e50: 2020 2022 7479 7065 223a 2022 7572 6c22     "type": "url"
-00000e60: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-00000e70: 7461 6773 223a 205b 5d2c 0d0a 2020 2020  tags": [],..    
-00000e80: 2020 2020 2020 2020 2275 726c 223a 2022          "url": "
-00000e90: 6874 7470 733a 2f2f 3130 2e31 312e 3130  https://10.11.10
-00000ea0: 2e31 333a 3434 332f 696d 6167 6573 2f62  .13:443/images/b
-00000eb0: 616e 6572 2e6a 7067 222c 0d0a 2020 2020  aner.jpg",..    
-00000ec0: 2020 2020 2020 2020 2273 6f63 6b65 7422          "socket"
-00000ed0: 3a20 7b0d 0a20 2020 2020 2020 2020 2020  : {..           
-00000ee0: 2020 2020 2022 7479 7065 223a 2022 736f       "type": "so
-00000ef0: 636b 6574 222c 0d0a 2020 2020 2020 2020  cket",..        
-00000f00: 2020 2020 2020 2020 2274 6167 7322 3a20          "tags": 
-00000f10: 5b5d 2c0d 0a20 2020 2020 2020 2020 2020  [],..           
-00000f20: 2020 2020 2022 6164 6472 6573 7322 3a20       "address": 
-00000f30: 2231 302e 3131 2e31 302e 3133 222c 0d0a  "10.11.10.13",..
-00000f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000f50: 2270 6f72 7422 3a20 3434 332c 0d0a 2020  "port": 443,..  
-00000f60: 2020 2020 2020 2020 2020 2020 2020 226e                "n
-00000f70: 6574 776f 726b 5f70 726f 746f 636f 6c22  etwork_protocol"
-00000f80: 3a20 6e75 6c6c 2c0d 0a20 2020 2020 2020  : null,..       
-00000f90: 2020 2020 2020 2020 2022 6332 223a 206e           "c2": n
-00000fa0: 756c 6c2c 0d0a 2020 2020 2020 2020 2020  ull,..          
-00000fb0: 2020 2020 2020 226c 6973 7465 6e22 3a20        "listen": 
-00000fc0: 6e75 6c6c 0d0a 2020 2020 2020 2020 2020  null..          
-00000fd0: 2020 7d2c 0d0a 2020 2020 2020 2020 2020    },..          
-00000fe0: 2020 2270 6174 6822 3a20 222f 696d 6167    "path": "/imag
-00000ff0: 6573 2f62 616e 6572 2e6a 7067 222c 0d0a  es/baner.jpg",..
-00001000: 2020 2020 2020 2020 2020 2020 2271 7565              "que
-00001010: 7279 223a 2022 222c 0d0a 2020 2020 2020  ry": "",..      
-00001020: 2020 2020 2020 2261 7070 6c69 6361 7469        "applicati
-00001030: 6f6e 5f70 726f 746f 636f 6c22 3a20 2268  on_protocol": "h
-00001040: 7474 7073 222c 0d0a 2020 2020 2020 2020  ttps",..        
-00001050: 2020 2020 2263 7265 6465 6e74 6961 6c22      "credential"
-00001060: 3a20 6e75 6c6c 0d0a 2020 2020 2020 2020  : null..        
-00001070: 7d2c 0d0a 2020 2020 2020 2020 7b0d 0a20  },..        {.. 
-00001080: 2020 2020 2020 2020 2020 2022 7479 7065             "type
-00001090: 223a 2022 736f 636b 6574 222c 0d0a 2020  ": "socket",..  
-000010a0: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
-000010b0: 3a20 5b5d 2c0d 0a20 2020 2020 2020 2020  : [],..         
-000010c0: 2020 2022 6164 6472 6573 7322 3a20 2231     "address": "1
-000010d0: 302e 3131 2e31 302e 3133 222c 0d0a 2020  0.11.10.13",..  
-000010e0: 2020 2020 2020 2020 2020 2270 6f72 7422            "port"
-000010f0: 3a20 3434 332c 0d0a 2020 2020 2020 2020  : 443,..        
-00001100: 2020 2020 226e 6574 776f 726b 5f70 726f      "network_pro
-00001110: 746f 636f 6c22 3a20 6e75 6c6c 2c0d 0a20  tocol": null,.. 
-00001120: 2020 2020 2020 2020 2020 2022 6332 223a             "c2":
-00001130: 206e 756c 6c2c 0d0a 2020 2020 2020 2020   null,..        
-00001140: 2020 2020 226c 6973 7465 6e22 3a20 6e75      "listen": nu
-00001150: 6c6c 0d0a 2020 2020 2020 2020 7d2c 0d0a  ll..        },..
-00001160: 2020 2020 2020 2020 7b0d 0a20 2020 2020          {..     
-00001170: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
-00001180: 7572 6c22 2c0d 0a20 2020 2020 2020 2020  url",..         
-00001190: 2020 2022 7461 6773 223a 205b 0d0a 2020     "tags": [..  
-000011a0: 2020 2020 2020 2020 2020 2020 2020 2270                "p
-000011b0: 726f 7879 220d 0a20 2020 2020 2020 2020  roxy"..         
-000011c0: 2020 205d 2c0d 0a20 2020 2020 2020 2020     ],..         
-000011d0: 2020 2022 7572 6c22 3a20 6e75 6c6c 2c0d     "url": null,.
-000011e0: 0a20 2020 2020 2020 2020 2020 2022 736f  .            "so
-000011f0: 636b 6574 223a 207b 0d0a 2020 2020 2020  cket": {..      
-00001200: 2020 2020 2020 2020 2020 2274 7970 6522            "type"
-00001210: 3a20 2273 6f63 6b65 7422 2c0d 0a20 2020  : "socket",..   
-00001220: 2020 2020 2020 2020 2020 2020 2022 7461               "ta
-00001230: 6773 223a 205b 5d2c 0d0a 2020 2020 2020  gs": [],..      
-00001240: 2020 2020 2020 2020 2020 2261 6464 7265            "addre
-00001250: 7373 223a 2022 3139 322e 3136 382e 312e  ss": "192.168.1.
-00001260: 3122 2c0d 0a20 2020 2020 2020 2020 2020  1",..           
-00001270: 2020 2020 2022 706f 7274 223a 2038 302c       "port": 80,
-00001280: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00001290: 2020 226e 6574 776f 726b 5f70 726f 746f    "network_proto
-000012a0: 636f 6c22 3a20 2274 6370 222c 0d0a 2020  col": "tcp",..  
-000012b0: 2020 2020 2020 2020 2020 2020 2020 2263                "c
-000012c0: 3222 3a20 6e75 6c6c 2c0d 0a20 2020 2020  2": null,..     
-000012d0: 2020 2020 2020 2020 2020 2022 6c69 7374             "list
-000012e0: 656e 223a 206e 756c 6c0d 0a20 2020 2020  en": null..     
-000012f0: 2020 2020 2020 207d 2c0d 0a20 2020 2020         },..     
-00001300: 2020 2020 2020 2022 7061 7468 223a 206e         "path": n
-00001310: 756c 6c2c 0d0a 2020 2020 2020 2020 2020  ull,..          
-00001320: 2020 2271 7565 7279 223a 206e 756c 6c2c    "query": null,
-00001330: 0d0a 2020 2020 2020 2020 2020 2020 2261  ..            "a
-00001340: 7070 6c69 6361 7469 6f6e 5f70 726f 746f  pplication_proto
-00001350: 636f 6c22 3a20 6e75 6c6c 2c0d 0a20 2020  col": null,..   
-00001360: 2020 2020 2020 2020 2022 6372 6564 656e           "creden
-00001370: 7469 616c 223a 207b 0d0a 2020 2020 2020  tial": {..      
-00001380: 2020 2020 2020 2020 2020 2274 7970 6522            "type"
-00001390: 3a20 2263 7265 6465 6e74 6961 6c22 2c0d  : "credential",.
-000013a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000013b0: 2022 7461 6773 223a 205b 5d2c 0d0a 2020   "tags": [],..  
-000013c0: 2020 2020 2020 2020 2020 2020 2020 2275                "u
-000013d0: 7365 726e 616d 6522 3a20 2261 646d 696e  sername": "admin
-000013e0: 222c 0d0a 2020 2020 2020 2020 2020 2020  ",..            
-000013f0: 2020 2020 2270 6173 7377 6f72 6422 3a20      "password": 
-00001400: 2270 6173 7322 0d0a 2020 2020 2020 2020  "pass"..        
-00001410: 2020 2020 7d0d 0a20 2020 2020 2020 207d      }..        }
-00001420: 2c0d 0a20 2020 2020 2020 207b 0d0a 2020  ,..        {..  
-00001430: 2020 2020 2020 2020 2020 2274 7970 6522            "type"
-00001440: 3a20 2273 6f63 6b65 7422 2c0d 0a20 2020  : "socket",..   
-00001450: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
-00001460: 205b 5d2c 0d0a 2020 2020 2020 2020 2020   [],..          
-00001470: 2020 2261 6464 7265 7373 223a 2022 3139    "address": "19
-00001480: 322e 3136 382e 312e 3122 2c0d 0a20 2020  2.168.1.1",..   
-00001490: 2020 2020 2020 2020 2022 706f 7274 223a           "port":
-000014a0: 2038 302c 0d0a 2020 2020 2020 2020 2020   80,..          
-000014b0: 2020 226e 6574 776f 726b 5f70 726f 746f    "network_proto
-000014c0: 636f 6c22 3a20 2274 6370 222c 0d0a 2020  col": "tcp",..  
-000014d0: 2020 2020 2020 2020 2020 2263 3222 3a20            "c2": 
-000014e0: 6e75 6c6c 2c0d 0a20 2020 2020 2020 2020  null,..         
-000014f0: 2020 2022 6c69 7374 656e 223a 206e 756c     "listen": nul
-00001500: 6c0d 0a20 2020 2020 2020 207d 2c0d 0a20  l..        },.. 
-00001510: 2020 2020 2020 207b 0d0a 2020 2020 2020         {..      
-00001520: 2020 2020 2020 2274 7970 6522 3a20 2263        "type": "c
-00001530: 7265 6465 6e74 6961 6c22 2c0d 0a20 2020  redential",..   
-00001540: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
-00001550: 205b 5d2c 0d0a 2020 2020 2020 2020 2020   [],..          
-00001560: 2020 2275 7365 726e 616d 6522 3a20 2261    "username": "a
-00001570: 646d 696e 222c 0d0a 2020 2020 2020 2020  dmin",..        
-00001580: 2020 2020 2270 6173 7377 6f72 6422 3a20      "password": 
-00001590: 2270 6173 7322 0d0a 2020 2020 2020 2020  "pass"..        
-000015a0: 7d2c 0d0a 2020 2020 2020 2020 7b0d 0a20  },..        {.. 
-000015b0: 2020 2020 2020 2020 2020 2022 7479 7065             "type
-000015c0: 223a 2022 7572 6c22 2c0d 0a20 2020 2020  ": "url",..     
-000015d0: 2020 2020 2020 2022 7461 6773 223a 205b         "tags": [
-000015e0: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
-000015f0: 2275 726c 223a 2022 6674 703a 2f2f 6261  "url": "ftp://ba
-00001600: 6468 6f73 742e 636f 6d3a 3231 222c 0d0a  dhost.com:21",..
-00001610: 2020 2020 2020 2020 2020 2020 2273 6f63              "soc
-00001620: 6b65 7422 3a20 7b0d 0a20 2020 2020 2020  ket": {..       
-00001630: 2020 2020 2020 2020 2022 7479 7065 223a           "type":
-00001640: 2022 736f 636b 6574 222c 0d0a 2020 2020   "socket",..    
-00001650: 2020 2020 2020 2020 2020 2020 2274 6167              "tag
-00001660: 7322 3a20 5b5d 2c0d 0a20 2020 2020 2020  s": [],..       
-00001670: 2020 2020 2020 2020 2022 6164 6472 6573           "addres
-00001680: 7322 3a20 2262 6164 686f 7374 2e63 6f6d  s": "badhost.com
-00001690: 222c 0d0a 2020 2020 2020 2020 2020 2020  ",..            
-000016a0: 2020 2020 2270 6f72 7422 3a20 3231 2c0d      "port": 21,.
-000016b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000016c0: 2022 6e65 7477 6f72 6b5f 7072 6f74 6f63   "network_protoc
-000016d0: 6f6c 223a 206e 756c 6c2c 0d0a 2020 2020  ol": null,..    
-000016e0: 2020 2020 2020 2020 2020 2020 2263 3222              "c2"
-000016f0: 3a20 6e75 6c6c 2c0d 0a20 2020 2020 2020  : null,..       
-00001700: 2020 2020 2020 2020 2022 6c69 7374 656e           "listen
-00001710: 223a 206e 756c 6c0d 0a20 2020 2020 2020  ": null..       
-00001720: 2020 2020 207d 2c0d 0a20 2020 2020 2020       },..       
-00001730: 2020 2020 2022 7061 7468 223a 206e 756c       "path": nul
-00001740: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
-00001750: 2271 7565 7279 223a 2022 222c 0d0a 2020  "query": "",..  
-00001760: 2020 2020 2020 2020 2020 2261 7070 6c69            "appli
-00001770: 6361 7469 6f6e 5f70 726f 746f 636f 6c22  cation_protocol"
-00001780: 3a20 2266 7470 222c 0d0a 2020 2020 2020  : "ftp",..      
-00001790: 2020 2020 2020 2263 7265 6465 6e74 6961        "credentia
-000017a0: 6c22 3a20 7b0d 0a20 2020 2020 2020 2020  l": {..         
-000017b0: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
-000017c0: 6372 6564 656e 7469 616c 222c 0d0a 2020  credential",..  
-000017d0: 2020 2020 2020 2020 2020 2020 2020 2274                "t
-000017e0: 6167 7322 3a20 5b5d 2c0d 0a20 2020 2020  ags": [],..     
-000017f0: 2020 2020 2020 2020 2020 2022 7573 6572             "user
-00001800: 6e61 6d65 223a 2022 6164 6d69 6e22 2c0d  name": "admin",.
-00001810: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001820: 2022 7061 7373 776f 7264 223a 2022 7061   "password": "pa
-00001830: 7373 220d 0a20 2020 2020 2020 2020 2020  ss"..           
-00001840: 207d 0d0a 2020 2020 2020 2020 7d2c 0d0a   }..        },..
-00001850: 2020 2020 2020 2020 7b0d 0a20 2020 2020          {..     
-00001860: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
-00001870: 736f 636b 6574 222c 0d0a 2020 2020 2020  socket",..      
-00001880: 2020 2020 2020 2274 6167 7322 3a20 5b5d        "tags": []
-00001890: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-000018a0: 6164 6472 6573 7322 3a20 2262 6164 686f  address": "badho
-000018b0: 7374 2e63 6f6d 222c 0d0a 2020 2020 2020  st.com",..      
-000018c0: 2020 2020 2020 2270 6f72 7422 3a20 3231        "port": 21
-000018d0: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-000018e0: 6e65 7477 6f72 6b5f 7072 6f74 6f63 6f6c  network_protocol
-000018f0: 223a 206e 756c 6c2c 0d0a 2020 2020 2020  ": null,..      
-00001900: 2020 2020 2020 2263 3222 3a20 6e75 6c6c        "c2": null
-00001910: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-00001920: 6c69 7374 656e 223a 206e 756c 6c0d 0a20  listen": null.. 
-00001930: 2020 2020 2020 207d 2c0d 0a20 2020 2020         },..     
-00001940: 2020 207b 0d0a 2020 2020 2020 2020 2020     {..          
-00001950: 2020 2274 7970 6522 3a20 2265 6d61 696c    "type": "email
-00001960: 5f61 6464 7265 7373 222c 0d0a 2020 2020  _address",..    
-00001970: 2020 2020 2020 2020 2274 6167 7322 3a20          "tags": 
-00001980: 5b5d 2c0d 0a20 2020 2020 2020 2020 2020  [],..           
-00001990: 2022 7661 6c75 6522 3a20 2265 6d61 696c   "value": "email
-000019a0: 4062 6164 2e63 6f6d 220d 0a20 2020 2020  @bad.com"..     
-000019b0: 2020 207d 2c0d 0a20 2020 2020 2020 207b     },..        {
-000019c0: 0d0a 2020 2020 2020 2020 2020 2020 2274  ..            "t
-000019d0: 7970 6522 3a20 2265 7665 6e74 222c 0d0a  ype": "event",..
-000019e0: 2020 2020 2020 2020 2020 2020 2274 6167              "tag
-000019f0: 7322 3a20 5b5d 2c0d 0a20 2020 2020 2020  s": [],..       
-00001a00: 2020 2020 2022 7661 6c75 6522 3a20 224d       "value": "M
-00001a10: 6963 726f 736f 6674 4578 6973 7422 0d0a  icrosoftExist"..
-00001a20: 2020 2020 2020 2020 7d2c 0d0a 2020 2020          },..    
-00001a30: 2020 2020 7b0d 0a20 2020 2020 2020 2020      {..         
-00001a40: 2020 2022 7479 7065 223a 2022 7575 6964     "type": "uuid
-00001a50: 222c 0d0a 2020 2020 2020 2020 2020 2020  ",..            
-00001a60: 2274 6167 7322 3a20 5b5d 2c0d 0a20 2020  "tags": [],..   
-00001a70: 2020 2020 2020 2020 2022 7661 6c75 6522           "value"
-00001a80: 3a20 2236 3534 6535 6366 662d 3831 3763  : "654e5cff-817c
-00001a90: 2d34 6533 642d 3862 3031 2d34 3761 3666  -4e3d-8b01-47a6f
-00001aa0: 3435 6165 3039 6122 0d0a 2020 2020 2020  45ae09a"..      
-00001ab0: 2020 7d2c 0d0a 2020 2020 2020 2020 7b0d    },..        {.
-00001ac0: 0a20 2020 2020 2020 2020 2020 2022 7479  .            "ty
-00001ad0: 7065 223a 2022 696e 6a65 6374 696f 6e5f  pe": "injection_
-00001ae0: 7072 6f63 6573 7322 2c0d 0a20 2020 2020  process",..     
-00001af0: 2020 2020 2020 2022 7461 6773 223a 205b         "tags": [
-00001b00: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
-00001b10: 2276 616c 7565 223a 2022 7376 6368 6f73  "value": "svchos
-00001b20: 7422 0d0a 2020 2020 2020 2020 7d2c 0d0a  t"..        },..
-00001b30: 2020 2020 2020 2020 7b0d 0a20 2020 2020          {..     
-00001b40: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
-00001b50: 696e 7465 7276 616c 222c 0d0a 2020 2020  interval",..    
-00001b60: 2020 2020 2020 2020 2274 6167 7322 3a20          "tags": 
-00001b70: 5b5d 2c0d 0a20 2020 2020 2020 2020 2020  [],..           
-00001b80: 2022 7661 6c75 6522 3a20 332e 300d 0a20   "value": 3.0.. 
-00001b90: 2020 2020 2020 207d 2c0d 0a20 2020 2020         },..     
-00001ba0: 2020 207b 0d0a 2020 2020 2020 2020 2020     {..          
-00001bb0: 2020 2274 7970 6522 3a20 2265 6e63 7279    "type": "encry
-00001bc0: 7074 696f 6e5f 6b65 7922 2c0d 0a20 2020  ption_key",..   
-00001bd0: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
-00001be0: 205b 5d2c 0d0a 2020 2020 2020 2020 2020   [],..          
-00001bf0: 2020 226b 6579 223a 2022 6147 5673 6247    "key": "aGVsbG
-00001c00: 383d 222c 0d0a 2020 2020 2020 2020 2020  8=",..          
-00001c10: 2020 2261 6c67 6f72 6974 686d 223a 2022    "algorithm": "
-00001c20: 7263 3422 2c0d 0a20 2020 2020 2020 2020  rc4",..         
-00001c30: 2020 2022 6d6f 6465 223a 206e 756c 6c2c     "mode": null,
-00001c40: 0d0a 2020 2020 2020 2020 2020 2020 2269  ..            "i
-00001c50: 7622 3a20 6e75 6c6c 0d0a 2020 2020 2020  v": null..      
-00001c60: 2020 7d2c 0d0a 2020 2020 2020 2020 7b0d    },..        {.
-00001c70: 0a20 2020 2020 2020 2020 2020 2022 7479  .            "ty
-00001c80: 7065 223a 2022 656e 6372 7970 7469 6f6e  pe": "encryption
-00001c90: 5f6b 6579 222c 0d0a 2020 2020 2020 2020  _key",..        
-00001ca0: 2020 2020 2274 6167 7322 3a20 5b5d 2c0d      "tags": [],.
-00001cb0: 0a20 2020 2020 2020 2020 2020 2022 6b65  .            "ke
-00001cc0: 7922 3a20 222f 2f2f 2f2f 773d 3d22 2c0d  y": "/////w==",.
-00001cd0: 0a20 2020 2020 2020 2020 2020 2022 616c  .            "al
-00001ce0: 676f 7269 7468 6d22 3a20 2261 6573 222c  gorithm": "aes",
-00001cf0: 0d0a 2020 2020 2020 2020 2020 2020 226d  ..            "m
-00001d00: 6f64 6522 3a20 2265 6362 222c 0d0a 2020  ode": "ecb",..  
-00001d10: 2020 2020 2020 2020 2020 2269 7622 3a20            "iv": 
-00001d20: 2241 4141 4141 413d 3d22 0d0a 2020 2020  "AAAAAA=="..    
-00001d30: 2020 2020 7d2c 0d0a 2020 2020 2020 2020      },..        
-00001d40: 7b0d 0a20 2020 2020 2020 2020 2020 2022  {..            "
-00001d50: 7479 7065 223a 2022 6465 636f 6465 645f  type": "decoded_
-00001d60: 7374 7269 6e67 222c 0d0a 2020 2020 2020  string",..      
-00001d70: 2020 2020 2020 2274 6167 7322 3a20 5b5d        "tags": []
-00001d80: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-00001d90: 7661 6c75 6522 3a20 2247 6574 5072 6f63  value": "GetProc
-00001da0: 6573 7322 2c0d 0a20 2020 2020 2020 2020  ess",..         
-00001db0: 2020 2022 656e 6372 7970 7469 6f6e 5f6b     "encryption_k
-00001dc0: 6579 223a 206e 756c 6c0d 0a20 2020 2020  ey": null..     
-00001dd0: 2020 207d 2c0d 0a20 2020 2020 2020 207b     },..        {
-00001de0: 0d0a 2020 2020 2020 2020 2020 2020 2274  ..            "t
-00001df0: 7970 6522 3a20 2264 6563 6f64 6564 5f73  ype": "decoded_s
-00001e00: 7472 696e 6722 2c0d 0a20 2020 2020 2020  tring",..       
-00001e10: 2020 2020 2022 7461 6773 223a 205b 5d2c       "tags": [],
-00001e20: 0d0a 2020 2020 2020 2020 2020 2020 2276  ..            "v
-00001e30: 616c 7565 223a 2022 6261 6473 7472 696e  alue": "badstrin
-00001e40: 6722 2c0d 0a20 2020 2020 2020 2020 2020  g",..           
-00001e50: 2022 656e 6372 7970 7469 6f6e 5f6b 6579   "encryption_key
-00001e60: 223a 207b 0d0a 2020 2020 2020 2020 2020  ": {..          
-00001e70: 2020 2020 2020 2274 7970 6522 3a20 2265        "type": "e
-00001e80: 6e63 7279 7074 696f 6e5f 6b65 7922 2c0d  ncryption_key",.
-00001e90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001ea0: 2022 7461 6773 223a 205b 5d2c 0d0a 2020   "tags": [],..  
-00001eb0: 2020 2020 2020 2020 2020 2020 2020 226b                "k
-00001ec0: 6579 223a 2022 2f2f 383d 222c 0d0a 2020  ey": "//8=",..  
-00001ed0: 2020 2020 2020 2020 2020 2020 2020 2261                "a
-00001ee0: 6c67 6f72 6974 686d 223a 2022 786f 7222  lgorithm": "xor"
-00001ef0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00001f00: 2020 2022 6d6f 6465 223a 206e 756c 6c2c     "mode": null,
-00001f10: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00001f20: 2020 2269 7622 3a20 6e75 6c6c 0d0a 2020    "iv": null..  
-00001f30: 2020 2020 2020 2020 2020 7d0d 0a20 2020            }..   
-00001f40: 2020 2020 207d 2c0d 0a20 2020 2020 2020       },..       
-00001f50: 207b 0d0a 2020 2020 2020 2020 2020 2020   {..            
-00001f60: 2274 7970 6522 3a20 2265 6e63 7279 7074  "type": "encrypt
-00001f70: 696f 6e5f 6b65 7922 2c0d 0a20 2020 2020  ion_key",..     
-00001f80: 2020 2020 2020 2022 7461 6773 223a 205b         "tags": [
-00001f90: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
-00001fa0: 226b 6579 223a 2022 2f2f 383d 222c 0d0a  "key": "//8=",..
-00001fb0: 2020 2020 2020 2020 2020 2020 2261 6c67              "alg
-00001fc0: 6f72 6974 686d 223a 2022 786f 7222 2c0d  orithm": "xor",.
-00001fd0: 0a20 2020 2020 2020 2020 2020 2022 6d6f  .            "mo
-00001fe0: 6465 223a 206e 756c 6c2c 0d0a 2020 2020  de": null,..    
-00001ff0: 2020 2020 2020 2020 2269 7622 3a20 6e75          "iv": nu
-00002000: 6c6c 0d0a 2020 2020 2020 2020 7d2c 0d0a  ll..        },..
-00002010: 2020 2020 2020 2020 7b0d 0a20 2020 2020          {..     
-00002020: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
-00002030: 6d69 7373 696f 6e5f 6964 222c 0d0a 2020  mission_id",..  
-00002040: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
-00002050: 3a20 5b5d 2c0d 0a20 2020 2020 2020 2020  : [],..         
-00002060: 2020 2022 7661 6c75 6522 3a20 2274 6172     "value": "tar
-00002070: 6765 7434 220d 0a20 2020 2020 2020 207d  get4"..        }
-00002080: 2c0d 0a20 2020 2020 2020 207b 0d0a 2020  ,..        {..  
-00002090: 2020 2020 2020 2020 2020 2274 7970 6522            "type"
-000020a0: 3a20 226d 7574 6578 222c 0d0a 2020 2020  : "mutex",..    
-000020b0: 2020 2020 2020 2020 2274 6167 7322 3a20          "tags": 
-000020c0: 5b5d 2c0d 0a20 2020 2020 2020 2020 2020  [],..           
-000020d0: 2022 7661 6c75 6522 3a20 2269 7468 696e   "value": "ithin
-000020e0: 6b69 6d61 6c6f 6e65 6e6f 7722 0d0a 2020  kimalonenow"..  
-000020f0: 2020 2020 2020 7d2c 0d0a 2020 2020 2020        },..      
-00002100: 2020 7b0d 0a20 2020 2020 2020 2020 2020    {..           
-00002110: 2022 7479 7065 223a 2022 6f74 6865 7222   "type": "other"
-00002120: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-00002130: 7461 6773 223a 205b 0d0a 2020 2020 2020  tags": [..      
-00002140: 2020 2020 2020 2020 2020 2273 6f6d 6574            "somet
-00002150: 6869 6e67 220d 0a20 2020 2020 2020 2020  hing"..         
-00002160: 2020 205d 2c0d 0a20 2020 2020 2020 2020     ],..         
-00002170: 2020 2022 6b65 7922 3a20 226d 6973 635f     "key": "misc_
-00002180: 696e 666f 222c 0d0a 2020 2020 2020 2020  info",..        
-00002190: 2020 2020 2276 616c 7565 223a 2022 736f      "value": "so
-000021a0: 6d65 206d 6973 6365 6c6c 616e 656f 7573  me miscellaneous
-000021b0: 2069 6e66 6f22 2c0d 0a20 2020 2020 2020   info",..       
-000021c0: 2020 2020 2022 7661 6c75 655f 666f 726d       "value_form
-000021d0: 6174 223a 2022 7374 7269 6e67 220d 0a20  at": "string".. 
-000021e0: 2020 2020 2020 207d 2c0d 0a20 2020 2020         },..     
-000021f0: 2020 207b 0d0a 2020 2020 2020 2020 2020     {..          
-00002200: 2020 2274 7970 6522 3a20 226f 7468 6572    "type": "other
-00002210: 222c 0d0a 2020 2020 2020 2020 2020 2020  ",..            
-00002220: 2274 6167 7322 3a20 5b5d 2c0d 0a20 2020  "tags": [],..   
-00002230: 2020 2020 2020 2020 2022 6b65 7922 3a20           "key": 
-00002240: 2272 616e 646f 6d5f 6461 7461 222c 0d0a  "random_data",..
-00002250: 2020 2020 2020 2020 2020 2020 2276 616c              "val
-00002260: 7565 223a 2022 3371 322b 3777 3d3d 222c  ue": "3q2+7w==",
-00002270: 0d0a 2020 2020 2020 2020 2020 2020 2276  ..            "v
-00002280: 616c 7565 5f66 6f72 6d61 7422 3a20 2262  alue_format": "b
-00002290: 7974 6573 220d 0a20 2020 2020 2020 207d  ytes"..        }
-000022a0: 2c0d 0a20 2020 2020 2020 207b 0d0a 2020  ,..        {..  
-000022b0: 2020 2020 2020 2020 2020 2274 7970 6522            "type"
-000022c0: 3a20 226f 7468 6572 222c 0d0a 2020 2020  : "other",..    
-000022d0: 2020 2020 2020 2020 2274 6167 7322 3a20          "tags": 
-000022e0: 5b5d 2c0d 0a20 2020 2020 2020 2020 2020  [],..           
-000022f0: 2022 6b65 7922 3a20 226b 6579 6c6f 6767   "key": "keylogg
-00002300: 6572 222c 0d0a 2020 2020 2020 2020 2020  er",..          
-00002310: 2020 2276 616c 7565 223a 2074 7275 652c    "value": true,
-00002320: 0d0a 2020 2020 2020 2020 2020 2020 2276  ..            "v
-00002330: 616c 7565 5f66 6f72 6d61 7422 3a20 2262  alue_format": "b
-00002340: 6f6f 6c65 616e 220d 0a20 2020 2020 2020  oolean"..       
-00002350: 207d 2c0d 0a20 2020 2020 2020 207b 0d0a   },..        {..
-00002360: 2020 2020 2020 2020 2020 2020 2274 7970              "typ
-00002370: 6522 3a20 226f 7468 6572 222c 0d0a 2020  e": "other",..  
-00002380: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
-00002390: 3a20 5b0d 0a20 2020 2020 2020 2020 2020  : [..           
-000023a0: 2020 2020 2022 7461 6731 220d 0a20 2020       "tag1"..   
-000023b0: 2020 2020 2020 2020 205d 2c0d 0a20 2020           ],..   
-000023c0: 2020 2020 2020 2020 2022 6b65 7922 3a20           "key": 
-000023d0: 226d 6973 635f 696e 7465 6765 7222 2c0d  "misc_integer",.
-000023e0: 0a20 2020 2020 2020 2020 2020 2022 7661  .            "va
-000023f0: 6c75 6522 3a20 3433 322c 0d0a 2020 2020  lue": 432,..    
-00002400: 2020 2020 2020 2020 2276 616c 7565 5f66          "value_f
-00002410: 6f72 6d61 7422 3a20 2269 6e74 6567 6572  ormat": "integer
-00002420: 220d 0a20 2020 2020 2020 207d 2c0d 0a20  "..        },.. 
-00002430: 2020 2020 2020 207b 0d0a 2020 2020 2020         {..      
-00002440: 2020 2020 2020 2274 7970 6522 3a20 2270        "type": "p
-00002450: 6970 6522 2c0d 0a20 2020 2020 2020 2020  ipe",..         
-00002460: 2020 2022 7461 6773 223a 205b 5d2c 0d0a     "tags": [],..
-00002470: 2020 2020 2020 2020 2020 2020 2276 616c              "val
-00002480: 7565 223a 2022 5c5c 2e5c 5c70 6970 655c  ue": "\\.\\pipe\
-00002490: 5c6e 616d 6564 7069 7065 220d 0a20 2020  \namedpipe"..   
-000024a0: 2020 2020 207d 2c0d 0a20 2020 2020 2020       },..       
-000024b0: 207b 0d0a 2020 2020 2020 2020 2020 2020   {..            
-000024c0: 2274 7970 6522 3a20 2272 6567 6973 7472  "type": "registr
-000024d0: 7922 2c0d 0a20 2020 2020 2020 2020 2020  y",..           
-000024e0: 2022 7461 6773 223a 205b 5d2c 0d0a 2020   "tags": [],..  
-000024f0: 2020 2020 2020 2020 2020 2268 6976 6522            "hive"
-00002500: 3a20 2248 4b45 595f 4c4f 4341 4c5f 4d41  : "HKEY_LOCAL_MA
-00002510: 4348 494e 4522 2c0d 0a20 2020 2020 2020  CHINE",..       
-00002520: 2020 2020 2022 7375 626b 6579 223a 2022       "subkey": "
-00002530: 536f 6674 7761 7265 5c5c 4d69 6372 6f73  Software\\Micros
-00002540: 6f66 745c 5c57 696e 646f 7773 5c5c 4375  oft\\Windows\\Cu
-00002550: 7272 656e 7456 6572 7369 6f6e 5c5c 5275  rrentVersion\\Ru
-00002560: 6e22 2c0d 0a20 2020 2020 2020 2020 2020  n",..           
-00002570: 2022 7661 6c75 6522 3a20 2255 7064 6174   "value": "Updat
-00002580: 6572 222c 0d0a 2020 2020 2020 2020 2020  er",..          
-00002590: 2020 2264 6174 6122 3a20 2263 3a5c 5c75    "data": "c:\\u
-000025a0: 7064 6174 652e 6578 6522 2c0d 0a20 2020  pdate.exe",..   
-000025b0: 2020 2020 2020 2020 2022 6461 7461 5f74           "data_t
-000025c0: 7970 6522 3a20 2252 4547 5f53 5a22 0d0a  ype": "REG_SZ"..
-000025d0: 2020 2020 2020 2020 7d2c 0d0a 2020 2020          },..    
-000025e0: 2020 2020 7b0d 0a20 2020 2020 2020 2020      {..         
-000025f0: 2020 2022 7479 7065 223a 2022 7265 6769     "type": "regi
-00002600: 7374 7279 222c 0d0a 2020 2020 2020 2020  stry",..        
-00002610: 2020 2020 2274 6167 7322 3a20 5b5d 2c0d      "tags": [],.
-00002620: 0a20 2020 2020 2020 2020 2020 2022 6869  .            "hi
-00002630: 7665 223a 2022 484b 4559 5f4c 4f43 414c  ve": "HKEY_LOCAL
-00002640: 5f4d 4143 4849 4e45 222c 0d0a 2020 2020  _MACHINE",..    
-00002650: 2020 2020 2020 2020 2273 7562 6b65 7922          "subkey"
-00002660: 3a20 2246 6f6f 5c5c 4261 7222 2c0d 0a20  : "Foo\\Bar",.. 
-00002670: 2020 2020 2020 2020 2020 2022 7661 6c75             "valu
-00002680: 6522 3a20 6e75 6c6c 2c0d 0a20 2020 2020  e": null,..     
-00002690: 2020 2020 2020 2022 6461 7461 223a 206e         "data": n
-000026a0: 756c 6c2c 0d0a 2020 2020 2020 2020 2020  ull,..          
-000026b0: 2020 2264 6174 615f 7479 7065 223a 206e    "data_type": n
-000026c0: 756c 6c0d 0a20 2020 2020 2020 207d 2c0d  ull..        },.
-000026d0: 0a20 2020 2020 2020 207b 0d0a 2020 2020  .        {..    
-000026e0: 2020 2020 2020 2020 2274 7970 6522 3a20          "type": 
-000026f0: 2272 6567 6973 7472 7922 2c0d 0a20 2020  "registry",..   
-00002700: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
-00002710: 205b 0d0a 2020 2020 2020 2020 2020 2020   [..            
-00002720: 2020 2020 2274 6167 3222 0d0a 2020 2020      "tag2"..    
-00002730: 2020 2020 2020 2020 5d2c 0d0a 2020 2020          ],..    
-00002740: 2020 2020 2020 2020 2268 6976 6522 3a20          "hive": 
-00002750: 6e75 6c6c 2c0d 0a20 2020 2020 2020 2020  null,..         
-00002760: 2020 2022 7375 626b 6579 223a 206e 756c     "subkey": nul
-00002770: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
-00002780: 2276 616c 7565 223a 2022 4261 7a22 2c0d  "value": "Baz",.
-00002790: 0a20 2020 2020 2020 2020 2020 2022 6461  .            "da
-000027a0: 7461 223a 206e 756c 6c2c 0d0a 2020 2020  ta": null,..    
-000027b0: 2020 2020 2020 2020 2264 6174 615f 7479          "data_ty
-000027c0: 7065 223a 206e 756c 6c0d 0a20 2020 2020  pe": null..     
-000027d0: 2020 207d 2c0d 0a20 2020 2020 2020 207b     },..        {
-000027e0: 0d0a 2020 2020 2020 2020 2020 2020 2274  ..            "t
-000027f0: 7970 6522 3a20 2272 7361 5f70 7269 7661  ype": "rsa_priva
-00002800: 7465 5f6b 6579 222c 0d0a 2020 2020 2020  te_key",..      
-00002810: 2020 2020 2020 2274 6167 7322 3a20 5b5d        "tags": []
-00002820: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-00002830: 7075 626c 6963 5f65 7870 6f6e 656e 7422  public_exponent"
-00002840: 3a20 372c 0d0a 2020 2020 2020 2020 2020  : 7,..          
-00002850: 2020 226d 6f64 756c 7573 223a 2031 3837    "modulus": 187
-00002860: 2c0d 0a20 2020 2020 2020 2020 2020 2022  ,..            "
-00002870: 7072 6976 6174 655f 6578 706f 6e65 6e74  private_exponent
-00002880: 223a 2032 332c 0d0a 2020 2020 2020 2020  ": 23,..        
-00002890: 2020 2020 2270 223a 2031 372c 0d0a 2020      "p": 17,..  
-000028a0: 2020 2020 2020 2020 2020 2271 223a 2031            "q": 1
-000028b0: 312c 0d0a 2020 2020 2020 2020 2020 2020  1,..            
-000028c0: 2264 5f6d 6f64 5f70 3122 3a20 372c 0d0a  "d_mod_p1": 7,..
-000028d0: 2020 2020 2020 2020 2020 2020 2264 5f6d              "d_m
-000028e0: 6f64 5f71 3122 3a20 332c 0d0a 2020 2020  od_q1": 3,..    
-000028f0: 2020 2020 2020 2020 2271 5f69 6e76 5f6d          "q_inv_m
-00002900: 6f64 5f70 223a 2031 340d 0a20 2020 2020  od_p": 14..     
-00002910: 2020 207d 2c0d 0a20 2020 2020 2020 207b     },..        {
-00002920: 0d0a 2020 2020 2020 2020 2020 2020 2274  ..            "t
-00002930: 7970 6522 3a20 2272 7361 5f70 7562 6c69  ype": "rsa_publi
-00002940: 635f 6b65 7922 2c0d 0a20 2020 2020 2020  c_key",..       
-00002950: 2020 2020 2022 7461 6773 223a 205b 5d2c       "tags": [],
-00002960: 0d0a 2020 2020 2020 2020 2020 2020 2270  ..            "p
-00002970: 7562 6c69 635f 6578 706f 6e65 6e74 223a  ublic_exponent":
-00002980: 2037 2c0d 0a20 2020 2020 2020 2020 2020   7,..           
-00002990: 2022 6d6f 6475 6c75 7322 3a20 3138 370d   "modulus": 187.
-000029a0: 0a20 2020 2020 2020 207d 2c0d 0a20 2020  .        },..   
-000029b0: 2020 2020 207b 0d0a 2020 2020 2020 2020       {..        
-000029c0: 2020 2020 2274 7970 6522 3a20 2273 6572      "type": "ser
-000029d0: 7669 6365 222c 0d0a 2020 2020 2020 2020  vice",..        
-000029e0: 2020 2020 2274 6167 7322 3a20 5b5d 2c0d      "tags": [],.
-000029f0: 0a20 2020 2020 2020 2020 2020 2022 6e61  .            "na
-00002a00: 6d65 223a 2022 5769 6e64 6f77 7355 7365  me": "WindowsUse
-00002a10: 724d 616e 6167 656d 656e 7422 2c0d 0a20  rManagement",.. 
-00002a20: 2020 2020 2020 2020 2020 2022 6469 7370             "disp
-00002a30: 6c61 795f 6e61 6d65 223a 2022 5769 6e64  lay_name": "Wind
-00002a40: 6f77 7320 5573 6572 204d 616e 6167 656d  ows User Managem
-00002a50: 656e 7422 2c0d 0a20 2020 2020 2020 2020  ent",..         
-00002a60: 2020 2022 6465 7363 7269 7074 696f 6e22     "description"
-00002a70: 3a20 2250 726f 7669 6465 7320 6120 636f  : "Provides a co
-00002a80: 6d6d 6f6e 206d 616e 6167 656d 656e 7420  mmon management 
-00002a90: 746f 2061 6363 6573 7320 696e 666f 726d  to access inform
-00002aa0: 6174 696f 6e20 6162 6f75 7420 7769 6e64  ation about wind
-00002ab0: 6f77 7320 7573 6572 2e22 2c0d 0a20 2020  ows user.",..   
-00002ac0: 2020 2020 2020 2020 2022 696d 6167 6522           "image"
-00002ad0: 3a20 2225 5379 7374 656d 255c 5c73 766f  : "%System%\\svo
-00002ae0: 686f 7374 2e65 7865 222c 0d0a 2020 2020  host.exe",..    
-00002af0: 2020 2020 2020 2020 2264 6c6c 223a 206e          "dll": n
-00002b00: 756c 6c0d 0a20 2020 2020 2020 207d 2c0d  ull..        },.
-00002b10: 0a20 2020 2020 2020 207b 0d0a 2020 2020  .        {..    
-00002b20: 2020 2020 2020 2020 2274 7970 6522 3a20          "type": 
-00002b30: 2270 6174 6822 2c0d 0a20 2020 2020 2020  "path",..       
-00002b40: 2020 2020 2022 7461 6773 223a 205b 5d2c       "tags": [],
-00002b50: 0d0a 2020 2020 2020 2020 2020 2020 2270  ..            "p
-00002b60: 6174 6822 3a20 2225 5379 7374 656d 255c  ath": "%System%\
-00002b70: 5c73 766f 686f 7374 2e65 7865 222c 0d0a  \svohost.exe",..
-00002b80: 2020 2020 2020 2020 2020 2020 2269 735f              "is_
-00002b90: 6469 7222 3a20 6661 6c73 652c 0d0a 2020  dir": false,..  
-00002ba0: 2020 2020 2020 2020 2020 2270 6f73 6978            "posix
-00002bb0: 223a 2066 616c 7365 2c0d 0a20 2020 2020  ": false,..     
-00002bc0: 2020 2020 2020 2022 6669 6c65 5f73 7973         "file_sys
-00002bd0: 7465 6d22 3a20 6e75 6c6c 0d0a 2020 2020  tem": null..    
-00002be0: 2020 2020 7d2c 0d0a 2020 2020 2020 2020      },..        
-00002bf0: 7b0d 0a20 2020 2020 2020 2020 2020 2022  {..            "
-00002c00: 7479 7065 223a 2022 7573 6572 5f61 6765  type": "user_age
-00002c10: 6e74 222c 0d0a 2020 2020 2020 2020 2020  nt",..          
-00002c20: 2020 2274 6167 7322 3a20 5b5d 2c0d 0a20    "tags": [],.. 
-00002c30: 2020 2020 2020 2020 2020 2022 7661 6c75             "valu
-00002c40: 6522 3a20 224d 6f7a 696c 6c61 2f34 2e30  e": "Mozilla/4.0
-00002c50: 2028 636f 6d70 6174 6962 6c65 3b20 4d49   (compatible; MI
-00002c60: 5345 2036 2e30 3b20 5769 6e64 6f77 7320  SE 6.0; Windows 
-00002c70: 4e54 2035 2e32 2922 0d0a 2020 2020 2020  NT 5.2)"..      
-00002c80: 2020 7d2c 0d0a 2020 2020 2020 2020 7b0d    },..        {.
-00002c90: 0a20 2020 2020 2020 2020 2020 2022 7479  .            "ty
-00002ca0: 7065 223a 2022 7665 7273 696f 6e22 2c0d  pe": "version",.
-00002cb0: 0a20 2020 2020 2020 2020 2020 2022 7461  .            "ta
-00002cc0: 6773 223a 205b 5d2c 0d0a 2020 2020 2020  gs": [],..      
-00002cd0: 2020 2020 2020 2276 616c 7565 223a 2022        "value": "
-00002ce0: 332e 3122 0d0a 2020 2020 2020 2020 7d2c  3.1"..        },
-00002cf0: 0d0a 2020 2020 2020 2020 7b0d 0a20 2020  ..        {..   
-00002d00: 2020 2020 2020 2020 2022 7479 7065 223a           "type":
-00002d10: 2022 7665 7273 696f 6e22 2c0d 0a20 2020   "version",..   
-00002d20: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
-00002d30: 205b 5d2c 0d0a 2020 2020 2020 2020 2020   [],..          
-00002d40: 2020 2276 616c 7565 223a 2022 3430 332e    "value": "403.
-00002d50: 3130 220d 0a20 2020 2020 2020 207d 2c0d  10"..        },.
-00002d60: 0a20 2020 2020 2020 207b 0d0a 2020 2020  .        {..    
-00002d70: 2020 2020 2020 2020 2274 7970 6522 3a20          "type": 
-00002d80: 2266 696c 6522 2c0d 0a20 2020 2020 2020  "file",..       
-00002d90: 2020 2020 2022 7461 6773 223a 205b 5d2c       "tags": [],
-00002da0: 0d0a 2020 2020 2020 2020 2020 2020 226e  ..            "n
-00002db0: 616d 6522 3a20 2263 6f6e 6669 672e 786d  ame": "config.xm
-00002dc0: 6c22 2c0d 0a20 2020 2020 2020 2020 2020  l",..           
-00002dd0: 2022 6465 7363 7269 7074 696f 6e22 3a20   "description": 
-00002de0: 2245 7874 7261 6374 6564 2062 6163 6b64  "Extracted backd
-00002df0: 6f6f 7220 466f 6f20 636f 6e66 6967 2066  oor Foo config f
-00002e00: 696c 6522 2c0d 0a20 2020 2020 2020 2020  ile",..         
-00002e10: 2020 2022 6d64 3522 3a20 2238 6334 3166     "md5": "8c41f
-00002e20: 3238 3032 3930 3465 3533 3436 3933 3930  2802904e53469390
-00002e30: 3834 3563 6665 6232 6232 3822 2c0d 0a20  845cfeb2b28",.. 
-00002e40: 2020 2020 2020 2020 2020 2022 7368 6131             "sha1
-00002e50: 223a 2022 6365 3635 3139 6131 6463 3731  ": "ce6519a1dc71
-00002e60: 3531 3065 6531 3565 3636 6233 3932 3666  510ee15e66b3926f
-00002e70: 6431 3634 6133 3733 3830 3361 222c 0d0a  d164a373803a",..
-00002e80: 2020 2020 2020 2020 2020 2020 2273 6861              "sha
-00002e90: 3235 3622 3a20 2238 3161 6464 6266 3733  256": "81addbf73
-00002ea0: 3264 3964 3663 3234 6231 6433 6564 6537  2d9d6c24b1d3ede7
-00002eb0: 6166 6365 6566 3661 3163 6666 3539 6166  afceef6a1cff59af
-00002ec0: 3762 3633 6430 3135 3034 6130 3931 3361  7b63d01504a0913a
-00002ed0: 3663 3637 3031 6122 2c0d 0a20 2020 2020  6c6701a",..     
-00002ee0: 2020 2020 2020 2022 6172 6368 6974 6563         "architec
-00002ef0: 7475 7265 223a 206e 756c 6c2c 0d0a 2020  ture": null,..  
-00002f00: 2020 2020 2020 2020 2020 2263 6f6d 7069            "compi
-00002f10: 6c65 5f74 696d 6522 3a20 6e75 6c6c 2c0d  le_time": null,.
-00002f20: 0a20 2020 2020 2020 2020 2020 2022 6669  .            "fi
-00002f30: 6c65 5f70 6174 6822 3a20 6e75 6c6c 2c0d  le_path": null,.
-00002f40: 0a20 2020 2020 2020 2020 2020 2022 6461  .            "da
-00002f50: 7461 223a 206e 756c 6c2c 0d0a 2020 2020  ta": null,..    
-00002f60: 2020 2020 2020 2020 2264 6572 6976 6174          "derivat
-00002f70: 696f 6e22 3a20 2265 6d62 6564 6465 6422  ion": "embedded"
-00002f80: 0d0a 2020 2020 2020 2020 7d0d 0a20 2020  ..        }..   
-00002f90: 205d 0d0a 7d                              ]..}
+00000000: 7b0a 2020 2020 2274 7970 6522 3a20 2272  {.    "type": "r
+00000010: 6570 6f72 7422 2c0a 2020 2020 2274 6167  eport",.    "tag
+00000020: 7322 3a20 5b0a 2020 2020 2020 2020 2274  s": [.        "t
+00000030: 6167 6769 6e67 222c 0a20 2020 2020 2020  agging",.       
+00000040: 2022 7465 7374 220a 2020 2020 5d2c 0a20   "test".    ],. 
+00000050: 2020 2022 6d77 6370 5f76 6572 7369 6f6e     "mwcp_version
+00000060: 223a 2022 4d57 4350 5f56 4552 5349 4f4e  ": "MWCP_VERSION
+00000070: 222c 0a20 2020 2022 696e 7075 745f 6669  ",.    "input_fi
+00000080: 6c65 223a 207b 0a20 2020 2020 2020 2022  le": {.        "
+00000090: 7479 7065 223a 2022 6669 6c65 222c 0a20  type": "file",. 
+000000a0: 2020 2020 2020 2022 7461 6773 223a 205b         "tags": [
+000000b0: 5d2c 0a20 2020 2020 2020 2022 6e61 6d65  ],.        "name
+000000c0: 223a 2022 696e 7075 745f 6669 6c65 2e62  ": "input_file.b
+000000d0: 696e 222c 0a20 2020 2020 2020 2022 6465  in",.        "de
+000000e0: 7363 7269 7074 696f 6e22 3a20 6e75 6c6c  scription": null
+000000f0: 2c0a 2020 2020 2020 2020 226d 6435 223a  ,.        "md5":
+00000100: 2022 3165 3530 3231 3061 3032 3032 3439   "1e50210a020249
+00000110: 3766 6237 3962 6333 3862 3661 6465 3663  7fb79bc38b6ade6c
+00000120: 3334 222c 0a20 2020 2020 2020 2022 7368  34",.        "sh
+00000130: 6131 223a 2022 6261 6633 3435 3531 6665  a1": "baf34551fe
+00000140: 6362 3438 6163 6333 6461 3836 3865 6238  cb48acc3da868eb8
+00000150: 3565 3162 3664 6163 3964 6533 3536 222c  5e1b6dac9de356",
+00000160: 0a20 2020 2020 2020 2022 7368 6132 3536  .        "sha256
+00000170: 223a 2022 3133 3037 3939 3065 3662 6135  ": "1307990e6ba5
+00000180: 6361 3134 3565 6233 3565 3939 3138 3261  ca145eb35e99182a
+00000190: 3962 6563 3436 3533 3162 6335 3464 6466  9bec46531bc54ddf
+000001a0: 3635 3661 3630 3263 3738 3066 6130 3234  656a602c780fa024
+000001b0: 3064 6565 222c 0a20 2020 2020 2020 2022  0dee",.        "
+000001c0: 6172 6368 6974 6563 7475 7265 223a 206e  architecture": n
+000001d0: 756c 6c2c 0a20 2020 2020 2020 2022 636f  ull,.        "co
+000001e0: 6d70 696c 655f 7469 6d65 223a 206e 756c  mpile_time": nul
+000001f0: 6c2c 0a20 2020 2020 2020 2022 6669 6c65  l,.        "file
+00000200: 5f70 6174 6822 3a20 2243 3a2f 696e 7075  _path": "C:/inpu
+00000210: 745f 6669 6c65 2e62 696e 222c 0a20 2020  t_file.bin",.   
+00000220: 2020 2020 2022 6461 7461 223a 206e 756c       "data": nul
+00000230: 6c2c 0a20 2020 2020 2020 2022 6465 7269  l,.        "deri
+00000240: 7661 7469 6f6e 223a 206e 756c 6c0a 2020  vation": null.  
+00000250: 2020 7d2c 0a20 2020 2022 7061 7273 6572    },.    "parser
+00000260: 223a 2022 466f 6f50 6172 7365 7222 2c0a  ": "FooParser",.
+00000270: 2020 2020 2265 7272 6f72 7322 3a20 5b0a      "errors": [.
+00000280: 2020 2020 2020 2020 225b 215d 2054 6573          "[!] Tes
+00000290: 7420 6572 726f 7220 6c6f 6722 0a20 2020  t error log".   
+000002a0: 205d 2c0a 2020 2020 226c 6f67 7322 3a20   ],.    "logs": 
+000002b0: 5b0a 2020 2020 2020 2020 225b 2b5d 2054  [.        "[+] T
+000002c0: 6573 7420 696e 666f 206c 6f67 222c 0a20  est info log",. 
+000002d0: 2020 2020 2020 2022 5b21 5d20 5465 7374         "[!] Test
+000002e0: 2065 7272 6f72 206c 6f67 222c 0a20 2020   error log",.   
+000002f0: 2020 2020 2022 5b2a 5d20 5465 7374 2064       "[*] Test d
+00000300: 6562 7567 206c 6f67 220a 2020 2020 5d2c  ebug log".    ],
+00000310: 0a20 2020 2022 6d65 7461 6461 7461 223a  .    "metadata":
+00000320: 205b 0a20 2020 2020 2020 207b 0a20 2020   [.        {.   
+00000330: 2020 2020 2020 2020 2022 7479 7065 223a           "type":
+00000340: 2022 7061 7468 222c 0a20 2020 2020 2020   "path",.       
+00000350: 2020 2020 2022 7461 6773 223a 205b 5d2c       "tags": [],
+00000360: 0a20 2020 2020 2020 2020 2020 2022 7061  .            "pa
+00000370: 7468 223a 2022 433a 5c5c 7769 6e64 6f77  th": "C:\\window
+00000380: 735c 5c74 656d 705c 5c31 5c5c 6c6f 675c  s\\temp\\1\\log\
+00000390: 5c6b 6579 6462 2e74 7874 222c 0a20 2020  \keydb.txt",.   
+000003a0: 2020 2020 2020 2020 2022 6973 5f64 6972           "is_dir
+000003b0: 223a 2066 616c 7365 2c0a 2020 2020 2020  ": false,.      
+000003c0: 2020 2020 2020 2270 6f73 6978 223a 2066        "posix": f
+000003d0: 616c 7365 2c0a 2020 2020 2020 2020 2020  alse,.          
+000003e0: 2020 2266 696c 655f 7379 7374 656d 223a    "file_system":
+000003f0: 206e 756c 6c0a 2020 2020 2020 2020 7d2c   null.        },
+00000400: 0a20 2020 2020 2020 207b 0a20 2020 2020  .        {.     
+00000410: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
+00000420: 7061 7468 222c 0a20 2020 2020 2020 2020  path",.         
+00000430: 2020 2022 7461 6773 223a 205b 5d2c 0a20     "tags": [],. 
+00000440: 2020 2020 2020 2020 2020 2022 7061 7468             "path
+00000450: 223a 2022 2541 5050 4441 5441 255c 5c66  ": "%APPDATA%\\f
+00000460: 6f6f 222c 0a20 2020 2020 2020 2020 2020  oo",.           
+00000470: 2022 6973 5f64 6972 223a 2074 7275 652c   "is_dir": true,
+00000480: 0a20 2020 2020 2020 2020 2020 2022 706f  .            "po
+00000490: 7369 7822 3a20 6661 6c73 652c 0a20 2020  six": false,.   
+000004a0: 2020 2020 2020 2020 2022 6669 6c65 5f73           "file_s
+000004b0: 7973 7465 6d22 3a20 6e75 6c6c 0a20 2020  ystem": null.   
+000004c0: 2020 2020 207d 2c0a 2020 2020 2020 2020       },.        
+000004d0: 7b0a 2020 2020 2020 2020 2020 2020 2274  {.            "t
+000004e0: 7970 6522 3a20 2270 6174 6822 2c0a 2020  ype": "path",.  
+000004f0: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
+00000500: 3a20 5b5d 2c0a 2020 2020 2020 2020 2020  : [],.          
+00000510: 2020 2270 6174 6822 3a20 2243 3a5c 5c66    "path": "C:\\f
+00000520: 6f6f 5c5c 6261 722e 7478 7422 2c0a 2020  oo\\bar.txt",.  
+00000530: 2020 2020 2020 2020 2020 2269 735f 6469            "is_di
+00000540: 7222 3a20 6661 6c73 652c 0a20 2020 2020  r": false,.     
+00000550: 2020 2020 2020 2022 706f 7369 7822 3a20         "posix": 
+00000560: 6661 6c73 652c 0a20 2020 2020 2020 2020  false,.         
+00000570: 2020 2022 6669 6c65 5f73 7973 7465 6d22     "file_system"
+00000580: 3a20 6e75 6c6c 0a20 2020 2020 2020 207d  : null.        }
+00000590: 2c0a 2020 2020 2020 2020 7b0a 2020 2020  ,.        {.    
+000005a0: 2020 2020 2020 2020 2274 7970 6522 3a20          "type": 
+000005b0: 2270 6174 6822 2c0a 2020 2020 2020 2020  "path",.        
+000005c0: 2020 2020 2274 6167 7322 3a20 5b5d 2c0a      "tags": [],.
+000005d0: 2020 2020 2020 2020 2020 2020 2270 6174              "pat
+000005e0: 6822 3a20 226d 616c 7761 7265 2e65 7865  h": "malware.exe
+000005f0: 222c 0a20 2020 2020 2020 2020 2020 2022  ",.            "
+00000600: 6973 5f64 6972 223a 2066 616c 7365 2c0a  is_dir": false,.
+00000610: 2020 2020 2020 2020 2020 2020 2270 6f73              "pos
+00000620: 6978 223a 206e 756c 6c2c 0a20 2020 2020  ix": null,.     
+00000630: 2020 2020 2020 2022 6669 6c65 5f73 7973         "file_sys
+00000640: 7465 6d22 3a20 6e75 6c6c 0a20 2020 2020  tem": null.     
+00000650: 2020 207d 2c0a 2020 2020 2020 2020 7b0a     },.        {.
+00000660: 2020 2020 2020 2020 2020 2020 2274 7970              "typ
+00000670: 6522 3a20 2261 6c70 6861 6265 7422 2c0a  e": "alphabet",.
+00000680: 2020 2020 2020 2020 2020 2020 2274 6167              "tag
+00000690: 7322 3a20 5b5d 2c0a 2020 2020 2020 2020  s": [],.        
+000006a0: 2020 2020 2261 6c70 6861 6265 7422 3a20      "alphabet": 
+000006b0: 2230 3132 3334 3536 3738 3941 4243 4445  "0123456789ABCDE
+000006c0: 4622 2c0a 2020 2020 2020 2020 2020 2020  F",.            
+000006d0: 2262 6173 6522 3a20 3136 0a20 2020 2020  "base": 16.     
+000006e0: 2020 207d 2c0a 2020 2020 2020 2020 7b0a     },.        {.
+000006f0: 2020 2020 2020 2020 2020 2020 2274 7970              "typ
+00000700: 6522 3a20 2261 6c70 6861 6265 7422 2c0a  e": "alphabet",.
+00000710: 2020 2020 2020 2020 2020 2020 2274 6167              "tag
+00000720: 7322 3a20 5b5d 2c0a 2020 2020 2020 2020  s": [],.        
+00000730: 2020 2020 2261 6c70 6861 6265 7422 3a20      "alphabet": 
+00000740: 2241 4243 4445 4647 4849 4a4b 4c4d 4e4f  "ABCDEFGHIJKLMNO
+00000750: 5051 5253 5455 5657 5859 5a32 3334 3536  PQRSTUVWXYZ23456
+00000760: 373d 222c 0a20 2020 2020 2020 2020 2020  7=",.           
+00000770: 2022 6261 7365 223a 2033 320a 2020 2020   "base": 32.    
+00000780: 2020 2020 7d2c 0a20 2020 2020 2020 207b      },.        {
+00000790: 0a20 2020 2020 2020 2020 2020 2022 7479  .            "ty
+000007a0: 7065 223a 2022 616c 7068 6162 6574 222c  pe": "alphabet",
+000007b0: 0a20 2020 2020 2020 2020 2020 2022 7461  .            "ta
+000007c0: 6773 223a 205b 5d2c 0a20 2020 2020 2020  gs": [],.       
+000007d0: 2020 2020 2022 616c 7068 6162 6574 223a       "alphabet":
+000007e0: 2022 4142 4344 4546 4748 494a 4b4c 4d4e   "ABCDEFGHIJKLMN
+000007f0: 4f50 5152 5354 5556 5758 595a 6162 6364  OPQRSTUVWXYZabcd
+00000800: 6566 6768 696a 6b6c 6d6e 6f70 7172 7374  efghijklmnopqrst
+00000810: 7576 7778 797a 3031 3233 3435 3637 3839  uvwxyz0123456789
+00000820: 2b2f 3d22 2c0a 2020 2020 2020 2020 2020  +/=",.          
+00000830: 2020 2262 6173 6522 3a20 3634 0a20 2020    "base": 64.   
+00000840: 2020 2020 207d 2c0a 2020 2020 2020 2020       },.        
+00000850: 7b0a 2020 2020 2020 2020 2020 2020 2274  {.            "t
+00000860: 7970 6522 3a20 2263 6f6d 6d61 6e64 222c  ype": "command",
+00000870: 0a20 2020 2020 2020 2020 2020 2022 7461  .            "ta
+00000880: 6773 223a 205b 5d2c 0a20 2020 2020 2020  gs": [],.       
+00000890: 2020 2020 2022 7661 6c75 6522 3a20 2263       "value": "c
+000008a0: 6d64 2e65 7865 202f 6320 6e6f 7465 7061  md.exe /c notepa
+000008b0: 642e 6578 6522 0a20 2020 2020 2020 207d  d.exe".        }
+000008c0: 2c0a 2020 2020 2020 2020 7b0a 2020 2020  ,.        {.    
+000008d0: 2020 2020 2020 2020 2274 7970 6522 3a20          "type": 
+000008e0: 2263 7265 6465 6e74 6961 6c22 2c0a 2020  "credential",.  
+000008f0: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
+00000900: 3a20 5b5d 2c0a 2020 2020 2020 2020 2020  : [],.          
+00000910: 2020 2275 7365 726e 616d 6522 3a20 2261    "username": "a
+00000920: 646d 696e 222c 0a20 2020 2020 2020 2020  dmin",.         
+00000930: 2020 2022 7061 7373 776f 7264 223a 2022     "password": "
+00000940: 3132 3334 3536 220a 2020 2020 2020 2020  123456".        
+00000950: 7d2c 0a20 2020 2020 2020 207b 0a20 2020  },.        {.   
+00000960: 2020 2020 2020 2020 2022 7479 7065 223a           "type":
+00000970: 2022 6372 6564 656e 7469 616c 222c 0a20   "credential",. 
+00000980: 2020 2020 2020 2020 2020 2022 7461 6773             "tags
+00000990: 223a 205b 5d2c 0a20 2020 2020 2020 2020  ": [],.         
+000009a0: 2020 2022 7573 6572 6e61 6d65 223a 2022     "username": "
+000009b0: 6d72 7573 6572 222c 0a20 2020 2020 2020  mruser",.       
+000009c0: 2020 2020 2022 7061 7373 776f 7264 223a       "password":
+000009d0: 206e 756c 6c0a 2020 2020 2020 2020 7d2c   null.        },
+000009e0: 0a20 2020 2020 2020 207b 0a20 2020 2020  .        {.     
+000009f0: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
+00000a00: 6372 6564 656e 7469 616c 222c 0a20 2020  credential",.   
+00000a10: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
+00000a20: 205b 5d2c 0a20 2020 2020 2020 2020 2020   [],.           
+00000a30: 2022 7573 6572 6e61 6d65 223a 206e 756c   "username": nul
+00000a40: 6c2c 0a20 2020 2020 2020 2020 2020 2022  l,.            "
+00000a50: 7061 7373 776f 7264 223a 2022 7365 6372  password": "secr
+00000a60: 6574 7322 0a20 2020 2020 2020 207d 2c0a  ets".        },.
+00000a70: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
+00000a80: 2020 2020 2020 2274 7970 6522 3a20 2263        "type": "c
+00000a90: 7279 7074 6f5f 6164 6472 6573 7322 2c0a  rypto_address",.
+00000aa0: 2020 2020 2020 2020 2020 2020 2274 6167              "tag
+00000ab0: 7322 3a20 5b5d 2c0a 2020 2020 2020 2020  s": [],.        
+00000ac0: 2020 2020 2261 6464 7265 7373 223a 2022      "address": "
+00000ad0: 3134 7156 694c 4a66 6447 6150 3445 6548  14qViLJfdGaP4EeH
+00000ae0: 6e44 794a 6245 4751 7973 6e43 7077 6b33  nDyJbEGQysnCpwk3
+00000af0: 6764 222c 0a20 2020 2020 2020 2020 2020  gd",.           
+00000b00: 2022 7379 6d62 6f6c 223a 2022 4254 4322   "symbol": "BTC"
+00000b10: 0a20 2020 2020 2020 207d 2c0a 2020 2020  .        },.    
+00000b20: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
+00000b30: 2020 2274 7970 6522 3a20 2273 6f63 6b65    "type": "socke
+00000b40: 7422 2c0a 2020 2020 2020 2020 2020 2020  t",.            
+00000b50: 2274 6167 7322 3a20 5b5d 2c0a 2020 2020  "tags": [],.    
+00000b60: 2020 2020 2020 2020 2261 6464 7265 7373          "address
+00000b70: 223a 2022 6261 642e 636f 6d22 2c0a 2020  ": "bad.com",.  
+00000b80: 2020 2020 2020 2020 2020 2270 6f72 7422            "port"
+00000b90: 3a20 3231 2c0a 2020 2020 2020 2020 2020  : 21,.          
+00000ba0: 2020 226e 6574 776f 726b 5f70 726f 746f    "network_proto
+00000bb0: 636f 6c22 3a20 2274 6370 222c 0a20 2020  col": "tcp",.   
+00000bc0: 2020 2020 2020 2020 2022 6332 223a 206e           "c2": n
+00000bd0: 756c 6c2c 0a20 2020 2020 2020 2020 2020  ull,.           
+00000be0: 2022 6c69 7374 656e 223a 206e 756c 6c0a   "listen": null.
+00000bf0: 2020 2020 2020 2020 7d2c 0a20 2020 2020          },.     
+00000c00: 2020 207b 0a20 2020 2020 2020 2020 2020     {.           
+00000c10: 2022 7479 7065 223a 2022 736f 636b 6574   "type": "socket
+00000c20: 222c 0a20 2020 2020 2020 2020 2020 2022  ",.            "
+00000c30: 7461 6773 223a 205b 5d2c 0a20 2020 2020  tags": [],.     
+00000c40: 2020 2020 2020 2022 6164 6472 6573 7322         "address"
+00000c50: 3a20 6e75 6c6c 2c0a 2020 2020 2020 2020  : null,.        
+00000c60: 2020 2020 2270 6f72 7422 3a20 3136 3335      "port": 1635
+00000c70: 2c0a 2020 2020 2020 2020 2020 2020 226e  ,.            "n
+00000c80: 6574 776f 726b 5f70 726f 746f 636f 6c22  etwork_protocol"
+00000c90: 3a20 2275 6470 222c 0a20 2020 2020 2020  : "udp",.       
+00000ca0: 2020 2020 2022 6332 223a 206e 756c 6c2c       "c2": null,
+00000cb0: 0a20 2020 2020 2020 2020 2020 2022 6c69  .            "li
+00000cc0: 7374 656e 223a 206e 756c 6c0a 2020 2020  sten": null.    
+00000cd0: 2020 2020 7d2c 0a20 2020 2020 2020 207b      },.        {
+00000ce0: 0a20 2020 2020 2020 2020 2020 2022 7479  .            "ty
+00000cf0: 7065 223a 2022 736f 636b 6574 222c 0a20  pe": "socket",. 
+00000d00: 2020 2020 2020 2020 2020 2022 7461 6773             "tags
+00000d10: 223a 205b 5d2c 0a20 2020 2020 2020 2020  ": [],.         
+00000d20: 2020 2022 6164 6472 6573 7322 3a20 6e75     "address": nu
+00000d30: 6c6c 2c0a 2020 2020 2020 2020 2020 2020  ll,.            
+00000d40: 2270 6f72 7422 3a20 3435 3638 2c0a 2020  "port": 4568,.  
+00000d50: 2020 2020 2020 2020 2020 226e 6574 776f            "netwo
+00000d60: 726b 5f70 726f 746f 636f 6c22 3a20 2274  rk_protocol": "t
+00000d70: 6370 222c 0a20 2020 2020 2020 2020 2020  cp",.           
+00000d80: 2022 6332 223a 206e 756c 6c2c 0a20 2020   "c2": null,.   
+00000d90: 2020 2020 2020 2020 2022 6c69 7374 656e           "listen
+00000da0: 223a 2074 7275 650a 2020 2020 2020 2020  ": true.        
+00000db0: 7d2c 0a20 2020 2020 2020 207b 0a20 2020  },.        {.   
+00000dc0: 2020 2020 2020 2020 2022 7479 7065 223a           "type":
+00000dd0: 2022 7572 6c22 2c0a 2020 2020 2020 2020   "url",.        
+00000de0: 2020 2020 2274 6167 7322 3a20 5b5d 2c0a      "tags": [],.
+00000df0: 2020 2020 2020 2020 2020 2020 2275 726c              "url
+00000e00: 223a 2022 6874 7470 733a 2f2f 3130 2e31  ": "https://10.1
+00000e10: 312e 3130 2e31 333a 3434 332f 696d 6167  1.10.13:443/imag
+00000e20: 6573 2f62 616e 6572 2e6a 7067 222c 0a20  es/baner.jpg",. 
+00000e30: 2020 2020 2020 2020 2020 2022 736f 636b             "sock
+00000e40: 6574 223a 207b 0a20 2020 2020 2020 2020  et": {.         
+00000e50: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
+00000e60: 736f 636b 6574 222c 0a20 2020 2020 2020  socket",.       
+00000e70: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
+00000e80: 205b 5d2c 0a20 2020 2020 2020 2020 2020   [],.           
+00000e90: 2020 2020 2022 6164 6472 6573 7322 3a20       "address": 
+00000ea0: 2231 302e 3131 2e31 302e 3133 222c 0a20  "10.11.10.13",. 
+00000eb0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00000ec0: 706f 7274 223a 2034 3433 2c0a 2020 2020  port": 443,.    
+00000ed0: 2020 2020 2020 2020 2020 2020 226e 6574              "net
+00000ee0: 776f 726b 5f70 726f 746f 636f 6c22 3a20  work_protocol": 
+00000ef0: 6e75 6c6c 2c0a 2020 2020 2020 2020 2020  null,.          
+00000f00: 2020 2020 2020 2263 3222 3a20 6e75 6c6c        "c2": null
+00000f10: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00000f20: 2020 226c 6973 7465 6e22 3a20 6e75 6c6c    "listen": null
+00000f30: 0a20 2020 2020 2020 2020 2020 207d 2c0a  .            },.
+00000f40: 2020 2020 2020 2020 2020 2020 2270 6174              "pat
+00000f50: 6822 3a20 222f 696d 6167 6573 2f62 616e  h": "/images/ban
+00000f60: 6572 2e6a 7067 222c 0a20 2020 2020 2020  er.jpg",.       
+00000f70: 2020 2020 2022 7175 6572 7922 3a20 2222       "query": ""
+00000f80: 2c0a 2020 2020 2020 2020 2020 2020 2261  ,.            "a
+00000f90: 7070 6c69 6361 7469 6f6e 5f70 726f 746f  pplication_proto
+00000fa0: 636f 6c22 3a20 2268 7474 7073 222c 0a20  col": "https",. 
+00000fb0: 2020 2020 2020 2020 2020 2022 6372 6564             "cred
+00000fc0: 656e 7469 616c 223a 206e 756c 6c0a 2020  ential": null.  
+00000fd0: 2020 2020 2020 7d2c 0a20 2020 2020 2020        },.       
+00000fe0: 207b 0a20 2020 2020 2020 2020 2020 2022   {.            "
+00000ff0: 7479 7065 223a 2022 736f 636b 6574 222c  type": "socket",
+00001000: 0a20 2020 2020 2020 2020 2020 2022 7461  .            "ta
+00001010: 6773 223a 205b 5d2c 0a20 2020 2020 2020  gs": [],.       
+00001020: 2020 2020 2022 6164 6472 6573 7322 3a20       "address": 
+00001030: 2231 302e 3131 2e31 302e 3133 222c 0a20  "10.11.10.13",. 
+00001040: 2020 2020 2020 2020 2020 2022 706f 7274             "port
+00001050: 223a 2034 3433 2c0a 2020 2020 2020 2020  ": 443,.        
+00001060: 2020 2020 226e 6574 776f 726b 5f70 726f      "network_pro
+00001070: 746f 636f 6c22 3a20 6e75 6c6c 2c0a 2020  tocol": null,.  
+00001080: 2020 2020 2020 2020 2020 2263 3222 3a20            "c2": 
+00001090: 6e75 6c6c 2c0a 2020 2020 2020 2020 2020  null,.          
+000010a0: 2020 226c 6973 7465 6e22 3a20 6e75 6c6c    "listen": null
+000010b0: 0a20 2020 2020 2020 207d 2c0a 2020 2020  .        },.    
+000010c0: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
+000010d0: 2020 2274 7970 6522 3a20 2275 726c 222c    "type": "url",
+000010e0: 0a20 2020 2020 2020 2020 2020 2022 7461  .            "ta
+000010f0: 6773 223a 205b 0a20 2020 2020 2020 2020  gs": [.         
+00001100: 2020 2020 2020 2022 7072 6f78 7922 0a20         "proxy". 
+00001110: 2020 2020 2020 2020 2020 205d 2c0a 2020             ],.  
+00001120: 2020 2020 2020 2020 2020 2275 726c 223a            "url":
+00001130: 206e 756c 6c2c 0a20 2020 2020 2020 2020   null,.         
+00001140: 2020 2022 736f 636b 6574 223a 207b 0a20     "socket": {. 
+00001150: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00001160: 7479 7065 223a 2022 736f 636b 6574 222c  type": "socket",
+00001170: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001180: 2022 7461 6773 223a 205b 5d2c 0a20 2020   "tags": [],.   
+00001190: 2020 2020 2020 2020 2020 2020 2022 6164               "ad
+000011a0: 6472 6573 7322 3a20 2231 3932 2e31 3638  dress": "192.168
+000011b0: 2e31 2e31 222c 0a20 2020 2020 2020 2020  .1.1",.         
+000011c0: 2020 2020 2020 2022 706f 7274 223a 2038         "port": 8
+000011d0: 302c 0a20 2020 2020 2020 2020 2020 2020  0,.             
+000011e0: 2020 2022 6e65 7477 6f72 6b5f 7072 6f74     "network_prot
+000011f0: 6f63 6f6c 223a 2022 7463 7022 2c0a 2020  ocol": "tcp",.  
+00001200: 2020 2020 2020 2020 2020 2020 2020 2263                "c
+00001210: 3222 3a20 6e75 6c6c 2c0a 2020 2020 2020  2": null,.      
+00001220: 2020 2020 2020 2020 2020 226c 6973 7465            "liste
+00001230: 6e22 3a20 6e75 6c6c 0a20 2020 2020 2020  n": null.       
+00001240: 2020 2020 207d 2c0a 2020 2020 2020 2020       },.        
+00001250: 2020 2020 2270 6174 6822 3a20 6e75 6c6c      "path": null
+00001260: 2c0a 2020 2020 2020 2020 2020 2020 2271  ,.            "q
+00001270: 7565 7279 223a 206e 756c 6c2c 0a20 2020  uery": null,.   
+00001280: 2020 2020 2020 2020 2022 6170 706c 6963           "applic
+00001290: 6174 696f 6e5f 7072 6f74 6f63 6f6c 223a  ation_protocol":
+000012a0: 206e 756c 6c2c 0a20 2020 2020 2020 2020   null,.         
+000012b0: 2020 2022 6372 6564 656e 7469 616c 223a     "credential":
+000012c0: 207b 0a20 2020 2020 2020 2020 2020 2020   {.             
+000012d0: 2020 2022 7479 7065 223a 2022 6372 6564     "type": "cred
+000012e0: 656e 7469 616c 222c 0a20 2020 2020 2020  ential",.       
+000012f0: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
+00001300: 205b 5d2c 0a20 2020 2020 2020 2020 2020   [],.           
+00001310: 2020 2020 2022 7573 6572 6e61 6d65 223a       "username":
+00001320: 2022 6164 6d69 6e22 2c0a 2020 2020 2020   "admin",.      
+00001330: 2020 2020 2020 2020 2020 2270 6173 7377            "passw
+00001340: 6f72 6422 3a20 2270 6173 7322 0a20 2020  ord": "pass".   
+00001350: 2020 2020 2020 2020 207d 0a20 2020 2020           }.     
+00001360: 2020 207d 2c0a 2020 2020 2020 2020 7b0a     },.        {.
+00001370: 2020 2020 2020 2020 2020 2020 2274 7970              "typ
+00001380: 6522 3a20 2273 6f63 6b65 7422 2c0a 2020  e": "socket",.  
+00001390: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
+000013a0: 3a20 5b5d 2c0a 2020 2020 2020 2020 2020  : [],.          
+000013b0: 2020 2261 6464 7265 7373 223a 2022 3139    "address": "19
+000013c0: 322e 3136 382e 312e 3122 2c0a 2020 2020  2.168.1.1",.    
+000013d0: 2020 2020 2020 2020 2270 6f72 7422 3a20          "port": 
+000013e0: 3830 2c0a 2020 2020 2020 2020 2020 2020  80,.            
+000013f0: 226e 6574 776f 726b 5f70 726f 746f 636f  "network_protoco
+00001400: 6c22 3a20 2274 6370 222c 0a20 2020 2020  l": "tcp",.     
+00001410: 2020 2020 2020 2022 6332 223a 206e 756c         "c2": nul
+00001420: 6c2c 0a20 2020 2020 2020 2020 2020 2022  l,.            "
+00001430: 6c69 7374 656e 223a 206e 756c 6c0a 2020  listen": null.  
+00001440: 2020 2020 2020 7d2c 0a20 2020 2020 2020        },.       
+00001450: 207b 0a20 2020 2020 2020 2020 2020 2022   {.            "
+00001460: 7479 7065 223a 2022 6372 6564 656e 7469  type": "credenti
+00001470: 616c 222c 0a20 2020 2020 2020 2020 2020  al",.           
+00001480: 2022 7461 6773 223a 205b 5d2c 0a20 2020   "tags": [],.   
+00001490: 2020 2020 2020 2020 2022 7573 6572 6e61           "userna
+000014a0: 6d65 223a 2022 6164 6d69 6e22 2c0a 2020  me": "admin",.  
+000014b0: 2020 2020 2020 2020 2020 2270 6173 7377            "passw
+000014c0: 6f72 6422 3a20 2270 6173 7322 0a20 2020  ord": "pass".   
+000014d0: 2020 2020 207d 2c0a 2020 2020 2020 2020       },.        
+000014e0: 7b0a 2020 2020 2020 2020 2020 2020 2274  {.            "t
+000014f0: 7970 6522 3a20 2275 726c 222c 0a20 2020  ype": "url",.   
+00001500: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
+00001510: 205b 5d2c 0a20 2020 2020 2020 2020 2020   [],.           
+00001520: 2022 7572 6c22 3a20 2266 7470 3a2f 2f62   "url": "ftp://b
+00001530: 6164 686f 7374 2e63 6f6d 3a32 3122 2c0a  adhost.com:21",.
+00001540: 2020 2020 2020 2020 2020 2020 2273 6f63              "soc
+00001550: 6b65 7422 3a20 7b0a 2020 2020 2020 2020  ket": {.        
+00001560: 2020 2020 2020 2020 2274 7970 6522 3a20          "type": 
+00001570: 2273 6f63 6b65 7422 2c0a 2020 2020 2020  "socket",.      
+00001580: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
+00001590: 3a20 5b5d 2c0a 2020 2020 2020 2020 2020  : [],.          
+000015a0: 2020 2020 2020 2261 6464 7265 7373 223a        "address":
+000015b0: 2022 6261 6468 6f73 742e 636f 6d22 2c0a   "badhost.com",.
+000015c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000015d0: 2270 6f72 7422 3a20 3231 2c0a 2020 2020  "port": 21,.    
+000015e0: 2020 2020 2020 2020 2020 2020 226e 6574              "net
+000015f0: 776f 726b 5f70 726f 746f 636f 6c22 3a20  work_protocol": 
+00001600: 6e75 6c6c 2c0a 2020 2020 2020 2020 2020  null,.          
+00001610: 2020 2020 2020 2263 3222 3a20 6e75 6c6c        "c2": null
+00001620: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00001630: 2020 226c 6973 7465 6e22 3a20 6e75 6c6c    "listen": null
+00001640: 0a20 2020 2020 2020 2020 2020 207d 2c0a  .            },.
+00001650: 2020 2020 2020 2020 2020 2020 2270 6174              "pat
+00001660: 6822 3a20 6e75 6c6c 2c0a 2020 2020 2020  h": null,.      
+00001670: 2020 2020 2020 2271 7565 7279 223a 2022        "query": "
+00001680: 222c 0a20 2020 2020 2020 2020 2020 2022  ",.            "
+00001690: 6170 706c 6963 6174 696f 6e5f 7072 6f74  application_prot
+000016a0: 6f63 6f6c 223a 2022 6674 7022 2c0a 2020  ocol": "ftp",.  
+000016b0: 2020 2020 2020 2020 2020 2263 7265 6465            "crede
+000016c0: 6e74 6961 6c22 3a20 7b0a 2020 2020 2020  ntial": {.      
+000016d0: 2020 2020 2020 2020 2020 2274 7970 6522            "type"
+000016e0: 3a20 2263 7265 6465 6e74 6961 6c22 2c0a  : "credential",.
+000016f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001700: 2274 6167 7322 3a20 5b5d 2c0a 2020 2020  "tags": [],.    
+00001710: 2020 2020 2020 2020 2020 2020 2275 7365              "use
+00001720: 726e 616d 6522 3a20 2261 646d 696e 222c  rname": "admin",
+00001730: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001740: 2022 7061 7373 776f 7264 223a 2022 7061   "password": "pa
+00001750: 7373 220a 2020 2020 2020 2020 2020 2020  ss".            
+00001760: 7d0a 2020 2020 2020 2020 7d2c 0a20 2020  }.        },.   
+00001770: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
+00001780: 2020 2022 7479 7065 223a 2022 736f 636b     "type": "sock
+00001790: 6574 222c 0a20 2020 2020 2020 2020 2020  et",.           
+000017a0: 2022 7461 6773 223a 205b 5d2c 0a20 2020   "tags": [],.   
+000017b0: 2020 2020 2020 2020 2022 6164 6472 6573           "addres
+000017c0: 7322 3a20 2262 6164 686f 7374 2e63 6f6d  s": "badhost.com
+000017d0: 222c 0a20 2020 2020 2020 2020 2020 2022  ",.            "
+000017e0: 706f 7274 223a 2032 312c 0a20 2020 2020  port": 21,.     
+000017f0: 2020 2020 2020 2022 6e65 7477 6f72 6b5f         "network_
+00001800: 7072 6f74 6f63 6f6c 223a 206e 756c 6c2c  protocol": null,
+00001810: 0a20 2020 2020 2020 2020 2020 2022 6332  .            "c2
+00001820: 223a 206e 756c 6c2c 0a20 2020 2020 2020  ": null,.       
+00001830: 2020 2020 2022 6c69 7374 656e 223a 206e       "listen": n
+00001840: 756c 6c0a 2020 2020 2020 2020 7d2c 0a20  ull.        },. 
+00001850: 2020 2020 2020 207b 0a20 2020 2020 2020         {.       
+00001860: 2020 2020 2022 7479 7065 223a 2022 656d       "type": "em
+00001870: 6169 6c5f 6164 6472 6573 7322 2c0a 2020  ail_address",.  
+00001880: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
+00001890: 3a20 5b5d 2c0a 2020 2020 2020 2020 2020  : [],.          
+000018a0: 2020 2276 616c 7565 223a 2022 656d 6169    "value": "emai
+000018b0: 6c40 6261 642e 636f 6d22 0a20 2020 2020  l@bad.com".     
+000018c0: 2020 207d 2c0a 2020 2020 2020 2020 7b0a     },.        {.
+000018d0: 2020 2020 2020 2020 2020 2020 2274 7970              "typ
+000018e0: 6522 3a20 2265 7665 6e74 222c 0a20 2020  e": "event",.   
+000018f0: 2020 2020 2020 2020 2022 7461 6773 223a           "tags":
+00001900: 205b 5d2c 0a20 2020 2020 2020 2020 2020   [],.           
+00001910: 2022 7661 6c75 6522 3a20 224d 6963 726f   "value": "Micro
+00001920: 736f 6674 4578 6973 7422 0a20 2020 2020  softExist".     
+00001930: 2020 207d 2c0a 2020 2020 2020 2020 7b0a     },.        {.
+00001940: 2020 2020 2020 2020 2020 2020 2274 7970              "typ
+00001950: 6522 3a20 2275 7569 6422 2c0a 2020 2020  e": "uuid",.    
+00001960: 2020 2020 2020 2020 2274 6167 7322 3a20          "tags": 
+00001970: 5b5d 2c0a 2020 2020 2020 2020 2020 2020  [],.            
+00001980: 2276 616c 7565 223a 2022 3635 3465 3563  "value": "654e5c
+00001990: 6666 2d38 3137 632d 3465 3364 2d38 6230  ff-817c-4e3d-8b0
+000019a0: 312d 3437 6136 6634 3561 6530 3961 220a  1-47a6f45ae09a".
+000019b0: 2020 2020 2020 2020 7d2c 0a20 2020 2020          },.     
+000019c0: 2020 207b 0a20 2020 2020 2020 2020 2020     {.           
+000019d0: 2022 7479 7065 223a 2022 696e 6a65 6374   "type": "inject
+000019e0: 696f 6e5f 7072 6f63 6573 7322 2c0a 2020  ion_process",.  
+000019f0: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
+00001a00: 3a20 5b5d 2c0a 2020 2020 2020 2020 2020  : [],.          
+00001a10: 2020 2276 616c 7565 223a 2022 7376 6368    "value": "svch
+00001a20: 6f73 7422 0a20 2020 2020 2020 207d 2c0a  ost".        },.
+00001a30: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
+00001a40: 2020 2020 2020 2274 7970 6522 3a20 2269        "type": "i
+00001a50: 6e74 6572 7661 6c22 2c0a 2020 2020 2020  nterval",.      
+00001a60: 2020 2020 2020 2274 6167 7322 3a20 5b5d        "tags": []
+00001a70: 2c0a 2020 2020 2020 2020 2020 2020 2276  ,.            "v
+00001a80: 616c 7565 223a 2033 2e30 0a20 2020 2020  alue": 3.0.     
+00001a90: 2020 207d 2c0a 2020 2020 2020 2020 7b0a     },.        {.
+00001aa0: 2020 2020 2020 2020 2020 2020 2274 7970              "typ
+00001ab0: 6522 3a20 2265 6e63 7279 7074 696f 6e5f  e": "encryption_
+00001ac0: 6b65 7922 2c0a 2020 2020 2020 2020 2020  key",.          
+00001ad0: 2020 2274 6167 7322 3a20 5b5d 2c0a 2020    "tags": [],.  
+00001ae0: 2020 2020 2020 2020 2020 226b 6579 223a            "key":
+00001af0: 2022 6147 5673 6247 383d 222c 0a20 2020   "aGVsbG8=",.   
+00001b00: 2020 2020 2020 2020 2022 616c 676f 7269           "algori
+00001b10: 7468 6d22 3a20 2272 6334 222c 0a20 2020  thm": "rc4",.   
+00001b20: 2020 2020 2020 2020 2022 6d6f 6465 223a           "mode":
+00001b30: 206e 756c 6c2c 0a20 2020 2020 2020 2020   null,.         
+00001b40: 2020 2022 6976 223a 206e 756c 6c0a 2020     "iv": null.  
+00001b50: 2020 2020 2020 7d2c 0a20 2020 2020 2020        },.       
+00001b60: 207b 0a20 2020 2020 2020 2020 2020 2022   {.            "
+00001b70: 7479 7065 223a 2022 656e 6372 7970 7469  type": "encrypti
+00001b80: 6f6e 5f6b 6579 222c 0a20 2020 2020 2020  on_key",.       
+00001b90: 2020 2020 2022 7461 6773 223a 205b 5d2c       "tags": [],
+00001ba0: 0a20 2020 2020 2020 2020 2020 2022 6b65  .            "ke
+00001bb0: 7922 3a20 222f 2f2f 2f2f 773d 3d22 2c0a  y": "/////w==",.
+00001bc0: 2020 2020 2020 2020 2020 2020 2261 6c67              "alg
+00001bd0: 6f72 6974 686d 223a 2022 6165 7322 2c0a  orithm": "aes",.
+00001be0: 2020 2020 2020 2020 2020 2020 226d 6f64              "mod
+00001bf0: 6522 3a20 2265 6362 222c 0a20 2020 2020  e": "ecb",.     
+00001c00: 2020 2020 2020 2022 6976 223a 2022 4141         "iv": "AA
+00001c10: 4141 4141 3d3d 220a 2020 2020 2020 2020  AAAA==".        
+00001c20: 7d2c 0a20 2020 2020 2020 207b 0a20 2020  },.        {.   
+00001c30: 2020 2020 2020 2020 2022 7479 7065 223a           "type":
+00001c40: 2022 6465 636f 6465 645f 7374 7269 6e67   "decoded_string
+00001c50: 222c 0a20 2020 2020 2020 2020 2020 2022  ",.            "
+00001c60: 7461 6773 223a 205b 5d2c 0a20 2020 2020  tags": [],.     
+00001c70: 2020 2020 2020 2022 7661 6c75 6522 3a20         "value": 
+00001c80: 2247 6574 5072 6f63 6573 7322 2c0a 2020  "GetProcess",.  
+00001c90: 2020 2020 2020 2020 2020 2265 6e63 7279            "encry
+00001ca0: 7074 696f 6e5f 6b65 7922 3a20 6e75 6c6c  ption_key": null
+00001cb0: 0a20 2020 2020 2020 207d 2c0a 2020 2020  .        },.    
+00001cc0: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
+00001cd0: 2020 2274 7970 6522 3a20 2264 6563 6f64    "type": "decod
+00001ce0: 6564 5f73 7472 696e 6722 2c0a 2020 2020  ed_string",.    
+00001cf0: 2020 2020 2020 2020 2274 6167 7322 3a20          "tags": 
+00001d00: 5b5d 2c0a 2020 2020 2020 2020 2020 2020  [],.            
+00001d10: 2276 616c 7565 223a 2022 6261 6473 7472  "value": "badstr
+00001d20: 696e 6722 2c0a 2020 2020 2020 2020 2020  ing",.          
+00001d30: 2020 2265 6e63 7279 7074 696f 6e5f 6b65    "encryption_ke
+00001d40: 7922 3a20 7b0a 2020 2020 2020 2020 2020  y": {.          
+00001d50: 2020 2020 2020 2274 7970 6522 3a20 2265        "type": "e
+00001d60: 6e63 7279 7074 696f 6e5f 6b65 7922 2c0a  ncryption_key",.
+00001d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001d80: 2274 6167 7322 3a20 5b5d 2c0a 2020 2020  "tags": [],.    
+00001d90: 2020 2020 2020 2020 2020 2020 226b 6579              "key
+00001da0: 223a 2022 2f2f 383d 222c 0a20 2020 2020  ": "//8=",.     
+00001db0: 2020 2020 2020 2020 2020 2022 616c 676f             "algo
+00001dc0: 7269 7468 6d22 3a20 2278 6f72 222c 0a20  rithm": "xor",. 
+00001dd0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00001de0: 6d6f 6465 223a 206e 756c 6c2c 0a20 2020  mode": null,.   
+00001df0: 2020 2020 2020 2020 2020 2020 2022 6976               "iv
+00001e00: 223a 206e 756c 6c0a 2020 2020 2020 2020  ": null.        
+00001e10: 2020 2020 7d0a 2020 2020 2020 2020 7d2c      }.        },
+00001e20: 0a20 2020 2020 2020 207b 0a20 2020 2020  .        {.     
+00001e30: 2020 2020 2020 2022 7479 7065 223a 2022         "type": "
+00001e40: 656e 6372 7970 7469 6f6e 5f6b 6579 222c  encryption_key",
+00001e50: 0a20 2020 2020 2020 2020 2020 2022 7461  .            "ta
+00001e60: 6773 223a 205b 5d2c 0a20 2020 2020 2020  gs": [],.       
+00001e70: 2020 2020 2022 6b65 7922 3a20 222f 2f38       "key": "//8
+00001e80: 3d22 2c0a 2020 2020 2020 2020 2020 2020  =",.            
+00001e90: 2261 6c67 6f72 6974 686d 223a 2022 786f  "algorithm": "xo
+00001ea0: 7222 2c0a 2020 2020 2020 2020 2020 2020  r",.            
+00001eb0: 226d 6f64 6522 3a20 6e75 6c6c 2c0a 2020  "mode": null,.  
+00001ec0: 2020 2020 2020 2020 2020 2269 7622 3a20            "iv": 
+00001ed0: 6e75 6c6c 0a20 2020 2020 2020 207d 2c0a  null.        },.
+00001ee0: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
+00001ef0: 2020 2020 2020 2274 7970 6522 3a20 226d        "type": "m
+00001f00: 6973 7369 6f6e 5f69 6422 2c0a 2020 2020  ission_id",.    
+00001f10: 2020 2020 2020 2020 2274 6167 7322 3a20          "tags": 
+00001f20: 5b5d 2c0a 2020 2020 2020 2020 2020 2020  [],.            
+00001f30: 2276 616c 7565 223a 2022 7461 7267 6574  "value": "target
+00001f40: 3422 0a20 2020 2020 2020 207d 2c0a 2020  4".        },.  
+00001f50: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+00001f60: 2020 2020 2274 7970 6522 3a20 226d 7574      "type": "mut
+00001f70: 6578 222c 0a20 2020 2020 2020 2020 2020  ex",.           
+00001f80: 2022 7461 6773 223a 205b 5d2c 0a20 2020   "tags": [],.   
+00001f90: 2020 2020 2020 2020 2022 7661 6c75 6522           "value"
+00001fa0: 3a20 2269 7468 696e 6b69 6d61 6c6f 6e65  : "ithinkimalone
+00001fb0: 6e6f 7722 0a20 2020 2020 2020 207d 2c0a  now".        },.
+00001fc0: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
+00001fd0: 2020 2020 2020 2274 7970 6522 3a20 226f        "type": "o
+00001fe0: 7468 6572 222c 0a20 2020 2020 2020 2020  ther",.         
+00001ff0: 2020 2022 7461 6773 223a 205b 0a20 2020     "tags": [.   
+00002000: 2020 2020 2020 2020 2020 2020 2022 736f               "so
+00002010: 6d65 7468 696e 6722 0a20 2020 2020 2020  mething".       
+00002020: 2020 2020 205d 2c0a 2020 2020 2020 2020       ],.        
+00002030: 2020 2020 226b 6579 223a 2022 6d69 7363      "key": "misc
+00002040: 5f69 6e66 6f22 2c0a 2020 2020 2020 2020  _info",.        
+00002050: 2020 2020 2276 616c 7565 223a 2022 736f      "value": "so
+00002060: 6d65 206d 6973 6365 6c6c 616e 656f 7573  me miscellaneous
+00002070: 2069 6e66 6f22 2c0a 2020 2020 2020 2020   info",.        
+00002080: 2020 2020 2276 616c 7565 5f66 6f72 6d61      "value_forma
+00002090: 7422 3a20 2273 7472 696e 6722 0a20 2020  t": "string".   
+000020a0: 2020 2020 207d 2c0a 2020 2020 2020 2020       },.        
+000020b0: 7b0a 2020 2020 2020 2020 2020 2020 2274  {.            "t
+000020c0: 7970 6522 3a20 226f 7468 6572 222c 0a20  ype": "other",. 
+000020d0: 2020 2020 2020 2020 2020 2022 7461 6773             "tags
+000020e0: 223a 205b 5d2c 0a20 2020 2020 2020 2020  ": [],.         
+000020f0: 2020 2022 6b65 7922 3a20 2272 616e 646f     "key": "rando
+00002100: 6d5f 6461 7461 222c 0a20 2020 2020 2020  m_data",.       
+00002110: 2020 2020 2022 7661 6c75 6522 3a20 2233       "value": "3
+00002120: 7132 2b37 773d 3d22 2c0a 2020 2020 2020  q2+7w==",.      
+00002130: 2020 2020 2020 2276 616c 7565 5f66 6f72        "value_for
+00002140: 6d61 7422 3a20 2262 7974 6573 220a 2020  mat": "bytes".  
+00002150: 2020 2020 2020 7d2c 0a20 2020 2020 2020        },.       
+00002160: 207b 0a20 2020 2020 2020 2020 2020 2022   {.            "
+00002170: 7479 7065 223a 2022 6f74 6865 7222 2c0a  type": "other",.
+00002180: 2020 2020 2020 2020 2020 2020 2274 6167              "tag
+00002190: 7322 3a20 5b5d 2c0a 2020 2020 2020 2020  s": [],.        
+000021a0: 2020 2020 226b 6579 223a 2022 6b65 796c      "key": "keyl
+000021b0: 6f67 6765 7222 2c0a 2020 2020 2020 2020  ogger",.        
+000021c0: 2020 2020 2276 616c 7565 223a 2074 7275      "value": tru
+000021d0: 652c 0a20 2020 2020 2020 2020 2020 2022  e,.            "
+000021e0: 7661 6c75 655f 666f 726d 6174 223a 2022  value_format": "
+000021f0: 626f 6f6c 6561 6e22 0a20 2020 2020 2020  boolean".       
+00002200: 207d 2c0a 2020 2020 2020 2020 7b0a 2020   },.        {.  
+00002210: 2020 2020 2020 2020 2020 2274 7970 6522            "type"
+00002220: 3a20 226f 7468 6572 222c 0a20 2020 2020  : "other",.     
+00002230: 2020 2020 2020 2022 7461 6773 223a 205b         "tags": [
+00002240: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002250: 2022 7461 6731 220a 2020 2020 2020 2020   "tag1".        
+00002260: 2020 2020 5d2c 0a20 2020 2020 2020 2020      ],.         
+00002270: 2020 2022 6b65 7922 3a20 226d 6973 635f     "key": "misc_
+00002280: 696e 7465 6765 7222 2c0a 2020 2020 2020  integer",.      
+00002290: 2020 2020 2020 2276 616c 7565 223a 2034        "value": 4
+000022a0: 3332 2c0a 2020 2020 2020 2020 2020 2020  32,.            
+000022b0: 2276 616c 7565 5f66 6f72 6d61 7422 3a20  "value_format": 
+000022c0: 2269 6e74 6567 6572 220a 2020 2020 2020  "integer".      
+000022d0: 2020 7d2c 0a20 2020 2020 2020 207b 0a20    },.        {. 
+000022e0: 2020 2020 2020 2020 2020 2022 7479 7065             "type
+000022f0: 223a 2022 7069 7065 222c 0a20 2020 2020  ": "pipe",.     
+00002300: 2020 2020 2020 2022 7461 6773 223a 205b         "tags": [
+00002310: 5d2c 0a20 2020 2020 2020 2020 2020 2022  ],.            "
+00002320: 7661 6c75 6522 3a20 225c 5c2e 5c5c 7069  value": "\\.\\pi
+00002330: 7065 5c5c 6e61 6d65 6470 6970 6522 0a20  pe\\namedpipe". 
+00002340: 2020 2020 2020 207d 2c0a 2020 2020 2020         },.      
+00002350: 2020 7b0a 2020 2020 2020 2020 2020 2020    {.            
+00002360: 2274 7970 6522 3a20 2272 6567 6973 7472  "type": "registr
+00002370: 7922 2c0a 2020 2020 2020 2020 2020 2020  y",.            
+00002380: 2274 6167 7322 3a20 5b5d 2c0a 2020 2020  "tags": [],.    
+00002390: 2020 2020 2020 2020 2268 6976 6522 3a20          "hive": 
+000023a0: 2248 4b45 595f 4c4f 4341 4c5f 4d41 4348  "HKEY_LOCAL_MACH
+000023b0: 494e 4522 2c0a 2020 2020 2020 2020 2020  INE",.          
+000023c0: 2020 2273 7562 6b65 7922 3a20 2253 6f66    "subkey": "Sof
+000023d0: 7477 6172 655c 5c4d 6963 726f 736f 6674  tware\\Microsoft
+000023e0: 5c5c 5769 6e64 6f77 735c 5c43 7572 7265  \\Windows\\Curre
+000023f0: 6e74 5665 7273 696f 6e5c 5c52 756e 222c  ntVersion\\Run",
+00002400: 0a20 2020 2020 2020 2020 2020 2022 7661  .            "va
+00002410: 6c75 6522 3a20 2255 7064 6174 6572 222c  lue": "Updater",
+00002420: 0a20 2020 2020 2020 2020 2020 2022 6461  .            "da
+00002430: 7461 223a 2022 633a 5c5c 7570 6461 7465  ta": "c:\\update
+00002440: 2e65 7865 222c 0a20 2020 2020 2020 2020  .exe",.         
+00002450: 2020 2022 6461 7461 5f74 7970 6522 3a20     "data_type": 
+00002460: 2252 4547 5f53 5a22 0a20 2020 2020 2020  "REG_SZ".       
+00002470: 207d 2c0a 2020 2020 2020 2020 7b0a 2020   },.        {.  
+00002480: 2020 2020 2020 2020 2020 2274 7970 6522            "type"
+00002490: 3a20 2272 6567 6973 7472 7922 2c0a 2020  : "registry",.  
+000024a0: 2020 2020 2020 2020 2020 2274 6167 7322            "tags"
+000024b0: 3a20 5b5d 2c0a 2020 2020 2020 2020 2020  : [],.          
+000024c0: 2020 2268 6976 6522 3a20 2248 4b45 595f    "hive": "HKEY_
+000024d0: 4c4f 4341 4c5f 4d41 4348 494e 4522 2c0a  LOCAL_MACHINE",.
+000024e0: 2020 2020 2020 2020 2020 2020 2273 7562              "sub
+000024f0: 6b65 7922 3a20 2246 6f6f 5c5c 4261 7222  key": "Foo\\Bar"
+00002500: 2c0a 2020 2020 2020 2020 2020 2020 2276  ,.            "v
+00002510: 616c 7565 223a 206e 756c 6c2c 0a20 2020  alue": null,.   
+00002520: 2020 2020 2020 2020 2022 6461 7461 223a           "data":
+00002530: 206e 756c 6c2c 0a20 2020 2020 2020 2020   null,.         
+00002540: 2020 2022 6461 7461 5f74 7970 6522 3a20     "data_type": 
+00002550: 6e75 6c6c 0a20 2020 2020 2020 207d 2c0a  null.        },.
+00002560: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
+00002570: 2020 2020 2020 2274 7970 6522 3a20 2272        "type": "r
+00002580: 6567 6973 7472 7922 2c0a 2020 2020 2020  egistry",.      
+00002590: 2020 2020 2020 2274 6167 7322 3a20 5b0a        "tags": [.
+000025a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000025b0: 2274 6167 3222 0a20 2020 2020 2020 2020  "tag2".         
+000025c0: 2020 205d 2c0a 2020 2020 2020 2020 2020     ],.          
+000025d0: 2020 2268 6976 6522 3a20 6e75 6c6c 2c0a    "hive": null,.
+000025e0: 2020 2020 2020 2020 2020 2020 2273 7562              "sub
+000025f0: 6b65 7922 3a20 6e75 6c6c 2c0a 2020 2020  key": null,.    
+00002600: 2020 2020 2020 2020 2276 616c 7565 223a          "value":
+00002610: 2022 4261 7a22 2c0a 2020 2020 2020 2020   "Baz",.        
+00002620: 2020 2020 2264 6174 6122 3a20 6e75 6c6c      "data": null
+00002630: 2c0a 2020 2020 2020 2020 2020 2020 2264  ,.            "d
+00002640: 6174 615f 7479 7065 223a 206e 756c 6c0a  ata_type": null.
+00002650: 2020 2020 2020 2020 7d2c 0a20 2020 2020          },.     
+00002660: 2020 207b 0a20 2020 2020 2020 2020 2020     {.           
+00002670: 2022 7479 7065 223a 2022 7273 615f 7072   "type": "rsa_pr
+00002680: 6976 6174 655f 6b65 7922 2c0a 2020 2020  ivate_key",.    
+00002690: 2020 2020 2020 2020 2274 6167 7322 3a20          "tags": 
+000026a0: 5b5d 2c0a 2020 2020 2020 2020 2020 2020  [],.            
+000026b0: 2270 7562 6c69 635f 6578 706f 6e65 6e74  "public_exponent
+000026c0: 223a 2037 2c0a 2020 2020 2020 2020 2020  ": 7,.          
+000026d0: 2020 226d 6f64 756c 7573 223a 2031 3837    "modulus": 187
+000026e0: 2c0a 2020 2020 2020 2020 2020 2020 2270  ,.            "p
+000026f0: 7269 7661 7465 5f65 7870 6f6e 656e 7422  rivate_exponent"
+00002700: 3a20 3233 2c0a 2020 2020 2020 2020 2020  : 23,.          
+00002710: 2020 2270 223a 2031 372c 0a20 2020 2020    "p": 17,.     
+00002720: 2020 2020 2020 2022 7122 3a20 3131 2c0a         "q": 11,.
+00002730: 2020 2020 2020 2020 2020 2020 2264 5f6d              "d_m
+00002740: 6f64 5f70 3122 3a20 372c 0a20 2020 2020  od_p1": 7,.     
+00002750: 2020 2020 2020 2022 645f 6d6f 645f 7131         "d_mod_q1
+00002760: 223a 2033 2c0a 2020 2020 2020 2020 2020  ": 3,.          
+00002770: 2020 2271 5f69 6e76 5f6d 6f64 5f70 223a    "q_inv_mod_p":
+00002780: 2031 340a 2020 2020 2020 2020 7d2c 0a20   14.        },. 
+00002790: 2020 2020 2020 207b 0a20 2020 2020 2020         {.       
+000027a0: 2020 2020 2022 7479 7065 223a 2022 7273       "type": "rs
+000027b0: 615f 7075 626c 6963 5f6b 6579 222c 0a20  a_public_key",. 
+000027c0: 2020 2020 2020 2020 2020 2022 7461 6773             "tags
+000027d0: 223a 205b 5d2c 0a20 2020 2020 2020 2020  ": [],.         
+000027e0: 2020 2022 7075 626c 6963 5f65 7870 6f6e     "public_expon
+000027f0: 656e 7422 3a20 372c 0a20 2020 2020 2020  ent": 7,.       
+00002800: 2020 2020 2022 6d6f 6475 6c75 7322 3a20       "modulus": 
+00002810: 3138 370a 2020 2020 2020 2020 7d2c 0a20  187.        },. 
+00002820: 2020 2020 2020 207b 0a20 2020 2020 2020         {.       
+00002830: 2020 2020 2022 7479 7065 223a 2022 7365       "type": "se
+00002840: 7276 6963 6522 2c0a 2020 2020 2020 2020  rvice",.        
+00002850: 2020 2020 2274 6167 7322 3a20 5b5d 2c0a      "tags": [],.
+00002860: 2020 2020 2020 2020 2020 2020 226e 616d              "nam
+00002870: 6522 3a20 2257 696e 646f 7773 5573 6572  e": "WindowsUser
+00002880: 4d61 6e61 6765 6d65 6e74 222c 0a20 2020  Management",.   
+00002890: 2020 2020 2020 2020 2022 6469 7370 6c61           "displa
+000028a0: 795f 6e61 6d65 223a 2022 5769 6e64 6f77  y_name": "Window
+000028b0: 7320 5573 6572 204d 616e 6167 656d 656e  s User Managemen
+000028c0: 7422 2c0a 2020 2020 2020 2020 2020 2020  t",.            
+000028d0: 2264 6573 6372 6970 7469 6f6e 223a 2022  "description": "
+000028e0: 5072 6f76 6964 6573 2061 2063 6f6d 6d6f  Provides a commo
+000028f0: 6e20 6d61 6e61 6765 6d65 6e74 2074 6f20  n management to 
+00002900: 6163 6365 7373 2069 6e66 6f72 6d61 7469  access informati
+00002910: 6f6e 2061 626f 7574 2077 696e 646f 7773  on about windows
+00002920: 2075 7365 722e 222c 0a20 2020 2020 2020   user.",.       
+00002930: 2020 2020 2022 696d 6167 6522 3a20 2225       "image": "%
+00002940: 5379 7374 656d 255c 5c73 766f 686f 7374  System%\\svohost
+00002950: 2e65 7865 222c 0a20 2020 2020 2020 2020  .exe",.         
+00002960: 2020 2022 646c 6c22 3a20 6e75 6c6c 0a20     "dll": null. 
+00002970: 2020 2020 2020 207d 2c0a 2020 2020 2020         },.      
+00002980: 2020 7b0a 2020 2020 2020 2020 2020 2020    {.            
+00002990: 2274 7970 6522 3a20 2270 6174 6822 2c0a  "type": "path",.
+000029a0: 2020 2020 2020 2020 2020 2020 2274 6167              "tag
+000029b0: 7322 3a20 5b5d 2c0a 2020 2020 2020 2020  s": [],.        
+000029c0: 2020 2020 2270 6174 6822 3a20 2225 5379      "path": "%Sy
+000029d0: 7374 656d 255c 5c73 766f 686f 7374 2e65  stem%\\svohost.e
+000029e0: 7865 222c 0a20 2020 2020 2020 2020 2020  xe",.           
+000029f0: 2022 6973 5f64 6972 223a 2066 616c 7365   "is_dir": false
+00002a00: 2c0a 2020 2020 2020 2020 2020 2020 2270  ,.            "p
+00002a10: 6f73 6978 223a 2066 616c 7365 2c0a 2020  osix": false,.  
+00002a20: 2020 2020 2020 2020 2020 2266 696c 655f            "file_
+00002a30: 7379 7374 656d 223a 206e 756c 6c0a 2020  system": null.  
+00002a40: 2020 2020 2020 7d2c 0a20 2020 2020 2020        },.       
+00002a50: 207b 0a20 2020 2020 2020 2020 2020 2022   {.            "
+00002a60: 7479 7065 223a 2022 7573 6572 5f61 6765  type": "user_age
+00002a70: 6e74 222c 0a20 2020 2020 2020 2020 2020  nt",.           
+00002a80: 2022 7461 6773 223a 205b 5d2c 0a20 2020   "tags": [],.   
+00002a90: 2020 2020 2020 2020 2022 7661 6c75 6522           "value"
+00002aa0: 3a20 224d 6f7a 696c 6c61 2f34 2e30 2028  : "Mozilla/4.0 (
+00002ab0: 636f 6d70 6174 6962 6c65 3b20 4d49 5345  compatible; MISE
+00002ac0: 2036 2e30 3b20 5769 6e64 6f77 7320 4e54   6.0; Windows NT
+00002ad0: 2035 2e32 2922 0a20 2020 2020 2020 207d   5.2)".        }
+00002ae0: 2c0a 2020 2020 2020 2020 7b0a 2020 2020  ,.        {.    
+00002af0: 2020 2020 2020 2020 2274 7970 6522 3a20          "type": 
+00002b00: 2276 6572 7369 6f6e 222c 0a20 2020 2020  "version",.     
+00002b10: 2020 2020 2020 2022 7461 6773 223a 205b         "tags": [
+00002b20: 5d2c 0a20 2020 2020 2020 2020 2020 2022  ],.            "
+00002b30: 7661 6c75 6522 3a20 2233 2e31 220a 2020  value": "3.1".  
+00002b40: 2020 2020 2020 7d2c 0a20 2020 2020 2020        },.       
+00002b50: 207b 0a20 2020 2020 2020 2020 2020 2022   {.            "
+00002b60: 7479 7065 223a 2022 7665 7273 696f 6e22  type": "version"
+00002b70: 2c0a 2020 2020 2020 2020 2020 2020 2274  ,.            "t
+00002b80: 6167 7322 3a20 5b5d 2c0a 2020 2020 2020  ags": [],.      
+00002b90: 2020 2020 2020 2276 616c 7565 223a 2022        "value": "
+00002ba0: 3430 332e 3130 220a 2020 2020 2020 2020  403.10".        
+00002bb0: 7d2c 0a20 2020 2020 2020 207b 0a20 2020  },.        {.   
+00002bc0: 2020 2020 2020 2020 2022 7479 7065 223a           "type":
+00002bd0: 2022 6669 6c65 222c 0a20 2020 2020 2020   "file",.       
+00002be0: 2020 2020 2022 7461 6773 223a 205b 5d2c       "tags": [],
+00002bf0: 0a20 2020 2020 2020 2020 2020 2022 6e61  .            "na
+00002c00: 6d65 223a 2022 636f 6e66 6967 2e78 6d6c  me": "config.xml
+00002c10: 222c 0a20 2020 2020 2020 2020 2020 2022  ",.            "
+00002c20: 6465 7363 7269 7074 696f 6e22 3a20 2245  description": "E
+00002c30: 7874 7261 6374 6564 2062 6163 6b64 6f6f  xtracted backdoo
+00002c40: 7220 466f 6f20 636f 6e66 6967 2066 696c  r Foo config fil
+00002c50: 6522 2c0a 2020 2020 2020 2020 2020 2020  e",.            
+00002c60: 226d 6435 223a 2022 3863 3431 6632 3830  "md5": "8c41f280
+00002c70: 3239 3034 6535 3334 3639 3339 3038 3435  2904e53469390845
+00002c80: 6366 6562 3262 3238 222c 0a20 2020 2020  cfeb2b28",.     
+00002c90: 2020 2020 2020 2022 7368 6131 223a 2022         "sha1": "
+00002ca0: 6365 3635 3139 6131 6463 3731 3531 3065  ce6519a1dc71510e
+00002cb0: 6531 3565 3636 6233 3932 3666 6431 3634  e15e66b3926fd164
+00002cc0: 6133 3733 3830 3361 222c 0a20 2020 2020  a373803a",.     
+00002cd0: 2020 2020 2020 2022 7368 6132 3536 223a         "sha256":
+00002ce0: 2022 3831 6164 6462 6637 3332 6439 6436   "81addbf732d9d6
+00002cf0: 6332 3462 3164 3365 6465 3761 6663 6565  c24b1d3ede7afcee
+00002d00: 6636 6131 6366 6635 3961 6637 6236 3364  f6a1cff59af7b63d
+00002d10: 3031 3530 3461 3039 3133 6136 6336 3730  01504a0913a6c670
+00002d20: 3161 222c 0a20 2020 2020 2020 2020 2020  1a",.           
+00002d30: 2022 6172 6368 6974 6563 7475 7265 223a   "architecture":
+00002d40: 206e 756c 6c2c 0a20 2020 2020 2020 2020   null,.         
+00002d50: 2020 2022 636f 6d70 696c 655f 7469 6d65     "compile_time
+00002d60: 223a 206e 756c 6c2c 0a20 2020 2020 2020  ": null,.       
+00002d70: 2020 2020 2022 6669 6c65 5f70 6174 6822       "file_path"
+00002d80: 3a20 6e75 6c6c 2c0a 2020 2020 2020 2020  : null,.        
+00002d90: 2020 2020 2264 6174 6122 3a20 6e75 6c6c      "data": null
+00002da0: 2c0a 2020 2020 2020 2020 2020 2020 2264  ,.            "d
+00002db0: 6572 6976 6174 696f 6e22 3a20 2265 6d62  erivation": "emb
+00002dc0: 6564 6465 6422 0a20 2020 2020 2020 207d  edded".        }
+00002dd0: 0a20 2020 205d 0a7d                      .    ].}
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_report/report.py` & `mwcp-3.9.0/mwcp/tests/test_report/report.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,368 +1,368 @@
-from uuid import UUID
-
-import mwcp
-
-report = {
-    "errors": ["[!] Test error log"],
-    "input_file": {
-        "architecture": None,
-        "compile_time": None,
-        "data": None,
-        "derivation": None,
-        "description": None,
-        "file_path": "C:/input_file.bin",
-        "md5": "1e50210a0202497fb79bc38b6ade6c34",
-        "name": "input_file.bin",
-        "sha1": "baf34551fecb48acc3da868eb85e1b6dac9de356",
-        "sha256": "1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee",
-        "tags": [],
-        "type": "file",
-    },
-    "logs": ["[+] Test info log", "[!] Test error log", "[*] Test debug log"],
-    "metadata": [
-        {
-            "file_system": None,
-            "is_dir": False,
-            "path": "C:\\windows\\temp\\1\\log\\keydb.txt",
-            "posix": False,
-            "tags": [],
-            "type": "path",
-        },
-        {
-            "file_system": None,
-            "is_dir": True,
-            "path": "%APPDATA%\\foo",
-            "posix": False,
-            "tags": [],
-            "type": "path",
-        },
-        {
-            "file_system": None,
-            "is_dir": False,
-            "path": "C:\\foo\\bar.txt",
-            "posix": False,
-            "tags": [],
-            "type": "path",
-        },
-        {
-            "file_system": None,
-            "is_dir": False,
-            "path": "malware.exe",
-            "posix": None,
-            "tags": [],
-            "type": "path",
-        },
-        {"alphabet": "0123456789ABCDEF", "base": 16, "tags": [], "type": "alphabet"},
-        {
-            "alphabet": "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=",
-            "base": 32,
-            "tags": [],
-            "type": "alphabet",
-        },
-        {
-            "alphabet": "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=",
-            "base": 64,
-            "tags": [],
-            "type": "alphabet",
-        },
-        {"tags": [], "type": "command", "value": "cmd.exe /c notepad.exe"},
-        {"password": "123456", "tags": [], "type": "credential", "username": "admin"},
-        {"password": None, "tags": [], "type": "credential", "username": "mruser"},
-        {"password": "secrets", "tags": [], "type": "credential", "username": None},
-        {
-            "address": "14qViLJfdGaP4EeHnDyJbEGQysnCpwk3gd",
-            "symbol": "BTC",
-            "tags": [],
-            "type": "crypto_address",
-        },
-        {
-            "address": "bad.com",
-            "c2": None,
-            "listen": None,
-            "network_protocol": "tcp",
-            "port": 21,
-            "tags": [],
-            "type": "socket",
-        },
-        {
-            "address": None,
-            "c2": None,
-            "listen": None,
-            "network_protocol": "udp",
-            "port": 1635,
-            "tags": [],
-            "type": "socket",
-        },
-        {
-            "address": None,
-            "c2": None,
-            "listen": True,
-            "network_protocol": "tcp",
-            "port": 4568,
-            "tags": [],
-            "type": "socket",
-        },
-        {
-            "application_protocol": "https",
-            "credential": None,
-            "path": "/images/baner.jpg",
-            "query": "",
-            "socket": {
-                "address": "10.11.10.13",
-                "c2": None,
-                "listen": None,
-                "network_protocol": None,
-                "port": 443,
-                "tags": [],
-                "type": "socket",
-            },
-            "tags": [],
-            "type": "url",
-            "url": "https://10.11.10.13:443/images/baner.jpg",
-        },
-        {
-            "address": "10.11.10.13",
-            "c2": None,
-            "listen": None,
-            "network_protocol": None,
-            "port": 443,
-            "tags": [],
-            "type": "socket",
-        },
-        {
-            "application_protocol": None,
-            "credential": {
-                "password": "pass",
-                "tags": [],
-                "type": "credential",
-                "username": "admin",
-            },
-            "path": None,
-            "query": None,
-            "socket": {
-                "address": "192.168.1.1",
-                "c2": None,
-                "listen": None,
-                "network_protocol": "tcp",
-                "port": 80,
-                "tags": [],
-                "type": "socket",
-            },
-            "tags": ["proxy"],
-            "type": "url",
-            "url": None,
-        },
-        {
-            "address": "192.168.1.1",
-            "c2": None,
-            "listen": None,
-            "network_protocol": "tcp",
-            "port": 80,
-            "tags": [],
-            "type": "socket",
-        },
-        {"password": "pass", "tags": [], "type": "credential", "username": "admin"},
-        {
-            "application_protocol": "ftp",
-            "credential": {
-                "password": "pass",
-                "tags": [],
-                "type": "credential",
-                "username": "admin",
-            },
-            "path": None,
-            "query": "",
-            "socket": {
-                "address": "badhost.com",
-                "c2": None,
-                "listen": None,
-                "network_protocol": None,
-                "port": 21,
-                "tags": [],
-                "type": "socket",
-            },
-            "tags": [],
-            "type": "url",
-            "url": "ftp://badhost.com:21",
-        },
-        {
-            "address": "badhost.com",
-            "c2": None,
-            "listen": None,
-            "network_protocol": None,
-            "port": 21,
-            "tags": [],
-            "type": "socket",
-        },
-        {"tags": [], "type": "email_address", "value": "email@bad.com"},
-        {"tags": [], "type": "event", "value": "MicrosoftExist"},
-        {
-            "tags": [],
-            "type": "uuid",
-            "value": UUID("654e5cff-817c-4e3d-8b01-47a6f45ae09a"),
-        },
-        {"tags": [], "type": "injection_process", "value": "svchost"},
-        {"tags": [], "type": "interval", "value": 3.0},
-        {
-            "algorithm": "rc4",
-            "iv": None,
-            "key": b"hello",
-            "mode": None,
-            "tags": [],
-            "type": "encryption_key",
-        },
-        {
-            "algorithm": "aes",
-            "iv": b"\x00\x00\x00\x00",
-            "key": b"\xff\xff\xff\xff",
-            "mode": "ecb",
-            "tags": [],
-            "type": "encryption_key",
-        },
-        {
-            "encryption_key": None,
-            "tags": [],
-            "type": "decoded_string",
-            "value": "GetProcess",
-        },
-        {
-            "encryption_key": {
-                "algorithm": "xor",
-                "iv": None,
-                "key": b"\xff\xff",
-                "mode": None,
-                "tags": [],
-                "type": "encryption_key",
-            },
-            "tags": [],
-            "type": "decoded_string",
-            "value": "badstring",
-        },
-        {
-            "algorithm": "xor",
-            "iv": None,
-            "key": b"\xff\xff",
-            "mode": None,
-            "tags": [],
-            "type": "encryption_key",
-        },
-        {"tags": [], "type": "mission_id", "value": "target4"},
-        {"tags": [], "type": "mutex", "value": "ithinkimalonenow"},
-        {
-            "key": "misc_info",
-            "tags": ["something"],
-            "type": "other",
-            "value": "some miscellaneous info",
-            "value_format": "string",
-        },
-        {
-            "key": "random_data",
-            "tags": [],
-            "type": "other",
-            "value": b"\xde\xad\xbe\xef",
-            "value_format": "bytes",
-        },
-        {
-            "key": "keylogger",
-            "tags": [],
-            "type": "other",
-            "value": True,
-            "value_format": "boolean",
-        },
-        {
-            "key": "misc_integer",
-            "tags": ["tag1"],
-            "type": "other",
-            "value": 432,
-            "value_format": "integer",
-        },
-        {
-            "tags": [],
-            "type": "pipe",
-            "value": "\\.\\pipe\\namedpipe",
-        },
-        {
-            "data": "c:\\update.exe",
-            "data_type": "REG_SZ",
-            "hive": "HKEY_LOCAL_MACHINE",
-            "subkey": "Software\\Microsoft\\Windows\\CurrentVersion\\Run",
-            "tags": [],
-            "type": "registry",
-            "value": "Updater",
-        },
-        {
-            "data": None,
-            "data_type": None,
-            "hive": "HKEY_LOCAL_MACHINE",
-            "subkey": "Foo\\Bar",
-            "tags": [],
-            "type": "registry",
-            "value": None,
-        },
-        {
-            "data": None,
-            "data_type": None,
-            "hive": None,
-            "subkey": None,
-            "tags": ["tag2"],
-            "type": "registry",
-            "value": "Baz",
-        },
-        {
-            "d_mod_p1": 7,
-            "d_mod_q1": 3,
-            "modulus": 187,
-            "p": 17,
-            "private_exponent": 23,
-            "public_exponent": 7,
-            "q": 11,
-            "q_inv_mod_p": 14,
-            "tags": [],
-            "type": "rsa_private_key",
-        },
-        {"modulus": 187, "public_exponent": 7, "tags": [], "type": "rsa_public_key"},
-        {
-            "description": "Provides a common management to access "
-            "information about windows user.",
-            "display_name": "Windows User Management",
-            "dll": None,
-            "image": "%System%\\svohost.exe",
-            "name": "WindowsUserManagement",
-            "tags": [],
-            "type": "service",
-        },
-        {
-            "file_system": None,
-            "is_dir": False,
-            "path": "%System%\\svohost.exe",
-            "posix": False,
-            "tags": [],
-            "type": "path",
-        },
-        {
-            "tags": [],
-            "type": "user_agent",
-            "value": "Mozilla/4.0 (compatible; MISE 6.0; Windows NT 5.2)",
-        },
-        {"tags": [], "type": "version", "value": "3.1"},
-        {"tags": [], "type": "version", "value": "403.10"},
-        {
-            "architecture": None,
-            "compile_time": None,
-            "data": None,
-            "derivation": "embedded",
-            "description": "Extracted backdoor Foo config file",
-            "file_path": None,
-            "md5": "8c41f2802904e53469390845cfeb2b28",
-            "name": "config.xml",
-            "sha1": "ce6519a1dc71510ee15e66b3926fd164a373803a",
-            "sha256": "81addbf732d9d6c24b1d3ede7afceef6a1cff59af7b63d01504a0913a6c6701a",
-            "tags": [],
-            "type": "file",
-        },
-    ],
-    "mwcp_version": mwcp.__version__,
-    "parser": "FooParser",
-    "tags": ["tagging", "test"],
-    "type": "report",
-}
+from uuid import UUID
+
+import mwcp
+
+report = {
+    "errors": ["[!] Test error log"],
+    "input_file": {
+        "architecture": None,
+        "compile_time": None,
+        "data": None,
+        "derivation": None,
+        "description": None,
+        "file_path": "C:/input_file.bin",
+        "md5": "1e50210a0202497fb79bc38b6ade6c34",
+        "name": "input_file.bin",
+        "sha1": "baf34551fecb48acc3da868eb85e1b6dac9de356",
+        "sha256": "1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee",
+        "tags": [],
+        "type": "file",
+    },
+    "logs": ["[+] Test info log", "[!] Test error log", "[*] Test debug log"],
+    "metadata": [
+        {
+            "file_system": None,
+            "is_dir": False,
+            "path": "C:\\windows\\temp\\1\\log\\keydb.txt",
+            "posix": False,
+            "tags": [],
+            "type": "path",
+        },
+        {
+            "file_system": None,
+            "is_dir": True,
+            "path": "%APPDATA%\\foo",
+            "posix": False,
+            "tags": [],
+            "type": "path",
+        },
+        {
+            "file_system": None,
+            "is_dir": False,
+            "path": "C:\\foo\\bar.txt",
+            "posix": False,
+            "tags": [],
+            "type": "path",
+        },
+        {
+            "file_system": None,
+            "is_dir": False,
+            "path": "malware.exe",
+            "posix": None,
+            "tags": [],
+            "type": "path",
+        },
+        {"alphabet": "0123456789ABCDEF", "base": 16, "tags": [], "type": "alphabet"},
+        {
+            "alphabet": "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=",
+            "base": 32,
+            "tags": [],
+            "type": "alphabet",
+        },
+        {
+            "alphabet": "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=",
+            "base": 64,
+            "tags": [],
+            "type": "alphabet",
+        },
+        {"tags": [], "type": "command", "value": "cmd.exe /c notepad.exe"},
+        {"password": "123456", "tags": [], "type": "credential", "username": "admin"},
+        {"password": None, "tags": [], "type": "credential", "username": "mruser"},
+        {"password": "secrets", "tags": [], "type": "credential", "username": None},
+        {
+            "address": "14qViLJfdGaP4EeHnDyJbEGQysnCpwk3gd",
+            "symbol": "BTC",
+            "tags": [],
+            "type": "crypto_address",
+        },
+        {
+            "address": "bad.com",
+            "c2": None,
+            "listen": None,
+            "network_protocol": "tcp",
+            "port": 21,
+            "tags": [],
+            "type": "socket",
+        },
+        {
+            "address": None,
+            "c2": None,
+            "listen": None,
+            "network_protocol": "udp",
+            "port": 1635,
+            "tags": [],
+            "type": "socket",
+        },
+        {
+            "address": None,
+            "c2": None,
+            "listen": True,
+            "network_protocol": "tcp",
+            "port": 4568,
+            "tags": [],
+            "type": "socket",
+        },
+        {
+            "application_protocol": "https",
+            "credential": None,
+            "path": "/images/baner.jpg",
+            "query": "",
+            "socket": {
+                "address": "10.11.10.13",
+                "c2": None,
+                "listen": None,
+                "network_protocol": None,
+                "port": 443,
+                "tags": [],
+                "type": "socket",
+            },
+            "tags": [],
+            "type": "url",
+            "url": "https://10.11.10.13:443/images/baner.jpg",
+        },
+        {
+            "address": "10.11.10.13",
+            "c2": None,
+            "listen": None,
+            "network_protocol": None,
+            "port": 443,
+            "tags": [],
+            "type": "socket",
+        },
+        {
+            "application_protocol": None,
+            "credential": {
+                "password": "pass",
+                "tags": [],
+                "type": "credential",
+                "username": "admin",
+            },
+            "path": None,
+            "query": None,
+            "socket": {
+                "address": "192.168.1.1",
+                "c2": None,
+                "listen": None,
+                "network_protocol": "tcp",
+                "port": 80,
+                "tags": [],
+                "type": "socket",
+            },
+            "tags": ["proxy"],
+            "type": "url",
+            "url": None,
+        },
+        {
+            "address": "192.168.1.1",
+            "c2": None,
+            "listen": None,
+            "network_protocol": "tcp",
+            "port": 80,
+            "tags": [],
+            "type": "socket",
+        },
+        {"password": "pass", "tags": [], "type": "credential", "username": "admin"},
+        {
+            "application_protocol": "ftp",
+            "credential": {
+                "password": "pass",
+                "tags": [],
+                "type": "credential",
+                "username": "admin",
+            },
+            "path": None,
+            "query": "",
+            "socket": {
+                "address": "badhost.com",
+                "c2": None,
+                "listen": None,
+                "network_protocol": None,
+                "port": 21,
+                "tags": [],
+                "type": "socket",
+            },
+            "tags": [],
+            "type": "url",
+            "url": "ftp://badhost.com:21",
+        },
+        {
+            "address": "badhost.com",
+            "c2": None,
+            "listen": None,
+            "network_protocol": None,
+            "port": 21,
+            "tags": [],
+            "type": "socket",
+        },
+        {"tags": [], "type": "email_address", "value": "email@bad.com"},
+        {"tags": [], "type": "event", "value": "MicrosoftExist"},
+        {
+            "tags": [],
+            "type": "uuid",
+            "value": UUID("654e5cff-817c-4e3d-8b01-47a6f45ae09a"),
+        },
+        {"tags": [], "type": "injection_process", "value": "svchost"},
+        {"tags": [], "type": "interval", "value": 3.0},
+        {
+            "algorithm": "rc4",
+            "iv": None,
+            "key": b"hello",
+            "mode": None,
+            "tags": [],
+            "type": "encryption_key",
+        },
+        {
+            "algorithm": "aes",
+            "iv": b"\x00\x00\x00\x00",
+            "key": b"\xff\xff\xff\xff",
+            "mode": "ecb",
+            "tags": [],
+            "type": "encryption_key",
+        },
+        {
+            "encryption_key": None,
+            "tags": [],
+            "type": "decoded_string",
+            "value": "GetProcess",
+        },
+        {
+            "encryption_key": {
+                "algorithm": "xor",
+                "iv": None,
+                "key": b"\xff\xff",
+                "mode": None,
+                "tags": [],
+                "type": "encryption_key",
+            },
+            "tags": [],
+            "type": "decoded_string",
+            "value": "badstring",
+        },
+        {
+            "algorithm": "xor",
+            "iv": None,
+            "key": b"\xff\xff",
+            "mode": None,
+            "tags": [],
+            "type": "encryption_key",
+        },
+        {"tags": [], "type": "mission_id", "value": "target4"},
+        {"tags": [], "type": "mutex", "value": "ithinkimalonenow"},
+        {
+            "key": "misc_info",
+            "tags": ["something"],
+            "type": "other",
+            "value": "some miscellaneous info",
+            "value_format": "string",
+        },
+        {
+            "key": "random_data",
+            "tags": [],
+            "type": "other",
+            "value": b"\xde\xad\xbe\xef",
+            "value_format": "bytes",
+        },
+        {
+            "key": "keylogger",
+            "tags": [],
+            "type": "other",
+            "value": True,
+            "value_format": "boolean",
+        },
+        {
+            "key": "misc_integer",
+            "tags": ["tag1"],
+            "type": "other",
+            "value": 432,
+            "value_format": "integer",
+        },
+        {
+            "tags": [],
+            "type": "pipe",
+            "value": "\\.\\pipe\\namedpipe",
+        },
+        {
+            "data": "c:\\update.exe",
+            "data_type": "REG_SZ",
+            "hive": "HKEY_LOCAL_MACHINE",
+            "subkey": "Software\\Microsoft\\Windows\\CurrentVersion\\Run",
+            "tags": [],
+            "type": "registry",
+            "value": "Updater",
+        },
+        {
+            "data": None,
+            "data_type": None,
+            "hive": "HKEY_LOCAL_MACHINE",
+            "subkey": "Foo\\Bar",
+            "tags": [],
+            "type": "registry",
+            "value": None,
+        },
+        {
+            "data": None,
+            "data_type": None,
+            "hive": None,
+            "subkey": None,
+            "tags": ["tag2"],
+            "type": "registry",
+            "value": "Baz",
+        },
+        {
+            "d_mod_p1": 7,
+            "d_mod_q1": 3,
+            "modulus": 187,
+            "p": 17,
+            "private_exponent": 23,
+            "public_exponent": 7,
+            "q": 11,
+            "q_inv_mod_p": 14,
+            "tags": [],
+            "type": "rsa_private_key",
+        },
+        {"modulus": 187, "public_exponent": 7, "tags": [], "type": "rsa_public_key"},
+        {
+            "description": "Provides a common management to access "
+            "information about windows user.",
+            "display_name": "Windows User Management",
+            "dll": None,
+            "image": "%System%\\svohost.exe",
+            "name": "WindowsUserManagement",
+            "tags": [],
+            "type": "service",
+        },
+        {
+            "file_system": None,
+            "is_dir": False,
+            "path": "%System%\\svohost.exe",
+            "posix": False,
+            "tags": [],
+            "type": "path",
+        },
+        {
+            "tags": [],
+            "type": "user_agent",
+            "value": "Mozilla/4.0 (compatible; MISE 6.0; Windows NT 5.2)",
+        },
+        {"tags": [], "type": "version", "value": "3.1"},
+        {"tags": [], "type": "version", "value": "403.10"},
+        {
+            "architecture": None,
+            "compile_time": None,
+            "data": None,
+            "derivation": "embedded",
+            "description": "Extracted backdoor Foo config file",
+            "file_path": None,
+            "md5": "8c41f2802904e53469390845cfeb2b28",
+            "name": "config.xml",
+            "sha1": "ce6519a1dc71510ee15e66b3926fd164a373803a",
+            "sha256": "81addbf732d9d6c24b1d3ede7afceef6a1cff59af7b63d01504a0913a6c6701a",
+            "tags": [],
+            "type": "file",
+        },
+    ],
+    "mwcp_version": mwcp.__version__,
+    "parser": "FooParser",
+    "tags": ["tagging", "test"],
+    "type": "report",
+}
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_report_writer/report_foreign.html` & `mwcp-3.9.0/mwcp/tests/test_report_writer/report_foreign.html`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,40 +1,40 @@
-<h1>File: input_file.bin</h1>
-<table>
-<thead>
-<tr><th>Field       </th><th>Value                                                           </th></tr>
-</thead>
-<tbody>
-<tr><td>Parser      </td><td>FooParser                                                       </td></tr>
-<tr><td>File Path   </td><td>C:/input_file.bin                                               </td></tr>
-<tr><td>Description </td><td>SuperMalware Implant                                            </td></tr>
-<tr><td>Architecture</td><td>                                                                </td></tr>
-<tr><td>MD5         </td><td>1e50210a0202497fb79bc38b6ade6c34                                </td></tr>
-<tr><td>SHA1        </td><td>baf34551fecb48acc3da868eb85e1b6dac9de356                        </td></tr>
-<tr><td>SHA256      </td><td>1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee</td></tr>
-<tr><td>Compile Time</td><td>                                                                </td></tr>
-</tbody>
-</table>
-
-<h2>Miscellaneous</h2>
-<table>
-<thead>
-<tr><th>Key   </th><th>Value                              </th></tr>
-</thead>
-<tbody>
-<tr><td>JAPAN </td><td>                   </td></tr>
-<tr><td>CHINA </td><td>                           </td></tr>
-<tr><td>KOREA </td><td>                   </td></tr>
-<tr><td>ISRAEL</td><td>                      </td></tr>
-<tr><td>EGYPT </td><td>                         </td></tr>
-<tr><td>RUSSIA</td><td>               </td></tr>
-<tr><td>MATH  </td><td> Eda = Q,  n  ,  f(i) =  g(i)</td></tr>
-<tr><td>FRANCE</td><td>franais langue trangre          </td></tr>
-<tr><td>SPAIN </td><td>maana ol                         </td></tr>
-</tbody>
-</table>
-
-<h1>File Tree</h1>
-<pre>
-&lt;input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant&gt;
-</pre>
-
+<h1>File: input_file.bin</h1>
+<table>
+<thead>
+<tr><th>Field       </th><th>Value                                                           </th></tr>
+</thead>
+<tbody>
+<tr><td>Parser      </td><td>FooParser                                                       </td></tr>
+<tr><td>File Path   </td><td>C:/input_file.bin                                               </td></tr>
+<tr><td>Description </td><td>SuperMalware Implant                                            </td></tr>
+<tr><td>Architecture</td><td>                                                                </td></tr>
+<tr><td>MD5         </td><td>1e50210a0202497fb79bc38b6ade6c34                                </td></tr>
+<tr><td>SHA1        </td><td>baf34551fecb48acc3da868eb85e1b6dac9de356                        </td></tr>
+<tr><td>SHA256      </td><td>1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee</td></tr>
+<tr><td>Compile Time</td><td>                                                                </td></tr>
+</tbody>
+</table>
+
+<h2>Miscellaneous</h2>
+<table>
+<thead>
+<tr><th>Key   </th><th>Value                              </th></tr>
+</thead>
+<tbody>
+<tr><td>JAPAN </td><td>                   </td></tr>
+<tr><td>CHINA </td><td>                           </td></tr>
+<tr><td>KOREA </td><td>                   </td></tr>
+<tr><td>ISRAEL</td><td>                      </td></tr>
+<tr><td>EGYPT </td><td>                         </td></tr>
+<tr><td>RUSSIA</td><td>               </td></tr>
+<tr><td>MATH  </td><td> Eda = Q,  n  ,  f(i) =  g(i)</td></tr>
+<tr><td>FRANCE</td><td>franais langue trangre          </td></tr>
+<tr><td>SPAIN </td><td>maana ol                         </td></tr>
+</tbody>
+</table>
+
+<h1>File Tree</h1>
+<pre>
+&lt;input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant&gt;
+</pre>
+
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_report_writer/report_foreign.md` & `mwcp-3.9.0/mwcp/tests/test_report_writer/report_foreign.md`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-# File: input_file.bin
-| Field        | Value                                                            |
-|:-------------|:-----------------------------------------------------------------|
-| Parser       | FooParser                                                        |
-| File Path    | C:/input_file.bin                                                |
-| Description  | SuperMalware Implant                                             |
-| Architecture |                                                                  |
-| MD5          | 1e50210a0202497fb79bc38b6ade6c34                                 |
-| SHA1         | baf34551fecb48acc3da868eb85e1b6dac9de356                         |
-| SHA256       | 1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee |
-| Compile Time |                                                                  |
-
-## Miscellaneous
-| Key    | Value                               |
-|:-------|:------------------------------------|
-| JAPAN  |                     |
-| CHINA  |                             |
-| KOREA  |                     |
-| ISRAEL |                        |
-| EGYPT  |                           |
-| RUSSIA |                 |
-| MATH   |  Eda = Q,  n  ,  f(i) =  g(i) |
-| FRANCE | franais langue trangre           |
-| SPAIN  | maana ol                          |
-
-# File Tree
-```
-<input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant>
-```
-
+# File: input_file.bin
+| Field        | Value                                                            |
+|:-------------|:-----------------------------------------------------------------|
+| Parser       | FooParser                                                        |
+| File Path    | C:/input_file.bin                                                |
+| Description  | SuperMalware Implant                                             |
+| Architecture |                                                                  |
+| MD5          | 1e50210a0202497fb79bc38b6ade6c34                                 |
+| SHA1         | baf34551fecb48acc3da868eb85e1b6dac9de356                         |
+| SHA256       | 1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee |
+| Compile Time |                                                                  |
+
+## Miscellaneous
+| Key    | Value                               |
+|:-------|:------------------------------------|
+| JAPAN  |                     |
+| CHINA  |                             |
+| KOREA  |                     |
+| ISRAEL |                        |
+| EGYPT  |                           |
+| RUSSIA |                 |
+| MATH   |  Eda = Q,  n  ,  f(i) =  g(i) |
+| FRANCE | franais langue trangre           |
+| SPAIN  | maana ol                          |
+
+# File Tree
+```
+<input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant>
+```
+
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_report_writer/report_foreign.txt` & `mwcp-3.9.0/mwcp/tests/test_report_writer/report_foreign.txt`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,28 +1,28 @@
------ File: input_file.bin -----
-Field         Value
-------------  ----------------------------------------------------------------
-Parser        FooParser
-File Path     C:/input_file.bin
-Description   SuperMalware Implant
-Architecture
-MD5           1e50210a0202497fb79bc38b6ade6c34
-SHA1          baf34551fecb48acc3da868eb85e1b6dac9de356
-SHA256        1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee
-Compile Time
-
----- Miscellaneous ----
-Key     Value
-------  -----------------------------------
-JAPAN   
-CHINA   
-KOREA    
-ISRAEL   
-EGYPT    
-RUSSIA   
-MATH     Eda = Q,  n  ,  f(i) =  g(i)
-FRANCE  franais langue trangre
-SPAIN   maana ol
-
------ File Tree -----
-<input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant>
-
+----- File: input_file.bin -----
+Field         Value
+------------  ----------------------------------------------------------------
+Parser        FooParser
+File Path     C:/input_file.bin
+Description   SuperMalware Implant
+Architecture
+MD5           1e50210a0202497fb79bc38b6ade6c34
+SHA1          baf34551fecb48acc3da868eb85e1b6dac9de356
+SHA256        1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee
+Compile Time
+
+---- Miscellaneous ----
+Key     Value
+------  -----------------------------------
+JAPAN   
+CHINA   
+KOREA    
+ISRAEL   
+EGYPT    
+RUSSIA   
+MATH     Eda = Q,  n  ,  f(i) =  g(i)
+FRANCE  franais langue trangre
+SPAIN   maana ol
+
+----- File Tree -----
+<input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant>
+
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_report_writer/report_wordwrap.html` & `mwcp-3.9.0/mwcp/tests/test_report_writer/report_wordwrap.html`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,111 +1,111 @@
-<h1>File: input_file.bin</h1>
-<table>
-<thead>
-<tr><th>Field       </th><th>Value                                                           </th></tr>
-</thead>
-<tbody>
-<tr><td>Parser      </td><td>FooParser                                                       </td></tr>
-<tr><td>File Path   </td><td>C:/input_file.bin                                               </td></tr>
-<tr><td>Description </td><td>SuperMalware Implant                                            </td></tr>
-<tr><td>Architecture</td><td>                                                                </td></tr>
-<tr><td>MD5         </td><td>1e50210a0202497fb79bc38b6ade6c34                                </td></tr>
-<tr><td>SHA1        </td><td>baf34551fecb48acc3da868eb85e1b6dac9de356                        </td></tr>
-<tr><td>SHA256      </td><td>1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee</td></tr>
-<tr><td>Compile Time</td><td>                                                                </td></tr>
-</tbody>
-</table>
-
-<h2>RSA Private Key</h2>
-<table>
-<thead>
-<tr><th>Value  </th></tr>
-</thead>
-<tbody>
-<tr><td><pre>Modulus (n):
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-Public Exponent (e):
-    1234 (0x4d2)
-Private Exponent (d):
-    1234 (0x4d2)
-p:
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-q:
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-d mod (p-1):
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-d mod (q-1):
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-(inverse of q) mod p:
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-</pre>        </td></tr>
-</tbody>
-</table>
-
-<h2>RSA Public Key</h2>
-<table>
-<thead>
-<tr><th>Value  </th></tr>
-</thead>
-<tbody>
-<tr><td><pre>Modulus (n):
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-Public Exponent (e):
-    1234 (0x4d2)
-</pre>        </td></tr>
-</tbody>
-</table>
-
-<h2>User Agent</h2>
-<table>
-<thead>
-<tr><th>Value  </th></tr>
-</thead>
-<tbody>
-<tr><td><pre>This is a really large user agent that will need to be word wrapped.This is a really large user
-agent that will need to be word wrapped.This is a really large user agent that will need to be word
-wrapped.This is a really large user agent that will need to be word wrapped.This is a really large
-user agent that will need to be word wrapped.This is a really large user agent that will need to be
-word wrapped.This is a really large user agent that will need to be word wrapped.This is a really
-large user agent that will need to be word wrapped.This is a really large user agent that will need
-to be word wrapped.This is a really large user agent that will need to be word wrapped.This is a
-really large user agent that will need to be word wrapped.This is a really large user agent that
-will need to be word wrapped.This is a really large user agent that will need to be word
-wrapped.This is a really large user agent that will need to be word wrapped.This is a really large
-user agent that will need to be word wrapped.This is a really large user agent that will need to be
-word wrapped.</pre>        </td></tr>
-</tbody>
-</table>
-
-<h1>File Tree</h1>
-<pre>
-&lt;input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant&gt;
-</pre>
-
+<h1>File: input_file.bin</h1>
+<table>
+<thead>
+<tr><th>Field       </th><th>Value                                                           </th></tr>
+</thead>
+<tbody>
+<tr><td>Parser      </td><td>FooParser                                                       </td></tr>
+<tr><td>File Path   </td><td>C:/input_file.bin                                               </td></tr>
+<tr><td>Description </td><td>SuperMalware Implant                                            </td></tr>
+<tr><td>Architecture</td><td>                                                                </td></tr>
+<tr><td>MD5         </td><td>1e50210a0202497fb79bc38b6ade6c34                                </td></tr>
+<tr><td>SHA1        </td><td>baf34551fecb48acc3da868eb85e1b6dac9de356                        </td></tr>
+<tr><td>SHA256      </td><td>1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee</td></tr>
+<tr><td>Compile Time</td><td>                                                                </td></tr>
+</tbody>
+</table>
+
+<h2>RSA Private Key</h2>
+<table>
+<thead>
+<tr><th>Value  </th></tr>
+</thead>
+<tbody>
+<tr><td><pre>Modulus (n):
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+Public Exponent (e):
+    1234 (0x4d2)
+Private Exponent (d):
+    1234 (0x4d2)
+p:
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+q:
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+d mod (p-1):
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+d mod (q-1):
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+(inverse of q) mod p:
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+</pre>        </td></tr>
+</tbody>
+</table>
+
+<h2>RSA Public Key</h2>
+<table>
+<thead>
+<tr><th>Value  </th></tr>
+</thead>
+<tbody>
+<tr><td><pre>Modulus (n):
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+Public Exponent (e):
+    1234 (0x4d2)
+</pre>        </td></tr>
+</tbody>
+</table>
+
+<h2>User Agent</h2>
+<table>
+<thead>
+<tr><th>Value  </th></tr>
+</thead>
+<tbody>
+<tr><td><pre>This is a really large user agent that will need to be word wrapped.This is a really large user
+agent that will need to be word wrapped.This is a really large user agent that will need to be word
+wrapped.This is a really large user agent that will need to be word wrapped.This is a really large
+user agent that will need to be word wrapped.This is a really large user agent that will need to be
+word wrapped.This is a really large user agent that will need to be word wrapped.This is a really
+large user agent that will need to be word wrapped.This is a really large user agent that will need
+to be word wrapped.This is a really large user agent that will need to be word wrapped.This is a
+really large user agent that will need to be word wrapped.This is a really large user agent that
+will need to be word wrapped.This is a really large user agent that will need to be word
+wrapped.This is a really large user agent that will need to be word wrapped.This is a really large
+user agent that will need to be word wrapped.This is a really large user agent that will need to be
+word wrapped.</pre>        </td></tr>
+</tbody>
+</table>
+
+<h1>File Tree</h1>
+<pre>
+&lt;input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant&gt;
+</pre>
+
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_report_writer/report_wordwrap.md` & `mwcp-3.9.0/mwcp/tests/test_report_writer/report_wordwrap.md`

 * *Ordering differences only*

 * *Files 3% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-# File: input_file.bin
-| Field        | Value                                                            |
-|:-------------|:-----------------------------------------------------------------|
-| Parser       | FooParser                                                        |
-| File Path    | C:/input_file.bin                                                |
-| Description  | SuperMalware Implant                                             |
-| Architecture |                                                                  |
-| MD5          | 1e50210a0202497fb79bc38b6ade6c34                                 |
-| SHA1         | baf34551fecb48acc3da868eb85e1b6dac9de356                         |
-| SHA256       | 1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee |
-| Compile Time |                                                                  |
-
-## RSA Private Key
-| Value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
-|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
-| Modulus (n):<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>Public Exponent (e):<br>    1234 (0x4d2)<br>Private Exponent (d):<br>    1234 (0x4d2)<br>p:<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>q:<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>d mod (p-1):<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>d mod (q-1):<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>(inverse of q) mod p:<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br> |
-
-## RSA Public Key
-| Value                                                                                                                                                                                                                                                                                         |
-|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
-| Modulus (n):<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>Public Exponent (e):<br>    1234 (0x4d2)<br> |
-
-## User Agent
-| Value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
-|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
-| This is a really large user agent that will need to be word wrapped.This is a really large user<br>agent that will need to be word wrapped.This is a really large user agent that will need to be word<br>wrapped.This is a really large user agent that will need to be word wrapped.This is a really large<br>user agent that will need to be word wrapped.This is a really large user agent that will need to be<br>word wrapped.This is a really large user agent that will need to be word wrapped.This is a really<br>large user agent that will need to be word wrapped.This is a really large user agent that will need<br>to be word wrapped.This is a really large user agent that will need to be word wrapped.This is a<br>really large user agent that will need to be word wrapped.This is a really large user agent that<br>will need to be word wrapped.This is a really large user agent that will need to be word<br>wrapped.This is a really large user agent that will need to be word wrapped.This is a really large<br>user agent that will need to be word wrapped.This is a really large user agent that will need to be<br>word wrapped. |
-
-# File Tree
-```
-<input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant>
-```
-
+# File: input_file.bin
+| Field        | Value                                                            |
+|:-------------|:-----------------------------------------------------------------|
+| Parser       | FooParser                                                        |
+| File Path    | C:/input_file.bin                                                |
+| Description  | SuperMalware Implant                                             |
+| Architecture |                                                                  |
+| MD5          | 1e50210a0202497fb79bc38b6ade6c34                                 |
+| SHA1         | baf34551fecb48acc3da868eb85e1b6dac9de356                         |
+| SHA256       | 1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee |
+| Compile Time |                                                                  |
+
+## RSA Private Key
+| Value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
+|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| Modulus (n):<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>Public Exponent (e):<br>    1234 (0x4d2)<br>Private Exponent (d):<br>    1234 (0x4d2)<br>p:<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>q:<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>d mod (p-1):<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>d mod (q-1):<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>(inverse of q) mod p:<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br> |
+
+## RSA Public Key
+| Value                                                                                                                                                                                                                                                                                         |
+|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| Modulus (n):<br>    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:<br>    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:<br>    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:<br>    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:<br>    f3:b3<br>Public Exponent (e):<br>    1234 (0x4d2)<br> |
+
+## User Agent
+| Value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
+|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| This is a really large user agent that will need to be word wrapped.This is a really large user<br>agent that will need to be word wrapped.This is a really large user agent that will need to be word<br>wrapped.This is a really large user agent that will need to be word wrapped.This is a really large<br>user agent that will need to be word wrapped.This is a really large user agent that will need to be<br>word wrapped.This is a really large user agent that will need to be word wrapped.This is a really<br>large user agent that will need to be word wrapped.This is a really large user agent that will need<br>to be word wrapped.This is a really large user agent that will need to be word wrapped.This is a<br>really large user agent that will need to be word wrapped.This is a really large user agent that<br>will need to be word wrapped.This is a really large user agent that will need to be word<br>wrapped.This is a really large user agent that will need to be word wrapped.This is a really large<br>user agent that will need to be word wrapped.This is a really large user agent that will need to be<br>word wrapped. |
+
+# File Tree
+```
+<input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant>
+```
+
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_report_writer/report_wordwrap.txt` & `mwcp-3.9.0/mwcp/tests/test_report_writer/report_wordwrap.txt`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,87 +1,87 @@
------ File: input_file.bin -----
-Field         Value
-------------  ----------------------------------------------------------------
-Parser        FooParser
-File Path     C:/input_file.bin
-Description   SuperMalware Implant
-Architecture
-MD5           1e50210a0202497fb79bc38b6ade6c34
-SHA1          baf34551fecb48acc3da868eb85e1b6dac9de356
-SHA256        1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee
-Compile Time
-
----- RSA Private Key ----
-Value
--------------------------------------------------
-Modulus (n):
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-Public Exponent (e):
-    1234 (0x4d2)
-Private Exponent (d):
-    1234 (0x4d2)
-p:
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-q:
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-d mod (p-1):
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-d mod (q-1):
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-(inverse of q) mod p:
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-
----- RSA Public Key ----
-Value
--------------------------------------------------
-Modulus (n):
-    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
-    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
-    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
-    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
-    f3:b3
-Public Exponent (e):
-    1234 (0x4d2)
-
----- User Agent ----
-Value
-----------------------------------------------------------------------------------------------------
-This is a really large user agent that will need to be word wrapped.This is a really large user
-  agent that will need to be word wrapped.This is a really large user agent that will need to be
-  word wrapped.This is a really large user agent that will need to be word wrapped.This is a really
-  large user agent that will need to be word wrapped.This is a really large user agent that will
-  need to be word wrapped.This is a really large user agent that will need to be word wrapped.This
-  is a really large user agent that will need to be word wrapped.This is a really large user agent
-  that will need to be word wrapped.This is a really large user agent that will need to be word
-  wrapped.This is a really large user agent that will need to be word wrapped.This is a really large
-  user agent that will need to be word wrapped.This is a really large user agent that will need to
-  be word wrapped.This is a really large user agent that will need to be word wrapped.This is a
-  really large user agent that will need to be word wrapped.This is a really large user agent that
-  will need to be word wrapped.
-
------ File Tree -----
-<input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant>
-
+----- File: input_file.bin -----
+Field         Value
+------------  ----------------------------------------------------------------
+Parser        FooParser
+File Path     C:/input_file.bin
+Description   SuperMalware Implant
+Architecture
+MD5           1e50210a0202497fb79bc38b6ade6c34
+SHA1          baf34551fecb48acc3da868eb85e1b6dac9de356
+SHA256        1307990e6ba5ca145eb35e99182a9bec46531bc54ddf656a602c780fa0240dee
+Compile Time
+
+---- RSA Private Key ----
+Value
+-------------------------------------------------
+Modulus (n):
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+Public Exponent (e):
+    1234 (0x4d2)
+Private Exponent (d):
+    1234 (0x4d2)
+p:
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+q:
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+d mod (p-1):
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+d mod (q-1):
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+(inverse of q) mod p:
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+
+---- RSA Public Key ----
+Value
+-------------------------------------------------
+Modulus (n):
+    9a:10:6f:8d:3e:4b:bb:73:1e:b2:aa:0e:c7:e9:a0:
+    d3:1b:fb:db:5a:ce:26:92:d2:3d:db:2a:95:ae:78:
+    ad:7a:e0:2d:90:73:38:5b:57:72:5a:28:10:f3:1f:
+    84:ff:3b:31:f8:4f:f3:b3:1f:84:ff:3b:31:f8:4f:
+    f3:b3
+Public Exponent (e):
+    1234 (0x4d2)
+
+---- User Agent ----
+Value
+----------------------------------------------------------------------------------------------------
+This is a really large user agent that will need to be word wrapped.This is a really large user
+  agent that will need to be word wrapped.This is a really large user agent that will need to be
+  word wrapped.This is a really large user agent that will need to be word wrapped.This is a really
+  large user agent that will need to be word wrapped.This is a really large user agent that will
+  need to be word wrapped.This is a really large user agent that will need to be word wrapped.This
+  is a really large user agent that will need to be word wrapped.This is a really large user agent
+  that will need to be word wrapped.This is a really large user agent that will need to be word
+  wrapped.This is a really large user agent that will need to be word wrapped.This is a really large
+  user agent that will need to be word wrapped.This is a really large user agent that will need to
+  be word wrapped.This is a really large user agent that will need to be word wrapped.This is a
+  really large user agent that will need to be word wrapped.This is a really large user agent that
+  will need to be word wrapped.
+
+----- File Tree -----
+<input_file.bin (1e50210a0202497fb79bc38b6ade6c34) : SuperMalware Implant>
+
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_report_writer.py` & `mwcp-3.9.0/mwcp/tests/test_report_writer.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,74 +1,74 @@
-
-import pytest
-
-from mwcp import metadata
-
-
-@pytest.mark.parametrize("text_format,report_name", [
-    ("markdown", "report.md"),
-    ("simple", "report.txt"),
-    ("html", "report.html"),
-])
-def test_basic(datadir, report, metadata_items, text_format, report_name):
-    """
-    Tests each metadata element to ensure they are presented
-    nicely in a report.
-    """
-    with report:
-        report.input_file.description = "SuperMalware Implant"
-        for item in metadata_items:
-            report.add(item)
-        report.add_tag("test", "tagging")
-
-    actual = report.as_text(text_format)
-    print(actual)
-    expected = (datadir / report_name).read_text()
-    assert actual == expected
-
-
-@pytest.mark.parametrize("text_format,report_name", [
-    ("markdown", "report_wordwrap.md"),
-    ("simple", "report_wordwrap.txt"),
-    ("html", "report_wordwrap.html"),
-])
-def test_wordwrap(datadir, report, text_format, report_name):
-    with report:
-        report.input_file.description = "SuperMalware Implant"
-        large_num = int("123"*50)  # Large number that will require word wrapping.
-        report.add(metadata.RSAPublicKey(1234, large_num))
-        report.add(metadata.RSAPrivateKey(
-            1234, large_num, 1234, large_num, large_num, large_num, large_num, large_num))
-        report.add(metadata.UserAgent("This is a really large user agent that will need to be word wrapped." * 16))
-
-    actual = report.as_text(text_format)
-    print(actual)
-    expected = (datadir / report_name).read_text()
-    assert actual == expected
-
-
-@pytest.mark.parametrize("text_format,report_name", [
-    ("markdown", "report_foreign.md"),
-    ("simple", "report_foreign.txt"),
-    ("html", "report_foreign.html"),
-])
-def test_foreign_characters(datadir, report, text_format, report_name):
-    with report:
-        report.input_file.description = "SuperMalware Implant"
-        report.add(metadata.Other("JAPAN", "\u30E6\u30FC\u30B6\u30FC\u5225\u30B5\u30A4\u30C8"))
-        report.add(metadata.Other("CHINA", "\u7B80\u4F53\u4E2D\u6587"))
-        report.add(metadata.Other("KOREA", "\uD06C\uB85C\uC2A4 \uD50C\uB7AB\uD3FC\uC73C\uB85C"))
-        report.add(metadata.Other("ISRAEL", "\u05DE\u05D3\u05D5\u05E8\u05D9\u05DD \u05DE\u05D1\u05D5\u05E7\u05E9\u05D9\u05DD"))
-        report.add(metadata.Other("EGYPT", "\u0623\u0641\u0636\u0644 \u0627\u0644\u0628\u062D\u0648\u062B"))
-        report.add(metadata.Other(
-            "RUSSIA",
-            "\u0414\u0435\u0441\u044F\u0442\u0443\u044E \u041C\u0435\u0436\u0434\u0443\u043D\u0430"
-            "\u0440\u043E\u0434\u043D\u0443\u044E"
-        ))
-        report.add(metadata.Other("MATH", "\u222E E\u22C5da = Q,  n \u2192 \u221E, \u2211 f(i) = \u220F g(i)"))
-        report.add(metadata.Other("FRANCE", "fran\u00E7ais langue \u00E9trang\u00E8re"))
-        report.add(metadata.Other("SPAIN", "ma\u00F1ana ol\u00E9"))
-
-    actual = report.as_text(text_format)
-    print(actual)
-    expected = (datadir / report_name).read_text("utf-8")
-    assert actual == expected
+
+import pytest
+
+from mwcp import metadata
+
+
+@pytest.mark.parametrize("text_format,report_name", [
+    ("markdown", "report.md"),
+    ("simple", "report.txt"),
+    ("html", "report.html"),
+])
+def test_basic(datadir, report, metadata_items, text_format, report_name):
+    """
+    Tests each metadata element to ensure they are presented
+    nicely in a report.
+    """
+    with report:
+        report.input_file.description = "SuperMalware Implant"
+        for item in metadata_items:
+            report.add(item)
+        report.add_tag("test", "tagging")
+
+    actual = report.as_text(text_format)
+    print(actual)
+    expected = (datadir / report_name).read_text()
+    assert actual == expected
+
+
+@pytest.mark.parametrize("text_format,report_name", [
+    ("markdown", "report_wordwrap.md"),
+    ("simple", "report_wordwrap.txt"),
+    ("html", "report_wordwrap.html"),
+])
+def test_wordwrap(datadir, report, text_format, report_name):
+    with report:
+        report.input_file.description = "SuperMalware Implant"
+        large_num = int("123"*50)  # Large number that will require word wrapping.
+        report.add(metadata.RSAPublicKey(1234, large_num))
+        report.add(metadata.RSAPrivateKey(
+            1234, large_num, 1234, large_num, large_num, large_num, large_num, large_num))
+        report.add(metadata.UserAgent("This is a really large user agent that will need to be word wrapped." * 16))
+
+    actual = report.as_text(text_format)
+    print(actual)
+    expected = (datadir / report_name).read_text()
+    assert actual == expected
+
+
+@pytest.mark.parametrize("text_format,report_name", [
+    ("markdown", "report_foreign.md"),
+    ("simple", "report_foreign.txt"),
+    ("html", "report_foreign.html"),
+])
+def test_foreign_characters(datadir, report, text_format, report_name):
+    with report:
+        report.input_file.description = "SuperMalware Implant"
+        report.add(metadata.Other("JAPAN", "\u30E6\u30FC\u30B6\u30FC\u5225\u30B5\u30A4\u30C8"))
+        report.add(metadata.Other("CHINA", "\u7B80\u4F53\u4E2D\u6587"))
+        report.add(metadata.Other("KOREA", "\uD06C\uB85C\uC2A4 \uD50C\uB7AB\uD3FC\uC73C\uB85C"))
+        report.add(metadata.Other("ISRAEL", "\u05DE\u05D3\u05D5\u05E8\u05D9\u05DD \u05DE\u05D1\u05D5\u05E7\u05E9\u05D9\u05DD"))
+        report.add(metadata.Other("EGYPT", "\u0623\u0641\u0636\u0644 \u0627\u0644\u0628\u062D\u0648\u062B"))
+        report.add(metadata.Other(
+            "RUSSIA",
+            "\u0414\u0435\u0441\u044F\u0442\u0443\u044E \u041C\u0435\u0436\u0434\u0443\u043D\u0430"
+            "\u0440\u043E\u0434\u043D\u0443\u044E"
+        ))
+        report.add(metadata.Other("MATH", "\u222E E\u22C5da = Q,  n \u2192 \u221E, \u2211 f(i) = \u220F g(i)"))
+        report.add(metadata.Other("FRANCE", "fran\u00E7ais langue \u00E9trang\u00E8re"))
+        report.add(metadata.Other("SPAIN", "ma\u00F1ana ol\u00E9"))
+
+    actual = report.as_text(text_format)
+    print(actual)
+    expected = (datadir / report_name).read_text("utf-8")
+    assert actual == expected
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_string_report.py` & `mwcp-3.9.0/mwcp/tests/test_string_report.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,24 +1,24 @@
-"""
-Tests components of string report extension.
-"""
-
-from mwcp import metadata
-
-
-def test_strings(report):
-    with report:
-        report.add(metadata.DecodedString("hello"))
-        report.add(metadata.DecodedString("world", encryption_key=metadata.EncryptionKey(b"\xde\xad\xbe\xef")))
-    assert report.strings() == ["hello", "world"]
-
-
-def test_string_report_generation(report, datadir):
-    report._external_strings_report = True
-    with report:
-        report.add(metadata.DecodedString("hello"))
-        report.add(metadata.DecodedString("world", encryption_key=metadata.EncryptionKey(b"\xde\xad\xbe\xef")))
-    string_reports = report.get(metadata.File)[:2]
-    assert string_reports[0].name.endswith(f"_strings.json")
-    assert string_reports[1].name.endswith(f"_strings.txt")
-    assert string_reports[0].data.decode("utf8") == (datadir / "strings.json").read_text()
-    assert string_reports[1].data.decode("utf8") == (datadir / "strings.txt").read_text()
+"""
+Tests components of string report extension.
+"""
+
+from mwcp import metadata
+
+
+def test_strings(report):
+    with report:
+        report.add(metadata.DecodedString("hello"))
+        report.add(metadata.DecodedString("world", encryption_key=metadata.EncryptionKey(b"\xde\xad\xbe\xef")))
+    assert report.strings() == ["hello", "world"]
+
+
+def test_string_report_generation(report, datadir):
+    report._external_strings_report = True
+    with report:
+        report.add(metadata.DecodedString("hello"))
+        report.add(metadata.DecodedString("world", encryption_key=metadata.EncryptionKey(b"\xde\xad\xbe\xef")))
+    string_reports = report.get(metadata.File)[:2]
+    assert string_reports[0].name.endswith(f"_strings.json")
+    assert string_reports[1].name.endswith(f"_strings.txt")
+    assert string_reports[0].data.decode("utf8") == (datadir / "strings.json").read_text()
+    assert string_reports[1].data.decode("utf8") == (datadir / "strings.txt").read_text()
```

### Comparing `mwcp-3.8.0/mwcp/tests/test_testing.py` & `mwcp-3.9.0/mwcp/tests/test_testing.py`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,51 +1,51 @@
-
-import mwcp
-from mwcp import testing
-
-
-def test_get_malware_repo_path(tmp_path):
-    """Tests generating malware repo path."""
-    malware_repo = tmp_path / "malware_repo"
-    malware_repo.mkdir()
-    mwcp.config["MALWARE_REPO"] = str(malware_repo)
-
-    test_file = tmp_path / "test.txt"
-    test_file.write_bytes(b"This is some test data!")
-    testing.add_to_malware_repo(test_file)
-
-    expected_path = malware_repo / "fb84" / "fb843efb2ffec987db12e72ca75c9ea2"
-
-    # Test with hashing a file.
-    sample_path = testing.get_path_in_malware_repo(test_file)
-    assert sample_path == expected_path
-
-    # Test with md5
-    sample_path = testing.get_path_in_malware_repo(md5="fb843efb2ffec987db12e72ca75c9ea2")
-    assert sample_path == expected_path
-
-    # Test with partial md5
-    sample_path = testing.get_path_in_malware_repo(md5="fb843e")
-    assert sample_path == expected_path
-
-
-def test_add_to_malware_repo(tmp_path):
-    """Tests adding a file to the malware repo."""
-    malware_repo = tmp_path / "malware_repo"
-    malware_repo.mkdir()
-    test_file = tmp_path / "test.txt"
-    test_file.write_bytes(b"This is some test data!")
-
-    mwcp.config["MALWARE_REPO"] = str(malware_repo)
-    sample_path = testing.add_to_malware_repo(test_file)
-    expected_sample_path = malware_repo / "fb84" / "fb843efb2ffec987db12e72ca75c9ea2"
-    assert sample_path == expected_sample_path
-    assert expected_sample_path.exists()
-    assert expected_sample_path.read_bytes() == test_file.read_bytes()
-
-
-def test_iter_md5s():
-    """Tests obtaining md5s for a parser based on test cases"""
-    mwcp.register_entry_points()
-    mwcp.config["TESTCASE_DIR"] = None  # need to clear any previously set testcase_dir from a previous unit test.
-    assert list(testing.iter_md5s("foo")) == ["f144899b86766688991c5d0d10902f4a"]
-    assert list(testing.iter_md5s("bogus")) == []
+
+import mwcp
+from mwcp import testing
+
+
+def test_get_malware_repo_path(tmp_path):
+    """Tests generating malware repo path."""
+    malware_repo = tmp_path / "malware_repo"
+    malware_repo.mkdir()
+    mwcp.config["MALWARE_REPO"] = str(malware_repo)
+
+    test_file = tmp_path / "test.txt"
+    test_file.write_bytes(b"This is some test data!")
+    testing.add_to_malware_repo(test_file)
+
+    expected_path = malware_repo / "fb84" / "fb843efb2ffec987db12e72ca75c9ea2"
+
+    # Test with hashing a file.
+    sample_path = testing.get_path_in_malware_repo(test_file)
+    assert sample_path == expected_path
+
+    # Test with md5
+    sample_path = testing.get_path_in_malware_repo(md5="fb843efb2ffec987db12e72ca75c9ea2")
+    assert sample_path == expected_path
+
+    # Test with partial md5
+    sample_path = testing.get_path_in_malware_repo(md5="fb843e")
+    assert sample_path == expected_path
+
+
+def test_add_to_malware_repo(tmp_path):
+    """Tests adding a file to the malware repo."""
+    malware_repo = tmp_path / "malware_repo"
+    malware_repo.mkdir()
+    test_file = tmp_path / "test.txt"
+    test_file.write_bytes(b"This is some test data!")
+
+    mwcp.config["MALWARE_REPO"] = str(malware_repo)
+    sample_path = testing.add_to_malware_repo(test_file)
+    expected_sample_path = malware_repo / "fb84" / "fb843efb2ffec987db12e72ca75c9ea2"
+    assert sample_path == expected_sample_path
+    assert expected_sample_path.exists()
+    assert expected_sample_path.read_bytes() == test_file.read_bytes()
+
+
+def test_iter_md5s():
+    """Tests obtaining md5s for a parser based on test cases"""
+    mwcp.register_entry_points()
+    mwcp.config["TESTCASE_DIR"] = None  # need to clear any previously set testcase_dir from a previous unit test.
+    assert list(testing.iter_md5s("foo")) == ["f144899b86766688991c5d0d10902f4a"]
+    assert list(testing.iter_md5s("bogus")) == []
```

### Comparing `mwcp-3.8.0/mwcp/tools/server/__init__.py` & `mwcp-3.9.0/mwcp/tools/server/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-from __future__ import absolute_import
-
-import flask as f
-
-from . import server
-
-
-def create_app(extra_config=None):
-    """
-    Create a Flask app instance for the MWCP API.
-
-    :param dict extra_config: Extra configuration options to add to the app
-    :return: Flask app for MWCP API
-    """
-    app = f.Flask(__name__)
-
-    app.config.setdefault("MENU_LINKS", []).extend(
-        [
-            {"name": "Upload", "endpoint": "mwcp.upload"},
-            {"name": "Parsers", "endpoint": "mwcp.parsers_list"},
-        ]
-    )
-
-    if extra_config:
-        app.config.from_mapping(extra_config)
-
-    server.init_app(app)
-    app.register_blueprint(server.bp)
-
-    return app
+from __future__ import absolute_import
+
+import flask as f
+
+from . import server
+
+
+def create_app(extra_config=None):
+    """
+    Create a Flask app instance for the MWCP API.
+
+    :param dict extra_config: Extra configuration options to add to the app
+    :return: Flask app for MWCP API
+    """
+    app = f.Flask(__name__)
+
+    app.config.setdefault("MENU_LINKS", []).extend(
+        [
+            {"name": "Upload", "endpoint": "mwcp.upload"},
+            {"name": "Parsers", "endpoint": "mwcp.parsers_list"},
+        ]
+    )
+
+    if extra_config:
+        app.config.from_mapping(extra_config)
+
+    server.init_app(app)
+    app.register_blueprint(server.bp)
+
+    return app
```

### Comparing `mwcp-3.8.0/mwcp/tools/server/server.py` & `mwcp-3.9.0/mwcp/tools/server/server.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,469 +1,481 @@
-"""
-DC3-MWCP server--simple REST API using the Flask framework.
-"""
-from __future__ import absolute_import, print_function
-
-import base64
-import hashlib
-import io
-import json
-import logging
-import os
-import zipfile
-from copy import copy
-
-import flask
-import mwcp
-import mwcp.parsers
-import pygments
-import pygments.formatter
-import pygments.lexer
-from mwcp.utils import logutil
-from pygments.formatters.html import HtmlFormatter
-from pygments.lexers.data import JsonLexer
-from pygments.lexers.special import TextLexer
-from werkzeug.utils import secure_filename
-
-from mwcp.report import Report
-from mwcp.stix.report_writer import STIXWriter
-
-bp = flask.Blueprint("mwcp", __name__)
-
-
-def init_app(app):
-    """Initialize the Flask application and MWCP"""
-    # Initialize MWCP
-    mwcp.config.load(os.getenv("MWCP_CONFIG", None))
-    mwcp.register_entry_points()
-
-
-@bp.route("/run_parser/<parser>", methods=["POST"], strict_slashes=False)
-@bp.route("/run_parser", methods=["POST"], strict_slashes=False)
-def run_parser(parser=None):
-    """
-    Execute a parser and return the results.
-
-    The file must be uploaded in the field "data".
-
-    The parser must be specified in the `parser` field, parameter, or in the resource name.
-
-    The field `output` may be set to `zip` to download a ZIP
-    file of the results and extracted components. By default the
-    output is JSON.
-
-    The field  or parameter `highlight` may also be set to return
-    a formatted HTML page with the results.
-
-    All fields (except `data`) may be set as URL parameters as well.
-
-    :param str parser: The name of the parser to run
-    """
-    return _build_parser_response(parser)
-
-
-@bp.route("/run_parsers/<path:parsers>", methods=["POST"])
-def run_parsers(parsers):
-    """
-    Execute multiple parsers on the same input file.
-
-    NOTE: The way this function works may change in a future version
-
-    :param str parsers: List of parsers to run
-    """
-    output = {}
-
-    dep_warning = (
-        "Running multiple parsers in a single request will be changed future version."
-    )
-    flask.current_app.logger.warning(dep_warning)
-    output.setdefault("errors", []).append(dep_warning)
-
-    datafile = flask.request.files.get("data")
-    if datafile:
-        data = datafile.read()
-        flask.current_app.logger.info(
-            "run_parsers %s %s %s",
-            parsers,
-            datafile.filename,
-            hashlib.md5(data).hexdigest(),
-        )
-        for parser in parsers.split("/"):
-            if parser:
-                # TODO: Determine if it should be possible to specify the output format and have file data not be included
-                report = _run_parser(parser, data=data)
-                output[parser] = _format_report(report)
-    else:
-        output.setdefault("errors", []).append("No input file provided")
-        flask.current_app.logger.error("run_parsers %s no input file", parsers)
-    return flask.jsonify(output)
-
-
-@bp.route("/parsers")
-def parsers_list():
-    """
-    List of configured parsers with names, sources, authors, and descriptions.
-
-    Normally an HTML table, but if `application/json` is the best mimetype set
-    in the `Accept` header, the response will be in JSON.
-    """
-    name_filter = flask.request.args.get("name", type=str)
-    source_filter = flask.request.args.get("source", type=str)
-
-    headers = ("Name", "Source", "Author", "Description")
-    parsers_info = mwcp.get_parser_descriptions(name=name_filter, source=source_filter)
-
-    if flask.request.accept_mimetypes.best == "application/json":
-        return flask.jsonify(
-            {"parsers": [parser_info._asdict() for parser_info in parsers_info]}
-        )
-
-    flask.g.title = "Parsers"
-    return flask.render_template("parsers.html", headers=headers, parsers=parsers_info)
-
-
-@bp.route("/upload")
-def upload():
-    """Upload page"""
-    flask.g.title = "Upload"
-    parsers_info = mwcp.get_parser_descriptions()
-    return flask.render_template("upload.html", parsers=parsers_info)
-
-
-@bp.route("/descriptions")
-def descriptions():
-    """
-    List descriptions of parser modules.
-    This is for backwards compatibility purposes.
-    Always a JSON response.
-    """
-    return flask.jsonify(
-        [
-            (parser_info.name, parser_info.author, parser_info.description)
-            for parser_info in mwcp.get_parser_descriptions()
-        ]
-    )
-
-
-@bp.route("/schema.json")
-def schema():
-    """
-    Provides JSON schema for report output.
-    """
-    return mwcp.schema()
-
-
-@bp.route("/logs")
-def logs():
-    """
-    Endpoint for all logs from the current session.
-
-    Always a JSON response.
-
-    This can be disabled with the ``DISABLE_LOGS_ENDPOINT`` key
-    in the app config.
-    """
-    if flask.current_app.config.get("DISABLE_LOGS_ENDPOINT"):
-        return (
-            flask.jsonify({"errors": ["Logs endpoint has been disabled by configuration"]}),
-            403,
-        )
-
-    return flask.jsonify({"errors": ["Logs endpoint is no longer supported."]})
-
-
-@bp.route("/")
-def default():
-    """
-    Homepage endpoint.
-    """
-    return flask.render_template("base.html")
-
-
-class RequestFilter(logging.Filter):
-    """
-    Filter to lock a handler to a specific request.
-
-    This is required for multi-threading the server.
-    """
-
-    def __init__(self, request):
-        super().__init__("request_filter")
-        # The `request` is usually a proxy to the real request
-        if hasattr(request, "_get_current_object"):
-            request = request._get_current_object()
-        self._request = request
-
-    def filter(self, record):
-        # Ensure the proxied request is our locked request
-        # And the record is created in a request context to begin with
-        if not flask.has_request_context():
-            return False
-        return flask.request == self._request
-
-
-def _legacy():
-    """Whether we are using legacy or new metadata schema."""
-    legacy = flask.request.values.get("legacy", default=True)
-    if isinstance(legacy, str):
-        legacy = legacy.lower() == "true"
-    return legacy
-
-
-def _include_logs():
-    """Whether to include logs in parse report."""
-    include_logs = flask.request.values.get("include_logs", default=True)
-    if isinstance(include_logs, str):
-        include_logs = include_logs.lower() == "true"
-    return include_logs
-
-
-def _external_strings():
-    """Whether to create external string reports for reported decoded strings."""
-    external_strings = flask.request.values.get("external_strings", default=False)
-    if isinstance(external_strings, str):
-        external_strings = external_strings.lower() == "true"
-    return external_strings
-
-
-def _highlight(data, is_json=True):
-    """
-    Render an HTML page with a highlighted JSON string or plain text.
-
-    :param data: Data to highlight, should be a string or JSON-able object
-    :param is_json: If the data is a JSON string or can be converted into such
-    :return: Response object with rendered template with highlighted data
-    """
-    if is_json and not isinstance(data, (str, bytes)):
-        data = json.dumps(data, indent=2)
-
-    # Pygments highlighting
-    lexer = JsonLexer() if is_json else TextLexer()
-    formatter = HtmlFormatter()
-    highlight = pygments.highlight(data, lexer, formatter)
-
-    return flask.render_template(
-        "results.html", highlight=highlight, extra_css=formatter.get_style_defs()
-    )
-
-
-def _build_zip(parser_results):
-    """
-    Build a ZIP file containing the results and artifacts of a parser run.
-
-    Expects the **full** parser results, including ``output_text`` and ``outputfile`` keys.
-
-    The folder structure looks like this:
-
-    .. code_block::
-
-        mwcp_server.zip
-        |
-        |-results.json
-        |-results.txt (this is ``output_text``)
-        |
-        |---files
-            |
-            |- ExtractedComponent1.exe
-            |- ExtractedComponent2.dll
-
-
-    :param parser_results:
-    :return: A BytesIO buffer containing a ZIP file
-    :rtype: io.BytesIO
-    """
-    zip_buf = io.BytesIO()
-    legacy = _legacy()
-
-    if legacy:
-        encoded_files = parser_results.pop("outputfile", [])
-    else:
-        encoded_files = []
-        metadata_list = list(parser_results["metadata"])
-        for element in metadata_list:
-            if element["type"] == "file":
-                encoded_files.append(element)
-                parser_results["metadata"].remove(element)
-
-    output_text = parser_results.pop("output_text", "")
-
-    zf = zipfile.ZipFile(
-        zip_buf, mode="w", compression=zipfile.ZIP_DEFLATED, allowZip64=True
-    )
-    with zf:
-        for file_obj in encoded_files:
-            if legacy:
-                filename = file_obj[0]
-                base64_data = file_obj[3]
-            else:
-                filename = file_obj["name"]
-                base64_data = file_obj["data"]
-            file_data = base64.b64decode(base64_data)
-            zf.writestr(os.path.join("files", filename), file_data)
-
-        zf.writestr("results.json", json.dumps(parser_results, indent=2))
-
-        if not isinstance(output_text, bytes):
-            output_text = output_text.encode("ascii", "backslashreplace")
-        zf.writestr("results.txt", output_text)
-
-    zip_buf.seek(0)
-    return zip_buf
-
-
-def _build_parser_response(parser=None, **kwargs):
-    """
-    Build the response object for a parser request.
-    This function handles the form fields and/or URL parameters and
-    returns an appropriate response object. This can be overridden
-    (e.g. by specific endpoints) as a parameter.
-
-    :param str parser: The name of the parser to run. Pulled from `parser`
-        URL parameter or form field if not specified.
-    :return: Flask response object
-    """
-    output = kwargs.get("output", "") or flask.request.values.get("output", "json")
-    output = output.lower()
-    if output not in ("json", "text", "zip", "stix"):
-        flask.current_app.logger.warning(
-            "Unknown output type received: '{}'".format(output)
-        )
-        output = "json"
-    highlight = kwargs.get("highlight") or flask.request.values.get("highlight")
-    include_file_data = not (kwargs.get("no_file_data") or flask.request.values.get("no_file_data"))
-
-    if not highlight:
-        json_response = flask.jsonify
-    else:
-        json_response = _highlight
-
-    report, response_code = _run_parser_request(parser, include_file_data=include_file_data)
-
-    if response_code != 200:
-        parser_results = _format_report(report)
-        return json_response(parser_results), response_code
-
-    if output == "stix":
-        writer = STIXWriter()
-        report.as_stix(writer)
-
-        if highlight:
-            return json_response(writer.serialize())
-        else:
-            return writer.serialize()
-    else:
-        parser_results = _format_report(report)
-
-    # A ZIP returns both JSON and plain text, and has no highlighting
-    if output == "zip":
-        filename = secure_filename(flask.request.files.get("data").filename)
-        zip_buf = _build_zip(parser_results)
-        return flask.send_file(
-            zip_buf, "application/zip", True, "{}_mwcp_output.zip".format(filename)
-        )
-
-    if highlight:
-        output_text = parser_results.pop("output_text", "")
-        if output == "text":
-            return _highlight(output_text, False)
-
-    return json_response(parser_results)
-
-
-def _format_report(report: Report):
-    if _legacy():
-        output = report.as_dict_legacy()
-    else:
-        output = report.as_json_dict()
-
-    output["output_text"] = report.as_text()
-
-    return output
-
-
-def _run_parser_request(parser=None, upload_name="data", include_file_data=True) -> (Report, int):
-    """
-    Run a parser based on the data in the current request.
-
-    This function handles getting the file from the form field, as well as
-    the parser from either a form field or url parameter if not explicitly set.
-
-    The results from the parser run (a ``dict``) is returned as well as an
-    appropriate HTTP status code. Specifically, a 2XX if the parser ran
-    successfully, a 4XX if there is a problem with the request (e.g no
-    file) or a 5XX if there was a problem with running the parser.
-
-    :param str parser: The name of the parser to run. Pulled from `parser`
-        URL parameter or form field if not specified.
-    :param str upload_name: The name of the field of the uploaded sample
-    :param boolean include_file_data: If the parser should include file data
-    :return: The results from the parser run and/or errors and an appropriate status code
-    :rtype: (Report, int)
-    """
-    errors = []
-
-    parser = parser or flask.request.values.get("parser")
-    if not parser:
-        errors.append("No parser specified")
-
-    uploaded_file = flask.request.files.get(upload_name)
-    if not uploaded_file:
-        flask.current_app.logger.error(
-            "Error running parser '{}' no input file".format(parser)
-        )
-        errors.append("No input file provided")
-
-    # Client errors
-    if errors:
-        report = Report()
-        for error in errors:
-            flask.current_app.logger.error(error)
-        return report, 400
-
-    data = uploaded_file.read()
-    flask.current_app.logger.info(
-        "Request for parser '%s' on '%s' %s",
-        parser,
-        secure_filename(uploaded_file.filename),
-        hashlib.md5(data).hexdigest(),
-    )
-    report = _run_parser(parser, data=data, include_file_data=include_file_data)
-
-    return report, 200
-
-
-def _run_parser(name, data=b"", include_file_data=True) -> Report:
-    """
-    Run an MWCP parser on given data.
-
-    Logs to a list handler that is locked to the current request.
-
-    :param str name: Name of the parser to run
-    :param bytes data: Data to run parser on
-    :param boolean include_file_data: If the parser should include file data
-    :return: Output from the reporter
-    :rtype: Report
-    """
-    report = Report()
-    log_filter = None
-    try:
-        include_logs = _include_logs()
-        if include_logs:
-            log_filter = RequestFilter(flask.request)
-
-        # Tell mwcp to not include logs, since we are going to collect them.
-        report = mwcp.run(
-            name,
-            data=data,
-            include_file_data=include_file_data,
-            include_logs=include_logs,
-            log_filter=log_filter,
-            external_strings_report=_external_strings(),
-        )
-
-    except Exception as e:
-        if flask.has_app_context():
-            flask.current_app.logger.error(
-                "Error running parser '%s': %s", name, str(e)
-            )
-    finally:
-        return report
+"""
+DC3-MWCP server--simple REST API using the Flask framework.
+"""
+from __future__ import absolute_import, print_function
+
+import base64
+import hashlib
+import io
+import json
+import logging
+import os
+import zipfile
+from copy import copy
+
+import flask
+import mwcp
+import mwcp.parsers
+import pygments
+import pygments.formatter
+import pygments.lexer
+from mwcp.utils import logutil
+from pygments.formatters.html import HtmlFormatter
+from pygments.lexers.data import JsonLexer
+from pygments.lexers.special import TextLexer
+from werkzeug.utils import secure_filename
+
+from mwcp.report import Report
+from mwcp.stix.report_writer import STIXWriter
+
+bp = flask.Blueprint("mwcp", __name__)
+YARA_MATCH = "-- YARA Match --"
+
+
+def init_app(app):
+    """Initialize the Flask application and MWCP"""
+    # Initialize MWCP
+    mwcp.config.load(os.getenv("MWCP_CONFIG", None))
+    mwcp.register_entry_points()
+
+
+@bp.route("/run_parser/<parser>", methods=["POST"], strict_slashes=False)
+@bp.route("/run_parser", methods=["POST"], strict_slashes=False)
+def run_parser(parser=None):
+    """
+    Execute a parser and return the results.
+
+    The file must be uploaded in the field "data".
+
+    The parser must be specified in the `parser` field, parameter, or in the resource name.
+
+    The field `output` may be set to `zip` to download a ZIP
+    file of the results and extracted components. By default the
+    output is JSON.
+
+    The field  or parameter `highlight` may also be set to return
+    a formatted HTML page with the results.
+
+    All fields (except `data`) may be set as URL parameters as well.
+
+    :param str parser: The name of the parser to run
+    """
+    return _build_parser_response(parser)
+
+
+@bp.route("/run_parsers/<path:parsers>", methods=["POST"])
+def run_parsers(parsers):
+    """
+    Execute multiple parsers on the same input file.
+
+    NOTE: The way this function works may change in a future version
+
+    :param str parsers: List of parsers to run
+    """
+    output = {}
+
+    dep_warning = (
+        "Running multiple parsers in a single request will be changed future version."
+    )
+    flask.current_app.logger.warning(dep_warning)
+    output.setdefault("errors", []).append(dep_warning)
+
+    datafile = flask.request.files.get("data")
+    if datafile:
+        data = datafile.read()
+        flask.current_app.logger.info(
+            "run_parsers %s %s %s",
+            parsers,
+            datafile.filename,
+            hashlib.md5(data).hexdigest(),
+        )
+        for parser in parsers.split("/"):
+            if parser:
+                # TODO: Determine if it should be possible to specify the output format and have file data not be included
+                report = _run_parser(parser, data=data)
+                output[parser] = _format_report(report)
+    else:
+        output.setdefault("errors", []).append("No input file provided")
+        flask.current_app.logger.error("run_parsers %s no input file", parsers)
+    return flask.jsonify(output)
+
+
+@bp.route("/parsers")
+def parsers_list():
+    """
+    List of configured parsers with names, sources, authors, and descriptions.
+
+    Normally an HTML table, but if `application/json` is the best mimetype set
+    in the `Accept` header, the response will be in JSON.
+    """
+    name_filter = flask.request.args.get("name", type=str)
+    source_filter = flask.request.args.get("source", type=str)
+
+    headers = ("Name", "Source", "Author", "Description")
+    parsers_info = mwcp.get_parser_descriptions(name=name_filter, source=source_filter)
+
+    if flask.request.accept_mimetypes.best == "application/json":
+        return flask.jsonify(
+            {"parsers": [parser_info._asdict() for parser_info in parsers_info]}
+        )
+
+    flask.g.title = "Parsers"
+    return flask.render_template("parsers.html", headers=headers, parsers=parsers_info)
+
+
+@bp.route("/upload")
+def upload():
+    """Upload page"""
+    flask.g.title = "Upload"
+    parsers = [parser.name for parser in mwcp.get_parser_descriptions()]
+    # Add yara match option if user has setup a yara repo.
+    if mwcp.config.get("YARA_REPO"):
+        parsers = [YARA_MATCH, *parsers]
+    return flask.render_template("upload.html", parsers=parsers)
+
+
+@bp.route("/descriptions")
+def descriptions():
+    """
+    List descriptions of parser modules.
+    This is for backwards compatibility purposes.
+    Always a JSON response.
+    """
+    return flask.jsonify(
+        [
+            (parser_info.name, parser_info.author, parser_info.description)
+            for parser_info in mwcp.get_parser_descriptions()
+        ]
+    )
+
+
+@bp.route("/schema.json")
+def schema():
+    """
+    Provides JSON schema for report output.
+    """
+    return mwcp.schema()
+
+
+@bp.route("/logs")
+def logs():
+    """
+    Endpoint for all logs from the current session.
+
+    Always a JSON response.
+
+    This can be disabled with the ``DISABLE_LOGS_ENDPOINT`` key
+    in the app config.
+    """
+    if flask.current_app.config.get("DISABLE_LOGS_ENDPOINT"):
+        return (
+            flask.jsonify({"errors": ["Logs endpoint has been disabled by configuration"]}),
+            403,
+        )
+
+    return flask.jsonify({"errors": ["Logs endpoint is no longer supported."]})
+
+
+@bp.route("/")
+def default():
+    """
+    Homepage endpoint.
+    """
+    return flask.render_template("base.html")
+
+
+class RequestFilter(logging.Filter):
+    """
+    Filter to lock a handler to a specific request.
+
+    This is required for multi-threading the server.
+    """
+
+    def __init__(self, request):
+        super().__init__("request_filter")
+        # The `request` is usually a proxy to the real request
+        if hasattr(request, "_get_current_object"):
+            request = request._get_current_object()
+        self._request = request
+
+    def filter(self, record):
+        # Ensure the proxied request is our locked request
+        # And the record is created in a request context to begin with
+        if not flask.has_request_context():
+            return False
+        return flask.request == self._request
+
+
+def _get_option(name, default=False) -> bool:
+    """Obtains flask request boolean option."""
+    option = flask.request.values.get(name, default=default)
+    if isinstance(option, str):
+        option = option.lower() == "true"
+    return option
+
+
+def _legacy():
+    """Whether we are using legacy or new metadata schema."""
+    return _get_option("legacy", True)
+
+
+def _include_logs():
+    """Whether to include logs in parse report."""
+    return _get_option("include_logs", True)
+
+
+def _external_strings():
+    """Whether to create external string reports for reported decoded strings."""
+    return _get_option("external_strings")
+
+
+def _recursive():
+    """
+    Whether to recursively process unidentified files with YARA matched parsers.
+    (Yara repo must be setup for this option to be active.)
+    """
+    return _get_option("recursive", True)
+
+
+def _highlight(data, is_json=True):
+    """
+    Render an HTML page with a highlighted JSON string or plain text.
+
+    :param data: Data to highlight, should be a string or JSON-able object
+    :param is_json: If the data is a JSON string or can be converted into such
+    :return: Response object with rendered template with highlighted data
+    """
+    if is_json and not isinstance(data, (str, bytes)):
+        data = json.dumps(data, indent=2)
+
+    # Pygments highlighting
+    lexer = JsonLexer() if is_json else TextLexer()
+    formatter = HtmlFormatter()
+    highlight = pygments.highlight(data, lexer, formatter)
+
+    return flask.render_template(
+        "results.html", highlight=highlight, extra_css=formatter.get_style_defs()
+    )
+
+
+def _build_zip(parser_results):
+    """
+    Build a ZIP file containing the results and artifacts of a parser run.
+
+    Expects the **full** parser results, including ``output_text`` and ``outputfile`` keys.
+
+    The folder structure looks like this:
+
+    .. code_block::
+
+        mwcp_server.zip
+        |
+        |-results.json
+        |-results.txt (this is ``output_text``)
+        |
+        |---files
+            |
+            |- ExtractedComponent1.exe
+            |- ExtractedComponent2.dll
+
+
+    :param parser_results:
+    :return: A BytesIO buffer containing a ZIP file
+    :rtype: io.BytesIO
+    """
+    zip_buf = io.BytesIO()
+    legacy = _legacy()
+
+    if legacy:
+        encoded_files = parser_results.pop("outputfile", [])
+    else:
+        encoded_files = []
+        metadata_list = list(parser_results["metadata"])
+        for element in metadata_list:
+            if element["type"] == "file":
+                encoded_files.append(element)
+                parser_results["metadata"].remove(element)
+
+    output_text = parser_results.pop("output_text", "")
+
+    zf = zipfile.ZipFile(
+        zip_buf, mode="w", compression=zipfile.ZIP_DEFLATED, allowZip64=True
+    )
+    with zf:
+        for file_obj in encoded_files:
+            if legacy:
+                filename = file_obj[0]
+                base64_data = file_obj[3]
+            else:
+                filename = file_obj["name"]
+                base64_data = file_obj["data"]
+            file_data = base64.b64decode(base64_data)
+            zf.writestr(os.path.join("files", filename), file_data)
+
+        zf.writestr("results.json", json.dumps(parser_results, indent=2))
+
+        if not isinstance(output_text, bytes):
+            output_text = output_text.encode("ascii", "backslashreplace")
+        zf.writestr("results.txt", output_text)
+
+    zip_buf.seek(0)
+    return zip_buf
+
+
+def _build_parser_response(parser=None, **kwargs):
+    """
+    Build the response object for a parser request.
+    This function handles the form fields and/or URL parameters and
+    returns an appropriate response object. This can be overridden
+    (e.g. by specific endpoints) as a parameter.
+
+    :param str parser: The name of the parser to run. Pulled from `parser`
+        URL parameter or form field if not specified.
+    :return: Flask response object
+    """
+    output = kwargs.get("output", "") or flask.request.values.get("output", "json")
+    output = output.lower()
+    if output not in ("json", "text", "zip", "stix"):
+        flask.current_app.logger.warning(
+            "Unknown output type received: '{}'".format(output)
+        )
+        output = "json"
+    highlight = kwargs.get("highlight") or flask.request.values.get("highlight")
+    include_file_data = not (kwargs.get("no_file_data") or flask.request.values.get("no_file_data"))
+
+    if not highlight:
+        json_response = flask.jsonify
+    else:
+        json_response = _highlight
+
+    report, response_code = _run_parser_request(parser, include_file_data=include_file_data)
+
+    if response_code != 200:
+        parser_results = _format_report(report)
+        return json_response(parser_results), response_code
+
+    if output == "stix":
+        writer = STIXWriter()
+        report.as_stix(writer)
+
+        if highlight:
+            return json_response(writer.serialize())
+        else:
+            return writer.serialize()
+    else:
+        parser_results = _format_report(report)
+
+    # A ZIP returns both JSON and plain text, and has no highlighting
+    if output == "zip":
+        filename = secure_filename(flask.request.files.get("data").filename)
+        zip_buf = _build_zip(parser_results)
+        return flask.send_file(
+            zip_buf, "application/zip", True, "{}_mwcp_output.zip".format(filename)
+        )
+
+    if highlight:
+        output_text = parser_results.pop("output_text", "")
+        if output == "text":
+            return _highlight(output_text, False)
+
+    return json_response(parser_results)
+
+
+def _format_report(report: Report):
+    if _legacy():
+        output = report.as_dict_legacy()
+    else:
+        output = report.as_json_dict()
+
+    output["output_text"] = report.as_text()
+
+    return output
+
+
+def _run_parser_request(parser=None, upload_name="data", include_file_data=True) -> (Report, int):
+    """
+    Run a parser based on the data in the current request.
+
+    This function handles getting the file from the form field, as well as
+    the parser from either a form field or url parameter if not explicitly set.
+
+    The results from the parser run (a ``dict``) is returned as well as an
+    appropriate HTTP status code. Specifically, a 2XX if the parser ran
+    successfully, a 4XX if there is a problem with the request (e.g no
+    file) or a 5XX if there was a problem with running the parser.
+
+    :param str parser: The name of the parser to run. Pulled from `parser`
+        URL parameter or form field if not specified.
+        Can be blank to use YARA matching.
+    :param str upload_name: The name of the field of the uploaded sample
+    :param boolean include_file_data: If the parser should include file data
+    :return: The results from the parser run and/or errors and an appropriate status code
+    :rtype: (Report, int)
+    """
+    errors = []
+
+    parser = parser or flask.request.values.get("parser")
+
+    uploaded_file = flask.request.files.get(upload_name)
+    if not uploaded_file:
+        flask.current_app.logger.error(
+            f"Error running parser '{parser or '-'}' no input file"
+        )
+        errors.append("No input file provided")
+
+    # Client errors
+    if errors:
+        report = Report()
+        for error in errors:
+            flask.current_app.logger.error(error)
+        return report, 400
+
+    data = uploaded_file.read()
+    flask.current_app.logger.info(
+        "Request for parser '%s' on '%s' %s",
+        parser,
+        secure_filename(uploaded_file.filename),
+        hashlib.md5(data).hexdigest(),
+    )
+    if parser == YARA_MATCH:
+        parser = None
+    report = _run_parser(parser, data=data, include_file_data=include_file_data)
+
+    return report, 200
+
+
+def _run_parser(name, data=b"", include_file_data=True) -> Report:
+    """
+    Run an MWCP parser on given data.
+
+    Logs to a list handler that is locked to the current request.
+
+    :param str name: Name of the parser to run (or None for YARA match)
+    :param bytes data: Data to run parser on
+    :param boolean include_file_data: If the parser should include file data
+    :return: Output from the reporter
+    :rtype: Report
+    """
+    report = Report()
+    log_filter = None
+    try:
+        include_logs = _include_logs()
+        if include_logs:
+            log_filter = RequestFilter(flask.request)
+
+        report = mwcp.run(
+            name,
+            data=data,
+            recursive=_recursive(),
+            include_file_data=include_file_data,
+            include_logs=include_logs,
+            log_filter=log_filter,
+            external_strings_report=_external_strings(),
+        )
+
+    except Exception as e:
+        if flask.has_app_context():
+            flask.current_app.logger.error(
+                "Error running parser '%s': %s", name, str(e)
+            )
+    finally:
+        return report
```

### Comparing `mwcp-3.8.0/mwcp/tools/server/templates/base.html` & `mwcp-3.9.0/mwcp/tools/server/templates/base.html`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,37 +1,37 @@
-<!DOCTYPE html>
-<html lang="en">
-<head>
-    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
-
-    <style type="text/css">
-        {{ extra_css|safe }}
-    </style>
-
-    <meta charset="UTF-8">
-    <title>{{ g.title + " |" if g.title else "" }} {{ config.get('SERVICE_NAME', 'DC3-MWCP Service') }}</title>
-</head>
-<body>
-<div class="container">
-    <div class="navbar">
-        <ul>
-            <li><a href="/">Home</a></li>
-            {% for link in config.get('MENU_LINKS', []) %}
-                <li><a href="{{ link.url or url_for(link.endpoint) }}">{{ link.name }}</a></li>
-            {% endfor %}
-        </ul>
-    </div>
-    <h2>{{ g.title|default(config.get('SERVICE_NAME', 'DC3-MWCP Service')) }}</h2>
-
-    {% block content %}{% endblock %}
-
-    <footer class='footer'>
-        {% block footer %}
-        <p>
-            {{ config.get('SERVICE_NAME', 'DC3-MWCP Service') }}.
-        </p>
-        {% endblock %}
-    </footer>
-</div>
-
-</body>
+<!DOCTYPE html>
+<html lang="en">
+<head>
+    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
+
+    <style type="text/css">
+        {{ extra_css|safe }}
+    </style>
+
+    <meta charset="UTF-8">
+    <title>{{ g.title + " |" if g.title else "" }} {{ config.get('SERVICE_NAME', 'DC3-MWCP Service') }}</title>
+</head>
+<body>
+<div class="container">
+    <div class="navbar">
+        <ul>
+            <li><a href="/">Home</a></li>
+            {% for link in config.get('MENU_LINKS', []) %}
+                <li><a href="{{ link.url or url_for(link.endpoint) }}">{{ link.name }}</a></li>
+            {% endfor %}
+        </ul>
+    </div>
+    <h2>{{ g.title|default(config.get('SERVICE_NAME', 'DC3-MWCP Service')) }}</h2>
+
+    {% block content %}{% endblock %}
+
+    <footer class='footer'>
+        {% block footer %}
+        <p>
+            {{ config.get('SERVICE_NAME', 'DC3-MWCP Service') }}.
+        </p>
+        {% endblock %}
+    </footer>
+</div>
+
+</body>
 </html>
```

### Comparing `mwcp-3.8.0/mwcp/tools/server/templates/upload.html` & `mwcp-3.9.0/mwcp/tools/server/templates/upload.html`

 * *Files 15% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-{% extends "base.html" %}
-
-{% block content %}
-    <form action="/run_parser" method="post" enctype="multipart/form-data">
-        <fieldset>
-        <label for="upload-file">File</label>
-        <input id="upload-file" type="file" name="data" required/>
-        <label for="parser">Parser</label>
-        <select id="parser" name="parser">
-        {% for parser in parsers %}
-            <option value="{{parser.name}}">{{parser.name}}</option>
-        {% endfor %}
-        </select>
-        <label for="options">Output Format</label>
-        <fieldset id="options">
-        <input id="request-text" type="radio" name="output" value="text" checked>
-        <label class="label-inline" for="request-text">Plain text</label>
-        <br />
-        <input id="request-json" type="radio" name="output" value="json">
-        <label class="label-inline" for="request-json">JSON</label>
-        <br />
-        <input id="request-zip" type="radio" name="output" value="zip">
-        <label class="label-inline" for="request-zip">ZIP</label>
-        <br />
-        <input id="request-stix" type="radio" name="output" value="stix">
-        <label class="label-inline" for="request-zip">STIX 2.1</label>
-        </fieldset>
-        <input type="hidden" id="highlight" name="highlight" value="True">
-        <input type="submit" value="Upload">
-        </fieldset>
-    </form>
+{% extends "base.html" %}
+
+{% block content %}
+    <form action="/run_parser" method="post" enctype="multipart/form-data">
+        <fieldset>
+        <label for="upload-file">File</label>
+        <input id="upload-file" type="file" name="data" required/>
+        <label for="parser">Parser</label>
+        <select id="parser" name="parser">
+        {% for parser in parsers %}
+            <option value="{{parser}}">{{parser}}</option>
+        {% endfor %}
+        </select>
+        <label for="options">Output Format</label>
+        <fieldset id="options">
+        <input id="request-text" type="radio" name="output" value="text" checked>
+        <label class="label-inline" for="request-text">Plain text</label>
+        <br />
+        <input id="request-json" type="radio" name="output" value="json">
+        <label class="label-inline" for="request-json">JSON</label>
+        <br />
+        <input id="request-zip" type="radio" name="output" value="zip">
+        <label class="label-inline" for="request-zip">ZIP</label>
+        <br />
+        <input id="request-stix" type="radio" name="output" value="stix">
+        <label class="label-inline" for="request-zip">STIX 2.1</label>
+        </fieldset>
+        <input type="hidden" id="highlight" name="highlight" value="True">
+        <input type="submit" value="Upload">
+        </fieldset>
+    </form>
 {% endblock %}
```

### Comparing `mwcp-3.8.0/mwcp/tools/update_legacy_tests.py` & `mwcp-3.9.0/mwcp/tools/update_legacy_tests.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,199 +1,199 @@
-"""
-This is a small helper script for converting legacy parser tests using the flat
-metadata schema into the newer schema.
-"""
-
-import logging
-import os
-import pathlib
-import sys
-
-import click
-
-import mwcp
-from mwcp.tester import Tester  # old interface
-from mwcp import testing        # new interface
-
-
-@click.command(context_settings={"help_option_names": ["-h", "--help"]})
-@click.option("-d", "--debug", is_flag=True, help="Enables DEBUG level logs.")
-@click.option("-v", "--verbose", is_flag=True, help="Enables INFO level logs.")
-@click.option(
-    "-c",
-    "--config",
-    "config_path",
-    type=click.Path(exists=True, dir_okay=False),
-    help="File path to configuration file.",
-    default=mwcp.config.user_path,
-    show_default=True,
-    envvar="MWCP_CONFIG",
-    show_envvar=True,
-)
-@click.option(
-    "--parser-dir",
-    type=click.Path(exists=True, file_okay=False),
-    help="Optional extra parser directory.",
-)
-@click.option(
-    "--parser-config",
-    type=click.Path(exists=True, dir_okay=False),
-    help="Optional parser configuration file to use with extra parser directory.",
-)
-@click.option(
-    "--parser-source",
-    help="Set a default parsers source to use. If not provided parsers from all sources will be available.",
-)
-@click.option(
-    "-t",
-    "--testcase-dir",
-    type=click.Path(file_okay=False),
-    help="Directory containing JSON test case files. (defaults to a "
-    '"tests" directory located within the parsers directory)',
-)
-@click.option(
-    "-m",
-    "--malware-repo",
-    type=click.Path(file_okay=False),
-    help="Directory containing malware samples used for testing.",
-)
-@click.option(
-    "--force", is_flag=True,
-    help="Force test case creation even when errors are encountered."
-)
-@click.option(
-    "--update-existing", is_flag=True,
-    help="Whether to update already converted tests cases.",
-)
-@click.option(
-    "--continue-on-failure", is_flag=True,
-    help="Whether to continue updating test cases if a legacy test case fails."
-)
-@click.option(
-    "--remove-old", is_flag=True,
-    help="Remove old test cases as new ones are created."
-)
-@click.option(
-    "--skip-testing", is_flag=True,
-    help="Don't run original test cases before updating."
-)
-@click.argument("parser", required=False)
-def main(debug, verbose, config_path, parser_dir, parser_config, parser_source,
-         testcase_dir, malware_repo, force, update_existing,
-         continue_on_failure, remove_old, skip_testing, parser):
-    # region Initial Setup stolen from cli
-
-    # Setup configuration
-    mwcp.config.load(config_path)
-    if parser_dir:
-        mwcp.config["PARSER_DIR"] = parser_dir
-    parser_dir = mwcp.config.get("PARSER_DIR")
-    if parser_config:
-        mwcp.config["PARSER_CONFIG_PATH"] = parser_config
-    parser_config = mwcp.config.get("PARSER_CONFIG_PATH")
-    if parser_source:
-        mwcp.config["PARSER_SOURCE"] = parser_source
-    parser_source = mwcp.config.get("PARSER_SOURCE")
-
-    # Setup logging
-    mwcp.setup_logging()
-    if debug:
-        logging.root.setLevel(logging.DEBUG)
-    elif verbose:
-        logging.root.setLevel(logging.INFO)
-    # else let log_config.yaml set log level.
-
-    # Register parsers
-    mwcp.register_entry_points()
-    if parser_dir:
-        mwcp.register_parser_directory(parser_dir, config_file_path=parser_config)
-    if parser_source:
-        mwcp.set_default_source(parser_source)
-
-    # endregion
-
-    # Overwrite configuration with command line flags.
-    if testcase_dir:
-        mwcp.config["TESTCASE_DIR"] = testcase_dir
-    if malware_repo:
-        mwcp.config["MALWARE_REPO"] = malware_repo
-
-    existing_test_cases = list(testing.iter_test_cases())
-
-    skipped = []
-    tester = Tester(parser_names=[parser or None])
-    for legacy_test_case in tester.test_cases:
-        input_file_path = legacy_test_case.input_file_path
-        parser = legacy_test_case.parser
-        md5 = pathlib.Path(input_file_path).name
-        friendly_name = f"{parser}-{md5}"
-
-        # First see if testcase was already added.
-        found = False
-        for test_case in existing_test_cases:
-            if input_file_path.endswith(test_case.md5) and parser in test_case.name:
-                found = True
-                break
-        if found and not update_existing:
-            click.secho(f"[+] Test case for {friendly_name} already exists. Skipping...")
-            continue
-
-        click.secho(f"[+] Converting {friendly_name}")
-
-        # Test if legacy test case works.
-        if not skip_testing:
-            results = legacy_test_case.run()
-            if not results.passed:
-                results.print()
-                if continue_on_failure:
-                    click.secho(f"[!] Failed above test. Skipping...", fg="red")
-                    skipped.append(friendly_name)
-                    continue
-                else:
-                    click.secho(f"[!] Failed above test. Exiting...", fg="red")
-                    sys.exit(1)
-
-        # Create new test case.
-        success = testing.add_tests(
-            input_file_path,
-            parsers=[parser],
-            force=force,
-            update=update_existing,
-        )
-        if not success:
-            if continue_on_failure:
-                click.secho(f"[!] Failed to add test case {friendly_name}. Skipping...", fg="red")
-                skipped.append(friendly_name)
-                continue
-            else:
-                click.secho(f"[!] Failed to add test case {friendly_name}. Exiting...", fg="red")
-                sys.exit(1)
-
-        # Remove old test case.
-        # TODO: implement to remove test for specific testcase... or just not support this.
-        if remove_old:
-            results_file_path = tester.get_results_filepath(parser)
-            results_list = tester.read_results_file(results_file_path)
-            for index, file_path in enumerate(tester._list_test_files(results_list)):
-                if os.path.basename(file_path) == os.path.basename(input_file_path):
-                    break
-            else:
-                click.secho(f"Failed to remove legacy test case for {friendly_name}", fg="red")
-                continue
-            del results_list[index]
-            if not results_list:
-                pathlib.Path(results_file_path).unlink()
-            else:
-                tester.write_results_file(results_list, results_file_path)
-
-    # Show user what test cases we skipped.
-    if skipped:
-        skipped_str = "\n\t- ".join(skipped)
-        click.secho(
-            f"The following test cases were not converted due to failure: \n\t- {skipped_str}",
-            fg="red"
-        )
-        sys.exit(1)
-
-
-if __name__ == "__main__":
-    main(sys.argv[1:])
+"""
+This is a small helper script for converting legacy parser tests using the flat
+metadata schema into the newer schema.
+"""
+
+import logging
+import os
+import pathlib
+import sys
+
+import click
+
+import mwcp
+from mwcp.tester import Tester  # old interface
+from mwcp import testing        # new interface
+
+
+@click.command(context_settings={"help_option_names": ["-h", "--help"]})
+@click.option("-d", "--debug", is_flag=True, help="Enables DEBUG level logs.")
+@click.option("-v", "--verbose", is_flag=True, help="Enables INFO level logs.")
+@click.option(
+    "-c",
+    "--config",
+    "config_path",
+    type=click.Path(exists=True, dir_okay=False),
+    help="File path to configuration file.",
+    default=mwcp.config.user_path,
+    show_default=True,
+    envvar="MWCP_CONFIG",
+    show_envvar=True,
+)
+@click.option(
+    "--parser-dir",
+    type=click.Path(exists=True, file_okay=False),
+    help="Optional extra parser directory.",
+)
+@click.option(
+    "--parser-config",
+    type=click.Path(exists=True, dir_okay=False),
+    help="Optional parser configuration file to use with extra parser directory.",
+)
+@click.option(
+    "--parser-source",
+    help="Set a default parsers source to use. If not provided parsers from all sources will be available.",
+)
+@click.option(
+    "-t",
+    "--testcase-dir",
+    type=click.Path(file_okay=False),
+    help="Directory containing JSON test case files. (defaults to a "
+    '"tests" directory located within the parsers directory)',
+)
+@click.option(
+    "-m",
+    "--malware-repo",
+    type=click.Path(file_okay=False),
+    help="Directory containing malware samples used for testing.",
+)
+@click.option(
+    "--force", is_flag=True,
+    help="Force test case creation even when errors are encountered."
+)
+@click.option(
+    "--update-existing", is_flag=True,
+    help="Whether to update already converted tests cases.",
+)
+@click.option(
+    "--continue-on-failure", is_flag=True,
+    help="Whether to continue updating test cases if a legacy test case fails."
+)
+@click.option(
+    "--remove-old", is_flag=True,
+    help="Remove old test cases as new ones are created."
+)
+@click.option(
+    "--skip-testing", is_flag=True,
+    help="Don't run original test cases before updating."
+)
+@click.argument("parser", required=False)
+def main(debug, verbose, config_path, parser_dir, parser_config, parser_source,
+         testcase_dir, malware_repo, force, update_existing,
+         continue_on_failure, remove_old, skip_testing, parser):
+    # region Initial Setup stolen from cli
+
+    # Setup configuration
+    mwcp.config.load(config_path)
+    if parser_dir:
+        mwcp.config["PARSER_DIR"] = parser_dir
+    parser_dir = mwcp.config.get("PARSER_DIR")
+    if parser_config:
+        mwcp.config["PARSER_CONFIG_PATH"] = parser_config
+    parser_config = mwcp.config.get("PARSER_CONFIG_PATH")
+    if parser_source:
+        mwcp.config["PARSER_SOURCE"] = parser_source
+    parser_source = mwcp.config.get("PARSER_SOURCE")
+
+    # Setup logging
+    mwcp.setup_logging()
+    if debug:
+        logging.root.setLevel(logging.DEBUG)
+    elif verbose:
+        logging.root.setLevel(logging.INFO)
+    # else let log_config.yaml set log level.
+
+    # Register parsers
+    mwcp.register_entry_points()
+    if parser_dir:
+        mwcp.register_parser_directory(parser_dir, config_file_path=parser_config)
+    if parser_source:
+        mwcp.set_default_source(parser_source)
+
+    # endregion
+
+    # Overwrite configuration with command line flags.
+    if testcase_dir:
+        mwcp.config["TESTCASE_DIR"] = testcase_dir
+    if malware_repo:
+        mwcp.config["MALWARE_REPO"] = malware_repo
+
+    existing_test_cases = list(testing.iter_test_cases())
+
+    skipped = []
+    tester = Tester(parser_names=[parser or None])
+    for legacy_test_case in tester.test_cases:
+        input_file_path = legacy_test_case.input_file_path
+        parser = legacy_test_case.parser
+        md5 = pathlib.Path(input_file_path).name
+        friendly_name = f"{parser}-{md5}"
+
+        # First see if testcase was already added.
+        found = False
+        for test_case in existing_test_cases:
+            if input_file_path.endswith(test_case.md5) and parser in test_case.name:
+                found = True
+                break
+        if found and not update_existing:
+            click.secho(f"[+] Test case for {friendly_name} already exists. Skipping...")
+            continue
+
+        click.secho(f"[+] Converting {friendly_name}")
+
+        # Test if legacy test case works.
+        if not skip_testing:
+            results = legacy_test_case.run()
+            if not results.passed:
+                results.print()
+                if continue_on_failure:
+                    click.secho(f"[!] Failed above test. Skipping...", fg="red")
+                    skipped.append(friendly_name)
+                    continue
+                else:
+                    click.secho(f"[!] Failed above test. Exiting...", fg="red")
+                    sys.exit(1)
+
+        # Create new test case.
+        success = testing.add_tests(
+            input_file_path,
+            parsers=[parser],
+            force=force,
+            update=update_existing,
+        )
+        if not success:
+            if continue_on_failure:
+                click.secho(f"[!] Failed to add test case {friendly_name}. Skipping...", fg="red")
+                skipped.append(friendly_name)
+                continue
+            else:
+                click.secho(f"[!] Failed to add test case {friendly_name}. Exiting...", fg="red")
+                sys.exit(1)
+
+        # Remove old test case.
+        # TODO: implement to remove test for specific testcase... or just not support this.
+        if remove_old:
+            results_file_path = tester.get_results_filepath(parser)
+            results_list = tester.read_results_file(results_file_path)
+            for index, file_path in enumerate(tester._list_test_files(results_list)):
+                if os.path.basename(file_path) == os.path.basename(input_file_path):
+                    break
+            else:
+                click.secho(f"Failed to remove legacy test case for {friendly_name}", fg="red")
+                continue
+            del results_list[index]
+            if not results_list:
+                pathlib.Path(results_file_path).unlink()
+            else:
+                tester.write_results_file(results_list, results_file_path)
+
+    # Show user what test cases we skipped.
+    if skipped:
+        skipped_str = "\n\t- ".join(skipped)
+        click.secho(
+            f"The following test cases were not converted due to failure: \n\t- {skipped_str}",
+            fg="red"
+        )
+        sys.exit(1)
+
+
+if __name__ == "__main__":
+    main(sys.argv[1:])
```

### Comparing `mwcp-3.8.0/mwcp/utils/construct/ARM.py` & `mwcp-3.9.0/mwcp/utils/construct/ARM.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,140 +1,140 @@
-"""
-Helper constructs for parsing the ARM instruction set.
-This module will be imported along with 'from mwcp.utils import construct'
-and accessible from the submodule "ARM". (e.g. construct.ARM.LDR)
-"""
-
-from . import version28 as construct
-from .version28 import this
-
-from . import helpers
-from mwcp.utils import elffileutils
-
-
-def _ByteSwapped(subcon, **ctx):
-    r"""
-    MODIFIED version of ByteSwapped that allows providing a context.
-    Swap the byte order within boundaries of the given subcon.
-
-    :param subcon: the subcon on top of byte swapped bytes
-    :param **ctx: Context passed to subcon.sizeof()
-
-    Example::
-
-        Int24ul <--> ByteSwapped(Int24ub)
-    """
-    size = subcon.sizeof(**ctx)
-    return construct.Transformed(subcon, construct.swapbytes, size, construct.swapbytes, size)
-
-
-# Single Data Transfer (LDR, STR)
-_ldr_str_inst = construct.BitStruct(
-    'cond' / construct.Nibble,
-    construct.Const(1, construct.BitsInteger(2)),  # must be '01'
-    'reg_imm_offset' / construct.Bit,              # 0 = immediate offset, 1 = register offset
-    'pre_post_indexing' / construct.Bit,           # 0 = post, 1 = pre
-    'up_down' / construct.Bit,                     # 0 = down, 1 = up
-    'byte_word' / construct.Bit,                   # 0 = word, 1 = byte
-    'write_back' / construct.Flag,
-    'load_store' / construct.Bit,                  # 0 = store, 1 = load
-    'base_register' / construct.Nibble,
-    'src_dest_register' / construct.Nibble,
-    'offset' / construct.IfThenElse(
-        this.reg_imm_offset,
-        construct.Octet >> construct.Nibble,       # shift applied to Rm >> Rm
-        construct.BitsInteger(12)
-    )
-)
-
-LDR = construct.ExprValidator(_ByteSwapped(_ldr_str_inst, reg_imm_offset=0), this.load_store == 1)
-
-
-# Data Processing
-_data_proc_inst = construct.BitStruct(
-    'cond' / construct.Nibble,
-    construct.Const(0, construct.BitsInteger(2)),  # must be '00'
-    'reg_imm_operand' / construct.Bit,             # 0 = immediate, 1 = register
-    'opcode' / construct.Enum(
-        construct.Nibble,
-        AND=0x0, EOR=0x1, SUB=0x2, RSB=0x3, ADD=0x4, ADC=0x5, SBC=0x6, RSC=0x7,
-        TST=0x8, TEQ=0x9, CMP=0xA, CMN=0xB, ORR=0xC, MOV=0xD, BIC=0xE, MVN=0xF,
-    ),
-    'set_cond' / construct.Flag,
-    'operand_1_reg' / construct.Nibble,
-    'dest_reg' / construct.Nibble,
-    'operand_2' / construct.IfThenElse(
-        this.reg_imm_operand,
-        construct.Octet >> construct.Nibble,       # shift applied to Rm >> Rm
-        construct.Nibble >> construct.Octet,       # rotate applied to Imm >> Imm
-    ),
-)
-# TODO: Finish adding support for analyzing data processing instructions.
-# (shifting/rotating will need to applied to the second operand)
-
-
-def ELFPointer(inst, inst_end, subcon, elf=None):
-    r"""
-    This is the ARM version of ELFPointer.
-    This subconstruct takes two arguments which
-    specify the parsed ARM instruction containing an immediate offset in its second operand
-    and the end offset (physical) for said instruction.
-
-    The following ARM instructions are currently supported:
-        - LDR
-
-    Example: for the instruction "LDR  R1, =data_offset"
-    spec = Struct(
-        'inst' / ARM.LDR,
-        'inst_end' / Tell,
-        'data' / ARM.ELFPointer(this.inst, this.inst_end, Bytes(100))
-    )
-
-    spec = Struct(
-        're' / Regex(
-            '\x01\x03(?P<data_ldr_inst>.{4})(?P<end>)\x06\x07', data_ldr_inst=ARM.LDR, end=Tell),
-        'data' / ARM.ELFPointer(this.re.data_ldr_inst, this.re.end, Bytes(100))
-    )
-
-    spec.parse(file_data, elf=elf_object)
-
-    :param inst: a construct.Container or function that represents the assembly instruction
-    :param inst_end: an int or a function that represents the location of the end of the instruction.
-    :param subcon: the subcon to use at the offset
-    :param elf: Optional elftools.ELFFile file object.
-        (if not supplied here, this must be supplied during parse()/build()
-    """
-    def _obtain_literal_pool_mem_offset(ctx):
-        """Obtains the memory offset to the entry in the literal pool."""
-        # Validate LDR instruction
-        _inst = inst(ctx._) if callable(inst) else inst
-        if _inst.load_store != 1:
-            raise construct.ConstructError('Load/Store bit must be set to 1')
-        if _inst.base_register != 15 or _inst.reg_imm_offset == 1:
-            raise construct.ConstructError(
-                'Only instructions with PC relative addressing is currently supported.')
-        if _inst.write_back:
-            raise construct.ConstructError('Write back cannot be enabled for PC relative addressing.')
-        # According to spec, PC is an address 8 bytes from the start of the instruction.
-        # (Which means 4 bytes from end.)
-        _elf = elf or ctx._params.elf
-        _inst_end = inst_end(ctx._) if callable(inst_end) else inst_end
-        _inst_end = elffileutils.obtain_memory_offset(_inst_end, elf=_elf)
-        pc = _inst_end + 4
-        mem_offset = pc + _inst.offset
-        return mem_offset
-
-    # HACK: FocusLast (which is FocusedSeq) will try to create a child context when it performs it's parsing.
-    # The user will be unaware of this shift and can cause issues if the subcon is dynamic.
-    # Therefore, patch the given subcon to use the parent context during parsing.
-    # TODO: Embedded() should allow for this functionality!
-    class _Embedded(construct.Subconstruct):
-        def _parse(self, stream, context, path):
-            return self.subcon._parsereport(stream, context._, path)
-    subcon = _Embedded(subcon)
-
-    # Use original ELFPointer to create a pointer to the entry in the literal pool, which
-    # in turn, is a pointer to the data we actually want.
-    return helpers.FocusLast(
-        helpers.ELFPointer(_obtain_literal_pool_mem_offset, construct.Int32ul, elf=elf),
-        helpers.ELFPointer(this[0], subcon, elf=elf),
-    )
+"""
+Helper constructs for parsing the ARM instruction set.
+This module will be imported along with 'from mwcp.utils import construct'
+and accessible from the submodule "ARM". (e.g. construct.ARM.LDR)
+"""
+
+from . import version28 as construct
+from .version28 import this
+
+from . import helpers
+from mwcp.utils import elffileutils
+
+
+def _ByteSwapped(subcon, **ctx):
+    r"""
+    MODIFIED version of ByteSwapped that allows providing a context.
+    Swap the byte order within boundaries of the given subcon.
+
+    :param subcon: the subcon on top of byte swapped bytes
+    :param **ctx: Context passed to subcon.sizeof()
+
+    Example::
+
+        Int24ul <--> ByteSwapped(Int24ub)
+    """
+    size = subcon.sizeof(**ctx)
+    return construct.Transformed(subcon, construct.swapbytes, size, construct.swapbytes, size)
+
+
+# Single Data Transfer (LDR, STR)
+_ldr_str_inst = construct.BitStruct(
+    'cond' / construct.Nibble,
+    construct.Const(1, construct.BitsInteger(2)),  # must be '01'
+    'reg_imm_offset' / construct.Bit,              # 0 = immediate offset, 1 = register offset
+    'pre_post_indexing' / construct.Bit,           # 0 = post, 1 = pre
+    'up_down' / construct.Bit,                     # 0 = down, 1 = up
+    'byte_word' / construct.Bit,                   # 0 = word, 1 = byte
+    'write_back' / construct.Flag,
+    'load_store' / construct.Bit,                  # 0 = store, 1 = load
+    'base_register' / construct.Nibble,
+    'src_dest_register' / construct.Nibble,
+    'offset' / construct.IfThenElse(
+        this.reg_imm_offset,
+        construct.Octet >> construct.Nibble,       # shift applied to Rm >> Rm
+        construct.BitsInteger(12)
+    )
+)
+
+LDR = construct.ExprValidator(_ByteSwapped(_ldr_str_inst, reg_imm_offset=0), this.load_store == 1)
+
+
+# Data Processing
+_data_proc_inst = construct.BitStruct(
+    'cond' / construct.Nibble,
+    construct.Const(0, construct.BitsInteger(2)),  # must be '00'
+    'reg_imm_operand' / construct.Bit,             # 0 = immediate, 1 = register
+    'opcode' / construct.Enum(
+        construct.Nibble,
+        AND=0x0, EOR=0x1, SUB=0x2, RSB=0x3, ADD=0x4, ADC=0x5, SBC=0x6, RSC=0x7,
+        TST=0x8, TEQ=0x9, CMP=0xA, CMN=0xB, ORR=0xC, MOV=0xD, BIC=0xE, MVN=0xF,
+    ),
+    'set_cond' / construct.Flag,
+    'operand_1_reg' / construct.Nibble,
+    'dest_reg' / construct.Nibble,
+    'operand_2' / construct.IfThenElse(
+        this.reg_imm_operand,
+        construct.Octet >> construct.Nibble,       # shift applied to Rm >> Rm
+        construct.Nibble >> construct.Octet,       # rotate applied to Imm >> Imm
+    ),
+)
+# TODO: Finish adding support for analyzing data processing instructions.
+# (shifting/rotating will need to applied to the second operand)
+
+
+def ELFPointer(inst, inst_end, subcon, elf=None):
+    r"""
+    This is the ARM version of ELFPointer.
+    This subconstruct takes two arguments which
+    specify the parsed ARM instruction containing an immediate offset in its second operand
+    and the end offset (physical) for said instruction.
+
+    The following ARM instructions are currently supported:
+        - LDR
+
+    Example: for the instruction "LDR  R1, =data_offset"
+    spec = Struct(
+        'inst' / ARM.LDR,
+        'inst_end' / Tell,
+        'data' / ARM.ELFPointer(this.inst, this.inst_end, Bytes(100))
+    )
+
+    spec = Struct(
+        're' / Regex(
+            '\x01\x03(?P<data_ldr_inst>.{4})(?P<end>)\x06\x07', data_ldr_inst=ARM.LDR, end=Tell),
+        'data' / ARM.ELFPointer(this.re.data_ldr_inst, this.re.end, Bytes(100))
+    )
+
+    spec.parse(file_data, elf=elf_object)
+
+    :param inst: a construct.Container or function that represents the assembly instruction
+    :param inst_end: an int or a function that represents the location of the end of the instruction.
+    :param subcon: the subcon to use at the offset
+    :param elf: Optional elftools.ELFFile file object.
+        (if not supplied here, this must be supplied during parse()/build()
+    """
+    def _obtain_literal_pool_mem_offset(ctx):
+        """Obtains the memory offset to the entry in the literal pool."""
+        # Validate LDR instruction
+        _inst = inst(ctx._) if callable(inst) else inst
+        if _inst.load_store != 1:
+            raise construct.ConstructError('Load/Store bit must be set to 1')
+        if _inst.base_register != 15 or _inst.reg_imm_offset == 1:
+            raise construct.ConstructError(
+                'Only instructions with PC relative addressing is currently supported.')
+        if _inst.write_back:
+            raise construct.ConstructError('Write back cannot be enabled for PC relative addressing.')
+        # According to spec, PC is an address 8 bytes from the start of the instruction.
+        # (Which means 4 bytes from end.)
+        _elf = elf or ctx._params.elf
+        _inst_end = inst_end(ctx._) if callable(inst_end) else inst_end
+        _inst_end = elffileutils.obtain_memory_offset(_inst_end, elf=_elf)
+        pc = _inst_end + 4
+        mem_offset = pc + _inst.offset
+        return mem_offset
+
+    # HACK: FocusLast (which is FocusedSeq) will try to create a child context when it performs it's parsing.
+    # The user will be unaware of this shift and can cause issues if the subcon is dynamic.
+    # Therefore, patch the given subcon to use the parent context during parsing.
+    # TODO: Embedded() should allow for this functionality!
+    class _Embedded(construct.Subconstruct):
+        def _parse(self, stream, context, path):
+            return self.subcon._parsereport(stream, context._, path)
+    subcon = _Embedded(subcon)
+
+    # Use original ELFPointer to create a pointer to the entry in the literal pool, which
+    # in turn, is a pointer to the data we actually want.
+    return helpers.FocusLast(
+        helpers.ELFPointer(_obtain_literal_pool_mem_offset, construct.Int32ul, elf=elf),
+        helpers.ELFPointer(this[0], subcon, elf=elf),
+    )
```

### Comparing `mwcp-3.8.0/mwcp/utils/construct/MIPS.py` & `mwcp-3.9.0/mwcp/utils/construct/MIPS.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,55 +1,55 @@
-"""
-Helper constructs for parsing the MIPS instruction set.
-This module will be imported along with 'from mwcp.utils import construct'
-and accessible from the submodule "MIPS". (e.g. construct.MIPS.lw)
-
-reference: github.com/MIPT-ILab/mipt-mips/wiki/MIPS-Instruction-Set
-"""
-
-from .version28 import *
-from .version28 import this
-
-
-_REGISTERS = {
-    '$zero': 0,
-    '$at': 1,
-    '$v0': 2, '$v1': 3,
-    '$a0': 4, '$a1': 5, '$a2': 6, '$a3': 7,
-    '$t0': 8, '$t1': 9, '$t2': 10, '$t3': 11, '$t4': 12, '$t5': 13, '$t6': 14, '$t7': 15,
-    '$s0': 16, '$s1': 17, '$s2': 18, '$s3': 19, '$s4': 20, '$s5': 21, '$s6': 22, '$s7': 23,
-    '$t8': 24, '$t9': 25,
-    '$k0': 26, '$k1': 27,
-    '$gp': 28, '$sp': 29, '$fp': 30, '$ra': 31,
-}
-_Register = Enum(BitsInteger(5), **_REGISTERS)
-
-# I-type instruction
-_I_inst = Struct(
-    Embedded(BitStruct(
-        'opcode' / Enum(
-            BitsInteger(6),
-            # NOTE: Some opcode values are reserved for other instruction formats
-            # and we should let construct fail if it sees one.
-            j=0x02, jal=0x03, beq=0x04, bne=0x05, blez=0x06, bgtz=0x07,
-            addi=0x08, addiu=0x09, slti=0x0A, sltiu=0x0B, andi=0x0C, ori=0x0D, xori=0x0E, lui=0x0F,
-            beql=0x14, bnel=0x15, blezl=0x16, bgtzl=0x17,
-            daddi=0x18, daddiu=0x19, ldl=0x1A, ldr=0x1B, jalx=0x1D,
-            lb=0x20, lh=0x21, lwl=0x22, lw=0x23, lbu=0x24, lhu=0x25, lwr=0x26, lwu=0x27,
-            sb=0x28, sh=0x29, swl=0x2A, sw=0x2B, sdl=0x2C, sdr=0x2D, swr=0x2E, cache=0x2F,
-            ll=0x30, lwc1=0x31, lwc2=0x32, pref=0x33, lld=0x34, ldc1=0x35, ldc2=0x36, ld=0x37,
-            sc=0x38, swc1=0x39, swc2=0x3A, scd=0x3C, sdc1=0x3D, sdc2=0x3E, sd=0x3F,
-        ),
-        'src_register' / _Register,
-        'target_register' / _Register,
-        # 'imm_constant' / construct.BitsInteger(16)
-    )),
-    # Need to move immediate outside of BitStruct to create signed number.
-    # (Luckly, the constant is byte aligned)
-    'imm_constant' / Int16sb
-)
-
-
-lw = ExprValidator(_I_inst, this.opcode == 'lw')
-
-# TODO: Create a MIPS version of ELFPointer that will account for the Global Offset Table and $gp register
-# from extracted "la" psuedo instructions.
+"""
+Helper constructs for parsing the MIPS instruction set.
+This module will be imported along with 'from mwcp.utils import construct'
+and accessible from the submodule "MIPS". (e.g. construct.MIPS.lw)
+
+reference: github.com/MIPT-ILab/mipt-mips/wiki/MIPS-Instruction-Set
+"""
+
+from .version28 import *
+from .version28 import this
+
+
+_REGISTERS = {
+    '$zero': 0,
+    '$at': 1,
+    '$v0': 2, '$v1': 3,
+    '$a0': 4, '$a1': 5, '$a2': 6, '$a3': 7,
+    '$t0': 8, '$t1': 9, '$t2': 10, '$t3': 11, '$t4': 12, '$t5': 13, '$t6': 14, '$t7': 15,
+    '$s0': 16, '$s1': 17, '$s2': 18, '$s3': 19, '$s4': 20, '$s5': 21, '$s6': 22, '$s7': 23,
+    '$t8': 24, '$t9': 25,
+    '$k0': 26, '$k1': 27,
+    '$gp': 28, '$sp': 29, '$fp': 30, '$ra': 31,
+}
+_Register = Enum(BitsInteger(5), **_REGISTERS)
+
+# I-type instruction
+_I_inst = Struct(
+    Embedded(BitStruct(
+        'opcode' / Enum(
+            BitsInteger(6),
+            # NOTE: Some opcode values are reserved for other instruction formats
+            # and we should let construct fail if it sees one.
+            j=0x02, jal=0x03, beq=0x04, bne=0x05, blez=0x06, bgtz=0x07,
+            addi=0x08, addiu=0x09, slti=0x0A, sltiu=0x0B, andi=0x0C, ori=0x0D, xori=0x0E, lui=0x0F,
+            beql=0x14, bnel=0x15, blezl=0x16, bgtzl=0x17,
+            daddi=0x18, daddiu=0x19, ldl=0x1A, ldr=0x1B, jalx=0x1D,
+            lb=0x20, lh=0x21, lwl=0x22, lw=0x23, lbu=0x24, lhu=0x25, lwr=0x26, lwu=0x27,
+            sb=0x28, sh=0x29, swl=0x2A, sw=0x2B, sdl=0x2C, sdr=0x2D, swr=0x2E, cache=0x2F,
+            ll=0x30, lwc1=0x31, lwc2=0x32, pref=0x33, lld=0x34, ldc1=0x35, ldc2=0x36, ld=0x37,
+            sc=0x38, swc1=0x39, swc2=0x3A, scd=0x3C, sdc1=0x3D, sdc2=0x3E, sd=0x3F,
+        ),
+        'src_register' / _Register,
+        'target_register' / _Register,
+        # 'imm_constant' / construct.BitsInteger(16)
+    )),
+    # Need to move immediate outside of BitStruct to create signed number.
+    # (Luckly, the constant is byte aligned)
+    'imm_constant' / Int16sb
+)
+
+
+lw = ExprValidator(_I_inst, this.opcode == 'lw')
+
+# TODO: Create a MIPS version of ELFPointer that will account for the Global Offset Table and $gp register
+# from extracted "la" psuedo instructions.
```

### Comparing `mwcp-3.8.0/mwcp/utils/construct/construct_html.py` & `mwcp-3.9.0/mwcp/utils/construct/construct_html.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,390 +1,390 @@
-"""This module is used to convert constructs to an HTML document.
-
-To use, run the html_hex with a construct and data:
-    print html_hex(CONSTRUCT, data)
-"""
-from __future__ import print_function
-
-import codecs
-import os
-import construct
-import itertools
-import jinja2
-import sys
-
-
-PY3 = sys.version_info.major == 3
-
-
-try:
-    # Python 2
-    from itertools import izip_longest
-except ImportError:
-    # Python 3
-    from itertools import zip_longest as izip_longest
-
-
-COLORPALLETTE = [
-        '#00ff00', '#0000ff', '#00ffff', '#ff0000', '#ffff00', '#ff00ff',
-        '#008000', '#000080', '#008080', '#00ff80', '#0080ff', '#800000', '#808000', '#80ff00',
-        '#800080', '#808080', '#80ff80', '#8000ff', '#8080ff', '#80ffff', '#ff8000', '#ff0080',
-        '#ff8080', '#ffff80', '#ff80ff',
-        '#004000', '#00bf00', '#000040', '#004040', '#008040', '#00bf40', '#00ff40', '#004080',
-        '#00bf80', '#0000bf', '#0040bf', '#0080bf', '#00bfbf', '#00ffbf', '#0040ff', '#00bfff',
-        '#400000', '#404000', '#408000', '#40bf00', '#40ff00', '#400040', '#404040', '#408040',
-        '#40bf40', '#40ff40', '#400080', '#404080', '#408080', '#40bf80', '#40ff80', '#4000bf',
-        '#4040bf', '#4080bf', '#40bfbf', '#40ffbf', '#4000ff', '#4040ff', '#4080ff', '#40bfff',
-        '#40ffff', '#804000', '#80bf00', '#800040', '#804040', '#808040', '#80bf40', '#80ff40',
-        '#804080', '#80bf80', '#8000bf', '#8040bf', '#8080bf', '#80bfbf', '#80ffbf', '#8040ff',
-        '#80bfff', '#bf0000', '#bf4000', '#bf8000', '#bfbf00', '#bfff00', '#bf0040', '#bf4040',
-        '#bf8040', '#bfbf40', '#bfff40', '#bf0080', '#bf4080', '#bf8080', '#bfbf80', '#bfff80',
-        '#bf00bf', '#bf40bf', '#bf80bf', '#bfbfbf', '#bfffbf', '#bf00ff', '#bf40ff', '#bf80ff',
-        '#bfbfff', '#bfffff', '#ff4000', '#ffbf00', '#ff0040', '#ff4040', '#ff8040', '#ffbf40',
-        '#ffff40', '#ff4080', '#ffbf80', '#ff00bf', '#ff40bf', '#ff80bf', '#ffbfbf', '#ffffbf',
-        '#ff40ff', '#ffbfff'
-    ]
-
-
-def brightness(hexcode):
-    """Calculates brightness for give html hex code of the format #xxxxxx"""
-    return int(hexcode[1:3], 16) * .299 + int(hexcode[3:5], 16) * .587 + int(hexcode[5:7], 16) * .114
-
-# Calculate brightness for each color and determine if text should be black or white.
-FORMAT_COLORS = [(bg_color, '#000000' if brightness(bg_color) >= 128 else '#ffffff') for bg_color in COLORPALLETTE]
-
-
-def grouper(n, iterable, fillvalue=None):
-    """
-    Groups iterable into n length chunks.
-    If the last chunk doesn't have n items, the remaining is filled with fillvalue.
-
-    >>> list(grouper(3, 'ABCDEFG', fillvalue='x'))
-    [('A', 'B', 'C'), ('D', 'E', 'F'), ('G', 'x', 'x')]
-    """
-    args = [iter(iterable)] * n
-    return izip_longest(fillvalue=fillvalue, *args)
-
-
-def _iter_colors(data, color_map, default=None):
-    """Yields byte and format color for each byte of data according to the member_map.
-
-    :param data: Data to iterate over.
-    :param color_map: Dictionary that matches offset a member and color to use
-    :param default: default colors to use.
-
-    :yield: tuple containing (byte, format_color_tuple)
-    """
-    iter_data = enumerate(data)
-    for offset, datum in iter_data:
-        if offset in color_map:
-            colors, member = color_map[offset]
-            yield datum, colors
-            for offset, datum in itertools.islice(iter_data, 0, member.length - 1):
-                yield datum, colors
-        else:
-            yield datum, default
-
-
-class Member(construct.RawCopy):
-    """
-    This is a subconstruct that collects offset, data, and size information into the given
-    member table, but then returns the original parsed value, like nothing happened.
-    (This is to allow the callbacks work like they originally functioned.)
-    """
-
-    def __init__(self, member_map, subcon):
-        """
-        :param member_map: a defaultdict(list) mapping the offsets to the parsed objects
-        :param subcon:
-        """
-        self._member_map = member_map
-        super(Member, self).__init__(subcon)
-        # version 2.9 doesn't perpetuate the name past one level anymore.
-        self.name = self.subcon.name
-
-    def _generate_value_str(self, value, indent=0):
-        tabs = '\t' * indent
-        if isinstance(value, construct.ListContainer):
-            return '- ' + tabs + ('\n' + '- ' + tabs).join(
-                self._generate_value_str(value_, indent=indent+1).lstrip()
-                for value_ in value)
-        elif isinstance(value, construct.Container):
-            # NOTE: must use items() instead of iteritems() to keep order.
-            return tabs + ('\n' + tabs).join(
-                '{}: \n{}'.format(name, self._generate_value_str(value_, indent=indent+1))
-                for name, value_ in value.items() if not name.startswith('_'))
-        elif isinstance(value, bytes):
-            # Escape unprintable bytes with "\x" notation.
-            # (using codecs necessary to get this to work in both python 2 and 3)
-            return tabs + codecs.escape_encode(value)[0].decode('utf-8')
-        else:
-            return tabs + '{}'.format(value)
-
-    def _parse(self, stream, context, path):
-        obj = super(Member, self)._parse(stream, context, path)
-
-        # Store offset, data, and size information then return original object like nothing happened...
-        if self.name and not self.name.startswith('_'):
-            obj.name = self.name
-            # Create a string representation of the value.
-            obj.value_str = self._generate_value_str(obj.value)
-            # Need path to so we can pull name history. (Add index if there is one.)
-            obj.path = path
-            index = getattr(context, '_index', None)
-            if index is not None:
-                obj.path += '[{}]'.format(index)
-            obj.docs = self.docs
-
-            # Map ourselves to every byte we cover.
-            for index in range(obj.offset1, obj.offset2):
-                self._member_map.setdefault(index, [])
-                self._member_map[index].append(obj)
-
-        return obj.value
-
-    def _build(self, obj, stream, context, path):
-        raise NotImplementedError('Unable to build using Member class.')
-
-
-class MemberMap(construct.Adapter):
-    r"""
-    Wraps Subconstruct to produce a member map of all the parsed objections and their offsets:
-
-    {offset: [list of parsed Containers in order of descending depth]}
-
-    Needs to implement ``_decode()`` and ``_encode()``.
-
-    :param subcon: the construct to wrap
-    """
-    def __init__(self, subcon):
-        # member_map is a dictionary mapping the offsets of elements to a list of elements it portrays
-        self._member_map = {}
-        subcon = self._wrap_subcon(subcon)
-        super(MemberMap, self).__init__(subcon)
-
-    def _wrap_subcon(self, subcon):
-        """Recursively wraps all subconstructs with Member."""
-        # Don't wrap the Probes.
-        if isinstance(subcon, construct.Probe):
-            return subcon
-
-        # Recursively wrap internals as until we hit an adapter or non-Construct object.
-        if isinstance(subcon, construct.Construct) and not isinstance(subcon, construct.Adapter):
-            if hasattr(subcon, 'subcon'):
-                subcon.subcon = self._wrap_subcon(subcon.subcon)
-            elif hasattr(subcon, 'subcons'):
-                new_subcons = []
-                for _subcon in subcon.subcons:
-                    new_subcons.append(self._wrap_subcon(_subcon))
-                subcon.subcons = new_subcons
-
-        # Switch uses "cases"
-        if isinstance(subcon, construct.Switch):
-            new_cases = {}
-            for case, _subcon in subcon.cases.items():
-                new_cases[case] = self._wrap_subcon(_subcon)
-            subcon.cases = new_cases
-            subcon.default = self._wrap_subcon(subcon.default)
-
-        return Member(self._member_map, subcon)
-
-    def _parse(self, stream, context, path):
-        # Clear the member_table from previous use.
-        self._member_map.clear()
-        return super(MemberMap, self)._parse(stream, context, path)
-
-    def _decode(self, obj, context, path):
-        """Returns a copy of the member map."""
-        return self._member_map.copy()
-
-    def _encode(self, obj, context, path):
-        raise NotImplementedError('Not supported.')
-
-
-def _gen_color_map(member_map, depth=1, member_callback=None):
-    """
-    Generates a color map that maps beginning offsets to a member.
-
-    :param member_map: A dictionary map, mapping byte offsets to members.
-    :param depth: The number of levels deep to display in table (defaults to all levels)
-    :param member_callback: Optional callback that can be used to tweak the member name or value before setting.
-    :return:
-    """
-    if depth is not None and depth <= 0:
-        raise ValueError('Invalid depth. Must be >= 1 or None.')
-
-    # Contains set of parent members that are not allowed to be present.
-    # (This helps to prevent a parent being displayed when a child contains a unnamed member (e.g. Padding))
-    blacklist = set()
-
-    visible_members = {}
-    curr_member = None
-    for offset, members in sorted(member_map.items()):
-        members = list(reversed(members))  # Members are generated in reverse with most depth being first.
-
-        # Grab member based on requested level, (use furthest depth member if not requested)
-        if depth is None:
-            idx = len(members) - 1
-        else:
-            idx = min(depth - 1, len(members) - 1)
-        member = members[idx]
-        blacklist.update(id(m) for m in members[:idx])
-
-        # Add to member to color map only if its the first time we are seeing it.
-        if member != curr_member and id(member) not in blacklist:
-            # Rename member to contain parent names.
-            # ([1:] to remove the "parsing" name)
-            member.name = ' / '.join(member.path.split(' -> ')[1:] + [member.name])
-            if member_callback:
-                results = member_callback(member.name, member.value_str)
-                if results:
-                    member.name, member.value_str = results
-            visible_members[offset] = member
-            curr_member = member
-
-    # Remove any blacklisted members that slipped by.
-    # (This happens when the first entry in a construct is empty.)
-    visible_members = {offset: member
-                       for offset, member in visible_members.items() if id(member) not in blacklist}
-
-    # Assign colors.
-    color_generator = itertools.cycle(FORMAT_COLORS)
-    color_map = {offset: (next(color_generator), member) for offset, member in sorted(visible_members.items())}
-
-    return color_map
-
-
-def html_hex(struct, data, width=16, depth=None, member_callback=None):
-    """
-    Uses construct to parse data and creates a user-friendly html hex dump.
-
-    :param struct: A construct.Construct object to parse.
-    :param data: Data to dump.
-    :param width: The number of bytes displayed for each line.
-    :param depth: The number of levels deep to display in table (defaults to all levels)
-    :param member_callback:
-        Optional callback function that can be used to tweak the
-        member name or value in the variable table.
-        Function must accept two parameters (name, value) and return a tuple of
-        the (name, value) or None to make no change.
-        e.g.
-        def edit_member(name, value):
-            if name == 'data':
-                return name, value.encode('hex')
-
-
-    :rtype str: returns unicode string of html data.
-
-    :raises ConstructError: If given struct fails to parse given data.
-    """
-    if width <= 0:
-        raise ValueError("Width must be a positive number.")
-    member_map = MemberMap(struct).parse(data)
-    color_map = _gen_color_map(member_map, depth=depth, member_callback=member_callback)
-
-    hex_dump = []
-    for line_number, line in enumerate(grouper(width, _iter_colors(data, color_map), fillvalue=(None, None))):
-        offset = line_number * width
-        hex_line = []
-        ascii_line = []
-        # Generate hex and ascii version of each byte.
-        current_color = None
-        for byte, color in line:
-            prefix, suffix = '', ''
-            if color:
-                if color != current_color:
-                    bg_color, text_color = color
-                    # End previous highlighting.
-                    if current_color:
-                        prefix += '</span>'
-                    prefix += '<span style="background:{};color:{}">'.format(bg_color, text_color)
-                    current_color = color
-            # Clear highlighting.
-            elif current_color:
-                prefix = '</span>'
-                current_color = None
-
-            if byte is not None:
-                if not PY3:
-                    byte = ord(byte)
-                hex_ = '{:02X}'.format(byte)
-                ascii = chr(byte) if 32 < byte < 127 else '.'
-            else:
-                hex_ = '&nbsp;&nbsp;'
-                ascii = '&nbsp;'
-
-            hex_line.append('{}{}{}'.format(prefix, hex_, suffix))
-            ascii_line.append('{}{}{}'.format(prefix, ascii, suffix))
-
-        hex_line = '&nbsp;'.join(hex_line)
-        ascii_line = ''.join(ascii_line)
-
-        # Clear highlighting.
-        if current_color:
-            hex_line += '</span>'
-            ascii_line += '</span>'
-
-        hex_dump.append(('{:06x}'.format(offset), hex_line, ascii_line))
-
-    env = jinja2.Environment(
-        loader=jinja2.FileSystemLoader(os.path.join(os.path.dirname(__file__))),
-        trim_blocks=True, lstrip_blocks=True)
-    template = env.get_template('construct_template.html')
-
-    return template.render(hex_dump=hex_dump, color_map=color_map, width=width)
-
-
-if __name__ == '__main__':
-    # Run an example if called directly.
-    from mwcp.utils.construct import version28 as construct
-    from mwcp.utils.construct.network import IP4Address
-    from mwcp.utils.construct.helpers import HexString
-    from construct import this
-
-    EMBED_SPEC = construct.Struct(
-        'a' / IP4Address,
-        'b' / IP4Address,
-        'c' / IP4Address,
-        'd' / IP4Address
-    )
-
-    address_struct = construct.Struct(
-        'first' / construct.Struct('a' / construct.Byte, 'b' / construct.Byte),
-        'second' / construct.Struct('inner2' / construct.Bytes(2))
-        # 'internal' / IP4Address
-    )
-
-    PACKET = construct.Struct(
-        construct.Padding(0x9),
-        'Hardcoded Value 1' / HexString(construct.Int32ul),
-        'Hardcoded Value 2' / HexString(construct.Int32ul),
-        'Hardcoded Value 3' / HexString(construct.Int32ul),
-        construct.Padding(0x17),
-        'Compromised Host IP' / IP4Address,  # Use IP adapter
-        # 'Unknown IP Addresses' / construct.Switch(
-        #     this['Hardcoded Value 1'],
-        #     {
-        #         '0x1f4' : EMBED_SPEC
-        #     },
-        # ),
-        'Unknown IP Addresses' / address_struct[4],
-        # 'Unknown IP Addresses' / IP4Address[4],
-        construct.Padding(8),
-        'Unknown Indicator' / construct.String(0xF),
-        construct.Padding(2),
-        'Number of CPUs' / construct.Int32ul,
-        'CPU Mhz' / construct.Int32ul,
-        'Total Memory (MB)' / construct.Int32ul,
-        'Compromised System Kernel' / construct.CString(),
-        'Possible Trojan Version' / construct.CString()
-    )
-
-    data = (b'\x01\x00\x00\x00}\x00\x00\x00\x00\xf4\x01\x00\x002\x00\x00\x00\xe8'
-            b'\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01'
-            b'\x01\x00\x00\x00\x00\x01\x00\x00\x00\xc0\xa8\x01\r\xc0\xa8\x01\r\xc0'
-            b'\xa8\x01\r\xc0\xa8\x01\r\xc0\xa8\x01\r\xff\xff\x01\x00\x00\x00\x00\x00'
-            b'-== Love AV ==-:\x00\x01\x00\x00\x00d\n\x00\x00\xc4\x07\x00\x00'
-            b'Linux 3.13.0-93-generic\x001:G2.40\x00')
-
-    print(html_hex(PACKET, data, depth=2))
-
+"""This module is used to convert constructs to an HTML document.
+
+To use, run the html_hex with a construct and data:
+    print html_hex(CONSTRUCT, data)
+"""
+from __future__ import print_function
+
+import codecs
+import os
+import construct
+import itertools
+import jinja2
+import sys
+
+
+PY3 = sys.version_info.major == 3
+
+
+try:
+    # Python 2
+    from itertools import izip_longest
+except ImportError:
+    # Python 3
+    from itertools import zip_longest as izip_longest
+
+
+COLORPALLETTE = [
+        '#00ff00', '#0000ff', '#00ffff', '#ff0000', '#ffff00', '#ff00ff',
+        '#008000', '#000080', '#008080', '#00ff80', '#0080ff', '#800000', '#808000', '#80ff00',
+        '#800080', '#808080', '#80ff80', '#8000ff', '#8080ff', '#80ffff', '#ff8000', '#ff0080',
+        '#ff8080', '#ffff80', '#ff80ff',
+        '#004000', '#00bf00', '#000040', '#004040', '#008040', '#00bf40', '#00ff40', '#004080',
+        '#00bf80', '#0000bf', '#0040bf', '#0080bf', '#00bfbf', '#00ffbf', '#0040ff', '#00bfff',
+        '#400000', '#404000', '#408000', '#40bf00', '#40ff00', '#400040', '#404040', '#408040',
+        '#40bf40', '#40ff40', '#400080', '#404080', '#408080', '#40bf80', '#40ff80', '#4000bf',
+        '#4040bf', '#4080bf', '#40bfbf', '#40ffbf', '#4000ff', '#4040ff', '#4080ff', '#40bfff',
+        '#40ffff', '#804000', '#80bf00', '#800040', '#804040', '#808040', '#80bf40', '#80ff40',
+        '#804080', '#80bf80', '#8000bf', '#8040bf', '#8080bf', '#80bfbf', '#80ffbf', '#8040ff',
+        '#80bfff', '#bf0000', '#bf4000', '#bf8000', '#bfbf00', '#bfff00', '#bf0040', '#bf4040',
+        '#bf8040', '#bfbf40', '#bfff40', '#bf0080', '#bf4080', '#bf8080', '#bfbf80', '#bfff80',
+        '#bf00bf', '#bf40bf', '#bf80bf', '#bfbfbf', '#bfffbf', '#bf00ff', '#bf40ff', '#bf80ff',
+        '#bfbfff', '#bfffff', '#ff4000', '#ffbf00', '#ff0040', '#ff4040', '#ff8040', '#ffbf40',
+        '#ffff40', '#ff4080', '#ffbf80', '#ff00bf', '#ff40bf', '#ff80bf', '#ffbfbf', '#ffffbf',
+        '#ff40ff', '#ffbfff'
+    ]
+
+
+def brightness(hexcode):
+    """Calculates brightness for give html hex code of the format #xxxxxx"""
+    return int(hexcode[1:3], 16) * .299 + int(hexcode[3:5], 16) * .587 + int(hexcode[5:7], 16) * .114
+
+# Calculate brightness for each color and determine if text should be black or white.
+FORMAT_COLORS = [(bg_color, '#000000' if brightness(bg_color) >= 128 else '#ffffff') for bg_color in COLORPALLETTE]
+
+
+def grouper(n, iterable, fillvalue=None):
+    """
+    Groups iterable into n length chunks.
+    If the last chunk doesn't have n items, the remaining is filled with fillvalue.
+
+    >>> list(grouper(3, 'ABCDEFG', fillvalue='x'))
+    [('A', 'B', 'C'), ('D', 'E', 'F'), ('G', 'x', 'x')]
+    """
+    args = [iter(iterable)] * n
+    return izip_longest(fillvalue=fillvalue, *args)
+
+
+def _iter_colors(data, color_map, default=None):
+    """Yields byte and format color for each byte of data according to the member_map.
+
+    :param data: Data to iterate over.
+    :param color_map: Dictionary that matches offset a member and color to use
+    :param default: default colors to use.
+
+    :yield: tuple containing (byte, format_color_tuple)
+    """
+    iter_data = enumerate(data)
+    for offset, datum in iter_data:
+        if offset in color_map:
+            colors, member = color_map[offset]
+            yield datum, colors
+            for offset, datum in itertools.islice(iter_data, 0, member.length - 1):
+                yield datum, colors
+        else:
+            yield datum, default
+
+
+class Member(construct.RawCopy):
+    """
+    This is a subconstruct that collects offset, data, and size information into the given
+    member table, but then returns the original parsed value, like nothing happened.
+    (This is to allow the callbacks work like they originally functioned.)
+    """
+
+    def __init__(self, member_map, subcon):
+        """
+        :param member_map: a defaultdict(list) mapping the offsets to the parsed objects
+        :param subcon:
+        """
+        self._member_map = member_map
+        super(Member, self).__init__(subcon)
+        # version 2.9 doesn't perpetuate the name past one level anymore.
+        self.name = self.subcon.name
+
+    def _generate_value_str(self, value, indent=0):
+        tabs = '\t' * indent
+        if isinstance(value, construct.ListContainer):
+            return '- ' + tabs + ('\n' + '- ' + tabs).join(
+                self._generate_value_str(value_, indent=indent+1).lstrip()
+                for value_ in value)
+        elif isinstance(value, construct.Container):
+            # NOTE: must use items() instead of iteritems() to keep order.
+            return tabs + ('\n' + tabs).join(
+                '{}: \n{}'.format(name, self._generate_value_str(value_, indent=indent+1))
+                for name, value_ in value.items() if not name.startswith('_'))
+        elif isinstance(value, bytes):
+            # Escape unprintable bytes with "\x" notation.
+            # (using codecs necessary to get this to work in both python 2 and 3)
+            return tabs + codecs.escape_encode(value)[0].decode('utf-8')
+        else:
+            return tabs + '{}'.format(value)
+
+    def _parse(self, stream, context, path):
+        obj = super(Member, self)._parse(stream, context, path)
+
+        # Store offset, data, and size information then return original object like nothing happened...
+        if self.name and not self.name.startswith('_'):
+            obj.name = self.name
+            # Create a string representation of the value.
+            obj.value_str = self._generate_value_str(obj.value)
+            # Need path to so we can pull name history. (Add index if there is one.)
+            obj.path = path
+            index = getattr(context, '_index', None)
+            if index is not None:
+                obj.path += '[{}]'.format(index)
+            obj.docs = self.docs
+
+            # Map ourselves to every byte we cover.
+            for index in range(obj.offset1, obj.offset2):
+                self._member_map.setdefault(index, [])
+                self._member_map[index].append(obj)
+
+        return obj.value
+
+    def _build(self, obj, stream, context, path):
+        raise NotImplementedError('Unable to build using Member class.')
+
+
+class MemberMap(construct.Adapter):
+    r"""
+    Wraps Subconstruct to produce a member map of all the parsed objections and their offsets:
+
+    {offset: [list of parsed Containers in order of descending depth]}
+
+    Needs to implement ``_decode()`` and ``_encode()``.
+
+    :param subcon: the construct to wrap
+    """
+    def __init__(self, subcon):
+        # member_map is a dictionary mapping the offsets of elements to a list of elements it portrays
+        self._member_map = {}
+        subcon = self._wrap_subcon(subcon)
+        super(MemberMap, self).__init__(subcon)
+
+    def _wrap_subcon(self, subcon):
+        """Recursively wraps all subconstructs with Member."""
+        # Don't wrap the Probes.
+        if isinstance(subcon, construct.Probe):
+            return subcon
+
+        # Recursively wrap internals as until we hit an adapter or non-Construct object.
+        if isinstance(subcon, construct.Construct) and not isinstance(subcon, construct.Adapter):
+            if hasattr(subcon, 'subcon'):
+                subcon.subcon = self._wrap_subcon(subcon.subcon)
+            elif hasattr(subcon, 'subcons'):
+                new_subcons = []
+                for _subcon in subcon.subcons:
+                    new_subcons.append(self._wrap_subcon(_subcon))
+                subcon.subcons = new_subcons
+
+        # Switch uses "cases"
+        if isinstance(subcon, construct.Switch):
+            new_cases = {}
+            for case, _subcon in subcon.cases.items():
+                new_cases[case] = self._wrap_subcon(_subcon)
+            subcon.cases = new_cases
+            subcon.default = self._wrap_subcon(subcon.default)
+
+        return Member(self._member_map, subcon)
+
+    def _parse(self, stream, context, path):
+        # Clear the member_table from previous use.
+        self._member_map.clear()
+        return super(MemberMap, self)._parse(stream, context, path)
+
+    def _decode(self, obj, context, path):
+        """Returns a copy of the member map."""
+        return self._member_map.copy()
+
+    def _encode(self, obj, context, path):
+        raise NotImplementedError('Not supported.')
+
+
+def _gen_color_map(member_map, depth=1, member_callback=None):
+    """
+    Generates a color map that maps beginning offsets to a member.
+
+    :param member_map: A dictionary map, mapping byte offsets to members.
+    :param depth: The number of levels deep to display in table (defaults to all levels)
+    :param member_callback: Optional callback that can be used to tweak the member name or value before setting.
+    :return:
+    """
+    if depth is not None and depth <= 0:
+        raise ValueError('Invalid depth. Must be >= 1 or None.')
+
+    # Contains set of parent members that are not allowed to be present.
+    # (This helps to prevent a parent being displayed when a child contains a unnamed member (e.g. Padding))
+    blacklist = set()
+
+    visible_members = {}
+    curr_member = None
+    for offset, members in sorted(member_map.items()):
+        members = list(reversed(members))  # Members are generated in reverse with most depth being first.
+
+        # Grab member based on requested level, (use furthest depth member if not requested)
+        if depth is None:
+            idx = len(members) - 1
+        else:
+            idx = min(depth - 1, len(members) - 1)
+        member = members[idx]
+        blacklist.update(id(m) for m in members[:idx])
+
+        # Add to member to color map only if its the first time we are seeing it.
+        if member != curr_member and id(member) not in blacklist:
+            # Rename member to contain parent names.
+            # ([1:] to remove the "parsing" name)
+            member.name = ' / '.join(member.path.split(' -> ')[1:] + [member.name])
+            if member_callback:
+                results = member_callback(member.name, member.value_str)
+                if results:
+                    member.name, member.value_str = results
+            visible_members[offset] = member
+            curr_member = member
+
+    # Remove any blacklisted members that slipped by.
+    # (This happens when the first entry in a construct is empty.)
+    visible_members = {offset: member
+                       for offset, member in visible_members.items() if id(member) not in blacklist}
+
+    # Assign colors.
+    color_generator = itertools.cycle(FORMAT_COLORS)
+    color_map = {offset: (next(color_generator), member) for offset, member in sorted(visible_members.items())}
+
+    return color_map
+
+
+def html_hex(struct, data, width=16, depth=None, member_callback=None):
+    """
+    Uses construct to parse data and creates a user-friendly html hex dump.
+
+    :param struct: A construct.Construct object to parse.
+    :param data: Data to dump.
+    :param width: The number of bytes displayed for each line.
+    :param depth: The number of levels deep to display in table (defaults to all levels)
+    :param member_callback:
+        Optional callback function that can be used to tweak the
+        member name or value in the variable table.
+        Function must accept two parameters (name, value) and return a tuple of
+        the (name, value) or None to make no change.
+        e.g.
+        def edit_member(name, value):
+            if name == 'data':
+                return name, value.encode('hex')
+
+
+    :rtype str: returns unicode string of html data.
+
+    :raises ConstructError: If given struct fails to parse given data.
+    """
+    if width <= 0:
+        raise ValueError("Width must be a positive number.")
+    member_map = MemberMap(struct).parse(data)
+    color_map = _gen_color_map(member_map, depth=depth, member_callback=member_callback)
+
+    hex_dump = []
+    for line_number, line in enumerate(grouper(width, _iter_colors(data, color_map), fillvalue=(None, None))):
+        offset = line_number * width
+        hex_line = []
+        ascii_line = []
+        # Generate hex and ascii version of each byte.
+        current_color = None
+        for byte, color in line:
+            prefix, suffix = '', ''
+            if color:
+                if color != current_color:
+                    bg_color, text_color = color
+                    # End previous highlighting.
+                    if current_color:
+                        prefix += '</span>'
+                    prefix += '<span style="background:{};color:{}">'.format(bg_color, text_color)
+                    current_color = color
+            # Clear highlighting.
+            elif current_color:
+                prefix = '</span>'
+                current_color = None
+
+            if byte is not None:
+                if not PY3:
+                    byte = ord(byte)
+                hex_ = '{:02X}'.format(byte)
+                ascii = chr(byte) if 32 < byte < 127 else '.'
+            else:
+                hex_ = '&nbsp;&nbsp;'
+                ascii = '&nbsp;'
+
+            hex_line.append('{}{}{}'.format(prefix, hex_, suffix))
+            ascii_line.append('{}{}{}'.format(prefix, ascii, suffix))
+
+        hex_line = '&nbsp;'.join(hex_line)
+        ascii_line = ''.join(ascii_line)
+
+        # Clear highlighting.
+        if current_color:
+            hex_line += '</span>'
+            ascii_line += '</span>'
+
+        hex_dump.append(('{:06x}'.format(offset), hex_line, ascii_line))
+
+    env = jinja2.Environment(
+        loader=jinja2.FileSystemLoader(os.path.join(os.path.dirname(__file__))),
+        trim_blocks=True, lstrip_blocks=True)
+    template = env.get_template('construct_template.html')
+
+    return template.render(hex_dump=hex_dump, color_map=color_map, width=width)
+
+
+if __name__ == '__main__':
+    # Run an example if called directly.
+    from mwcp.utils.construct import version28 as construct
+    from mwcp.utils.construct.network import IP4Address
+    from mwcp.utils.construct.helpers import HexString
+    from construct import this
+
+    EMBED_SPEC = construct.Struct(
+        'a' / IP4Address,
+        'b' / IP4Address,
+        'c' / IP4Address,
+        'd' / IP4Address
+    )
+
+    address_struct = construct.Struct(
+        'first' / construct.Struct('a' / construct.Byte, 'b' / construct.Byte),
+        'second' / construct.Struct('inner2' / construct.Bytes(2))
+        # 'internal' / IP4Address
+    )
+
+    PACKET = construct.Struct(
+        construct.Padding(0x9),
+        'Hardcoded Value 1' / HexString(construct.Int32ul),
+        'Hardcoded Value 2' / HexString(construct.Int32ul),
+        'Hardcoded Value 3' / HexString(construct.Int32ul),
+        construct.Padding(0x17),
+        'Compromised Host IP' / IP4Address,  # Use IP adapter
+        # 'Unknown IP Addresses' / construct.Switch(
+        #     this['Hardcoded Value 1'],
+        #     {
+        #         '0x1f4' : EMBED_SPEC
+        #     },
+        # ),
+        'Unknown IP Addresses' / address_struct[4],
+        # 'Unknown IP Addresses' / IP4Address[4],
+        construct.Padding(8),
+        'Unknown Indicator' / construct.String(0xF),
+        construct.Padding(2),
+        'Number of CPUs' / construct.Int32ul,
+        'CPU Mhz' / construct.Int32ul,
+        'Total Memory (MB)' / construct.Int32ul,
+        'Compromised System Kernel' / construct.CString(),
+        'Possible Trojan Version' / construct.CString()
+    )
+
+    data = (b'\x01\x00\x00\x00}\x00\x00\x00\x00\xf4\x01\x00\x002\x00\x00\x00\xe8'
+            b'\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01'
+            b'\x01\x00\x00\x00\x00\x01\x00\x00\x00\xc0\xa8\x01\r\xc0\xa8\x01\r\xc0'
+            b'\xa8\x01\r\xc0\xa8\x01\r\xc0\xa8\x01\r\xff\xff\x01\x00\x00\x00\x00\x00'
+            b'-== Love AV ==-:\x00\x01\x00\x00\x00d\n\x00\x00\xc4\x07\x00\x00'
+            b'Linux 3.13.0-93-generic\x001:G2.40\x00')
+
+    print(html_hex(PACKET, data, depth=2))
+
```

### Comparing `mwcp-3.8.0/mwcp/utils/construct/construct_template.html` & `mwcp-3.9.0/mwcp/utils/construct/construct_template.html`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,157 +1,157 @@
-{#
-    This is the html template used to convert parsed constructs into user-friendly html
-    that can be used in reports.
-
-    Please see construct_html.py for its use.
-#}
-
-<html>
-<head>
-<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
-<meta name=Generator content="Microsoft Word 14 (filtered)">
-<style>
-<!--
- /* Font Definitions */
- @font-face
-	{font-family:Courier;
-	panose-1:2 7 4 9 2 2 5 2 4 4;}
-@font-face
-	{font-family:"Cambria Math";
-	panose-1:2 4 5 3 5 4 6 3 2 4;}
-@font-face
-	{font-family:Calibri;
-	panose-1:2 15 5 2 2 2 4 3 2 4;}
- /* Style Definitions */
- p.MsoNormal, li.MsoNormal, div.MsoNormal
-	{margin:0in;
-	margin-bottom:.0001pt;
-	font-size:11.0pt;
-	font-family:"Times New Roman","serif";}
-h1
-	{mso-style-link:"Heading 1 Char";
-	margin:0in;
-	margin-bottom:.0001pt;
-	page-break-after:avoid;
-	font-size:16.0pt;
-	font-family:"Calibri","sans-serif";
-	color:#943634;}
-h3
-	{mso-style-link:"Heading 3 Char";
-	margin-top:10.0pt;
-	margin-right:0in;
-	margin-bottom:0in;
-	margin-left:0in;
-	margin-bottom:.0001pt;
-	page-break-after:avoid;
-	font-size:11.0pt;
-	font-family:"Times New Roman","serif";}
-p.MsoNoSpacing, li.MsoNoSpacing, div.MsoNoSpacing
-	{mso-style-link:"No Spacing Char";
-	margin:0in;
-	margin-bottom:.0001pt;
-	font-size:11.0pt;
-	font-family:"Calibri","sans-serif";}
-span.Heading1Char
-	{mso-style-name:"Heading 1 Char";
-	mso-style-link:"Heading 1";
-	color:#943634;
-	font-weight:bold;}
-span.Heading3Char
-	{mso-style-name:"Heading 3 Char";
-	mso-style-link:"Heading 3";
-	font-family:"Times New Roman","serif";
-	font-weight:bold;}
-span.NoSpacingChar
-	{mso-style-name:"No Spacing Char";
-	mso-style-link:"No Spacing";
-	font-family:"Calibri","sans-serif";}
-.MsoChpDefault
-	{font-family:"Calibri","sans-serif";}
-.MsoPapDefault
-	{margin-bottom:10.0pt;
-	line-height:115%;}
-@page WordSection1
-	{size:8.5in 11.0in;
-	margin:1.0in 1.0in 1.0in 1.0in;}
-div.WordSection1
-	{page:WordSection1;}
--->
-</style>
-</head>
-<body lang=EN-US>
-<div class=WordSection1>
-
-<!-- Hex Dump -->
-<p class=MsoNormal style='background:#FFFFFF'>
-    <span style='font-size:8.0pt;font-family:"Courier New"'>
-        &nbsp;offset&nbsp;|
-        {%- for i in range(width) -%}
-            &nbsp;{% if i < 16 %}&nbsp;{% endif %}{{'%x'|format(i)}}
-        {%- endfor -%}
-        &nbsp;|&nbsp;
-        {%- for _ in range(width) -%}
-            {{'%x'|format(loop.cycle(*range(16)))}}  {#- We only have enough space for the first digit -#}
-        {%- endfor -%}
-        <br/>
-        &nbsp;------ |  {{'-- ' * width}} | {{'-' * width}}
-        {% for offset, hex_line, ascii_line in hex_dump %}
-        <br/>&nbsp;{{offset}}&nbsp;|&nbsp;{{hex_line}}&nbsp;|&nbsp;{{ascii_line}}
-        {% endfor %}
-    </span>
-</p>
-
-<!-- Variable Table -->
-<p class=MsoNormal>&nbsp;</p>
-    <table class=MsoNormalTable border=1 cellspacing=0 cellpadding=0
-     style='margin-left:5.4pt;border-collapse:collapse;border:none'>
-     <tr>
-      <td width=175 valign=top style='width:131.05pt;border:solid windowtext 1.0pt;
-      background:#244061;padding:0in 5.4pt 0in 5.4pt'>
-      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
-      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Offset</span></b></p>
-      </td>
-      <td width=238 valign=top style='width:178.7pt;border:solid windowtext 1.0pt;
-      border-left:none;background:#244061;padding:0in 5.4pt 0in 5.4pt'>
-      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
-      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Name</span></b></p>
-      </td>
-      <td width=218 valign=top style='width:163.65pt;border:solid windowtext 1.0pt;
-      border-left:none;background:#244061;padding:0in 5.4pt 0in 5.4pt'>
-      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
-      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Value</span></b></p>
-      </td>
-     </tr>
-
-    {% for offset, (colors, member) in color_map.items()|sort %}
-        <tr>
-            {# Offset #}
-            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';  ">{{'%06x' % offset}}</span>
-                </p>
-            </td>
-
-            {# Name #}
-            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New';background:{{colors[0]}};color:{{colors[1]}}">
-                        {{member.name}}
-                    </span>
-                </p>
-            </td>
-
-            {# Value #}
-            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
-                <p class=MsoNoSpacing>
-                    <span style="font-size:8.0pt;font-family:'Courier New'">
-                        {{member.value_str|replace('\n', '<br/>')|replace('\t', '&nbsp;&nbsp;')}}
-                    </span>
-                </p>
-            </td>
-        </tr>
-    {% endfor %}
-
-    </table>
-</div>
-</body>
+{#
+    This is the html template used to convert parsed constructs into user-friendly html
+    that can be used in reports.
+
+    Please see construct_html.py for its use.
+#}
+
+<html>
+<head>
+<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
+<meta name=Generator content="Microsoft Word 14 (filtered)">
+<style>
+<!--
+ /* Font Definitions */
+ @font-face
+	{font-family:Courier;
+	panose-1:2 7 4 9 2 2 5 2 4 4;}
+@font-face
+	{font-family:"Cambria Math";
+	panose-1:2 4 5 3 5 4 6 3 2 4;}
+@font-face
+	{font-family:Calibri;
+	panose-1:2 15 5 2 2 2 4 3 2 4;}
+ /* Style Definitions */
+ p.MsoNormal, li.MsoNormal, div.MsoNormal
+	{margin:0in;
+	margin-bottom:.0001pt;
+	font-size:11.0pt;
+	font-family:"Times New Roman","serif";}
+h1
+	{mso-style-link:"Heading 1 Char";
+	margin:0in;
+	margin-bottom:.0001pt;
+	page-break-after:avoid;
+	font-size:16.0pt;
+	font-family:"Calibri","sans-serif";
+	color:#943634;}
+h3
+	{mso-style-link:"Heading 3 Char";
+	margin-top:10.0pt;
+	margin-right:0in;
+	margin-bottom:0in;
+	margin-left:0in;
+	margin-bottom:.0001pt;
+	page-break-after:avoid;
+	font-size:11.0pt;
+	font-family:"Times New Roman","serif";}
+p.MsoNoSpacing, li.MsoNoSpacing, div.MsoNoSpacing
+	{mso-style-link:"No Spacing Char";
+	margin:0in;
+	margin-bottom:.0001pt;
+	font-size:11.0pt;
+	font-family:"Calibri","sans-serif";}
+span.Heading1Char
+	{mso-style-name:"Heading 1 Char";
+	mso-style-link:"Heading 1";
+	color:#943634;
+	font-weight:bold;}
+span.Heading3Char
+	{mso-style-name:"Heading 3 Char";
+	mso-style-link:"Heading 3";
+	font-family:"Times New Roman","serif";
+	font-weight:bold;}
+span.NoSpacingChar
+	{mso-style-name:"No Spacing Char";
+	mso-style-link:"No Spacing";
+	font-family:"Calibri","sans-serif";}
+.MsoChpDefault
+	{font-family:"Calibri","sans-serif";}
+.MsoPapDefault
+	{margin-bottom:10.0pt;
+	line-height:115%;}
+@page WordSection1
+	{size:8.5in 11.0in;
+	margin:1.0in 1.0in 1.0in 1.0in;}
+div.WordSection1
+	{page:WordSection1;}
+-->
+</style>
+</head>
+<body lang=EN-US>
+<div class=WordSection1>
+
+<!-- Hex Dump -->
+<p class=MsoNormal style='background:#FFFFFF'>
+    <span style='font-size:8.0pt;font-family:"Courier New"'>
+        &nbsp;offset&nbsp;|
+        {%- for i in range(width) -%}
+            &nbsp;{% if i < 16 %}&nbsp;{% endif %}{{'%x'|format(i)}}
+        {%- endfor -%}
+        &nbsp;|&nbsp;
+        {%- for _ in range(width) -%}
+            {{'%x'|format(loop.cycle(*range(16)))}}  {#- We only have enough space for the first digit -#}
+        {%- endfor -%}
+        <br/>
+        &nbsp;------ |  {{'-- ' * width}} | {{'-' * width}}
+        {% for offset, hex_line, ascii_line in hex_dump %}
+        <br/>&nbsp;{{offset}}&nbsp;|&nbsp;{{hex_line}}&nbsp;|&nbsp;{{ascii_line}}
+        {% endfor %}
+    </span>
+</p>
+
+<!-- Variable Table -->
+<p class=MsoNormal>&nbsp;</p>
+    <table class=MsoNormalTable border=1 cellspacing=0 cellpadding=0
+     style='margin-left:5.4pt;border-collapse:collapse;border:none'>
+     <tr>
+      <td width=175 valign=top style='width:131.05pt;border:solid windowtext 1.0pt;
+      background:#244061;padding:0in 5.4pt 0in 5.4pt'>
+      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
+      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Offset</span></b></p>
+      </td>
+      <td width=238 valign=top style='width:178.7pt;border:solid windowtext 1.0pt;
+      border-left:none;background:#244061;padding:0in 5.4pt 0in 5.4pt'>
+      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
+      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Name</span></b></p>
+      </td>
+      <td width=218 valign=top style='width:163.65pt;border:solid windowtext 1.0pt;
+      border-left:none;background:#244061;padding:0in 5.4pt 0in 5.4pt'>
+      <p class=MsoNoSpacing align=center style='text-align:center'><b><span
+      style='font-size:9.0pt;font-family:"Times New Roman","serif";color:white'>Value</span></b></p>
+      </td>
+     </tr>
+
+    {% for offset, (colors, member) in color_map.items()|sort %}
+        <tr>
+            {# Offset #}
+            <td width=175 valign=top style="width:131.05pt;border:solid windowtext 1.0pt;  border-top:none;padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';  ">{{'%06x' % offset}}</span>
+                </p>
+            </td>
+
+            {# Name #}
+            <td width=238 valign=top style="width:178.7pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New';background:{{colors[0]}};color:{{colors[1]}}">
+                        {{member.name}}
+                    </span>
+                </p>
+            </td>
+
+            {# Value #}
+            <td width=218 valign=top style="width:163.65pt;border-top:none;border-left:  none;border-bottom:solid windowtext 1.0pt;border-right:solid windowtext 1.0pt;  padding:0in 5.4pt 0in 5.4pt">
+                <p class=MsoNoSpacing>
+                    <span style="font-size:8.0pt;font-family:'Courier New'">
+                        {{member.value_str|replace('\n', '<br/>')|replace('\t', '&nbsp;&nbsp;')}}
+                    </span>
+                </p>
+            </td>
+        </tr>
+    {% endfor %}
+
+    </table>
+</div>
+</body>
 </html>
```

### Comparing `mwcp-3.8.0/mwcp/utils/construct/datetime_.py` & `mwcp-3.9.0/mwcp/utils/construct/datetime_.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,61 +1,61 @@
-"""
-Date/Time constructs
-"""
-
-from __future__ import absolute_import
-
-import datetime
-
-from .version28 import *
-
-
-# TODO: Implement _encode.
-class _DateTimeDateDataAdapter(Adapter):
-    r"""
-    Adapter for a C# DateTime.dateData object to DateTime format. Obtain the DateTime.Ticks and the DateTime.Kind
-    property to format datetime.
-
-
-    >>> _DateTimeDateDataAdapter(Int64sl).parse('\x80\xb4N3\xd1\xd4\xd1H')
-    '2014-11-23 01:09:01 UTC'
-    """
-    def _decode(self, obj, context, path):
-        ticks = obj & 0x3fffffffffffffff
-        kind = (obj >> 62) & 0x03
-        converted_ticks = datetime.datetime(1, 1, 1) + datetime.timedelta(microseconds=ticks / 10)
-        if kind == 0:
-            return converted_ticks.strftime("%Y-%m-%d %H:%M:%S")
-        elif kind == 1:
-            return converted_ticks.strftime("%Y-%m-%d %H:%M:%S UTC")
-        elif kind == 2:
-            return converted_ticks.strftime("%Y-%m-%d %H:%M:%S Local")
-
-
-DateTimeDateData = _DateTimeDateDataAdapter(Int64sl)
-
-
-# TODO: Implement _encode
-class EpochTimeAdapter(Adapter):
-    r"""
-    Adapter to convert time_t, EpochTime, to an isoformat
-
-    >>> EpochTimeAdapter(construct.Int32ul, tz=datetime.timezone.utc).parse(b'\xff\x93\x37\x57')
-    '2016-05-14T21:09:19+00:00'
-    >>> EpochTimeAdapter(construct.Int32ul).parse(b'\xff\x93\x37\x57')
-    '2016-05-14T17:09:19'
-    """
-    def __init__(self, subcon, tz=None):
-        """
-        :param tz: Optional timezone object, default is localtime
-        :param subcon: subcon to parse EpochTime.
-        """
-        super(EpochTimeAdapter, self).__init__(subcon)
-        self._tz = tz
-
-    def _decode(self, obj, context, path):
-        return datetime.datetime.fromtimestamp(obj, tz=self._tz).isoformat()
-
-
-# Add common helpers
-EpochTime = EpochTimeAdapter(Int32ul)
-EpochTimeUTC = EpochTimeAdapter(construct.Int32ul, tz=datetime.timezone.utc)
+"""
+Date/Time constructs
+"""
+
+from __future__ import absolute_import
+
+import datetime
+
+from .version28 import *
+
+
+# TODO: Implement _encode.
+class _DateTimeDateDataAdapter(Adapter):
+    r"""
+    Adapter for a C# DateTime.dateData object to DateTime format. Obtain the DateTime.Ticks and the DateTime.Kind
+    property to format datetime.
+
+
+    >>> _DateTimeDateDataAdapter(Int64sl).parse('\x80\xb4N3\xd1\xd4\xd1H')
+    '2014-11-23 01:09:01 UTC'
+    """
+    def _decode(self, obj, context, path):
+        ticks = obj & 0x3fffffffffffffff
+        kind = (obj >> 62) & 0x03
+        converted_ticks = datetime.datetime(1, 1, 1) + datetime.timedelta(microseconds=ticks / 10)
+        if kind == 0:
+            return converted_ticks.strftime("%Y-%m-%d %H:%M:%S")
+        elif kind == 1:
+            return converted_ticks.strftime("%Y-%m-%d %H:%M:%S UTC")
+        elif kind == 2:
+            return converted_ticks.strftime("%Y-%m-%d %H:%M:%S Local")
+
+
+DateTimeDateData = _DateTimeDateDataAdapter(Int64sl)
+
+
+# TODO: Implement _encode
+class EpochTimeAdapter(Adapter):
+    r"""
+    Adapter to convert time_t, EpochTime, to an isoformat
+
+    >>> EpochTimeAdapter(construct.Int32ul, tz=datetime.timezone.utc).parse(b'\xff\x93\x37\x57')
+    '2016-05-14T21:09:19+00:00'
+    >>> EpochTimeAdapter(construct.Int32ul).parse(b'\xff\x93\x37\x57')
+    '2016-05-14T17:09:19'
+    """
+    def __init__(self, subcon, tz=None):
+        """
+        :param tz: Optional timezone object, default is localtime
+        :param subcon: subcon to parse EpochTime.
+        """
+        super(EpochTimeAdapter, self).__init__(subcon)
+        self._tz = tz
+
+    def _decode(self, obj, context, path):
+        return datetime.datetime.fromtimestamp(obj, tz=self._tz).isoformat()
+
+
+# Add common helpers
+EpochTime = EpochTimeAdapter(Int32ul)
+EpochTimeUTC = EpochTimeAdapter(construct.Int32ul, tz=datetime.timezone.utc)
```

### Comparing `mwcp-3.8.0/mwcp/utils/construct/helpers.py` & `mwcp-3.9.0/mwcp/utils/construct/helpers.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,2946 +1,2869 @@
 00000000: 2222 2254 6869 7320 6d6f 6475 6c65 7320  """This modules 
 00000010: 636f 6e74 6169 6e73 2068 656c 7065 7220  contains helper 
 00000020: 6675 6e63 7469 6f6e 7320 666f 7220 7468  functions for th
 00000030: 6520 636f 6e73 7472 7563 7420 6c69 6272  e construct libr
-00000040: 6172 792e 2222 220d 0a0d 0a69 6d70 6f72  ary."""....impor
-00000050: 7420 6f73 0d0a 696d 706f 7274 2069 6f0d  t os..import io.
-00000060: 0a69 6d70 6f72 7420 7265 0d0a 696d 706f  .import re..impo
-00000070: 7274 2073 7472 696e 670d 0a69 6d70 6f72  rt string..impor
-00000080: 7420 7575 6964 0d0a 696d 706f 7274 207a  t uuid..import z
-00000090: 6c69 620d 0a0d 0a66 726f 6d20 6d77 6370  lib....from mwcp
-000000a0: 2e75 7469 6c73 2069 6d70 6f72 7420 6375  .utils import cu
-000000b0: 7374 6f6d 6261 7365 3634 2c20 656c 6666  stombase64, elff
-000000c0: 696c 6575 7469 6c73 2c20 7065 6669 6c65  ileutils, pefile
-000000d0: 7574 696c 730d 0a0d 0a0d 0a23 2050 6174  utils......# Pat
-000000e0: 6368 2077 6974 6820 7665 7273 696f 6e20  ch with version 
-000000f0: 322e 3820 6368 616e 6765 732e 0d0a 6672  2.8 changes...fr
-00000100: 6f6d 206d 7763 702e 7574 696c 732e 636f  om mwcp.utils.co
-00000110: 6e73 7472 7563 7420 696d 706f 7274 2076  nstruct import v
-00000120: 6572 7369 6f6e 3238 2061 7320 636f 6e73  ersion28 as cons
-00000130: 7472 7563 740d 0a66 726f 6d20 2e76 6572  truct..from .ver
-00000140: 7369 6f6e 3238 2069 6d70 6f72 7420 2a0d  sion28 import *.
-00000150: 0a0d 0a0d 0a42 5954 4520 3d20 4279 7465  .....BYTE = Byte
-00000160: 0d0a 574f 5244 203d 2049 6e74 3136 756c  ..WORD = Int16ul
-00000170: 0d0a 4457 4f52 4420 3d20 554c 4f4e 4720  ..DWORD = ULONG 
-00000180: 3d20 496e 7433 3275 6c0d 0a51 574f 5244  = Int32ul..QWORD
-00000190: 203d 2055 4c4f 4e47 4c4f 4e47 203d 2049   = ULONGLONG = I
-000001a0: 6e74 3634 756c 0d0a 0d0a 0d0a 6465 6620  nt64ul......def 
-000001b0: 6368 756e 6b28 7365 712c 2073 697a 6529  chunk(seq, size)
-000001c0: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-000001d0: 5265 7475 726e 7320 616e 2069 7465 7261  Returns an itera
-000001e0: 746f 7220 7468 6174 2079 6965 6c64 7320  tor that yields 
-000001f0: 6675 6c6c 2063 6875 6e6b 7320 7365 7120  full chunks seq 
-00000200: 696e 746f 2073 697a 6520 6368 756e 6b73  into size chunks
-00000210: 2e0d 0a0d 0a20 2020 203e 3e3e 206c 6973  .....    >>> lis
-00000220: 7428 6368 756e 6b28 2768 656c 6c6f 272c  t(chunk('hello',
-00000230: 2032 2929 0d0a 2020 2020 5b28 2768 272c   2))..    [('h',
-00000240: 2027 6527 292c 2028 276c 272c 2027 6c27   'e'), ('l', 'l'
-00000250: 295d 0d0a 2020 2020 3e3e 3e20 6c69 7374  )]..    >>> list
-00000260: 2863 6875 6e6b 2827 6865 6c6c 6f21 272c  (chunk('hello!',
-00000270: 2032 2929 0d0a 2020 2020 5b28 2768 272c   2))..    [('h',
-00000280: 2027 6527 292c 2028 276c 272c 2027 6c27   'e'), ('l', 'l'
-00000290: 292c 2028 276f 272c 2027 2127 295d 0d0a  ), ('o', '!')]..
-000002a0: 2020 2020 2222 220d 0a20 2020 2072 6574      """..    ret
-000002b0: 7572 6e20 7a69 7028 2a28 5b69 7465 7228  urn zip(*([iter(
-000002c0: 7365 7129 5d20 2a20 7369 7a65 2929 0d0a  seq)] * size))..
-000002d0: 0d0a 0d0a 636c 6173 7320 426f 6f6c 6561  ....class Boolea
-000002e0: 6e28 4164 6170 7465 7229 3a0d 0a20 2020  n(Adapter):..   
-000002f0: 2072 2222 220d 0a20 2020 2041 6461 7074   r"""..    Adapt
-00000300: 6572 2075 7365 6420 746f 2063 6f6e 7665  er used to conve
-00000310: 7274 2070 6172 7365 6420 7661 6c75 6520  rt parsed value 
-00000320: 696e 746f 2061 2062 6f6f 6c65 616e 2e0d  into a boolean..
-00000330: 0a20 2020 204e 4f54 453a 2057 6869 6c65  .    NOTE: While
-00000340: 2073 696d 696c 6172 2074 6f20 636f 6e73   similar to cons
-00000350: 7472 7563 742e 466c 6167 2c20 7468 6973  truct.Flag, this
-00000360: 2061 6461 7074 6572 2061 6363 6570 7473   adapter accepts
-00000370: 2061 6e79 2076 616c 7565 206f 7468 6572   any value other
-00000380: 2074 6861 6e20 3020 6f72 2027 2720 6173   than 0 or '' as
-00000390: 2074 7275 652e 0d0a 2020 2020 2020 2020   true...        
-000003a0: 2020 416e 6420 7769 6c6c 2077 6f72 6b20    And will work 
-000003b0: 7769 7468 206d 6f72 6520 7468 616e 206a  with more than j
-000003c0: 7573 7420 636f 6e73 7472 7563 742e 4279  ust construct.By
-000003d0: 7465 2e0d 0a0d 0a20 2020 2057 4152 4e49  te.....    WARNI
-000003e0: 4e47 3a20 4475 6520 746f 2074 6865 206c  NG: Due to the l
-000003f0: 6f73 7379 206e 6174 7572 652c 2074 6869  ossy nature, thi
-00000400: 7320 6361 6e27 7420 6265 2075 7365 6420  s can't be used 
-00000410: 746f 2062 7569 6c64 2e0d 0a0d 0a20 2020  to build.....   
-00000420: 2065 2e67 2e0d 0a20 2020 203e 3e3e 2042   e.g...    >>> B
-00000430: 6f6f 6c65 616e 2849 6e74 3332 756c 292e  oolean(Int32ul).
-00000440: 7061 7273 6528 6227 5c78 3031 5c78 3032  parse(b'\x01\x02
-00000450: 5c78 3033 5c78 3034 2729 0d0a 2020 2020  \x03\x04')..    
-00000460: 5472 7565 0d0a 2020 2020 3e3e 3e20 426f  True..    >>> Bo
-00000470: 6f6c 6561 6e28 496e 7433 3275 6c29 2e70  olean(Int32ul).p
-00000480: 6172 7365 2862 275c 7830 305c 7830 305c  arse(b'\x00\x00\
-00000490: 7830 305c 7830 3027 290d 0a20 2020 2046  x00\x00')..    F
-000004a0: 616c 7365 0d0a 2020 2020 3e3e 3e20 426f  alse..    >>> Bo
-000004b0: 6f6c 6561 6e28 4353 7472 696e 6728 2929  olean(CString())
-000004c0: 2e70 6172 7365 2862 2768 656c 6c6f 5c78  .parse(b'hello\x
-000004d0: 3030 2729 0d0a 2020 2020 5472 7565 0d0a  00')..    True..
-000004e0: 2020 2020 3e3e 3e20 426f 6f6c 6561 6e28      >>> Boolean(
-000004f0: 4353 7472 696e 6728 2929 2e70 6172 7365  CString()).parse
-00000500: 2862 275c 7830 3027 290d 0a20 2020 2046  (b'\x00')..    F
-00000510: 616c 7365 0d0a 2020 2020 2222 220d 0a0d  alse..    """...
-00000520: 0a20 2020 2064 6566 205f 6465 636f 6465  .    def _decode
-00000530: 2873 656c 662c 206f 626a 2c20 636f 6e74  (self, obj, cont
-00000540: 6578 742c 2070 6174 6829 3a0d 0a20 2020  ext, path):..   
-00000550: 2020 2020 2072 6574 7572 6e20 626f 6f6c       return bool
-00000560: 286f 626a 290d 0a0d 0a0d 0a63 6c61 7373  (obj)......class
-00000570: 2045 7272 6f72 4d65 7373 6167 6528 436f   ErrorMessage(Co
-00000580: 6e73 7472 7563 7429 3a0d 0a20 2020 2072  nstruct):..    r
-00000590: 2222 220d 0a20 2020 2052 6169 7365 7320  """..    Raises 
-000005a0: 616e 2065 7863 6570 7469 6f6e 2077 6865  an exception whe
-000005b0: 6e20 7472 6967 6765 7265 6420 6279 2070  n triggered by p
-000005c0: 6172 7365 206f 7220 6275 696c 642e 2043  arse or build. C
-000005d0: 616e 2062 6520 7573 6564 2061 7320 6120  an be used as a 
-000005e0: 7365 6e74 696e 656c 2074 6861 7420 626c  sentinel that bl
-000005f0: 6f77 7320 6120 7768 6973 746c 6520 7768  ows a whistle wh
-00000600: 656e 2061 2063 6f6e 6469 7469 6f6e 616c  en a conditional
-00000610: 2062 7261 6e63 6820 676f 6573 2074 6865   branch goes the
-00000620: 2077 726f 6e67 2077 6179 2c20 6f72 2074   wrong way, or t
-00000630: 6f20 7261 6973 6520 616e 2065 7272 6f72  o raise an error
-00000640: 2065 7870 6c69 6369 746c 7920 7468 6520   explicitly the 
-00000650: 6465 636c 6172 6174 6976 6520 7761 792e  declarative way.
-00000660: 0d0a 2020 2020 5468 6973 206d 6f64 6966  ..    This modif
-00000670: 6963 6174 696f 6e20 616c 6c6f 7773 2074  ication allows t
-00000680: 6865 2061 6269 6c69 7479 2074 6f20 7375  he ability to su
-00000690: 7070 6c79 2061 2063 7573 746f 6d20 6d65  pply a custom me
-000006a0: 7373 6167 652e 0d0a 0d0a 2020 2020 4578  ssage.....    Ex
-000006b0: 616d 706c 653a 3a0d 0a0d 0a20 2020 2020  ample::....     
-000006c0: 2020 203e 3e3e 2064 203d 2022 7822 2f49     >>> d = "x"/I
-000006d0: 6e74 3873 6220 3e3e 2049 6654 6865 6e45  nt8sb >> IfThenE
-000006e0: 6c73 6528 7468 6973 2e78 203e 2030 2c20  lse(this.x > 0, 
-000006f0: 496e 7438 7362 2c20 4572 726f 724d 6573  Int8sb, ErrorMes
-00000700: 7361 6765 2827 4661 696c 6564 2069 6620  sage('Failed if 
-00000710: 7374 6174 656d 656e 7427 2929 0d0a 2020  statement'))..  
-00000720: 2020 2020 2020 3e3e 3e20 642e 7061 7273        >>> d.pars
-00000730: 6528 6222 5c78 6666 5c78 3035 2229 0d0a  e(b"\xff\x05")..
-00000740: 2020 2020 2020 2020 5472 6163 6562 6163          Tracebac
-00000750: 6b20 286d 6f73 7420 7265 6365 6e74 2063  k (most recent c
-00000760: 616c 6c20 6c61 7374 293a 0d0a 2020 2020  all last):..    
-00000770: 2020 2020 2020 2020 2e2e 2e0d 0a20 2020          .....   
-00000780: 2020 2020 2045 7870 6c69 6369 7445 7272       ExplicitErr
-00000790: 6f72 3a20 4661 696c 6564 2069 6620 7374  or: Failed if st
-000007a0: 6174 656d 656e 740d 0a20 2020 2022 2222  atement..    """
-000007b0: 0d0a 2020 2020 5f5f 736c 6f74 735f 5f20  ..    __slots__ 
-000007c0: 3d20 5b27 6d65 7373 6167 6527 5d0d 0a0d  = ['message']...
-000007d0: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-000007e0: 5f28 7365 6c66 2c20 6d65 7373 6167 653d  _(self, message=
-000007f0: 2245 7272 6f72 2066 6965 6c64 2077 6173  "Error field was
-00000800: 2061 6374 6976 6174 6564 2e22 293a 0d0a   activated."):..
-00000810: 2020 2020 2020 2020 7375 7065 7228 7365          super(se
-00000820: 6c66 2e5f 5f63 6c61 7373 5f5f 2c20 7365  lf.__class__, se
-00000830: 6c66 292e 5f5f 696e 6974 5f5f 2829 0d0a  lf).__init__()..
-00000840: 2020 2020 2020 2020 7365 6c66 2e6d 6573          self.mes
-00000850: 7361 6765 203d 206d 6573 7361 6765 0d0a  sage = message..
-00000860: 0d0a 2020 2020 6465 6620 5f70 6172 7365  ..    def _parse
-00000870: 2873 656c 662c 2073 7472 6561 6d2c 2063  (self, stream, c
-00000880: 6f6e 7465 7874 2c20 7061 7468 293a 0d0a  ontext, path):..
-00000890: 2020 2020 2020 2020 6d65 7373 6167 6520          message 
-000008a0: 3d20 7365 6c66 2e6d 6573 7361 6765 2863  = self.message(c
-000008b0: 6f6e 7465 7874 2920 6966 2063 616c 6c61  ontext) if calla
-000008c0: 626c 6528 7365 6c66 2e6d 6573 7361 6765  ble(self.message
-000008d0: 2920 656c 7365 2073 656c 662e 6d65 7373  ) else self.mess
-000008e0: 6167 650d 0a20 2020 2020 2020 2072 6169  age..        rai
-000008f0: 7365 2045 7870 6c69 6369 7445 7272 6f72  se ExplicitError
-00000900: 286d 6573 7361 6765 290d 0a0d 0a20 2020  (message)....   
-00000910: 2064 6566 205f 6275 696c 6428 7365 6c66   def _build(self
-00000920: 2c20 6f62 6a2c 2073 7472 6561 6d2c 2063  , obj, stream, c
-00000930: 6f6e 7465 7874 2c20 7061 7468 293a 0d0a  ontext, path):..
-00000940: 2020 2020 2020 2020 6d65 7373 6167 6520          message 
-00000950: 3d20 7365 6c66 2e6d 6573 7361 6765 2863  = self.message(c
-00000960: 6f6e 7465 7874 2920 6966 2063 616c 6c61  ontext) if calla
-00000970: 626c 6528 7365 6c66 2e6d 6573 7361 6765  ble(self.message
-00000980: 2920 656c 7365 2073 656c 662e 6d65 7373  ) else self.mess
-00000990: 6167 650d 0a20 2020 2020 2020 2072 6169  age..        rai
-000009a0: 7365 2045 7870 6c69 6369 7445 7272 6f72  se ExplicitError
-000009b0: 286d 6573 7361 6765 290d 0a0d 0a0d 0a64  (message)......d
-000009c0: 6566 2053 7472 696e 6731 3628 6c65 6e67  ef String16(leng
-000009d0: 7468 293a 0d0a 2020 2020 7222 2222 0d0a  th):..    r"""..
-000009e0: 2020 2020 4372 6561 7465 7320 5554 462d      Creates UTF-
-000009f0: 3136 2028 6c69 7474 6c65 2065 6e64 6961  16 (little endia
-00000a00: 6e29 2065 6e63 6f64 6564 2073 7472 696e  n) encoded strin
-00000a10: 672e 0d0a 0d0a 2020 2020 3e3e 3e20 5374  g.....    >>> St
-00000a20: 7269 6e67 3136 2831 3029 2e62 7569 6c64  ring16(10).build
-00000a30: 2875 2768 656c 6c6f 2729 0d0a 2020 2020  (u'hello')..    
-00000a40: 2768 5c78 3030 655c 7830 306c 5c78 3030  'h\x00e\x00l\x00
-00000a50: 6c5c 7830 306f 5c78 3030 270d 0a20 2020  l\x00o\x00'..   
-00000a60: 203e 3e3e 2053 7472 696e 6731 3628 3130   >>> String16(10
-00000a70: 292e 7061 7273 6528 6227 685c 7830 3065  ).parse(b'h\x00e
-00000a80: 5c78 3030 6c5c 7830 306c 5c78 3030 6f5c  \x00l\x00l\x00o\
-00000a90: 7830 3027 290d 0a20 2020 2075 2768 656c  x00')..    u'hel
-00000aa0: 6c6f 270d 0a20 2020 203e 3e3e 2053 7472  lo'..    >>> Str
-00000ab0: 696e 6731 3628 3136 292e 7061 7273 6528  ing16(16).parse(
-00000ac0: 6227 685c 7830 3065 5c78 3030 6c5c 7830  b'h\x00e\x00l\x0
-00000ad0: 306c 5c78 3030 6f5c 7830 305c 7830 305c  0l\x00o\x00\x00\
-00000ae0: 7830 305c 7830 305c 7830 305c 7830 305c  x00\x00\x00\x00\
-00000af0: 7830 3027 290d 0a20 2020 2075 2768 656c  x00')..    u'hel
-00000b00: 6c6f 270d 0a20 2020 2022 2222 0d0a 2020  lo'..    """..  
-00000b10: 2020 7265 7475 726e 2053 7472 696e 6728    return String(
-00000b20: 6c65 6e67 7468 2c20 656e 636f 6469 6e67  length, encoding
-00000b30: 3d27 7574 662d 3136 2d6c 6527 290d 0a0d  ='utf-16-le')...
-00000b40: 0a0d 0a64 6566 2053 7472 696e 6733 3228  ...def String32(
-00000b50: 6c65 6e67 7468 293a 0d0a 2020 2020 7222  length):..    r"
-00000b60: 2222 0d0a 2020 2020 4372 6561 7465 7320  ""..    Creates 
-00000b70: 5554 462d 3332 2028 6c69 7474 6c65 2065  UTF-32 (little e
-00000b80: 6e64 6961 6e29 2065 6e63 6f64 6564 2073  ndian) encoded s
-00000b90: 7472 696e 672e 0d0a 0d0a 2020 2020 3e3e  tring.....    >>
-00000ba0: 3e20 5374 7269 6e67 3332 2832 3029 2e62  > String32(20).b
-00000bb0: 7569 6c64 2875 2768 656c 6c6f 2729 0d0a  uild(u'hello')..
-00000bc0: 2020 2020 2768 5c78 3030 5c78 3030 5c78      'h\x00\x00\x
-00000bd0: 3030 655c 7830 305c 7830 305c 7830 306c  00e\x00\x00\x00l
-00000be0: 5c78 3030 5c78 3030 5c78 3030 6c5c 7830  \x00\x00\x00l\x0
-00000bf0: 305c 7830 305c 7830 306f 5c78 3030 5c78  0\x00\x00o\x00\x
-00000c00: 3030 5c78 3030 270d 0a20 2020 203e 3e3e  00\x00'..    >>>
-00000c10: 2053 7472 696e 6733 3228 3230 292e 7061   String32(20).pa
-00000c20: 7273 6528 6227 685c 7830 305c 7830 305c  rse(b'h\x00\x00\
-00000c30: 7830 3065 5c78 3030 5c78 3030 5c78 3030  x00e\x00\x00\x00
-00000c40: 6c5c 7830 305c 7830 305c 7830 306c 5c78  l\x00\x00\x00l\x
-00000c50: 3030 5c78 3030 5c78 3030 6f5c 7830 305c  00\x00\x00o\x00\
-00000c60: 7830 305c 7830 3027 290d 0a20 2020 2075  x00\x00')..    u
-00000c70: 2768 656c 6c6f 270d 0a20 2020 2022 2222  'hello'..    """
-00000c80: 0d0a 2020 2020 7265 7475 726e 2053 7472  ..    return Str
-00000c90: 696e 6728 6c65 6e67 7468 2c20 656e 636f  ing(length, enco
-00000ca0: 6469 6e67 3d27 7574 662d 3332 2d6c 6527  ding='utf-32-le'
-00000cb0: 290d 0a0d 0a0d 0a63 6c61 7373 2050 7269  )......class Pri
-00000cc0: 6e74 6162 6c65 2856 616c 6964 6174 6f72  ntable(Validator
-00000cd0: 293a 0d0a 2020 2020 7222 2222 0d0a 2020  ):..    r"""..  
-00000ce0: 2020 5661 6c69 6461 746f 7220 7573 6564    Validator used
-00000cf0: 2074 6f20 7661 6c69 6461 7465 2074 6861   to validate tha
-00000d00: 7420 6120 7061 7273 6564 2053 7472 696e  t a parsed Strin
-00000d10: 6720 286f 7220 4279 7465 7329 2069 7320  g (or Bytes) is 
-00000d20: 6120 7072 696e 7461 626c 6520 2861 7363  a printable (asc
-00000d30: 6969 2920 7374 7269 6e67 2e0d 0a0d 0a20  ii) string..... 
-00000d40: 2020 204e 4f54 453a 2041 2056 616c 6964     NOTE: A Valid
-00000d50: 6174 696f 6e45 7272 6f72 2069 7320 6120  ationError is a 
-00000d60: 7479 7065 206f 6620 436f 6e73 7472 7563  type of Construc
-00000d70: 7445 7272 6f72 2061 6e64 2077 696c 6c20  tError and will 
-00000d80: 6265 2063 6175 7365 2069 6620 6361 7463  be cause if catc
-00000d90: 6869 6e67 2043 6f6e 7374 7275 6374 4572  hing ConstructEr
-00000da0: 726f 722e 0d0a 0d0a 2020 2020 3e3e 3e20  ror.....    >>> 
-00000db0: 5072 696e 7461 626c 6528 5374 7269 6e67  Printable(String
-00000dc0: 2835 2929 2e70 6172 7365 2862 2768 656c  (5)).parse(b'hel
-00000dd0: 6c6f 2729 0d0a 2020 2020 7527 6865 6c6c  lo')..    u'hell
-00000de0: 6f27 0d0a 2020 2020 3e3e 3e20 5072 696e  o'..    >>> Prin
-00000df0: 7461 626c 6528 5374 7269 6e67 2835 2929  table(String(5))
-00000e00: 2e70 6172 7365 2862 2768 655c 7831 316f  .parse(b'he\x11o
-00000e10: 2127 290d 0a20 2020 2054 7261 6365 6261  !')..    Traceba
-00000e20: 636b 2028 6d6f 7374 2072 6563 656e 7420  ck (most recent 
-00000e30: 6361 6c6c 206c 6173 7429 3a0d 0a20 2020  call last):..   
-00000e40: 2020 2020 202e 2e2e 0d0a 2020 2020 5661       .....    Va
-00000e50: 6c69 6461 7469 6f6e 4572 726f 723a 206f  lidationError: o
-00000e60: 626a 6563 7420 6661 696c 6564 2076 616c  bject failed val
-00000e70: 6964 6174 696f 6e3a 2068 6511 6f21 0d0a  idation: he.o!..
-00000e80: 2020 2020 3e3e 3e20 5072 696e 7461 626c      >>> Printabl
-00000e90: 6528 4279 7465 7328 3329 292e 7061 7273  e(Bytes(3)).pars
-00000ea0: 6528 6227 5c78 3031 4e4f 2729 0d0a 2020  e(b'\x01NO')..  
-00000eb0: 2020 5472 6163 6562 6163 6b20 286d 6f73    Traceback (mos
-00000ec0: 7420 7265 6365 6e74 2063 616c 6c20 6c61  t recent call la
-00000ed0: 7374 293a 0d0a 2020 2020 2020 2020 2e2e  st):..        ..
-00000ee0: 2e0d 0a20 2020 2056 616c 6964 6174 696f  ...    Validatio
-00000ef0: 6e45 7272 6f72 3a20 6f62 6a65 6374 2066  nError: object f
-00000f00: 6169 6c65 6420 7661 6c69 6461 7469 6f6e  ailed validation
-00000f10: 3a20 014e 4f0d 0a20 2020 203e 3e3e 2050  : .NO..    >>> P
-00000f20: 7269 6e74 6162 6c65 2842 7974 6573 2833  rintable(Bytes(3
-00000f30: 2929 2e70 6172 7365 2862 2759 4553 2729  )).parse(b'YES')
-00000f40: 0d0a 2020 2020 2759 4553 270d 0a20 2020  ..    'YES'..   
-00000f50: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
-00000f60: 5f76 616c 6964 6174 6528 7365 6c66 2c20  _validate(self, 
-00000f70: 6f62 6a2c 2063 6f6e 7465 7874 2c20 7061  obj, context, pa
-00000f80: 7468 293a 0d0a 2020 2020 2020 2020 6966  th):..        if
-00000f90: 2069 7369 6e73 7461 6e63 6528 6f62 6a2c   isinstance(obj,
-00000fa0: 2062 7974 6573 293a 0d0a 2020 2020 2020   bytes):..      
-00000fb0: 2020 2020 2020 7265 7475 726e 2061 6c6c        return all
-00000fc0: 2863 6872 2862 7974 6529 2069 6e20 7374  (chr(byte) in st
-00000fd0: 7269 6e67 2e70 7269 6e74 6162 6c65 2066  ring.printable f
-00000fe0: 6f72 2062 7974 6520 696e 206f 626a 290d  or byte in obj).
-00000ff0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00001000: 6973 696e 7374 616e 6365 286f 626a 2c20  isinstance(obj, 
-00001010: 7374 7269 6e67 7479 7065 7329 2061 6e64  stringtypes) and
-00001020: 2061 6c6c 2863 6861 7220 696e 2073 7472   all(char in str
-00001030: 696e 672e 7072 696e 7461 626c 6520 666f  ing.printable fo
-00001040: 7220 6368 6172 2069 6e20 6f62 6a29 0d0a  r char in obj)..
-00001050: 0d0a 0d0a 2320 436f 6e74 696e 756f 7573  ....# Continuous
-00001060: 6c79 2070 6172 7365 7320 756e 7469 6c20  ly parses until 
-00001070: 6974 2068 6974 7320 7468 6520 6669 7273  it hits the firs
-00001080: 7420 6e6f 6e2d 7a65 726f 2062 7974 652e  t non-zero byte.
-00001090: 0d0a 536b 6970 4e75 6c6c 203d 2043 6f6e  ..SkipNull = Con
-000010a0: 7374 2862 275c 7830 3027 295b 3a5d 0d0a  st(b'\x00')[:]..
-000010b0: 0d0a 2320 436f 6e74 696e 756f 7573 6c79  ..# Continuously
-000010c0: 2070 6172 7365 7320 756e 7469 6c20 6974   parses until it
-000010d0: 2068 6974 7320 7468 6520 6669 7273 7420   hits the first 
-000010e0: 7a65 726f 2062 7974 6520 2863 6f6e 7375  zero byte (consu
-000010f0: 6d65 6429 2e0d 0a23 2055 7365 2074 6869  med)...# Use thi
-00001100: 7320 696e 7374 6561 6420 6f66 2043 5374  s instead of CSt
-00001110: 7269 6e67 2829 2069 6620 796f 7520 6361  ring() if you ca
-00001120: 6e27 7420 6775 6172 616e 7465 6520 6974  n't guarantee it
-00001130: 2077 6f6e 2774 2066 6169 6c20 746f 2064   won't fail to d
-00001140: 6563 6f64 652e 0d0a 4342 7974 6573 203d  ecode...CBytes =
-00001150: 204e 756c 6c54 6572 6d69 6e61 7465 6428   NullTerminated(
-00001160: 4772 6565 6479 4279 7465 7329 0d0a 0d0a  GreedyBytes)....
-00001170: 0d0a 636c 6173 7320 4279 7465 7354 6572  ..class BytesTer
-00001180: 6d69 6e61 7465 6428 4e75 6c6c 5465 726d  minated(NullTerm
-00001190: 696e 6174 6564 293a 0d0a 2020 2020 7222  inated):..    r"
-000011a0: 2222 0d0a 2020 2020 4279 7465 7354 6572  ""..    BytesTer
-000011b0: 6d69 6e61 7465 6420 6973 2074 6865 2073  minated is the s
-000011c0: 616d 6520 6173 204e 756c 6c54 6572 6d69  ame as NullTermi
-000011d0: 6e61 7465 6420 6578 6365 7074 2074 6861  nated except tha
-000011e0: 7420 6974 2069 7320 7461 7267 6574 6564  t it is targeted
-000011f0: 2066 6f72 2062 696e 6172 7920 6461 7461   for binary data
-00001200: 2061 6e64 206e 6f74 2073 7472 696e 6773   and not strings
-00001210: 2c20 616e 640d 0a20 2020 2074 6865 7265  , and..    there
-00001220: 666f 7265 2074 6865 2074 6572 6d69 6e61  fore the termina
-00001230: 746f 7220 6361 6e20 6265 2061 6e20 6172  tor can be an ar
-00001240: 6269 7472 6172 7920 6c65 6e67 7468 2028  bitrary length (
-00001250: 6173 206f 7070 6f73 6564 2074 6f20 6861  as opposed to ha
-00001260: 7669 6e67 206c 656e 6774 6820 6571 7561  ving length equa
-00001270: 6c20 746f 2074 6865 2063 6861 7261 6374  l to the charact
-00001280: 6572 2077 6964 7468 292e 0d0a 2020 2020  er width)...    
-00001290: 5365 6520 7468 6520 4e75 6c6c 5465 726d  See the NullTerm
-000012a0: 696e 6174 6564 2064 6f63 756d 656e 7461  inated documenta
-000012b0: 7469 6f6e 2066 6f72 2074 6865 2072 656d  tion for the rem
-000012c0: 6169 6e64 6572 206f 6620 7468 6520 6675  ainder of the fu
-000012d0: 6e63 7469 6f6e 616c 6974 7920 616e 6420  nctionality and 
-000012e0: 6f70 7469 6f6e 732e 0d0a 0d0a 2020 2020  options.....    
-000012f0: 3e3e 3e20 4279 7465 7354 6572 6d69 6e61  >>> BytesTermina
-00001300: 7465 6428 4772 6565 6479 4279 7465 732c  ted(GreedyBytes,
-00001310: 2074 6572 6d3d 6227 5445 524d 2729 2e70   term=b'TERM').p
-00001320: 6172 7365 2862 2768 656c 6c6f 5445 524d  arse(b'helloTERM
-00001330: 2729 0d0a 2020 2020 2768 656c 6c6f 270d  ')..    'hello'.
-00001340: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-00001350: 2320 5468 6520 6f6e 6c79 206d 6574 686f  # The only metho
-00001360: 6420 7765 206e 6565 6420 746f 206f 7665  d we need to ove
-00001370: 7272 6964 6520 6973 205f 7061 7273 652e  rride is _parse.
-00001380: 2045 7665 7279 7468 696e 6720 656c 7365   Everything else
-00001390: 2066 726f 6d20 4e75 6c6c 5465 726d 696e   from NullTermin
-000013a0: 6174 6564 2077 6f72 6b73 2061 732d 6973  ated works as-is
-000013b0: 2e0d 0a20 2020 2064 6566 205f 7061 7273  ...    def _pars
-000013c0: 6528 7365 6c66 2c20 7374 7265 616d 2c20  e(self, stream, 
-000013d0: 636f 6e74 6578 742c 2070 6174 6829 3a0d  context, path):.
-000013e0: 0a20 2020 2020 2020 2074 6572 6d20 3d20  .        term = 
-000013f0: 7365 6c66 2e74 6572 6d0d 0a20 2020 2020  self.term..     
-00001400: 2020 2074 6572 6d5f 6c65 6e20 3d20 6c65     term_len = le
-00001410: 6e28 7465 726d 290d 0a20 2020 2020 2020  n(term)..       
-00001420: 2069 6620 7465 726d 5f6c 656e 203c 2031   if term_len < 1
-00001430: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-00001440: 6169 7365 2050 6164 6469 6e67 4572 726f  aise PaddingErro
-00001450: 7228 2242 7974 6573 5465 726d 696e 6174  r("BytesTerminat
-00001460: 6564 2074 6572 6d20 6d75 7374 2062 6520  ed term must be 
-00001470: 6174 206c 6561 7374 2031 2062 7974 6522  at least 1 byte"
-00001480: 290d 0a20 2020 2020 2020 2064 6174 6120  )..        data 
-00001490: 3d20 6227 270d 0a20 2020 2020 2020 2077  = b''..        w
-000014a0: 6869 6c65 2054 7275 653a 0d0a 2020 2020  hile True:..    
-000014b0: 2020 2020 2020 2020 706f 7320 3d20 7374          pos = st
-000014c0: 7265 616d 5f74 656c 6c28 7374 7265 616d  ream_tell(stream
-000014d0: 290d 0a20 2020 2020 2020 2020 2020 2074  )..            t
-000014e0: 7279 3a0d 0a20 2020 2020 2020 2020 2020  ry:..           
-000014f0: 2020 2020 2062 203d 2073 7472 6561 6d5f       b = stream_
-00001500: 7265 6164 2873 7472 6561 6d2c 2074 6572  read(stream, ter
-00001510: 6d5f 6c65 6e29 0d0a 2020 2020 2020 2020  m_len)..        
-00001520: 2020 2020 2020 2020 7374 7265 616d 5f73          stream_s
-00001530: 6565 6b28 7374 7265 616d 2c20 706f 732c  eek(stream, pos,
-00001540: 2030 290d 0a20 2020 2020 2020 2020 2020   0)..           
-00001550: 2065 7863 6570 7420 5374 7265 616d 4572   except StreamEr
-00001560: 726f 723a 0d0a 2020 2020 2020 2020 2020  ror:..          
-00001570: 2020 2020 2020 6966 2073 656c 662e 7265        if self.re
-00001580: 7175 6972 653a 0d0a 2020 2020 2020 2020  quire:..        
-00001590: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-000015a0: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
-000015b0: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
-000015c0: 2020 2020 2020 2020 2020 2020 2020 7374                st
-000015d0: 7265 616d 5f73 6565 6b28 7374 7265 616d  ream_seek(stream
-000015e0: 2c20 706f 732c 2030 290d 0a20 2020 2020  , pos, 0)..     
-000015f0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00001600: 6174 6120 2b3d 2073 7472 6561 6d5f 7265  ata += stream_re
-00001610: 6164 5f65 6e74 6972 6528 7374 7265 616d  ad_entire(stream
-00001620: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
-00001630: 2020 2020 2020 2062 7265 616b 0d0a 0d0a         break....
-00001640: 2020 2020 2020 2020 2020 2020 6966 2062              if b
-00001650: 203d 3d20 7465 726d 3a0d 0a20 2020 2020   == term:..     
-00001660: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-00001670: 6c66 2e69 6e63 6c75 6465 3a0d 0a20 2020  lf.include:..   
-00001680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001690: 2064 6174 6120 2b3d 2062 0d0a 2020 2020   data += b..    
-000016a0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-000016b0: 656c 662e 636f 6e73 756d 653a 0d0a 2020  elf.consume:..  
-000016c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000016d0: 2020 7374 7265 616d 5f72 6561 6428 7374    stream_read(st
-000016e0: 7265 616d 2c20 7465 726d 5f6c 656e 290d  ream, term_len).
-000016f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001700: 2062 7265 616b 0d0a 2020 2020 2020 2020   break..        
-00001710: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
-00001720: 2020 2020 2020 2020 2020 2064 6174 6120             data 
-00001730: 2b3d 2073 7472 6561 6d5f 7265 6164 2873  += stream_read(s
-00001740: 7472 6561 6d2c 2031 290d 0a20 2020 2020  tream, 1)..     
-00001750: 2020 2069 6620 7365 6c66 2e73 7562 636f     if self.subco
-00001760: 6e20 6973 2047 7265 6564 7942 7974 6573  n is GreedyBytes
-00001770: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-00001780: 6574 7572 6e20 6461 7461 0d0a 2020 2020  eturn data..    
-00001790: 2020 2020 6966 2074 7970 6528 7365 6c66      if type(self
-000017a0: 2e73 7562 636f 6e29 2069 7320 4772 6565  .subcon) is Gree
-000017b0: 6479 5374 7269 6e67 3a0d 0a20 2020 2020  dyString:..     
-000017c0: 2020 2020 2020 2072 6574 7572 6e20 6461         return da
-000017d0: 7461 2e64 6563 6f64 6528 7365 6c66 2e73  ta.decode(self.s
-000017e0: 7562 636f 6e2e 656e 636f 6469 6e67 290d  ubcon.encoding).
-000017f0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00001800: 7365 6c66 2e73 7562 636f 6e2e 5f70 6172  self.subcon._par
-00001810: 7365 7265 706f 7274 2869 6f2e 4279 7465  sereport(io.Byte
-00001820: 7349 4f28 6461 7461 292c 2063 6f6e 7465  sIO(data), conte
-00001830: 7874 2c20 7061 7468 290d 0a0d 0a0d 0a23  xt, path)......#
-00001840: 2054 4f44 4f3a 204d 616b 6520 6120 4c53   TODO: Make a LS
-00001850: 7472 6970 7065 643f 0d0a 636c 6173 7320  tripped?..class 
-00001860: 5374 7269 7070 6564 2841 6461 7074 6572  Stripped(Adapter
-00001870: 293a 0d0a 2020 2020 7222 2222 0d0a 2020  ):..    r"""..  
-00001880: 2020 416e 2061 6461 7074 6572 2074 6861    An adapter tha
-00001890: 7420 7374 7269 7073 2063 6861 7261 6374  t strips charact
-000018a0: 6572 732f 6279 7465 7320 6672 6f6d 2074  ers/bytes from t
-000018b0: 6865 2072 6967 6874 206f 6620 7468 6520  he right of the 
-000018c0: 7061 7273 6564 2072 6573 756c 7473 2e0d  parsed results..
-000018d0: 0a0d 0a20 2020 204e 4f54 453a 2057 6869  ...    NOTE: Whi
-000018e0: 6c65 2074 6869 7320 6d61 7920 6c6f 6f6b  le this may look
-000018f0: 2073 696d 696c 6172 2074 6f20 5061 6464   similar to Padd
-00001900: 6564 2829 2074 6869 7320 6973 2064 6966  ed() this is dif
-00001910: 6665 7265 6e74 2062 6563 6175 7365 2074  ferent because t
-00001920: 6869 730d 0a20 2020 2064 6f65 736e 2774  his..    doesn't
-00001930: 2074 616b 6520 6120 6c65 6e67 7468 2061   take a length a
-00001940: 6e64 2069 6e73 7465 6164 2073 7472 6970  nd instead strip
-00001950: 7320 6f75 7420 7468 6520 6e75 6c6c 7320  s out the nulls 
-00001960: 6672 6f6d 2077 6974 6869 6e20 7468 6520  from within the 
-00001970: 616c 7265 6164 7920 7061 7273 6564 2073  already parsed s
-00001980: 7562 636f 6e73 7472 7563 742e 0d0a 0d0a  ubconstruct.....
-00001990: 2020 2020 3a70 6172 616d 2073 7562 636f      :param subco
-000019a0: 6e3a 2054 6865 2073 7562 2d63 6f6e 7374  n: The sub-const
-000019b0: 7275 6374 2074 6f20 7772 6170 2e0d 0a20  ruct to wrap... 
-000019c0: 2020 203a 7061 7261 6d20 7061 643a 2054     :param pad: T
-000019d0: 6865 2063 6861 7261 6374 6572 2f62 7974  he character/byt
-000019e0: 6573 2074 6f20 7573 6520 666f 7220 7374  es to use for st
-000019f0: 7269 7070 696e 672e 2044 6566 6175 6c74  ripping. Default
-00001a00: 7320 746f 206e 756c 6c20 6368 6172 6163  s to null charac
-00001a10: 7465 722e 0d0a 0d0a 2020 2020 3e3e 3e20  ter.....    >>> 
-00001a20: 5374 7269 7070 6564 2847 7265 6564 7942  Stripped(GreedyB
-00001a30: 7974 6573 292e 7061 7273 6528 6227 6865  ytes).parse(b'he
-00001a40: 6c6c 6f5c 7830 305c 7830 305c 7830 3027  llo\x00\x00\x00'
-00001a50: 290d 0a20 2020 2027 6865 6c6c 6f27 0d0a  )..    'hello'..
-00001a60: 2020 2020 3e3e 3e20 5374 7269 7070 6564      >>> Stripped
-00001a70: 2842 7974 6573 2831 3029 292e 7061 7273  (Bytes(10)).pars
-00001a80: 6528 6227 6865 6c6c 6f5c 7830 305c 7830  e(b'hello\x00\x0
-00001a90: 305c 7830 305c 7830 305c 7830 3027 290d  0\x00\x00\x00').
-00001aa0: 0a20 2020 2027 6865 6c6c 6f27 0d0a 2020  .    'hello'..  
-00001ab0: 2020 3e3e 3e20 5374 7269 7070 6564 2842    >>> Stripped(B
-00001ac0: 7974 6573 2831 3429 2c20 7061 643d 6227  ytes(14), pad=b'
-00001ad0: 5041 4427 292e 7061 7273 6528 6227 6865  PAD').parse(b'he
-00001ae0: 6c6c 6f50 4144 5041 4450 4144 2729 0d0a  lloPADPADPAD')..
-00001af0: 2020 2020 2768 656c 6c6f 270d 0a20 2020      'hello'..   
-00001b00: 203e 3e3e 2053 7472 6970 7065 6428 4279   >>> Stripped(By
-00001b10: 7465 7328 3134 292c 2070 6164 3d62 2750  tes(14), pad=b'P
-00001b20: 4144 2729 2e62 7569 6c64 2862 2768 656c  AD').build(b'hel
-00001b30: 6c6f 2729 0d0a 2020 2020 2768 656c 6c6f  lo')..    'hello
-00001b40: 5041 4450 4144 5041 4427 0d0a 2020 2020  PADPADPAD'..    
-00001b50: 3e3e 3e20 5374 7269 7070 6564 2843 5374  >>> Stripped(CSt
-00001b60: 7269 6e67 2829 2c20 7061 643d 7527 5041  ring(), pad=u'PA
-00001b70: 4427 292e 7061 7273 6528 6227 6865 6c6c  D').parse(b'hell
-00001b80: 6f50 4144 5041 445c 7830 3027 290d 0a20  oPADPAD\x00').. 
-00001b90: 2020 2075 2768 656c 6c6f 270d 0a20 2020     u'hello'..   
-00001ba0: 203e 3e3e 2053 7472 6970 7065 6428 5374   >>> Stripped(St
-00001bb0: 7269 6e67 2831 3429 2c20 7061 643d 7527  ring(14), pad=u'
-00001bc0: 5041 4427 292e 7061 7273 6528 6227 6865  PAD').parse(b'he
-00001bd0: 6c6c 6f50 4144 5041 445c 7830 305c 7830  lloPADPAD\x00\x0
-00001be0: 305c 7830 3027 290d 0a20 2020 2075 2768  0\x00')..    u'h
-00001bf0: 656c 6c6f 270d 0a0d 0a20 2020 2023 2057  ello'....    # W
-00001c00: 4152 4e49 4e47 3a20 4966 2070 6164 6469  ARNING: If paddi
-00001c10: 6e67 2064 6f65 736e 2774 2066 6974 2069  ng doesn't fit i
-00001c20: 6e20 7468 6520 7065 7273 6372 6962 6564  n the perscribed
-00001c30: 2064 6174 6120 6974 2077 696c 6c20 6e6f   data it will no
-00001c40: 7420 7374 7269 7020 6974 210d 0a20 2020  t strip it!..   
-00001c50: 203e 3e3e 2053 7472 6970 7065 6428 4279   >>> Stripped(By
-00001c60: 7465 7328 3133 292c 2070 6164 3d62 2750  tes(13), pad=b'P
-00001c70: 4144 2729 2e70 6172 7365 2862 2768 656c  AD').parse(b'hel
-00001c80: 6c6f 5041 4450 4144 5041 2729 0d0a 2020  loPADPADPA')..  
-00001c90: 2020 2768 656c 6c6f 5041 4450 4144 5041    'helloPADPADPA
-00001ca0: 270d 0a20 2020 203e 3e3e 2053 7472 6970  '..    >>> Strip
-00001cb0: 7065 6428 4279 7465 7328 3133 292c 2070  ped(Bytes(13), p
-00001cc0: 6164 3d62 2750 4144 2729 2e62 7569 6c64  ad=b'PAD').build
-00001cd0: 2862 2768 656c 6c6f 2729 0d0a 2020 2020  (b'hello')..    
-00001ce0: 5472 6163 6562 6163 6b20 286d 6f73 7420  Traceback (most 
-00001cf0: 7265 6365 6e74 2063 616c 6c20 6c61 7374  recent call last
-00001d00: 293a 0d0a 2020 2020 2020 2020 2e2e 2e0d  ):..        ....
-00001d10: 0a20 2020 2053 7472 6561 6d45 7272 6f72  .    StreamError
-00001d20: 3a20 6279 7465 7320 6f62 6a65 6374 206f  : bytes object o
-00001d30: 6620 7772 6f6e 6720 6c65 6e67 7468 2c20  f wrong length, 
-00001d40: 6578 7065 6374 6564 2031 332c 2066 6f75  expected 13, fou
-00001d50: 6e64 2035 0d0a 0d0a 2020 2020 2320 4966  nd 5....    # If
-00001d60: 2074 6865 2077 7261 7070 6564 2073 7562   the wrapped sub
-00001d70: 636f 6e73 7472 7563 7427 7320 7369 7a65  construct's size
-00001d80: 2063 616e 2774 2062 6520 6465 7465 726d   can't be determ
-00001d90: 696e 652c 2069 6620 6465 6661 756c 7473  ine, if defaults
-00001da0: 2074 6f20 6e6f 7420 7072 6f76 6964 696e   to not providin
-00001db0: 6720 6120 7061 642e 0d0a 2020 2020 3e3e  g a pad...    >>
-00001dc0: 3e20 5374 7269 7070 6564 2843 5374 7269  > Stripped(CStri
-00001dd0: 6e67 2829 2c20 7061 643d 7527 5041 4427  ng(), pad=u'PAD'
-00001de0: 292e 6275 696c 6428 7527 6865 6c6c 6f27  ).build(u'hello'
-00001df0: 290d 0a20 2020 2027 6865 6c6c 6f5c 7830  )..    'hello\x0
-00001e00: 3027 0d0a 2020 2020 2222 220d 0a0d 0a20  0'..    """.... 
-00001e10: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00001e20: 7365 6c66 2c20 7375 6263 6f6e 2c20 7061  self, subcon, pa
-00001e30: 643d 4e6f 6e65 293a 0d0a 2020 2020 2020  d=None):..      
-00001e40: 2020 7375 7065 7228 5374 7269 7070 6564    super(Stripped
-00001e50: 2c20 7365 6c66 292e 5f5f 696e 6974 5f5f  , self).__init__
-00001e60: 2873 7562 636f 6e29 0d0a 2020 2020 2020  (subcon)..      
-00001e70: 2020 7365 6c66 2e70 6164 203d 2070 6164    self.pad = pad
-00001e80: 0d0a 0d0a 2020 2020 6465 6620 5f64 6563  ....    def _dec
-00001e90: 6f64 6528 7365 6c66 2c20 6f62 6a2c 2063  ode(self, obj, c
-00001ea0: 6f6e 7465 7874 2c20 7061 7468 293a 0d0a  ontext, path):..
-00001eb0: 2020 2020 2020 2020 7061 6420 3d20 7365          pad = se
-00001ec0: 6c66 2e70 6164 0d0a 0d0a 2020 2020 2020  lf.pad....      
-00001ed0: 2020 6966 2070 6164 2069 7320 4e6f 6e65    if pad is None
-00001ee0: 3a0d 0a20 2020 2020 2020 2020 2020 2070  :..            p
-00001ef0: 6164 203d 2075 275c 3027 2069 6620 6973  ad = u'\0' if is
-00001f00: 696e 7374 616e 6365 286f 626a 2c20 756e  instance(obj, un
-00001f10: 6963 6f64 6573 7472 696e 6774 7970 6529  icodestringtype)
-00001f20: 2065 6c73 6520 6227 5c78 3030 270d 0a0d   else b'\x00'...
-00001f30: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-00001f40: 6973 696e 7374 616e 6365 2870 6164 2c20  isinstance(pad, 
-00001f50: 7479 7065 286f 626a 2929 3a0d 0a20 2020  type(obj)):..   
-00001f60: 2020 2020 2020 2020 2072 6169 7365 2050           raise P
-00001f70: 6164 6469 6e67 4572 726f 7228 224e 756c  addingError("Nul
-00001f80: 6c53 7472 6970 7065 6420 7061 6420 6d75  lStripped pad mu
-00001f90: 7374 2062 6520 6f66 2074 6865 2073 616d  st be of the sam
-00001fa0: 6520 7479 7065 3a20 7b7d 2076 7320 7b7d  e type: {} vs {}
-00001fb0: 222e 666f 726d 6174 2874 7970 6528 7061  ".format(type(pa
-00001fc0: 6429 2c20 7479 7065 286f 626a 2929 290d  d), type(obj))).
-00001fd0: 0a0d 0a20 2020 2020 2020 2075 6e69 7420  ...        unit 
-00001fe0: 3d20 6c65 6e28 7061 6429 0d0a 2020 2020  = len(pad)..    
-00001ff0: 2020 2020 6966 2075 6e69 7420 3c20 313a      if unit < 1:
-00002000: 0d0a 2020 2020 2020 2020 2020 2020 7261  ..            ra
-00002010: 6973 6520 5061 6464 696e 6745 7272 6f72  ise PaddingError
-00002020: 2822 4e75 6c6c 5374 7269 7070 6564 2070  ("NullStripped p
-00002030: 6164 206d 7573 7420 6265 2061 7420 6c65  ad must be at le
-00002040: 6173 7420 3120 6279 7465 2229 0d0a 0d0a  ast 1 byte")....
-00002050: 2020 2020 2020 2020 6f62 6a20 3d20 6f62          obj = ob
-00002060: 6a0d 0a20 2020 2020 2020 2069 6620 756e  j..        if un
-00002070: 6974 203d 3d20 313a 0d0a 2020 2020 2020  it == 1:..      
-00002080: 2020 2020 2020 6f62 6a20 3d20 6f62 6a2e        obj = obj.
-00002090: 7273 7472 6970 2870 6164 290d 0a20 2020  rstrip(pad)..   
-000020a0: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-000020b0: 2020 2020 2020 2020 7461 696c 756e 6974          tailunit
-000020c0: 203d 206c 656e 286f 626a 2920 2520 756e   = len(obj) % un
-000020d0: 6974 0d0a 2020 2020 2020 2020 2020 2020  it..            
-000020e0: 656e 6420 3d20 6c65 6e28 6f62 6a29 0d0a  end = len(obj)..
-000020f0: 2020 2020 2020 2020 2020 2020 6966 2074              if t
-00002100: 6169 6c75 6e69 7420 616e 6420 6f62 6a5b  ailunit and obj[
-00002110: 2d74 6169 6c75 6e69 743a 5d20 3d3d 2070  -tailunit:] == p
-00002120: 6164 5b3a 7461 696c 756e 6974 5d3a 0d0a  ad[:tailunit]:..
-00002130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002140: 656e 6420 2d3d 2074 6169 6c75 6e69 740d  end -= tailunit.
-00002150: 0a20 2020 2020 2020 2020 2020 2077 6869  .            whi
-00002160: 6c65 2065 6e64 2d75 6e69 7420 3e3d 2030  le end-unit >= 0
-00002170: 2061 6e64 206f 626a 5b65 6e64 2d75 6e69   and obj[end-uni
-00002180: 743a 656e 645d 203d 3d20 7061 643a 0d0a  t:end] == pad:..
-00002190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000021a0: 656e 6420 2d3d 2075 6e69 740d 0a20 2020  end -= unit..   
-000021b0: 2020 2020 2020 2020 206f 626a 203d 206f           obj = o
-000021c0: 626a 5b3a 656e 645d 0d0a 0d0a 2020 2020  bj[:end]....    
-000021d0: 2020 2020 7265 7475 726e 206f 626a 0d0a      return obj..
-000021e0: 0d0a 2020 2020 6465 6620 5f65 6e63 6f64  ..    def _encod
-000021f0: 6528 7365 6c66 2c20 6f62 6a2c 2063 6f6e  e(self, obj, con
-00002200: 7465 7874 2c20 7061 7468 293a 0d0a 2020  text, path):..  
-00002210: 2020 2020 2020 7061 6420 3d20 7365 6c66        pad = self
-00002220: 2e70 6164 0d0a 0d0a 2020 2020 2020 2020  .pad....        
-00002230: 6966 2070 6164 2069 7320 4e6f 6e65 3a0d  if pad is None:.
-00002240: 0a20 2020 2020 2020 2020 2020 2070 6164  .            pad
-00002250: 203d 2075 275c 3027 2069 6620 6973 696e   = u'\0' if isin
-00002260: 7374 616e 6365 2873 656c 662e 7375 6263  stance(self.subc
-00002270: 6f6e 2c20 5374 7269 6e67 456e 636f 6465  on, StringEncode
-00002280: 6429 2065 6c73 6520 6227 5c78 3030 270d  d) else b'\x00'.
-00002290: 0a0d 0a20 2020 2020 2020 2074 7279 3a0d  ...        try:.
-000022a0: 0a20 2020 2020 2020 2020 2020 2073 697a  .            siz
-000022b0: 6520 3d20 7365 6c66 2e73 7562 636f 6e2e  e = self.subcon.
-000022c0: 5f73 697a 656f 6628 636f 6e74 6578 742c  _sizeof(context,
-000022d0: 2070 6174 6829 0d0a 2020 2020 2020 2020   path)..        
-000022e0: 6578 6365 7074 2053 697a 656f 6645 7272  except SizeofErr
-000022f0: 6f72 3a0d 0a20 2020 2020 2020 2020 2020  or:..           
-00002300: 2072 6574 7572 6e20 6f62 6a20 2023 2044   return obj  # D
-00002310: 6f6e 2774 2070 6164 2069 6620 7765 2063  on't pad if we c
-00002320: 616e 2774 2066 6967 7572 6520 6f75 7420  an't figure out 
-00002330: 7369 7a65 2e0d 0a0d 0a20 2020 2020 2020  size.....       
-00002340: 2075 6e69 7420 3d20 6c65 6e28 7061 6429   unit = len(pad)
-00002350: 0d0a 2020 2020 2020 2020 6966 2075 6e69  ..        if uni
-00002360: 7420 3d3d 2031 3a0d 0a20 2020 2020 2020  t == 1:..       
-00002370: 2020 2020 206f 626a 203d 206f 626a 2e6c       obj = obj.l
-00002380: 6a75 7374 2873 697a 652c 2070 6164 290d  just(size, pad).
-00002390: 0a20 2020 2020 2020 2023 204f 6e6c 7920  .        # Only 
-000023a0: 7061 6420 6966 2069 7420 6669 7473 2069  pad if it fits i
-000023b0: 6e20 6e69 6365 6c79 2e0d 0a20 2020 2020  n nicely...     
-000023c0: 2020 2065 6c69 6620 2873 697a 6520 2d20     elif (size - 
-000023d0: 6c65 6e28 6f62 6a29 2920 2520 756e 6974  len(obj)) % unit
-000023e0: 203d 3d20 303a 0d0a 2020 2020 2020 2020   == 0:..        
-000023f0: 2020 2020 6f62 6a20 3d20 286f 626a 202b      obj = (obj +
-00002400: 2028 7061 6420 2a20 2873 697a 6520 2d20   (pad * (size - 
-00002410: 6c65 6e28 6f62 6a29 2929 295b 3a73 697a  len(obj))))[:siz
-00002420: 655d 0d0a 0d0a 2020 2020 2020 2020 7265  e]....        re
-00002430: 7475 726e 206f 626a 0d0a 0d0a 0d0a 636c  turn obj......cl
-00002440: 6173 7320 4865 7853 7472 696e 6728 4164  ass HexString(Ad
-00002450: 6170 7465 7229 3a0d 0a20 2020 2072 2222  apter):..    r""
-00002460: 220d 0a20 2020 2041 6461 7074 6572 2075  "..    Adapter u
-00002470: 7365 6420 746f 2063 6f6e 7665 7274 2061  sed to convert a
-00002480: 6e20 696e 7420 696e 746f 2061 2068 6578  n int into a hex
-00002490: 2073 7472 696e 6720 6571 7569 7661 6c65   string equivale
-000024a0: 6e74 2e0d 0a0d 0a20 2020 2065 2e67 2e0d  nt.....    e.g..
-000024b0: 0a20 2020 203e 3e3e 2048 6578 5374 7269  .    >>> HexStri
-000024c0: 6e67 2849 6e74 3332 756c 292e 6275 696c  ng(Int32ul).buil
-000024d0: 6428 2730 7831 3233 2729 0d0a 2020 2020  d('0x123')..    
-000024e0: 2723 5c78 3031 5c78 3030 5c78 3030 270d  '#\x01\x00\x00'.
-000024f0: 0a20 2020 203e 3e3e 2048 6578 5374 7269  .    >>> HexStri
-00002500: 6e67 2849 6e74 3332 756c 292e 7061 7273  ng(Int32ul).pars
-00002510: 6528 6227 5c78 3230 5c78 3031 5c78 3030  e(b'\x20\x01\x00
-00002520: 5c78 3030 2729 0d0a 2020 2020 2730 7831  \x00')..    '0x1
-00002530: 3230 270d 0a20 2020 203e 3e3e 2048 6578  20'..    >>> Hex
-00002540: 5374 7269 6e67 2849 6e74 3136 7562 292e  String(Int16ub).
-00002550: 7061 7273 6528 6227 5c78 3132 5c78 3334  parse(b'\x12\x34
-00002560: 2729 0d0a 2020 2020 2730 7831 3233 3427  ')..    '0x1234'
-00002570: 0d0a 2020 2020 3e3e 3e20 4865 7853 7472  ..    >>> HexStr
-00002580: 696e 6728 4279 7465 7349 6e74 6567 6572  ing(BytesInteger
-00002590: 2832 3029 292e 7061 7273 6528 6227 5c78  (20)).parse(b'\x
-000025a0: 3031 2720 2a20 3230 290d 0a20 2020 2027  01' * 20)..    '
-000025b0: 3078 3130 3130 3130 3130 3130 3130 3130  0x10101010101010
-000025c0: 3130 3130 3130 3130 3130 3130 3130 3130  1010101010101010
-000025d0: 3130 3130 3130 3130 3127 0d0a 2020 2020  101010101'..    
-000025e0: 2222 220d 0a0d 0a20 2020 2064 6566 205f  """....    def _
-000025f0: 656e 636f 6465 2873 656c 662c 206f 626a  encode(self, obj
-00002600: 2c20 636f 6e74 6578 742c 2070 6174 6829  , context, path)
-00002610: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
-00002620: 6e20 696e 7428 6f62 6a2c 2031 3629 0d0a  n int(obj, 16)..
-00002630: 0d0a 2020 2020 6465 6620 5f64 6563 6f64  ..    def _decod
-00002640: 6528 7365 6c66 2c20 6f62 6a2c 2063 6f6e  e(self, obj, con
-00002650: 7465 7874 2c20 7061 7468 293a 0d0a 2020  text, path):..  
-00002660: 2020 2020 2020 6865 785f 7374 7269 6e67        hex_string
-00002670: 203d 2068 6578 286f 626a 290d 0a20 2020   = hex(obj)..   
-00002680: 2020 2020 2069 6620 6865 785f 7374 7269       if hex_stri
-00002690: 6e67 2e65 6e64 7377 6974 6828 274c 2729  ng.endswith('L')
-000026a0: 3a0d 0a20 2020 2020 2020 2020 2020 2068  :..            h
-000026b0: 6578 5f73 7472 696e 6720 3d20 6865 785f  ex_string = hex_
-000026c0: 7374 7269 6e67 5b3a 2d31 5d0d 0a20 2020  string[:-1]..   
-000026d0: 2020 2020 2072 6574 7572 6e20 6865 785f       return hex_
-000026e0: 7374 7269 6e67 0d0a 0d0a 0d0a 636c 6173  string......clas
-000026f0: 7320 4261 7365 3634 2841 6461 7074 6572  s Base64(Adapter
-00002700: 293a 0d0a 2020 2020 7222 2222 0d0a 2020  ):..    r"""..  
-00002710: 2020 4164 6170 7465 7220 7573 6564 2074    Adapter used t
-00002720: 6f20 4261 7365 3634 2065 6e63 6f64 6564  o Base64 encoded
-00002730: 2f64 6563 6f64 6520 6120 7661 6c75 652e  /decode a value.
-00002740: 0d0a 0d0a 2020 2020 5741 524e 494e 473a  ....    WARNING:
-00002750: 2054 6869 7320 6164 6170 7465 7220 6d75   This adapter mu
-00002760: 7374 2062 6520 7573 6564 206f 6e20 6120  st be used on a 
-00002770: 756e 6963 6f64 6520 7374 7269 6e67 2076  unicode string v
-00002780: 616c 7565 2e0d 0a0d 0a20 2020 203a 7061  alue.....    :pa
-00002790: 7261 6d20 7375 6263 6f6e 3a20 7468 6520  ram subcon: the 
-000027a0: 636f 6e73 7472 7563 7420 746f 2077 7261  construct to wra
-000027b0: 700d 0a20 2020 203a 7061 7261 6d20 6375  p..    :param cu
-000027c0: 7374 6f6d 5f61 6c70 6861 3a20 6f70 7469  stom_alpha: opti
-000027d0: 6f6e 616c 2063 7573 746f 6d20 616c 7068  onal custom alph
-000027e0: 6162 6574 2074 6f20 7573 650d 0a0d 0a20  abet to use.... 
-000027f0: 2020 2065 2e67 2e0d 0a20 2020 203e 3e3e     e.g...    >>>
-00002800: 2042 6173 6536 3428 4772 6565 6479 5374   Base64(GreedySt
-00002810: 7269 6e67 2829 292e 6275 696c 6428 6227  ring()).build(b'
-00002820: 6865 6c6c 6f27 290d 0a20 2020 2027 6147  hello')..    'aG
-00002830: 5673 6247 383d 270d 0a20 2020 203e 3e3e  VsbG8='..    >>>
-00002840: 2042 6173 6536 3428 4772 6565 6479 5374   Base64(GreedySt
-00002850: 7269 6e67 2829 292e 7061 7273 6528 6227  ring()).parse(b'
-00002860: 6147 5673 6247 383d 2729 0d0a 2020 2020  aGVsbG8=')..    
-00002870: 2768 656c 6c6f 270d 0a20 2020 203e 3e3e  'hello'..    >>>
-00002880: 2042 6173 6536 3428 4772 6565 6479 4279   Base64(GreedyBy
-00002890: 7465 7329 2e62 7569 6c64 2862 275c 7830  tes).build(b'\x0
-000028a0: 315c 7830 325c 7830 335c 7830 3427 290d  1\x02\x03\x04').
-000028b0: 0a20 2020 2027 4151 4944 4241 3d3d 270d  .    'AQIDBA=='.
-000028c0: 0a20 2020 203e 3e3e 2042 6173 6536 3428  .    >>> Base64(
-000028d0: 4772 6565 6479 4279 7465 7329 2e70 6172  GreedyBytes).par
-000028e0: 7365 2862 2741 5149 4442 413d 3d27 290d  se(b'AQIDBA==').
-000028f0: 0a20 2020 2027 5c78 3031 5c78 3032 5c78  .    '\x01\x02\x
-00002900: 3033 5c78 3034 270d 0a0d 0a20 2020 204e  03\x04'....    N
-00002910: 4f54 453a 2053 7472 696e 6720 7369 7a65  OTE: String size
-00002920: 2069 7320 6261 7365 6420 6f6e 2074 6865   is based on the
-00002930: 2065 6e63 6f64 6564 2076 6572 7369 6f6e   encoded version
-00002940: 2e0d 0a20 2020 203e 3e3e 2042 6173 6536  ...    >>> Base6
-00002950: 3428 5374 7269 6e67 2831 3629 292e 6275  4(String(16)).bu
-00002960: 696c 6428 7527 6865 6c6c 6f20 776f 726c  ild(u'hello worl
-00002970: 6427 290d 0a20 2020 2027 6147 5673 6247  d')..    'aGVsbG
-00002980: 3867 6432 3979 6247 513d 270d 0a20 2020  8gd29ybGQ='..   
-00002990: 203e 3e3e 2042 6173 6536 3428 5374 7269   >>> Base64(Stri
-000029a0: 6e67 2831 3629 292e 7061 7273 6528 6227  ng(16)).parse(b'
-000029b0: 6147 5673 6247 3867 6432 3979 6247 513d  aGVsbG8gd29ybGQ=
-000029c0: 2729 0d0a 2020 2020 2768 656c 6c6f 2077  ')..    'hello w
-000029d0: 6f72 6c64 270d 0a0d 0a20 2020 2053 7570  orld'....    Sup
-000029e0: 706c 7969 6e67 2061 2063 7573 746f 6d20  plying a custom 
-000029f0: 616c 7068 6162 6574 2069 7320 616c 736f  alphabet is also
-00002a00: 2073 7570 706f 7274 6564 2e0d 0a20 2020   supported...   
-00002a10: 203e 3e3e 2073 7065 6320 3d20 4261 7365   >>> spec = Base
-00002a20: 3634 2853 7472 696e 6728 3136 292c 2063  64(String(16), c
-00002a30: 7573 746f 6d5f 616c 7068 613d 2745 4647  ustom_alpha='EFG
-00002a40: 4851 5253 5455 5657 6566 6768 696a 6b6c  HQRSTUVWefghijkl
-00002a50: 6d6e 6f70 494a 4b4c 4d4e 4f50 4142 4344  mnopIJKLMNOPABCD
-00002a60: 7172 7374 7576 7778 7958 595a 6162 6364  qrstuvwxyXYZabcd
-00002a70: 7a30 3132 3334 3536 3738 392b 2f3d 2729  z0123456789+/=')
-00002a80: 0d0a 2020 2020 3e3e 3e20 7370 6563 2e62  ..    >>> spec.b
-00002a90: 7569 6c64 2875 2768 656c 6c6f 2077 6f72  uild(u'hello wor
-00002aa0: 6c64 2729 0d0a 2020 2020 274c 536f 584d  ld')..    'LSoXM
-00002ab0: 5338 424f 3239 644d 536a 3d27 0d0a 2020  S8BO29dMSj='..  
-00002ac0: 2020 3e3e 3e20 7370 6563 2e70 6172 7365    >>> spec.parse
-00002ad0: 2862 274c 536f 584d 5338 424f 3239 644d  (b'LSoXMS8BO29dM
-00002ae0: 536a 3d27 290d 0a20 2020 2027 6865 6c6c  Sj=')..    'hell
-00002af0: 6f20 776f 726c 6427 0d0a 2020 2020 2222  o world'..    ""
-00002b00: 220d 0a20 2020 205f 5f73 6c6f 7473 5f5f  "..    __slots__
-00002b10: 203d 205b 2773 7562 636f 6e27 2c20 2763   = ['subcon', 'c
-00002b20: 7573 746f 6d5f 616c 7068 6127 5d0d 0a0d  ustom_alpha']...
-00002b30: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00002b40: 5f28 7365 6c66 2c20 7375 6263 6f6e 2c20  _(self, subcon, 
-00002b50: 6375 7374 6f6d 5f61 6c70 6861 3d4e 6f6e  custom_alpha=Non
-00002b60: 6529 3a0d 0a20 2020 2020 2020 2073 7570  e):..        sup
-00002b70: 6572 2842 6173 6536 342c 2073 656c 6629  er(Base64, self)
-00002b80: 2e5f 5f69 6e69 745f 5f28 7375 6263 6f6e  .__init__(subcon
-00002b90: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-00002ba0: 6375 7374 6f6d 5f61 6c70 6861 203d 2063  custom_alpha = c
-00002bb0: 7573 746f 6d5f 616c 7068 610d 0a0d 0a20  ustom_alpha.... 
-00002bc0: 2020 2064 6566 205f 656e 636f 6465 2873     def _encode(s
-00002bd0: 656c 662c 206f 626a 2c20 636f 6e74 6578  elf, obj, contex
-00002be0: 742c 2070 6174 6829 3a0d 0a20 2020 2020  t, path):..     
-00002bf0: 2020 206f 626a 203d 2063 7573 746f 6d62     obj = customb
-00002c00: 6173 6536 342e 6236 3465 6e63 6f64 6528  ase64.b64encode(
-00002c10: 6f62 6a2c 2061 6c70 6861 6265 743d 7365  obj, alphabet=se
-00002c20: 6c66 2e63 7573 746f 6d5f 616c 7068 6129  lf.custom_alpha)
-00002c30: 0d0a 2020 2020 2020 2020 2320 436f 6e76  ..        # Conv
-00002c40: 6572 7420 746f 2075 6e69 636f 6465 2069  ert to unicode i
-00002c50: 6620 7772 6170 7065 6420 7375 6263 6f6e  f wrapped subcon
-00002c60: 2065 7870 6563 7473 2069 742e 0d0a 2020   expects it...  
-00002c70: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
-00002c80: 6e63 6528 7365 6c66 2e73 7562 636f 6e2c  nce(self.subcon,
-00002c90: 2053 7472 696e 6745 6e63 6f64 6564 293a   StringEncoded):
-00002ca0: 0d0a 2020 2020 2020 2020 2020 2020 6f62  ..            ob
-00002cb0: 6a20 3d20 6f62 6a2e 6465 636f 6465 2827  j = obj.decode('
-00002cc0: 7574 662d 3827 290d 0a20 2020 2020 2020  utf-8')..       
-00002cd0: 2072 6574 7572 6e20 6f62 6a0d 0a0d 0a20   return obj.... 
-00002ce0: 2020 2064 6566 205f 6465 636f 6465 2873     def _decode(s
-00002cf0: 656c 662c 206f 626a 2c20 636f 6e74 6578  elf, obj, contex
-00002d00: 742c 2070 6174 6829 3a0d 0a20 2020 2020  t, path):..     
-00002d10: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
-00002d20: 286f 626a 2c20 7374 7229 3a0d 0a20 2020  (obj, str):..   
-00002d30: 2020 2020 2020 2020 206f 626a 203d 206f           obj = o
-00002d40: 626a 2e65 6e63 6f64 6528 2775 7466 2d38  bj.encode('utf-8
-00002d50: 2729 0d0a 2020 2020 2020 2020 7265 7475  ')..        retu
-00002d60: 726e 2063 7573 746f 6d62 6173 6536 342e  rn custombase64.
-00002d70: 6236 3464 6563 6f64 6528 6f62 6a2c 2061  b64decode(obj, a
-00002d80: 6c70 6861 6265 743d 7365 6c66 2e63 7573  lphabet=self.cus
-00002d90: 746f 6d5f 616c 7068 6129 0d0a 0d0a 0d0a  tom_alpha)......
-00002da0: 636c 6173 7320 5a4c 4942 2841 6461 7074  class ZLIB(Adapt
-00002db0: 6572 293a 0d0a 2020 2020 7222 2222 0d0a  er):..    r"""..
-00002dc0: 2020 2020 4164 6170 7465 7220 7573 6564      Adapter used
-00002dd0: 2074 6f20 7a6c 6962 2063 6f6d 7072 6573   to zlib compres
-00002de0: 732f 6465 636f 6d70 7265 7373 2061 2064  s/decompress a d
-00002df0: 6174 6120 6275 6666 6572 0d0a 0d0a 2020  ata buffer....  
-00002e00: 2020 3a70 6172 616d 2073 7562 636f 6e3a    :param subcon:
-00002e10: 2054 6865 2063 6f6e 7374 7275 6374 2074   The construct t
-00002e20: 6f20 7772 6170 0d0a 2020 2020 3a70 6172  o wrap..    :par
-00002e30: 616d 2069 6e74 206c 6576 656c 3a20 5468  am int level: Th
-00002e40: 6520 7a6c 6962 2063 6f6d 7072 6573 7369  e zlib compressi
-00002e50: 6f6e 206c 6576 656c 0d0a 2020 2020 3a70  on level..    :p
-00002e60: 6172 616d 2069 6e74 2077 6269 7473 3a20  aram int wbits: 
-00002e70: 5468 6520 7a6c 6962 2064 6563 6f6d 7072  The zlib decompr
-00002e80: 6573 7369 6f6e 2077 696e 646f 7720 7369  ession window si
-00002e90: 7a65 0d0a 2020 2020 3a70 6172 616d 2069  ze..    :param i
-00002ea0: 6e74 2062 7566 7369 7a65 3a20 5468 6520  nt bufsize: The 
-00002eb0: 696e 6974 6961 6c20 6f75 7470 7574 2062  initial output b
-00002ec0: 7566 6665 7220 7369 7a65 0d0a 0d0a 2020  uffer size....  
-00002ed0: 2020 3e3e 3e20 5a4c 4942 2842 7974 6573    >>> ZLIB(Bytes
-00002ee0: 2831 3229 292e 6275 696c 6428 6227 6461  (12)).build(b'da
-00002ef0: 7461 2729 0d0a 2020 2020 2778 5c78 3963  ta')..    'x\x9c
-00002f00: 4b49 2c49 5c78 3034 5c78 3030 5c78 3034  KI,I\x04\x00\x04
-00002f10: 5c78 3030 5c78 3031 5c78 3962 270d 0a20  \x00\x01\x9b'.. 
-00002f20: 2020 203e 3e3e 205a 4c49 4228 4772 6565     >>> ZLIB(Gree
-00002f30: 6479 4279 7465 732c 206c 6576 656c 3d30  dyBytes, level=0
-00002f40: 292e 6275 696c 6428 6227 6461 7461 2729  ).build(b'data')
-00002f50: 0d0a 2020 2020 2778 5c78 3031 5c78 3031  ..    'x\x01\x01
-00002f60: 5c78 3034 5c78 3030 5c78 6662 5c78 6666  \x04\x00\xfb\xff
-00002f70: 6461 7461 5c78 3034 5c78 3030 5c78 3031  data\x04\x00\x01
-00002f80: 5c78 3962 270d 0a20 2020 203e 3e3e 205a  \x9b'..    >>> Z
-00002f90: 4c49 4228 4772 6565 6479 4279 7465 7329  LIB(GreedyBytes)
-00002fa0: 2e70 6172 7365 2862 2778 5e4b 492c 495c  .parse(b'x^KI,I\
-00002fb0: 7830 345c 7830 305c 7830 345c 7830 305c  x04\x00\x04\x00\
-00002fc0: 7830 315c 7839 6227 290d 0a20 2020 2027  x01\x9b')..    '
-00002fd0: 6461 7461 270d 0a20 2020 2022 2222 0d0a  data'..    """..
-00002fe0: 2020 2020 5f5f 736c 6f74 735f 5f20 3d20      __slots__ = 
-00002ff0: 5b22 7375 6263 6f6e 222c 2022 7762 6974  ["subcon", "wbit
-00003000: 7322 2c20 2262 7566 7369 7a65 222c 2022  s", "bufsize", "
-00003010: 6c65 7665 6c22 5d0d 0a0d 0a20 2020 2064  level"]....    d
-00003020: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
-00003030: 2c20 7375 6263 6f6e 2c20 7762 6974 733d  , subcon, wbits=
-00003040: 4e6f 6e65 2c20 6275 6673 697a 653d 4e6f  None, bufsize=No
-00003050: 6e65 2c20 6c65 7665 6c3d 4e6f 6e65 293a  ne, level=None):
-00003060: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
-00003070: 5a4c 4942 2c20 7365 6c66 292e 5f5f 696e  ZLIB, self).__in
-00003080: 6974 5f5f 2873 7562 636f 6e29 0d0a 2020  it__(subcon)..  
-00003090: 2020 2020 2020 7365 6c66 2e77 6269 7473        self.wbits
-000030a0: 203d 2077 6269 7473 0d0a 2020 2020 2020   = wbits..      
-000030b0: 2020 7365 6c66 2e62 7566 7369 7a65 203d    self.bufsize =
-000030c0: 2062 7566 7369 7a65 0d0a 2020 2020 2020   bufsize..      
-000030d0: 2020 7365 6c66 2e6c 6576 656c 203d 206c    self.level = l
-000030e0: 6576 656c 0d0a 0d0a 2020 2020 6465 6620  evel....    def 
-000030f0: 5f65 6e63 6f64 6528 7365 6c66 2c20 6f62  _encode(self, ob
-00003100: 6a2c 2063 6f6e 7465 7874 2c20 7061 7468  j, context, path
-00003110: 293a 0d0a 2020 2020 2020 2020 6c65 7665  ):..        leve
-00003120: 6c20 3d20 7365 6c66 2e6c 6576 656c 2863  l = self.level(c
-00003130: 6f6e 7465 7874 2920 6966 2063 616c 6c61  ontext) if calla
-00003140: 626c 6528 7365 6c66 2e6c 6576 656c 2920  ble(self.level) 
-00003150: 656c 7365 2073 656c 662e 6c65 7665 6c0d  else self.level.
-00003160: 0a20 2020 2020 2020 2069 6620 6c65 7665  .        if leve
-00003170: 6c20 6973 206e 6f74 204e 6f6e 653a 0d0a  l is not None:..
-00003180: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00003190: 726e 207a 6c69 622e 636f 6d70 7265 7373  rn zlib.compress
-000031a0: 286f 626a 2c20 6c65 7665 6c29 0d0a 2020  (obj, level)..  
-000031b0: 2020 2020 2020 7265 7475 726e 207a 6c69        return zli
-000031c0: 622e 636f 6d70 7265 7373 286f 626a 290d  b.compress(obj).
-000031d0: 0a0d 0a20 2020 2064 6566 205f 6465 636f  ...    def _deco
-000031e0: 6465 2873 656c 662c 206f 626a 2c20 636f  de(self, obj, co
-000031f0: 6e74 6578 742c 2070 6174 6829 3a0d 0a20  ntext, path):.. 
-00003200: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
-00003210: 2020 2020 5a4c 4942 2064 6563 6f6d 7072      ZLIB decompr
-00003220: 6573 7320 6120 6275 6666 6572 2c20 6361  ess a buffer, ca
-00003230: 6e6e 6f74 2075 7365 2062 7566 7369 7a65  nnot use bufsize
-00003240: 2069 6620 7762 6974 7320 6973 206e 6f74   if wbits is not
-00003250: 2073 6574 0d0a 0d0a 2020 2020 2020 2020   set....        
-00003260: 3a70 6172 616d 206f 626a 3a0d 0a20 2020  :param obj:..   
-00003270: 2020 2020 203a 7061 7261 6d20 636f 6e74       :param cont
-00003280: 6578 743a 0d0a 0d0a 2020 2020 2020 2020  ext:....        
-00003290: 3a72 6574 7572 6e3a 0d0a 2020 2020 2020  :return:..      
-000032a0: 2020 2222 220d 0a20 2020 2020 2020 2077    """..        w
-000032b0: 6269 7473 203d 2073 656c 662e 7762 6974  bits = self.wbit
-000032c0: 7328 636f 6e74 6578 7429 2069 6620 6361  s(context) if ca
-000032d0: 6c6c 6162 6c65 2873 656c 662e 7762 6974  llable(self.wbit
-000032e0: 7329 2065 6c73 6520 7365 6c66 2e77 6269  s) else self.wbi
-000032f0: 7473 0d0a 2020 2020 2020 2020 6275 6673  ts..        bufs
-00003300: 697a 6520 3d20 7365 6c66 2e62 7566 7369  ize = self.bufsi
-00003310: 7a65 2863 6f6e 7465 7874 2920 6966 2063  ze(context) if c
-00003320: 616c 6c61 626c 6528 7365 6c66 2e62 7566  allable(self.buf
-00003330: 7369 7a65 2920 656c 7365 2073 656c 662e  size) else self.
-00003340: 6275 6673 697a 650d 0a20 2020 2020 2020  bufsize..       
-00003350: 2069 6620 7762 6974 7320 6973 206e 6f74   if wbits is not
-00003360: 204e 6f6e 6520 616e 6420 6275 6673 697a   None and bufsiz
-00003370: 6520 6973 206e 6f74 204e 6f6e 653a 0d0a  e is not None:..
-00003380: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00003390: 726e 207a 6c69 622e 6465 636f 6d70 7265  rn zlib.decompre
-000033a0: 7373 286f 626a 2c20 7762 6974 732c 2062  ss(obj, wbits, b
-000033b0: 7566 7369 7a65 290d 0a20 2020 2020 2020  ufsize)..       
-000033c0: 2065 6c69 6620 7762 6974 7320 6973 206e   elif wbits is n
-000033d0: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
-000033e0: 2020 2020 2020 7265 7475 726e 207a 6c69        return zli
-000033f0: 622e 6465 636f 6d70 7265 7373 286f 626a  b.decompress(obj
-00003400: 2c20 7762 6974 7329 0d0a 2020 2020 2020  , wbits)..      
-00003410: 2020 7265 7475 726e 207a 6c69 622e 6465    return zlib.de
-00003420: 636f 6d70 7265 7373 286f 626a 290d 0a0d  compress(obj)...
-00003430: 0a0d 0a63 6c61 7373 2055 5549 4441 6461  ...class UUIDAda
-00003440: 7074 6572 2841 6461 7074 6572 293a 0d0a  pter(Adapter):..
-00003450: 2020 2020 7222 2222 0d0a 2020 2020 4164      r"""..    Ad
-00003460: 6170 7465 7220 7573 6564 2074 6f20 636f  apter used to co
-00003470: 6e76 6572 7420 7061 7273 6564 2062 7974  nvert parsed byt
-00003480: 6573 2074 6f20 6120 7374 7269 6e67 2072  es to a string r
-00003490: 6570 7265 7365 6e74 696e 6720 7468 6520  epresenting the 
-000034a0: 5555 4944 2e0d 0a20 2020 2041 6461 7074  UUID...    Adapt
-000034b0: 6572 2063 616e 2064 6563 6f64 6520 3136  er can decode 16
-000034c0: 2062 7974 6573 2073 7472 6169 6768 7420   bytes straight 
-000034d0: 6f72 2069 6e20 6c69 7474 6c65 2d65 6e64  or in little-end
-000034e0: 6961 6e20 6f72 6465 7220 6966 2079 6f75  ian order if you
-000034f0: 2073 6574 206c 653d 5472 7565 2e0d 0a0d   set le=True....
-00003500: 0a20 2020 2065 2e67 2e0d 0a20 2020 203e  .    e.g...    >
-00003510: 3e3e 2055 5549 4441 6461 7074 6572 2842  >> UUIDAdapter(B
-00003520: 7974 6573 2831 3629 292e 6275 696c 6428  ytes(16)).build(
-00003530: 277b 3132 3334 3536 3738 2d31 3233 342d  '{12345678-1234-
-00003540: 3536 3738 2d31 3233 342d 3536 3738 3132  5678-1234-567812
-00003550: 3334 3536 3738 7d27 290d 0a20 2020 2027  345678}')..    '
-00003560: 7856 345c 7831 3234 5c78 3132 7856 5c78  xV4\x124\x12xV\x
-00003570: 3132 3456 785c 7831 3234 5678 270d 0a20  124Vx\x124Vx'.. 
-00003580: 2020 203e 3e3e 2055 5549 4441 6461 7074     >>> UUIDAdapt
-00003590: 6572 2842 7974 6573 2831 3629 2c20 6c65  er(Bytes(16), le
-000035a0: 3d46 616c 7365 292e 6275 696c 6428 277b  =False).build('{
-000035b0: 3132 3334 3536 3738 2d31 3233 342d 3536  12345678-1234-56
-000035c0: 3738 2d31 3233 342d 3536 3738 3132 3334  78-1234-56781234
-000035d0: 3536 3738 7d27 290d 0a20 2020 2027 5c78  5678}')..    '\x
-000035e0: 3132 3456 785c 7831 3234 5678 5c78 3132  124Vx\x124Vx\x12
-000035f0: 3456 785c 7831 3234 5678 270d 0a20 2020  4Vx\x124Vx'..   
-00003600: 203e 3e3e 2055 5549 4441 6461 7074 6572   >>> UUIDAdapter
-00003610: 2842 7974 6573 2831 3629 292e 7061 7273  (Bytes(16)).pars
-00003620: 6528 6227 7856 345c 7831 3234 5c78 3132  e(b'xV4\x124\x12
-00003630: 7856 5c78 3132 3456 785c 7831 3234 5678  xV\x124Vx\x124Vx
-00003640: 2729 0d0a 2020 2020 277b 3132 3334 3536  ')..    '{123456
-00003650: 3738 2d31 3233 342d 3536 3738 2d31 3233  78-1234-5678-123
-00003660: 342d 3536 3738 3132 3334 3536 3738 7d27  4-567812345678}'
-00003670: 0d0a 2020 2020 2222 220d 0a20 2020 205f  ..    """..    _
-00003680: 5f73 6c6f 7473 5f5f 203d 205b 2773 7562  _slots__ = ['sub
-00003690: 636f 6e27 2c20 276c 6527 5d0d 0a0d 0a20  con', 'le'].... 
-000036a0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-000036b0: 7365 6c66 2c20 7375 6263 6f6e 2c20 6c65  self, subcon, le
-000036c0: 3d54 7275 6529 3a0d 0a20 2020 2020 2020  =True):..       
-000036d0: 2073 7570 6572 2855 5549 4441 6461 7074   super(UUIDAdapt
-000036e0: 6572 2c20 7365 6c66 292e 5f5f 696e 6974  er, self).__init
-000036f0: 5f5f 2873 7562 636f 6e29 0d0a 2020 2020  __(subcon)..    
-00003700: 2020 2020 7365 6c66 2e6c 6520 3d20 6c65      self.le = le
-00003710: 0d0a 0d0a 2020 2020 6465 6620 5f65 6e63  ....    def _enc
-00003720: 6f64 6528 7365 6c66 2c20 6f62 6a2c 2063  ode(self, obj, c
-00003730: 6f6e 7465 7874 2c20 7061 7468 293a 0d0a  ontext, path):..
-00003740: 2020 2020 2020 2020 6f62 6a20 3d20 7575          obj = uu
-00003750: 6964 2e55 5549 4428 6f62 6a29 0d0a 2020  id.UUID(obj)..  
-00003760: 2020 2020 2020 6966 2073 656c 662e 6c65        if self.le
-00003770: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-00003780: 6574 7572 6e20 6f62 6a2e 6279 7465 735f  eturn obj.bytes_
-00003790: 6c65 0d0a 2020 2020 2020 2020 656c 7365  le..        else
-000037a0: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-000037b0: 6574 7572 6e20 6f62 6a2e 6279 7465 730d  eturn obj.bytes.
-000037c0: 0a0d 0a20 2020 2064 6566 205f 6465 636f  ...    def _deco
-000037d0: 6465 2873 656c 662c 206f 626a 2c20 636f  de(self, obj, co
-000037e0: 6e74 6578 742c 2070 6174 6829 3a0d 0a20  ntext, path):.. 
-000037f0: 2020 2020 2020 2069 6620 7365 6c66 2e6c         if self.l
-00003800: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00003810: 5f75 7569 6420 3d20 7575 6964 2e55 5549  _uuid = uuid.UUI
-00003820: 4428 6279 7465 735f 6c65 3d6f 626a 290d  D(bytes_le=obj).
-00003830: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
-00003840: 2020 2020 2020 2020 2020 2020 5f75 7569              _uui
-00003850: 6420 3d20 7575 6964 2e55 5549 4428 6279  d = uuid.UUID(by
-00003860: 7465 733d 6f62 6a29 0d0a 2020 2020 2020  tes=obj)..      
-00003870: 2020 7265 7475 726e 2027 7b27 202b 2073    return '{' + s
-00003880: 7472 285f 7575 6964 2920 2b20 277d 270d  tr(_uuid) + '}'.
-00003890: 0a0d 0a0d 0a64 6566 2055 5549 4428 6c65  .....def UUID(le
-000038a0: 3d54 7275 6529 3a0d 0a20 2020 2072 2222  =True):..    r""
-000038b0: 2241 2063 6f6e 7665 6e69 656e 6365 2066  "A convenience f
-000038c0: 756e 6374 696f 6e20 666f 7220 7573 696e  unction for usin
-000038d0: 6720 7468 6520 5555 4944 4164 6170 7465  g the UUIDAdapte
-000038e0: 7220 7769 7468 2031 3620 6279 7465 732e  r with 16 bytes.
-000038f0: 0d0a 0d0a 2020 2020 3a70 6172 616d 206c  ....    :param l
-00003900: 653a 2057 6865 7468 6572 2074 6f20 7573  e: Whether to us
-00003910: 6520 2262 7974 6573 5f6c 6522 206f 7220  e "bytes_le" or 
-00003920: 2262 7974 6573 2220 7768 656e 2063 6f6e  "bytes" when con
-00003930: 7374 7275 6374 696e 6720 7468 6520 5555  structing the UU
-00003940: 4944 2e0d 0a0d 0a20 2020 2065 2e67 2e0d  ID.....    e.g..
-00003950: 0a20 2020 203e 3e3e 2055 5549 4428 292e  .    >>> UUID().
-00003960: 6275 696c 6428 277b 3132 3334 3536 3738  build('{12345678
-00003970: 2d31 3233 342d 3536 3738 2d31 3233 342d  -1234-5678-1234-
-00003980: 3536 3738 3132 3334 3536 3738 7d27 290d  567812345678}').
-00003990: 0a20 2020 2027 7856 345c 7831 3234 5c78  .    'xV4\x124\x
-000039a0: 3132 7856 5c78 3132 3456 785c 7831 3234  12xV\x124Vx\x124
-000039b0: 5678 270d 0a20 2020 203e 3e3e 2055 5549  Vx'..    >>> UUI
-000039c0: 4428 6c65 3d46 616c 7365 292e 6275 696c  D(le=False).buil
-000039d0: 6428 277b 3132 3334 3536 3738 2d31 3233  d('{12345678-123
-000039e0: 342d 3536 3738 2d31 3233 342d 3536 3738  4-5678-1234-5678
-000039f0: 3132 3334 3536 3738 7d27 290d 0a20 2020  12345678}')..   
-00003a00: 2027 5c78 3132 3456 785c 7831 3234 5678   '\x124Vx\x124Vx
-00003a10: 5c78 3132 3456 785c 7831 3234 5678 270d  \x124Vx\x124Vx'.
-00003a20: 0a20 2020 203e 3e3e 2055 5549 4428 292e  .    >>> UUID().
-00003a30: 7061 7273 6528 6227 7856 345c 7831 3234  parse(b'xV4\x124
-00003a40: 5c78 3132 7856 5c78 3132 3456 785c 7831  \x12xV\x124Vx\x1
-00003a50: 3234 5678 2729 0d0a 2020 2020 277b 3132  24Vx')..    '{12
-00003a60: 3334 3536 3738 2d31 3233 342d 3536 3738  345678-1234-5678
-00003a70: 2d31 3233 342d 3536 3738 3132 3334 3536  -1234-5678123456
-00003a80: 3738 7d27 0d0a 2020 2020 3e3e 3e20 5555  78}'..    >>> UU
-00003a90: 4944 286c 653d 4661 6c73 6529 2e70 6172  ID(le=False).par
-00003aa0: 7365 2862 275c 7831 3234 5678 5c78 3132  se(b'\x124Vx\x12
-00003ab0: 3456 785c 7831 3234 5678 5c78 3132 3456  4Vx\x124Vx\x124V
-00003ac0: 7827 290d 0a20 2020 2027 7b31 3233 3435  x')..    '{12345
-00003ad0: 3637 382d 3132 3334 2d35 3637 382d 3132  678-1234-5678-12
-00003ae0: 3334 2d35 3637 3831 3233 3435 3637 387d  34-567812345678}
-00003af0: 270d 0a20 2020 2022 2222 0d0a 2020 2020  '..    """..    
-00003b00: 7265 7475 726e 2055 5549 4441 6461 7074  return UUIDAdapt
-00003b10: 6572 2842 7974 6573 2831 3629 2c20 6c65  er(Bytes(16), le
-00003b20: 3d6c 6529 0d0a 0d0a 0d0a 6465 6620 454c  =le)......def EL
-00003b30: 4650 6f69 6e74 6572 286d 656d 5f6f 6666  FPointer(mem_off
-00003b40: 2c20 7375 6263 6f6e 2c20 656c 663d 4e6f  , subcon, elf=No
-00003b50: 6e65 293a 0d0a 2020 2020 7222 2222 0d0a  ne):..    r"""..
-00003b60: 2020 2020 506f 696e 7465 7220 666f 7220      Pointer for 
-00003b70: 454c 4620 6669 6c65 732e 2054 6869 7320  ELF files. This 
-00003b80: 776f 726b 7320 666f 7220 626f 7468 206d  works for both m
-00003b90: 656d 6f72 7920 7369 7a65 732e 0d0a 0d0a  emory sizes.....
-00003ba0: 2020 2020 4e4f 5445 3a20 5468 6973 206f      NOTE: This o
-00003bb0: 6e6c 7920 776f 726b 7320 666f 7220 7838  nly works for x8
-00003bc0: 3620 696e 7374 7275 6374 696f 6e73 2e20  6 instructions. 
-00003bd0: 466f 7220 6f74 6865 7220 6172 6368 6974  For other archit
-00003be0: 6563 7475 7265 732c 0d0a 2020 2020 706c  ectures,..    pl
-00003bf0: 6561 7365 2073 6565 2074 6865 2022 454c  ease see the "EL
-00003c00: 4650 6f69 6e74 6572 2220 7769 7468 696e  FPointer" within
-00003c10: 2074 6865 6972 2072 6573 7065 6374 6976   their respectiv
-00003c20: 6520 7375 626d 6f64 756c 6573 2e20 2865  e submodules. (e
-00003c30: 2e67 2e20 636f 6e73 7472 7563 742e 4152  .g. construct.AR
-00003c40: 4d2e 454c 4650 6f69 6e74 6572 290d 0a0d  M.ELFPointer)...
-00003c50: 0a20 2020 2073 7065 632e 7061 7273 6528  .    spec.parse(
-00003c60: 6669 6c65 5f64 6174 612c 2070 653d 656c  file_data, pe=el
-00003c70: 665f 6f62 6a65 6374 290d 0a0d 0a20 2020  f_object)....   
-00003c80: 203a 7061 7261 6d20 6d65 6d5f 6f66 663a   :param mem_off:
-00003c90: 2061 6e20 696e 7420 6f72 2061 2066 756e   an int or a fun
-00003ca0: 6374 696f 6e20 7468 6174 2072 6570 7265  ction that repre
-00003cb0: 7365 6e74 7320 7468 6520 6d65 6d6f 7279  sents the memory
-00003cc0: 206f 6666 7365 7420 666f 7220 7468 6520   offset for the 
-00003cd0: 6571 7569 7661 6c65 6e74 2070 6879 7369  equivalent physi
-00003ce0: 6361 6c20 6f66 6673 6574 2e0d 0a20 2020  cal offset...   
-00003cf0: 203a 7061 7261 6d20 7375 6263 6f6e 3a20   :param subcon: 
-00003d00: 7468 6520 7375 6263 6f6e 2074 6f20 7573  the subcon to us
-00003d10: 6520 6174 2074 6865 206f 6666 7365 740d  e at the offset.
-00003d20: 0a20 2020 203a 7061 7261 6d20 656c 663a  .    :param elf:
-00003d30: 204f 7074 696f 6e61 6c20 656c 6674 6f6f   Optional elftoo
-00003d40: 6c73 2e45 4c46 4669 6c65 2066 696c 6520  ls.ELFFile file 
-00003d50: 6f62 6a65 6374 2e0d 0a20 2020 2020 2020  object...       
-00003d60: 2028 6966 206e 6f74 2073 7570 706c 6965   (if not supplie
-00003d70: 6420 6865 7265 2c20 7468 6973 206d 7573  d here, this mus
-00003d80: 7420 6265 2073 7570 706c 6965 6420 6475  t be supplied du
-00003d90: 7269 6e67 2070 6172 7365 2829 2f62 7569  ring parse()/bui
-00003da0: 6c64 2829 0d0a 2020 2020 2222 220d 0a20  ld()..    """.. 
-00003db0: 2020 2064 6566 205f 6f62 7461 696e 5f70     def _obtain_p
-00003dc0: 6879 7369 6361 6c5f 6f66 6673 6574 2863  hysical_offset(c
-00003dd0: 7478 293a 0d0a 2020 2020 2020 2020 5f65  tx):..        _e
-00003de0: 6c66 203d 2065 6c66 206f 7220 6374 782e  lf = elf or ctx.
-00003df0: 5f70 6172 616d 732e 656c 660d 0a20 2020  _params.elf..   
-00003e00: 2020 2020 205f 6d65 6d5f 6f66 6620 3d20       _mem_off = 
-00003e10: 6d65 6d5f 6f66 6628 6374 7829 2069 6620  mem_off(ctx) if 
-00003e20: 6361 6c6c 6162 6c65 286d 656d 5f6f 6666  callable(mem_off
-00003e30: 2920 656c 7365 206d 656d 5f6f 6666 0d0a  ) else mem_off..
-00003e40: 2020 2020 2020 2020 7068 795f 6f66 6620          phy_off 
-00003e50: 3d20 656c 6666 696c 6575 7469 6c73 2e6f  = elffileutils.o
-00003e60: 6274 6169 6e5f 7068 7973 6963 616c 5f6f  btain_physical_o
-00003e70: 6666 7365 7428 5f6d 656d 5f6f 6666 2c20  ffset(_mem_off, 
-00003e80: 656c 663d 5f65 6c66 290d 0a20 2020 2020  elf=_elf)..     
-00003e90: 2020 2069 6620 7068 795f 6f66 6620 6973     if phy_off is
-00003ea0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
-00003eb0: 2020 2020 7261 6973 6520 436f 6e73 7472      raise Constr
-00003ec0: 7563 7445 7272 6f72 2827 556e 6162 6c65  uctError('Unable
-00003ed0: 2074 6f20 6465 636f 6465 2076 6972 7475   to decode virtu
-00003ee0: 616c 2061 6464 7265 7373 2729 0d0a 2020  al address')..  
-00003ef0: 2020 2020 2020 7265 7475 726e 2070 6879        return phy
-00003f00: 5f6f 6666 0d0a 0d0a 2020 2020 7265 7475  _off....    retu
-00003f10: 726e 2050 6f69 6e74 6572 285f 6f62 7461  rn Pointer(_obta
-00003f20: 696e 5f70 6879 7369 6361 6c5f 6f66 6673  in_physical_offs
-00003f30: 6574 2c20 7375 6263 6f6e 290d 0a0d 0a0d  et, subcon).....
-00003f40: 0a63 6c61 7373 2050 4550 6879 7369 6361  .class PEPhysica
-00003f50: 6c41 6464 7265 7373 2841 6461 7074 6572  lAddress(Adapter
-00003f60: 293a 0d0a 2020 2020 7222 2222 0d0a 2020  ):..    r"""..  
-00003f70: 2020 4164 6170 7465 7220 7573 6564 2074    Adapter used t
-00003f80: 6f20 636f 6e76 6572 7420 616e 2069 6e74  o convert an int
-00003f90: 2072 6570 7265 7365 6e74 696e 6720 6120   representing a 
-00003fa0: 5045 206d 656d 6f72 7920 6164 6472 6573  PE memory addres
-00003fb0: 7320 696e 746f 2061 2070 6879 7369 6361  s into a physica
-00003fc0: 6c20 6164 6472 6573 732e 0d0a 0d0a 2020  l address.....  
-00003fd0: 2020 5468 6520 5045 206f 626a 6563 7420    The PE object 
-00003fe0: 6361 6e20 6569 7468 6572 2062 6520 7061  can either be pa
-00003ff0: 7373 6564 2069 6e74 6f20 7468 6520 7370  ssed into the sp
-00004000: 6563 6966 6963 2063 6f6e 7374 7275 6374  ecific construct
-00004010: 2c20 6f72 2061 7320 6120 6b65 7977 6f72  , or as a keywor
-00004020: 6420 6172 756d 656e 7420 696e 0d0a 2020  d arument in..  
-00004030: 2020 7468 6520 7061 7273 6528 292f 6275    the parse()/bu
-00004040: 696c 6428 2920 6675 6e63 7469 6f6e 732e  ild() functions.
-00004050: 0d0a 2020 2020 4966 2070 6173 7365 6420  ..    If passed 
-00004060: 696e 2074 6872 6f75 6768 2070 6172 7365  in through parse
-00004070: 2829 2f62 7569 6c64 2829 2c20 7468 6520  ()/build(), the 
-00004080: 7361 6d65 2050 4520 6f62 6a65 6374 2077  same PE object w
-00004090: 696c 6c20 6265 2075 7365 6420 666f 7220  ill be used for 
-000040a0: 616c 6c20 696e 7374 616e 6365 732e 0d0a  all instances...
-000040b0: 0d0a 2020 2020 5468 6973 2041 6461 7074  ..    This Adapt
-000040c0: 6572 2069 7320 7573 6566 756c 2077 6865  er is useful whe
-000040d0: 6e20 7573 6564 2061 6c6f 6e67 2d73 6964  n used along-sid
-000040e0: 6520 7468 6520 506f 696e 7465 7220 636f  e the Pointer co
-000040f0: 6e73 7472 7563 743a 0d0a 2020 2020 7370  nstruct:..    sp
-00004100: 6563 203d 2053 7472 7563 7428 0d0a 2020  ec = Struct(..  
-00004110: 2020 2020 2020 276f 6666 7365 7427 202f        'offset' /
-00004120: 2050 4550 6879 7369 6361 6c41 6464 7265   PEPhysicalAddre
-00004130: 7373 2849 6e74 3332 756c 292c 0d0a 2020  ss(Int32ul),..  
-00004140: 2020 2020 2020 2764 6174 6127 202f 2050        'data' / P
-00004150: 6f69 6e74 6572 2874 6869 732e 6f66 6673  ointer(this.offs
-00004160: 6574 2c20 4279 7465 7328 3130 3029 290d  et, Bytes(100)).
-00004170: 0a20 2020 2029 0d0a 0d0a 2020 2020 652e  .    )....    e.
-00004180: 672e 0d0a 2020 2020 3e3e 2077 6974 6820  g...    >> with 
-00004190: 6f70 656e 2872 2743 3a5c 3332 6269 745f  open(r'C:\32bit_
-000041a0: 6578 6527 2c20 2772 6227 2920 6173 2066  exe', 'rb') as f
-000041b0: 6f3a 0d0a 2020 2020 2e2e 2e20 2020 2020  o:..    ...     
-000041c0: 6669 6c65 5f64 6174 6120 3d20 666f 2e72  file_data = fo.r
-000041d0: 6561 6428 290d 0a20 2020 203e 3e20 7065  ead()..    >> pe
-000041e0: 203d 2070 6566 696c 6575 7469 6c73 2e6f   = pefileutils.o
-000041f0: 6274 6169 6e5f 7065 2866 696c 655f 6461  btain_pe(file_da
-00004200: 7461 290d 0a20 2020 203e 3e20 5045 5068  ta)..    >> PEPh
-00004210: 7973 6963 616c 4164 6472 6573 7328 496e  ysicalAddress(In
-00004220: 7433 3275 6c2c 2070 653d 7065 292e 6275  t32ul, pe=pe).bu
-00004230: 696c 6428 3130 3029 0d0a 2020 2020 2764  ild(100)..    'd
-00004240: 5c78 3030 405c 7830 3027 0d0a 2020 2020  \x00@\x00'..    
-00004250: 3e3e 2050 4550 6879 7369 6361 6c41 6464  >> PEPhysicalAdd
-00004260: 7265 7373 2849 6e74 3332 756c 2c20 7065  ress(Int32ul, pe
-00004270: 3d70 6529 2e70 6172 7365 2862 2764 5c78  =pe).parse(b'd\x
-00004280: 3030 405c 7830 3027 290d 0a20 2020 2031  00@\x00')..    1
-00004290: 3030 0d0a 2020 2020 3e3e 2050 4550 6879  00..    >> PEPhy
-000042a0: 7369 6361 6c41 6464 7265 7373 2849 6e74  sicalAddress(Int
-000042b0: 3332 756c 292e 6275 696c 6428 3130 302c  32ul).build(100,
-000042c0: 2070 653d 7065 290d 0a20 2020 2027 645c   pe=pe)..    'd\
-000042d0: 7830 3040 5c78 3030 270d 0a20 2020 203e  x00@\x00'..    >
-000042e0: 3e20 5045 5068 7973 6963 616c 4164 6472  > PEPhysicalAddr
-000042f0: 6573 7328 496e 7433 3275 6c29 2e70 6172  ess(Int32ul).par
-00004300: 7365 2862 2764 5c78 3030 405c 7830 3027  se(b'd\x00@\x00'
-00004310: 2c20 7065 3d70 6529 0d0a 2020 2020 3130  , pe=pe)..    10
-00004320: 300d 0a20 2020 2022 2222 0d0a 2020 2020  0..    """..    
-00004330: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-00004340: 662c 2073 7562 636f 6e2c 2070 653d 4e6f  f, subcon, pe=No
-00004350: 6e65 293a 0d0a 2020 2020 2020 2020 2222  ne):..        ""
-00004360: 220d 0a20 2020 2020 2020 203a 7061 7261  "..        :para
-00004370: 6d20 7065 3a20 4f70 7469 6f6e 616c 2050  m pe: Optional P
-00004380: 4520 6669 6c65 206f 626a 6563 742e 2028  E file object. (
-00004390: 6966 206e 6f74 2073 7570 706c 6965 6420  if not supplied 
-000043a0: 6865 7265 2c20 7468 6973 206d 7573 7420  here, this must 
-000043b0: 6265 2073 7570 706c 6965 6420 6475 7269  be supplied duri
-000043c0: 6e67 2070 6172 7365 2829 2f62 7569 6c64  ng parse()/build
-000043d0: 2829 0d0a 2020 2020 2020 2020 3a70 6172  ()..        :par
-000043e0: 616d 2073 7562 636f 6e3a 2073 7562 636f  am subcon: subco
-000043f0: 6e20 746f 2070 6172 7365 206d 656d 6f72  n to parse memor
-00004400: 7920 6f66 6673 6574 2e0d 0a20 2020 2020  y offset...     
-00004410: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00004420: 7375 7065 7228 5045 5068 7973 6963 616c  super(PEPhysical
-00004430: 4164 6472 6573 732c 2073 656c 6629 2e5f  Address, self)._
-00004440: 5f69 6e69 745f 5f28 7375 6263 6f6e 290d  _init__(subcon).
-00004450: 0a20 2020 2020 2020 2073 656c 662e 5f70  .        self._p
-00004460: 6520 3d20 7065 0d0a 0d0a 2020 2020 6465  e = pe....    de
-00004470: 6620 5f65 6e63 6f64 6528 7365 6c66 2c20  f _encode(self, 
-00004480: 6f62 6a2c 2063 6f6e 7465 7874 2c20 7061  obj, context, pa
-00004490: 7468 293a 0d0a 2020 2020 2020 2020 7065  th):..        pe
-000044a0: 203d 2073 656c 662e 5f70 6520 6f72 2063   = self._pe or c
-000044b0: 6f6e 7465 7874 2e5f 7061 7261 6d73 2e70  ontext._params.p
-000044c0: 650d 0a20 2020 2020 2020 2061 6464 7265  e..        addre
-000044d0: 7373 203d 2070 6566 696c 6575 7469 6c73  ss = pefileutils
-000044e0: 2e6f 6274 6169 6e5f 6d65 6d6f 7279 5f6f  .obtain_memory_o
-000044f0: 6666 7365 7428 6f62 6a2c 2070 653d 7065  ffset(obj, pe=pe
-00004500: 290d 0a20 2020 2020 2020 2069 6620 6164  )..        if ad
-00004510: 6472 6573 7320 6973 204e 6f6e 653a 0d0a  dress is None:..
-00004520: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-00004530: 6520 436f 6e73 7472 7563 7445 7272 6f72  e ConstructError
-00004540: 2827 556e 6162 6c65 2074 6f20 656e 636f  ('Unable to enco
-00004550: 6465 2070 6879 7369 6361 6c20 6164 6472  de physical addr
-00004560: 6573 732e 2729 0d0a 2020 2020 2020 2020  ess.')..        
-00004570: 7265 7475 726e 2061 6464 7265 7373 0d0a  return address..
-00004580: 0d0a 2020 2020 6465 6620 5f64 6563 6f64  ..    def _decod
-00004590: 6528 7365 6c66 2c20 6f62 6a2c 2063 6f6e  e(self, obj, con
-000045a0: 7465 7874 2c20 7061 7468 293a 0d0a 2020  text, path):..  
-000045b0: 2020 2020 2020 7065 203d 2073 656c 662e        pe = self.
-000045c0: 5f70 6520 6f72 2063 6f6e 7465 7874 2e5f  _pe or context._
-000045d0: 7061 7261 6d73 2e70 650d 0a20 2020 2020  params.pe..     
-000045e0: 2020 2061 6464 7265 7373 203d 2070 6566     address = pef
-000045f0: 696c 6575 7469 6c73 2e6f 6274 6169 6e5f  ileutils.obtain_
-00004600: 7068 7973 6963 616c 5f6f 6666 7365 7428  physical_offset(
-00004610: 6f62 6a2c 2070 653d 7065 290d 0a20 2020  obj, pe=pe)..   
-00004620: 2020 2020 2069 6620 6164 6472 6573 7320       if address 
-00004630: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
-00004640: 2020 2020 2020 7261 6973 6520 436f 6e73        raise Cons
-00004650: 7472 7563 7445 7272 6f72 2827 556e 6162  tructError('Unab
-00004660: 6c65 2074 6f20 6465 636f 6465 2076 6972  le to decode vir
-00004670: 7475 616c 2061 6464 7265 7373 2e27 290d  tual address.').
-00004680: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00004690: 6164 6472 6573 730d 0a0d 0a0d 0a64 6566  address......def
-000046a0: 2050 4550 6f69 6e74 6572 286d 656d 5f6f   PEPointer(mem_o
-000046b0: 6666 2c20 7375 6263 6f6e 2c20 7065 3d4e  ff, subcon, pe=N
-000046c0: 6f6e 6529 3a0d 0a20 2020 2072 2222 220d  one):..    r""".
-000046d0: 0a20 2020 2054 6869 7320 6973 2061 6e20  .    This is an 
-000046e0: 616c 7465 726e 6174 6976 6520 746f 2050  alternative to P
-000046f0: 4550 6879 7369 6361 6c41 6464 7265 7373  EPhysicalAddress
-00004700: 2077 6865 6e20 796f 7520 6172 6520 7573   when you are us
-00004710: 696e 6720 7468 6520 6164 6472 6573 7320  ing the address 
-00004720: 616c 6f6e 6720 7769 7468 2050 6f69 6e74  along with Point
-00004730: 6572 0d0a 0d0a 2020 2020 5369 6d70 6c69  er....    Simpli
-00004740: 6669 6573 3a0d 0a20 2020 2073 7065 6320  fies:..    spec 
-00004750: 3d20 5374 7275 6374 280d 0a20 2020 2020  = Struct(..     
-00004760: 2020 2027 6f66 6673 6574 2720 2f20 5045     'offset' / PE
-00004770: 5068 7973 6963 616c 4164 6472 6573 7328  PhysicalAddress(
-00004780: 496e 7433 3275 6c29 2c0d 0a20 2020 2020  Int32ul),..     
-00004790: 2020 2027 6461 7461 2720 2f20 506f 696e     'data' / Poin
-000047a0: 7465 7228 7468 6973 2e6f 6666 7365 742c  ter(this.offset,
-000047b0: 2042 7974 6573 2831 3030 2929 0d0a 2020   Bytes(100))..  
-000047c0: 2020 290d 0a20 2020 2074 6f3a 0d0a 2020    )..    to:..  
-000047d0: 2020 7370 6563 203d 2053 7472 7563 7428    spec = Struct(
-000047e0: 0d0a 2020 2020 2020 2020 276f 6666 7365  ..        'offse
-000047f0: 7427 202f 2049 6e74 3332 756c 2c0d 0a20  t' / Int32ul,.. 
-00004800: 2020 2020 2020 2027 6461 7461 2720 2f20         'data' / 
-00004810: 5045 506f 696e 7465 7228 7468 6973 2e6f  PEPointer(this.o
-00004820: 6666 7365 742c 2042 7974 6573 2831 3030  ffset, Bytes(100
-00004830: 2929 0d0a 2020 2020 290d 0a0d 0a20 2020  ))..    )....   
-00004840: 2073 7065 632e 7061 7273 6528 6669 6c65   spec.parse(file
-00004850: 5f64 6174 612c 2070 653d 7065 5f6f 626a  _data, pe=pe_obj
-00004860: 6563 7429 0d0a 0d0a 2020 2020 3a70 6172  ect)....    :par
-00004870: 616d 206d 656d 5f6f 6666 3a20 616e 2069  am mem_off: an i
-00004880: 6e74 206f 7220 6120 6675 6e63 7469 6f6e  nt or a function
-00004890: 2074 6861 7420 7265 7072 6573 656e 7473   that represents
-000048a0: 2074 6865 206d 656d 6f72 7920 6f66 6673   the memory offs
-000048b0: 6574 2066 6f72 2074 6865 2065 7175 6976  et for the equiv
-000048c0: 616c 656e 7420 7068 7973 6963 616c 206f  alent physical o
-000048d0: 6666 7365 742e 0d0a 2020 2020 3a70 6172  ffset...    :par
-000048e0: 616d 2073 7562 636f 6e3a 2074 6865 2073  am subcon: the s
-000048f0: 7562 636f 6e20 746f 2075 7365 2061 7420  ubcon to use at 
-00004900: 7468 6520 6f66 6673 6574 0d0a 2020 2020  the offset..    
-00004910: 3a70 6172 616d 2070 653a 204f 7074 696f  :param pe: Optio
-00004920: 6e61 6c20 5045 2066 696c 6520 6f62 6a65  nal PE file obje
-00004930: 6374 2e20 2869 6620 6e6f 7420 7375 7070  ct. (if not supp
-00004940: 6c69 6564 2068 6572 652c 2074 6869 7320  lied here, this 
-00004950: 6d75 7374 2062 6520 7375 7070 6c69 6564  must be supplied
-00004960: 2064 7572 696e 6720 7061 7273 6528 292f   during parse()/
-00004970: 6275 696c 6428 290d 0a20 2020 2022 2222  build()..    """
-00004980: 0d0a 2020 2020 6465 6620 5f6f 6274 6169  ..    def _obtai
-00004990: 6e5f 7068 7973 6963 616c 5f6f 6666 7365  n_physical_offse
-000049a0: 7428 6374 7829 3a0d 0a20 2020 2020 2020  t(ctx):..       
-000049b0: 205f 7065 203d 2070 6520 6f72 2063 7478   _pe = pe or ctx
-000049c0: 2e5f 7061 7261 6d73 2e70 650d 0a20 2020  ._params.pe..   
-000049d0: 2020 2020 205f 6d65 6d5f 6f66 6620 3d20       _mem_off = 
-000049e0: 6d65 6d5f 6f66 6628 6374 7829 2069 6620  mem_off(ctx) if 
-000049f0: 6361 6c6c 6162 6c65 286d 656d 5f6f 6666  callable(mem_off
-00004a00: 2920 656c 7365 206d 656d 5f6f 6666 0d0a  ) else mem_off..
-00004a10: 2020 2020 2020 2020 7068 795f 6f66 6620          phy_off 
-00004a20: 3d20 7065 6669 6c65 7574 696c 732e 6f62  = pefileutils.ob
-00004a30: 7461 696e 5f70 6879 7369 6361 6c5f 6f66  tain_physical_of
-00004a40: 6673 6574 285f 6d65 6d5f 6f66 662c 2070  fset(_mem_off, p
-00004a50: 653d 5f70 6529 0d0a 2020 2020 2020 2020  e=_pe)..        
-00004a60: 6966 2070 6879 5f6f 6666 2069 7320 4e6f  if phy_off is No
-00004a70: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-00004a80: 2072 6169 7365 2043 6f6e 7374 7275 6374   raise Construct
-00004a90: 4572 726f 7228 2755 6e61 626c 6520 746f  Error('Unable to
-00004aa0: 2064 6563 6f64 6520 7669 7274 7561 6c20   decode virtual 
-00004ab0: 6164 6472 6573 7327 290d 0a20 2020 2020  address')..     
-00004ac0: 2020 2072 6574 7572 6e20 7068 795f 6f66     return phy_of
-00004ad0: 660d 0a0d 0a20 2020 2072 6574 7572 6e20  f....    return 
-00004ae0: 506f 696e 7465 7228 5f6f 6274 6169 6e5f  Pointer(_obtain_
-00004af0: 7068 7973 6963 616c 5f6f 6666 7365 742c  physical_offset,
-00004b00: 2073 7562 636f 6e29 0d0a 0d0a 0d0a 6465   subcon)......de
-00004b10: 6620 5045 506f 696e 7465 7236 3428 6d65  f PEPointer64(me
-00004b20: 6d5f 6f66 662c 2069 6e73 745f 656e 642c  m_off, inst_end,
-00004b30: 2073 7562 636f 6e2c 2070 653d 4e6f 6e65   subcon, pe=None
-00004b40: 293a 0d0a 2020 2020 7222 2222 0d0a 2020  ):..    r"""..  
-00004b50: 2020 5468 6973 2069 7320 7468 6520 3634    This is the 64
-00004b60: 2d62 6974 2076 6572 7369 6f6e 206f 6620  -bit version of 
-00004b70: 5045 506f 696e 7465 722e 0d0a 2020 2020  PEPointer...    
-00004b80: 5468 6973 2073 7562 636f 6e73 7472 7563  This subconstruc
-00004b90: 7420 7461 6b65 7320 616e 2065 7874 7261  t takes an extra
-00004ba0: 2061 7267 756d 656e 7420 7768 6963 6820   argument which 
-00004bb0: 7370 6563 6966 6965 730d 0a20 2020 2074  specifies..    t
-00004bc0: 6865 206c 6f63 6174 696f 6e20 6f66 2074  he location of t
-00004bd0: 6865 2065 6e64 206f 6620 7468 6520 696e  he end of the in
-00004be0: 7374 7275 6374 696f 6e20 666f 7220 7768  struction for wh
-00004bf0: 6963 6820 7468 6520 6d65 6d6f 7279 5f6f  ich the memory_o
-00004c00: 6666 7365 7420 7761 7320 7573 6564 2e0d  ffset was used..
-00004c10: 0a20 2020 2028 4120 7061 7261 6d65 7465  .    (A paramete
-00004c20: 7220 6e65 6365 7373 6172 7920 666f 7220  r necessary for 
-00004c30: 3634 2d62 6974 290d 0a0d 0a20 2020 2045  64-bit)....    E
-00004c40: 7861 6d70 6c65 3a0d 0a20 2020 2073 7065  xample:..    spe
-00004c50: 6320 3d20 5374 7275 6374 280d 0a20 2020  c = Struct(..   
-00004c60: 2020 2020 2027 6f66 6673 6574 2720 2f20       'offset' / 
-00004c70: 496e 7433 3275 6c2c 0d0a 2020 2020 2020  Int32ul,..      
-00004c80: 2020 5061 6464 696e 6728 3229 2c0d 0a20    Padding(2),.. 
-00004c90: 2020 2020 2020 2027 696e 7374 5f65 6e64         'inst_end
-00004ca0: 2720 2f20 5465 6c6c 2c0d 0a20 2020 2020  ' / Tell,..     
-00004cb0: 2020 2027 6461 7461 2720 2f20 5045 506f     'data' / PEPo
-00004cc0: 696e 7465 7236 3428 7468 6973 2e6f 6666  inter64(this.off
-00004cd0: 7365 742c 2074 6869 732e 696e 7374 5f65  set, this.inst_e
-00004ce0: 6e64 2c20 4279 7465 2831 3030 2929 0d0a  nd, Byte(100))..
-00004cf0: 2020 2020 290d 0a0d 0a20 2020 2073 7065      )....    spe
-00004d00: 6320 3d20 5374 7275 6374 280d 0a20 2020  c = Struct(..   
-00004d10: 2020 2020 2027 696e 7374 7275 6374 696f       'instructio
-00004d20: 6e27 202f 2052 6567 6578 280d 0a20 2020  n' / Regex(..   
-00004d30: 2020 2020 2020 2020 2027 5c78 3031 5c78           '\x01\x
-00004d40: 3033 283f 503c 6461 7461 5f70 7472 3e2e  03(?P<data_ptr>.
-00004d50: 7b34 7d29 5c78 3034 5c78 3035 283f 503c  {4})\x04\x05(?P<
-00004d60: 656e 643e 295c 7830 365c 7830 3727 2c20  end>)\x06\x07', 
-00004d70: 6461 7461 5f70 7472 3d44 574f 5244 2c20  data_ptr=DWORD, 
-00004d80: 656e 643d 5465 6c6c 292c 0d0a 2020 2020  end=Tell),..    
-00004d90: 2020 2020 2764 6174 6127 202f 2050 4550      'data' / PEP
-00004da0: 6f69 6e74 6572 3634 2874 6869 732e 696e  ointer64(this.in
-00004db0: 7374 7275 6374 696f 6e2e 6461 7461 5f70  struction.data_p
-00004dc0: 7472 2c20 7468 6973 2e69 6e73 7472 7563  tr, this.instruc
-00004dd0: 7469 6f6e 2e65 6e64 2c20 4279 7465 7328  tion.end, Bytes(
-00004de0: 3130 3029 290d 0a20 2020 2029 0d0a 0d0a  100))..    )....
-00004df0: 2020 2020 7370 6563 2e70 6172 7365 2866      spec.parse(f
-00004e00: 696c 655f 6461 7461 2c20 7065 3d70 655f  ile_data, pe=pe_
-00004e10: 6f62 6a65 6374 290d 0a0d 0a20 2020 203a  object)....    :
-00004e20: 7061 7261 6d20 6d65 6d5f 6f66 663a 2061  param mem_off: a
-00004e30: 6e20 696e 7420 6f72 2061 2066 756e 6374  n int or a funct
-00004e40: 696f 6e20 7468 6174 2072 6570 7265 7365  ion that represe
-00004e50: 6e74 7320 7468 6520 6d65 6d6f 7279 206f  nts the memory o
-00004e60: 6666 7365 7420 666f 7220 7468 6520 6571  ffset for the eq
-00004e70: 7569 7665 6c65 6e74 2070 6879 7369 6361  uivelent physica
-00004e80: 6c20 6f66 6673 6574 2e0d 0a20 2020 203a  l offset...    :
-00004e90: 7061 7261 6d20 696e 7374 5f65 6e64 3a20  param inst_end: 
-00004ea0: 616e 2069 6e74 206f 7220 6120 6675 6e63  an int or a func
-00004eb0: 7469 6f6e 2074 6861 7420 7265 7072 6573  tion that repres
-00004ec0: 656e 7473 2074 6865 206c 6f63 6174 696f  ents the locatio
-00004ed0: 6e20 6f66 2074 6865 2065 6e64 206f 6620  n of the end of 
-00004ee0: 7468 6520 696e 7374 7275 6374 696f 6e20  the instruction 
-00004ef0: 746f 2062 6520 7265 6c61 7469 7665 2074  to be relative t
-00004f00: 6f2e 0d0a 2020 2020 3a70 6172 616d 2073  o...    :param s
-00004f10: 7562 636f 6e3a 2074 6865 2073 7562 636f  ubcon: the subco
-00004f20: 6e20 746f 2075 7365 2061 7420 7468 6520  n to use at the 
-00004f30: 6f66 6673 6574 0d0a 2020 2020 3a70 6172  offset..    :par
-00004f40: 616d 2070 653a 204f 7074 696f 6e61 6c20  am pe: Optional 
-00004f50: 5045 2066 696c 6520 6f62 6a65 6374 2e20  PE file object. 
-00004f60: 2869 6620 6e6f 7420 7375 7070 6c69 6564  (if not supplied
-00004f70: 2068 6572 652c 2074 6869 7320 6d75 7374   here, this must
-00004f80: 2062 6520 7375 7070 6c69 6564 2064 7572   be supplied dur
-00004f90: 696e 6720 7061 7273 6528 292f 6275 696c  ing parse()/buil
-00004fa0: 6428 290d 0a20 2020 2022 2222 0d0a 2020  d()..    """..  
-00004fb0: 2020 6465 6620 5f6f 6274 6169 6e5f 7068    def _obtain_ph
-00004fc0: 7973 6963 616c 5f6f 6666 7365 7428 6374  ysical_offset(ct
-00004fd0: 7829 3a0d 0a20 2020 2020 2020 205f 7065  x):..        _pe
-00004fe0: 203d 2070 6520 6f72 2063 7478 2e5f 7061   = pe or ctx._pa
-00004ff0: 7261 6d73 2e70 650d 0a20 2020 2020 2020  rams.pe..       
-00005000: 205f 6d65 6d5f 6f66 6620 3d20 6d65 6d5f   _mem_off = mem_
-00005010: 6f66 6628 6374 7829 2069 6620 6361 6c6c  off(ctx) if call
-00005020: 6162 6c65 286d 656d 5f6f 6666 2920 656c  able(mem_off) el
-00005030: 7365 206d 656d 5f6f 6666 0d0a 2020 2020  se mem_off..    
-00005040: 2020 2020 5f69 6e73 745f 656e 6420 3d20      _inst_end = 
-00005050: 696e 7374 5f65 6e64 2863 7478 2920 6966  inst_end(ctx) if
-00005060: 2063 616c 6c61 626c 6528 696e 7374 5f65   callable(inst_e
-00005070: 6e64 2920 656c 7365 2069 6e73 745f 656e  nd) else inst_en
-00005080: 640d 0a20 2020 2020 2020 2070 6879 5f6f  d..        phy_o
-00005090: 6666 203d 2070 6566 696c 6575 7469 6c73  ff = pefileutils
-000050a0: 2e6f 6274 6169 6e5f 7068 7973 6963 616c  .obtain_physical
-000050b0: 5f6f 6666 7365 745f 7836 3428 5f6d 656d  _offset_x64(_mem
-000050c0: 5f6f 6666 2c20 5f69 6e73 745f 656e 642c  _off, _inst_end,
-000050d0: 2070 653d 5f70 6529 0d0a 2020 2020 2020   pe=_pe)..      
-000050e0: 2020 6966 2070 6879 5f6f 6666 2069 7320    if phy_off is 
-000050f0: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
-00005100: 2020 2072 6169 7365 2043 6f6e 7374 7275     raise Constru
-00005110: 6374 4572 726f 7228 2755 6e61 626c 6520  ctError('Unable 
-00005120: 746f 2064 6563 6f64 6520 7669 7274 7561  to decode virtua
-00005130: 6c20 6164 6472 6573 7327 290d 0a20 2020  l address')..   
-00005140: 2020 2020 2072 6574 7572 6e20 7068 795f       return phy_
-00005150: 6f66 660d 0a0d 0a20 2020 2072 6574 7572  off....    retur
-00005160: 6e20 506f 696e 7465 7228 5f6f 6274 6169  n Pointer(_obtai
-00005170: 6e5f 7068 7973 6963 616c 5f6f 6666 7365  n_physical_offse
-00005180: 742c 2073 7562 636f 6e29 0d0a 0d0a 0d0a  t, subcon)......
-00005190: 636c 6173 7320 4465 6c69 6d69 7465 6428  class Delimited(
-000051a0: 436f 6e73 7472 7563 7429 3a0d 0a20 2020  Construct):..   
-000051b0: 2072 2222 220d 0a20 2020 2041 2063 6f6e   r"""..    A con
-000051c0: 7374 7275 6374 2075 7365 6420 746f 2070  struct used to p
-000051d0: 6172 7365 2064 656c 696d 6974 6564 2064  arse delimited d
-000051e0: 6174 612e 0d0a 0d0a 2020 2020 4e4f 5445  ata.....    NOTE
-000051f0: 3a20 5468 6520 7061 7273 6564 2063 6f6e  : The parsed con
-00005200: 7374 7275 6374 7320 7769 6c6c 2062 6520  structs will be 
-00005210: 6275 6666 6572 6564 0d0a 0d0a 2020 2020  buffered....    
-00005220: 3e3e 3e20 7370 6563 203d 2044 656c 696d  >>> spec = Delim
-00005230: 6974 6564 2862 277c 272c 0d0a 2020 2020  ited(b'|',..    
-00005240: 2e2e 2e20 2020 2020 2766 6972 7374 2720  ...     'first' 
-00005250: 2f20 4353 7472 696e 6728 292c 0d0a 2020  / CString(),..  
-00005260: 2020 2e2e 2e20 2020 2020 2773 6563 6f6e    ...     'secon
-00005270: 6427 202f 2049 6e74 3332 756c 2c0d 0a20  d' / Int32ul,.. 
-00005280: 2020 202e 2e2e 2020 2020 2023 2057 6865     ...     # Whe
-00005290: 6e20 7573 696e 6720 6120 4772 6565 6479  n using a Greedy
-000052a0: 2063 6f6e 7374 7275 6374 2c20 6569 7468   construct, eith
-000052b0: 6572 2061 6c6c 2064 6174 6120 7469 6c6c  er all data till
-000052c0: 2045 4f46 206f 7220 7468 6520 6e65 7874   EOF or the next
-000052d0: 2064 656c 696d 6974 6572 2077 696c 6c20   delimiter will 
-000052e0: 6265 2063 6f6e 7375 6d65 642e 0d0a 2020  be consumed...  
-000052f0: 2020 2e2e 2e20 2020 2020 2774 6869 7264    ...     'third
-00005300: 2720 2f20 4772 6565 6479 4279 7465 732c  ' / GreedyBytes,
-00005310: 0d0a 2020 2020 2e2e 2e20 2020 2020 2766  ..    ...     'f
-00005320: 6f75 7274 6827 202f 2042 7974 650d 0a20  ourth' / Byte.. 
-00005330: 2020 202e 2e2e 2029 0d0a 2020 2020 3e3e     ... )..    >>
-00005340: 3e20 7370 6563 2e70 6172 7365 2862 2748  > spec.parse(b'H
-00005350: 656c 6c6f 5c78 3030 5c78 3030 7c5c 7830  ello\x00\x00|\x0
-00005360: 315c 7830 305c 7830 305c 7830 307c 776f  1\x00\x00\x00|wo
-00005370: 726c 6421 215c 7830 315c 7830 327c 5c78  rld!!\x01\x02|\x
-00005380: 6666 2729 0d0a 2020 2020 436f 6e74 6169  ff')..    Contai
+00000040: 6172 792e 2222 220a 0a69 6d70 6f72 7420  ary."""..import 
+00000050: 6f73 0a69 6d70 6f72 7420 696f 0a69 6d70  os.import io.imp
+00000060: 6f72 7420 7265 0a69 6d70 6f72 7420 7374  ort re.import st
+00000070: 7269 6e67 0a69 6d70 6f72 7420 7575 6964  ring.import uuid
+00000080: 0a69 6d70 6f72 7420 7a6c 6962 0a0a 6672  .import zlib..fr
+00000090: 6f6d 206d 7763 702e 7574 696c 7320 696d  om mwcp.utils im
+000000a0: 706f 7274 2063 7573 746f 6d62 6173 6536  port custombase6
+000000b0: 342c 2065 6c66 6669 6c65 7574 696c 732c  4, elffileutils,
+000000c0: 2070 6566 696c 6575 7469 6c73 0a0a 0a23   pefileutils...#
+000000d0: 2050 6174 6368 2077 6974 6820 7665 7273   Patch with vers
+000000e0: 696f 6e20 322e 3820 6368 616e 6765 732e  ion 2.8 changes.
+000000f0: 0a66 726f 6d20 6d77 6370 2e75 7469 6c73  .from mwcp.utils
+00000100: 2e63 6f6e 7374 7275 6374 2069 6d70 6f72  .construct impor
+00000110: 7420 7665 7273 696f 6e32 3820 6173 2063  t version28 as c
+00000120: 6f6e 7374 7275 6374 0a66 726f 6d20 2e76  onstruct.from .v
+00000130: 6572 7369 6f6e 3238 2069 6d70 6f72 7420  ersion28 import 
+00000140: 2a0a 0a0a 4259 5445 203d 2042 7974 650a  *...BYTE = Byte.
+00000150: 574f 5244 203d 2049 6e74 3136 756c 0a44  WORD = Int16ul.D
+00000160: 574f 5244 203d 2055 4c4f 4e47 203d 2049  WORD = ULONG = I
+00000170: 6e74 3332 756c 0a51 574f 5244 203d 2055  nt32ul.QWORD = U
+00000180: 4c4f 4e47 4c4f 4e47 203d 2049 6e74 3634  LONGLONG = Int64
+00000190: 756c 0a0a 0a64 6566 2063 6875 6e6b 2873  ul...def chunk(s
+000001a0: 6571 2c20 7369 7a65 293a 0a20 2020 2022  eq, size):.    "
+000001b0: 2222 0a20 2020 2052 6574 7572 6e73 2061  "".    Returns a
+000001c0: 6e20 6974 6572 6174 6f72 2074 6861 7420  n iterator that 
+000001d0: 7969 656c 6473 2066 756c 6c20 6368 756e  yields full chun
+000001e0: 6b73 2073 6571 2069 6e74 6f20 7369 7a65  ks seq into size
+000001f0: 2063 6875 6e6b 732e 0a0a 2020 2020 3e3e   chunks...    >>
+00000200: 3e20 6c69 7374 2863 6875 6e6b 2827 6865  > list(chunk('he
+00000210: 6c6c 6f27 2c20 3229 290a 2020 2020 5b28  llo', 2)).    [(
+00000220: 2768 272c 2027 6527 292c 2028 276c 272c  'h', 'e'), ('l',
+00000230: 2027 6c27 295d 0a20 2020 203e 3e3e 206c   'l')].    >>> l
+00000240: 6973 7428 6368 756e 6b28 2768 656c 6c6f  ist(chunk('hello
+00000250: 2127 2c20 3229 290a 2020 2020 5b28 2768  !', 2)).    [('h
+00000260: 272c 2027 6527 292c 2028 276c 272c 2027  ', 'e'), ('l', '
+00000270: 6c27 292c 2028 276f 272c 2027 2127 295d  l'), ('o', '!')]
+00000280: 0a20 2020 2022 2222 0a20 2020 2072 6574  .    """.    ret
+00000290: 7572 6e20 7a69 7028 2a28 5b69 7465 7228  urn zip(*([iter(
+000002a0: 7365 7129 5d20 2a20 7369 7a65 2929 0a0a  seq)] * size))..
+000002b0: 0a63 6c61 7373 2042 6f6f 6c65 616e 2841  .class Boolean(A
+000002c0: 6461 7074 6572 293a 0a20 2020 2072 2222  dapter):.    r""
+000002d0: 220a 2020 2020 4164 6170 7465 7220 7573  ".    Adapter us
+000002e0: 6564 2074 6f20 636f 6e76 6572 7420 7061  ed to convert pa
+000002f0: 7273 6564 2076 616c 7565 2069 6e74 6f20  rsed value into 
+00000300: 6120 626f 6f6c 6561 6e2e 0a20 2020 204e  a boolean..    N
+00000310: 4f54 453a 2057 6869 6c65 2073 696d 696c  OTE: While simil
+00000320: 6172 2074 6f20 636f 6e73 7472 7563 742e  ar to construct.
+00000330: 466c 6167 2c20 7468 6973 2061 6461 7074  Flag, this adapt
+00000340: 6572 2061 6363 6570 7473 2061 6e79 2076  er accepts any v
+00000350: 616c 7565 206f 7468 6572 2074 6861 6e20  alue other than 
+00000360: 3020 6f72 2027 2720 6173 2074 7275 652e  0 or '' as true.
+00000370: 0a20 2020 2020 2020 2020 2041 6e64 2077  .          And w
+00000380: 696c 6c20 776f 726b 2077 6974 6820 6d6f  ill work with mo
+00000390: 7265 2074 6861 6e20 6a75 7374 2063 6f6e  re than just con
+000003a0: 7374 7275 6374 2e42 7974 652e 0a0a 2020  struct.Byte...  
+000003b0: 2020 5741 524e 494e 473a 2044 7565 2074    WARNING: Due t
+000003c0: 6f20 7468 6520 6c6f 7373 7920 6e61 7475  o the lossy natu
+000003d0: 7265 2c20 7468 6973 2063 616e 2774 2062  re, this can't b
+000003e0: 6520 7573 6564 2074 6f20 6275 696c 642e  e used to build.
+000003f0: 0a0a 2020 2020 652e 672e 0a20 2020 203e  ..    e.g..    >
+00000400: 3e3e 2042 6f6f 6c65 616e 2849 6e74 3332  >> Boolean(Int32
+00000410: 756c 292e 7061 7273 6528 6227 5c78 3031  ul).parse(b'\x01
+00000420: 5c78 3032 5c78 3033 5c78 3034 2729 0a20  \x02\x03\x04'). 
+00000430: 2020 2054 7275 650a 2020 2020 3e3e 3e20     True.    >>> 
+00000440: 426f 6f6c 6561 6e28 496e 7433 3275 6c29  Boolean(Int32ul)
+00000450: 2e70 6172 7365 2862 275c 7830 305c 7830  .parse(b'\x00\x0
+00000460: 305c 7830 305c 7830 3027 290a 2020 2020  0\x00\x00').    
+00000470: 4661 6c73 650a 2020 2020 3e3e 3e20 426f  False.    >>> Bo
+00000480: 6f6c 6561 6e28 4353 7472 696e 6728 2929  olean(CString())
+00000490: 2e70 6172 7365 2862 2768 656c 6c6f 5c78  .parse(b'hello\x
+000004a0: 3030 2729 0a20 2020 2054 7275 650a 2020  00').    True.  
+000004b0: 2020 3e3e 3e20 426f 6f6c 6561 6e28 4353    >>> Boolean(CS
+000004c0: 7472 696e 6728 2929 2e70 6172 7365 2862  tring()).parse(b
+000004d0: 275c 7830 3027 290a 2020 2020 4661 6c73  '\x00').    Fals
+000004e0: 650a 2020 2020 2222 220a 0a20 2020 2064  e.    """..    d
+000004f0: 6566 205f 6465 636f 6465 2873 656c 662c  ef _decode(self,
+00000500: 206f 626a 2c20 636f 6e74 6578 742c 2070   obj, context, p
+00000510: 6174 6829 3a0a 2020 2020 2020 2020 7265  ath):.        re
+00000520: 7475 726e 2062 6f6f 6c28 6f62 6a29 0a0a  turn bool(obj)..
+00000530: 0a63 6c61 7373 2045 7272 6f72 4d65 7373  .class ErrorMess
+00000540: 6167 6528 436f 6e73 7472 7563 7429 3a0a  age(Construct):.
+00000550: 2020 2020 7222 2222 0a20 2020 2052 6169      r""".    Rai
+00000560: 7365 7320 616e 2065 7863 6570 7469 6f6e  ses an exception
+00000570: 2077 6865 6e20 7472 6967 6765 7265 6420   when triggered 
+00000580: 6279 2070 6172 7365 206f 7220 6275 696c  by parse or buil
+00000590: 642e 2043 616e 2062 6520 7573 6564 2061  d. Can be used a
+000005a0: 7320 6120 7365 6e74 696e 656c 2074 6861  s a sentinel tha
+000005b0: 7420 626c 6f77 7320 6120 7768 6973 746c  t blows a whistl
+000005c0: 6520 7768 656e 2061 2063 6f6e 6469 7469  e when a conditi
+000005d0: 6f6e 616c 2062 7261 6e63 6820 676f 6573  onal branch goes
+000005e0: 2074 6865 2077 726f 6e67 2077 6179 2c20   the wrong way, 
+000005f0: 6f72 2074 6f20 7261 6973 6520 616e 2065  or to raise an e
+00000600: 7272 6f72 2065 7870 6c69 6369 746c 7920  rror explicitly 
+00000610: 7468 6520 6465 636c 6172 6174 6976 6520  the declarative 
+00000620: 7761 792e 0a20 2020 2054 6869 7320 6d6f  way..    This mo
+00000630: 6469 6669 6361 7469 6f6e 2061 6c6c 6f77  dification allow
+00000640: 7320 7468 6520 6162 696c 6974 7920 746f  s the ability to
+00000650: 2073 7570 706c 7920 6120 6375 7374 6f6d   supply a custom
+00000660: 206d 6573 7361 6765 2e0a 0a20 2020 2045   message...    E
+00000670: 7861 6d70 6c65 3a3a 0a0a 2020 2020 2020  xample::..      
+00000680: 2020 3e3e 3e20 6420 3d20 2278 222f 496e    >>> d = "x"/In
+00000690: 7438 7362 203e 3e20 4966 5468 656e 456c  t8sb >> IfThenEl
+000006a0: 7365 2874 6869 732e 7820 3e20 302c 2049  se(this.x > 0, I
+000006b0: 6e74 3873 622c 2045 7272 6f72 4d65 7373  nt8sb, ErrorMess
+000006c0: 6167 6528 2746 6169 6c65 6420 6966 2073  age('Failed if s
+000006d0: 7461 7465 6d65 6e74 2729 290a 2020 2020  tatement')).    
+000006e0: 2020 2020 3e3e 3e20 642e 7061 7273 6528      >>> d.parse(
+000006f0: 6222 5c78 6666 5c78 3035 2229 0a20 2020  b"\xff\x05").   
+00000700: 2020 2020 2054 7261 6365 6261 636b 2028       Traceback (
+00000710: 6d6f 7374 2072 6563 656e 7420 6361 6c6c  most recent call
+00000720: 206c 6173 7429 3a0a 2020 2020 2020 2020   last):.        
+00000730: 2020 2020 2e2e 2e0a 2020 2020 2020 2020      ....        
+00000740: 4578 706c 6963 6974 4572 726f 723a 2046  ExplicitError: F
+00000750: 6169 6c65 6420 6966 2073 7461 7465 6d65  ailed if stateme
+00000760: 6e74 0a20 2020 2022 2222 0a20 2020 205f  nt.    """.    _
+00000770: 5f73 6c6f 7473 5f5f 203d 205b 276d 6573  _slots__ = ['mes
+00000780: 7361 6765 275d 0a0a 2020 2020 6465 6620  sage']..    def 
+00000790: 5f5f 696e 6974 5f5f 2873 656c 662c 206d  __init__(self, m
+000007a0: 6573 7361 6765 3d22 4572 726f 7220 6669  essage="Error fi
+000007b0: 656c 6420 7761 7320 6163 7469 7661 7465  eld was activate
+000007c0: 642e 2229 3a0a 2020 2020 2020 2020 7375  d."):.        su
+000007d0: 7065 7228 7365 6c66 2e5f 5f63 6c61 7373  per(self.__class
+000007e0: 5f5f 2c20 7365 6c66 292e 5f5f 696e 6974  __, self).__init
+000007f0: 5f5f 2829 0a20 2020 2020 2020 2073 656c  __().        sel
+00000800: 662e 6d65 7373 6167 6520 3d20 6d65 7373  f.message = mess
+00000810: 6167 650a 0a20 2020 2064 6566 205f 7061  age..    def _pa
+00000820: 7273 6528 7365 6c66 2c20 7374 7265 616d  rse(self, stream
+00000830: 2c20 636f 6e74 6578 742c 2070 6174 6829  , context, path)
+00000840: 3a0a 2020 2020 2020 2020 6d65 7373 6167  :.        messag
+00000850: 6520 3d20 7365 6c66 2e6d 6573 7361 6765  e = self.message
+00000860: 2863 6f6e 7465 7874 2920 6966 2063 616c  (context) if cal
+00000870: 6c61 626c 6528 7365 6c66 2e6d 6573 7361  lable(self.messa
+00000880: 6765 2920 656c 7365 2073 656c 662e 6d65  ge) else self.me
+00000890: 7373 6167 650a 2020 2020 2020 2020 7261  ssage.        ra
+000008a0: 6973 6520 4578 706c 6963 6974 4572 726f  ise ExplicitErro
+000008b0: 7228 6d65 7373 6167 6529 0a0a 2020 2020  r(message)..    
+000008c0: 6465 6620 5f62 7569 6c64 2873 656c 662c  def _build(self,
+000008d0: 206f 626a 2c20 7374 7265 616d 2c20 636f   obj, stream, co
+000008e0: 6e74 6578 742c 2070 6174 6829 3a0a 2020  ntext, path):.  
+000008f0: 2020 2020 2020 6d65 7373 6167 6520 3d20        message = 
+00000900: 7365 6c66 2e6d 6573 7361 6765 2863 6f6e  self.message(con
+00000910: 7465 7874 2920 6966 2063 616c 6c61 626c  text) if callabl
+00000920: 6528 7365 6c66 2e6d 6573 7361 6765 2920  e(self.message) 
+00000930: 656c 7365 2073 656c 662e 6d65 7373 6167  else self.messag
+00000940: 650a 2020 2020 2020 2020 7261 6973 6520  e.        raise 
+00000950: 4578 706c 6963 6974 4572 726f 7228 6d65  ExplicitError(me
+00000960: 7373 6167 6529 0a0a 0a64 6566 2053 7472  ssage)...def Str
+00000970: 696e 6731 3628 6c65 6e67 7468 293a 0a20  ing16(length):. 
+00000980: 2020 2072 2222 220a 2020 2020 4372 6561     r""".    Crea
+00000990: 7465 7320 5554 462d 3136 2028 6c69 7474  tes UTF-16 (litt
+000009a0: 6c65 2065 6e64 6961 6e29 2065 6e63 6f64  le endian) encod
+000009b0: 6564 2073 7472 696e 672e 0a0a 2020 2020  ed string...    
+000009c0: 3e3e 3e20 5374 7269 6e67 3136 2831 3029  >>> String16(10)
+000009d0: 2e62 7569 6c64 2875 2768 656c 6c6f 2729  .build(u'hello')
+000009e0: 0a20 2020 2027 685c 7830 3065 5c78 3030  .    'h\x00e\x00
+000009f0: 6c5c 7830 306c 5c78 3030 6f5c 7830 3027  l\x00l\x00o\x00'
+00000a00: 0a20 2020 203e 3e3e 2053 7472 696e 6731  .    >>> String1
+00000a10: 3628 3130 292e 7061 7273 6528 6227 685c  6(10).parse(b'h\
+00000a20: 7830 3065 5c78 3030 6c5c 7830 306c 5c78  x00e\x00l\x00l\x
+00000a30: 3030 6f5c 7830 3027 290a 2020 2020 7527  00o\x00').    u'
+00000a40: 6865 6c6c 6f27 0a20 2020 203e 3e3e 2053  hello'.    >>> S
+00000a50: 7472 696e 6731 3628 3136 292e 7061 7273  tring16(16).pars
+00000a60: 6528 6227 685c 7830 3065 5c78 3030 6c5c  e(b'h\x00e\x00l\
+00000a70: 7830 306c 5c78 3030 6f5c 7830 305c 7830  x00l\x00o\x00\x0
+00000a80: 305c 7830 305c 7830 305c 7830 305c 7830  0\x00\x00\x00\x0
+00000a90: 305c 7830 3027 290a 2020 2020 7527 6865  0\x00').    u'he
+00000aa0: 6c6c 6f27 0a20 2020 2022 2222 0a20 2020  llo'.    """.   
+00000ab0: 2072 6574 7572 6e20 5374 7269 6e67 286c   return String(l
+00000ac0: 656e 6774 682c 2065 6e63 6f64 696e 673d  ength, encoding=
+00000ad0: 2775 7466 2d31 362d 6c65 2729 0a0a 0a64  'utf-16-le')...d
+00000ae0: 6566 2053 7472 696e 6733 3228 6c65 6e67  ef String32(leng
+00000af0: 7468 293a 0a20 2020 2072 2222 220a 2020  th):.    r""".  
+00000b00: 2020 4372 6561 7465 7320 5554 462d 3332    Creates UTF-32
+00000b10: 2028 6c69 7474 6c65 2065 6e64 6961 6e29   (little endian)
+00000b20: 2065 6e63 6f64 6564 2073 7472 696e 672e   encoded string.
+00000b30: 0a0a 2020 2020 3e3e 3e20 5374 7269 6e67  ..    >>> String
+00000b40: 3332 2832 3029 2e62 7569 6c64 2875 2768  32(20).build(u'h
+00000b50: 656c 6c6f 2729 0a20 2020 2027 685c 7830  ello').    'h\x0
+00000b60: 305c 7830 305c 7830 3065 5c78 3030 5c78  0\x00\x00e\x00\x
+00000b70: 3030 5c78 3030 6c5c 7830 305c 7830 305c  00\x00l\x00\x00\
+00000b80: 7830 306c 5c78 3030 5c78 3030 5c78 3030  x00l\x00\x00\x00
+00000b90: 6f5c 7830 305c 7830 305c 7830 3027 0a20  o\x00\x00\x00'. 
+00000ba0: 2020 203e 3e3e 2053 7472 696e 6733 3228     >>> String32(
+00000bb0: 3230 292e 7061 7273 6528 6227 685c 7830  20).parse(b'h\x0
+00000bc0: 305c 7830 305c 7830 3065 5c78 3030 5c78  0\x00\x00e\x00\x
+00000bd0: 3030 5c78 3030 6c5c 7830 305c 7830 305c  00\x00l\x00\x00\
+00000be0: 7830 306c 5c78 3030 5c78 3030 5c78 3030  x00l\x00\x00\x00
+00000bf0: 6f5c 7830 305c 7830 305c 7830 3027 290a  o\x00\x00\x00').
+00000c00: 2020 2020 7527 6865 6c6c 6f27 0a20 2020      u'hello'.   
+00000c10: 2022 2222 0a20 2020 2072 6574 7572 6e20   """.    return 
+00000c20: 5374 7269 6e67 286c 656e 6774 682c 2065  String(length, e
+00000c30: 6e63 6f64 696e 673d 2775 7466 2d33 322d  ncoding='utf-32-
+00000c40: 6c65 2729 0a0a 0a63 6c61 7373 2050 7269  le')...class Pri
+00000c50: 6e74 6162 6c65 2856 616c 6964 6174 6f72  ntable(Validator
+00000c60: 293a 0a20 2020 2072 2222 220a 2020 2020  ):.    r""".    
+00000c70: 5661 6c69 6461 746f 7220 7573 6564 2074  Validator used t
+00000c80: 6f20 7661 6c69 6461 7465 2074 6861 7420  o validate that 
+00000c90: 6120 7061 7273 6564 2053 7472 696e 6720  a parsed String 
+00000ca0: 286f 7220 4279 7465 7329 2069 7320 6120  (or Bytes) is a 
+00000cb0: 7072 696e 7461 626c 6520 2861 7363 6969  printable (ascii
+00000cc0: 2920 7374 7269 6e67 2e0a 0a20 2020 204e  ) string...    N
+00000cd0: 4f54 453a 2041 2056 616c 6964 6174 696f  OTE: A Validatio
+00000ce0: 6e45 7272 6f72 2069 7320 6120 7479 7065  nError is a type
+00000cf0: 206f 6620 436f 6e73 7472 7563 7445 7272   of ConstructErr
+00000d00: 6f72 2061 6e64 2077 696c 6c20 6265 2063  or and will be c
+00000d10: 6175 7365 2069 6620 6361 7463 6869 6e67  ause if catching
+00000d20: 2043 6f6e 7374 7275 6374 4572 726f 722e   ConstructError.
+00000d30: 0a0a 2020 2020 3e3e 3e20 5072 696e 7461  ..    >>> Printa
+00000d40: 626c 6528 5374 7269 6e67 2835 2929 2e70  ble(String(5)).p
+00000d50: 6172 7365 2862 2768 656c 6c6f 2729 0a20  arse(b'hello'). 
+00000d60: 2020 2075 2768 656c 6c6f 270a 2020 2020     u'hello'.    
+00000d70: 3e3e 3e20 5072 696e 7461 626c 6528 5374  >>> Printable(St
+00000d80: 7269 6e67 2835 2929 2e70 6172 7365 2862  ring(5)).parse(b
+00000d90: 2768 655c 7831 316f 2127 290a 2020 2020  'he\x11o!').    
+00000da0: 5472 6163 6562 6163 6b20 286d 6f73 7420  Traceback (most 
+00000db0: 7265 6365 6e74 2063 616c 6c20 6c61 7374  recent call last
+00000dc0: 293a 0a20 2020 2020 2020 202e 2e2e 0a20  ):.        .... 
+00000dd0: 2020 2056 616c 6964 6174 696f 6e45 7272     ValidationErr
+00000de0: 6f72 3a20 6f62 6a65 6374 2066 6169 6c65  or: object faile
+00000df0: 6420 7661 6c69 6461 7469 6f6e 3a20 6865  d validation: he
+00000e00: 116f 210a 2020 2020 3e3e 3e20 5072 696e  .o!.    >>> Prin
+00000e10: 7461 626c 6528 4279 7465 7328 3329 292e  table(Bytes(3)).
+00000e20: 7061 7273 6528 6227 5c78 3031 4e4f 2729  parse(b'\x01NO')
+00000e30: 0a20 2020 2054 7261 6365 6261 636b 2028  .    Traceback (
+00000e40: 6d6f 7374 2072 6563 656e 7420 6361 6c6c  most recent call
+00000e50: 206c 6173 7429 3a0a 2020 2020 2020 2020   last):.        
+00000e60: 2e2e 2e0a 2020 2020 5661 6c69 6461 7469  ....    Validati
+00000e70: 6f6e 4572 726f 723a 206f 626a 6563 7420  onError: object 
+00000e80: 6661 696c 6564 2076 616c 6964 6174 696f  failed validatio
+00000e90: 6e3a 2001 4e4f 0a20 2020 203e 3e3e 2050  n: .NO.    >>> P
+00000ea0: 7269 6e74 6162 6c65 2842 7974 6573 2833  rintable(Bytes(3
+00000eb0: 2929 2e70 6172 7365 2862 2759 4553 2729  )).parse(b'YES')
+00000ec0: 0a20 2020 2027 5945 5327 0a20 2020 2022  .    'YES'.    "
+00000ed0: 2222 0a0a 2020 2020 6465 6620 5f76 616c  ""..    def _val
+00000ee0: 6964 6174 6528 7365 6c66 2c20 6f62 6a2c  idate(self, obj,
+00000ef0: 2063 6f6e 7465 7874 2c20 7061 7468 293a   context, path):
+00000f00: 0a20 2020 2020 2020 2069 6620 6973 696e  .        if isin
+00000f10: 7374 616e 6365 286f 626a 2c20 6279 7465  stance(obj, byte
+00000f20: 7329 3a0a 2020 2020 2020 2020 2020 2020  s):.            
+00000f30: 7265 7475 726e 2061 6c6c 2863 6872 2862  return all(chr(b
+00000f40: 7974 6529 2069 6e20 7374 7269 6e67 2e70  yte) in string.p
+00000f50: 7269 6e74 6162 6c65 2066 6f72 2062 7974  rintable for byt
+00000f60: 6520 696e 206f 626a 290a 2020 2020 2020  e in obj).      
+00000f70: 2020 7265 7475 726e 2069 7369 6e73 7461    return isinsta
+00000f80: 6e63 6528 6f62 6a2c 2073 7472 696e 6774  nce(obj, stringt
+00000f90: 7970 6573 2920 616e 6420 616c 6c28 6368  ypes) and all(ch
+00000fa0: 6172 2069 6e20 7374 7269 6e67 2e70 7269  ar in string.pri
+00000fb0: 6e74 6162 6c65 2066 6f72 2063 6861 7220  ntable for char 
+00000fc0: 696e 206f 626a 290a 0a0a 2320 436f 6e74  in obj)...# Cont
+00000fd0: 696e 756f 7573 6c79 2070 6172 7365 7320  inuously parses 
+00000fe0: 756e 7469 6c20 6974 2068 6974 7320 7468  until it hits th
+00000ff0: 6520 6669 7273 7420 6e6f 6e2d 7a65 726f  e first non-zero
+00001000: 2062 7974 652e 0a53 6b69 704e 756c 6c20   byte..SkipNull 
+00001010: 3d20 436f 6e73 7428 6227 5c78 3030 2729  = Const(b'\x00')
+00001020: 5b3a 5d0a 0a23 2043 6f6e 7469 6e75 6f75  [:]..# Continuou
+00001030: 736c 7920 7061 7273 6573 2075 6e74 696c  sly parses until
+00001040: 2069 7420 6869 7473 2074 6865 2066 6972   it hits the fir
+00001050: 7374 207a 6572 6f20 6279 7465 2028 636f  st zero byte (co
+00001060: 6e73 756d 6564 292e 0a23 2055 7365 2074  nsumed)..# Use t
+00001070: 6869 7320 696e 7374 6561 6420 6f66 2043  his instead of C
+00001080: 5374 7269 6e67 2829 2069 6620 796f 7520  String() if you 
+00001090: 6361 6e27 7420 6775 6172 616e 7465 6520  can't guarantee 
+000010a0: 6974 2077 6f6e 2774 2066 6169 6c20 746f  it won't fail to
+000010b0: 2064 6563 6f64 652e 0a43 4279 7465 7320   decode..CBytes 
+000010c0: 3d20 4e75 6c6c 5465 726d 696e 6174 6564  = NullTerminated
+000010d0: 2847 7265 6564 7942 7974 6573 290a 0a0a  (GreedyBytes)...
+000010e0: 636c 6173 7320 4279 7465 7354 6572 6d69  class BytesTermi
+000010f0: 6e61 7465 6428 4e75 6c6c 5465 726d 696e  nated(NullTermin
+00001100: 6174 6564 293a 0a20 2020 2072 2222 220a  ated):.    r""".
+00001110: 2020 2020 4279 7465 7354 6572 6d69 6e61      BytesTermina
+00001120: 7465 6420 6973 2074 6865 2073 616d 6520  ted is the same 
+00001130: 6173 204e 756c 6c54 6572 6d69 6e61 7465  as NullTerminate
+00001140: 6420 6578 6365 7074 2074 6861 7420 6974  d except that it
+00001150: 2069 7320 7461 7267 6574 6564 2066 6f72   is targeted for
+00001160: 2062 696e 6172 7920 6461 7461 2061 6e64   binary data and
+00001170: 206e 6f74 2073 7472 696e 6773 2c20 616e   not strings, an
+00001180: 640a 2020 2020 7468 6572 6566 6f72 6520  d.    therefore 
+00001190: 7468 6520 7465 726d 696e 6174 6f72 2063  the terminator c
+000011a0: 616e 2062 6520 616e 2061 7262 6974 7261  an be an arbitra
+000011b0: 7279 206c 656e 6774 6820 2861 7320 6f70  ry length (as op
+000011c0: 706f 7365 6420 746f 2068 6176 696e 6720  posed to having 
+000011d0: 6c65 6e67 7468 2065 7175 616c 2074 6f20  length equal to 
+000011e0: 7468 6520 6368 6172 6163 7465 7220 7769  the character wi
+000011f0: 6474 6829 2e0a 2020 2020 5365 6520 7468  dth)..    See th
+00001200: 6520 4e75 6c6c 5465 726d 696e 6174 6564  e NullTerminated
+00001210: 2064 6f63 756d 656e 7461 7469 6f6e 2066   documentation f
+00001220: 6f72 2074 6865 2072 656d 6169 6e64 6572  or the remainder
+00001230: 206f 6620 7468 6520 6675 6e63 7469 6f6e   of the function
+00001240: 616c 6974 7920 616e 6420 6f70 7469 6f6e  ality and option
+00001250: 732e 0a0a 2020 2020 3e3e 3e20 4279 7465  s...    >>> Byte
+00001260: 7354 6572 6d69 6e61 7465 6428 4772 6565  sTerminated(Gree
+00001270: 6479 4279 7465 732c 2074 6572 6d3d 6227  dyBytes, term=b'
+00001280: 5445 524d 2729 2e70 6172 7365 2862 2768  TERM').parse(b'h
+00001290: 656c 6c6f 5445 524d 2729 0a20 2020 2027  elloTERM').    '
+000012a0: 6865 6c6c 6f27 0a20 2020 2022 2222 0a0a  hello'.    """..
+000012b0: 2020 2020 2320 5468 6520 6f6e 6c79 206d      # The only m
+000012c0: 6574 686f 6420 7765 206e 6565 6420 746f  ethod we need to
+000012d0: 206f 7665 7272 6964 6520 6973 205f 7061   override is _pa
+000012e0: 7273 652e 2045 7665 7279 7468 696e 6720  rse. Everything 
+000012f0: 656c 7365 2066 726f 6d20 4e75 6c6c 5465  else from NullTe
+00001300: 726d 696e 6174 6564 2077 6f72 6b73 2061  rminated works a
+00001310: 732d 6973 2e0a 2020 2020 6465 6620 5f70  s-is..    def _p
+00001320: 6172 7365 2873 656c 662c 2073 7472 6561  arse(self, strea
+00001330: 6d2c 2063 6f6e 7465 7874 2c20 7061 7468  m, context, path
+00001340: 293a 0a20 2020 2020 2020 2074 6572 6d20  ):.        term 
+00001350: 3d20 7365 6c66 2e74 6572 6d0a 2020 2020  = self.term.    
+00001360: 2020 2020 7465 726d 5f6c 656e 203d 206c      term_len = l
+00001370: 656e 2874 6572 6d29 0a20 2020 2020 2020  en(term).       
+00001380: 2069 6620 7465 726d 5f6c 656e 203c 2031   if term_len < 1
+00001390: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+000013a0: 6973 6520 5061 6464 696e 6745 7272 6f72  ise PaddingError
+000013b0: 2822 4279 7465 7354 6572 6d69 6e61 7465  ("BytesTerminate
+000013c0: 6420 7465 726d 206d 7573 7420 6265 2061  d term must be a
+000013d0: 7420 6c65 6173 7420 3120 6279 7465 2229  t least 1 byte")
+000013e0: 0a20 2020 2020 2020 2064 6174 6120 3d20  .        data = 
+000013f0: 6227 270a 2020 2020 2020 2020 7768 696c  b''.        whil
+00001400: 6520 5472 7565 3a0a 2020 2020 2020 2020  e True:.        
+00001410: 2020 2020 706f 7320 3d20 7374 7265 616d      pos = stream
+00001420: 5f74 656c 6c28 7374 7265 616d 290a 2020  _tell(stream).  
+00001430: 2020 2020 2020 2020 2020 7472 793a 0a20            try:. 
+00001440: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+00001450: 203d 2073 7472 6561 6d5f 7265 6164 2873   = stream_read(s
+00001460: 7472 6561 6d2c 2074 6572 6d5f 6c65 6e29  tream, term_len)
+00001470: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001480: 2073 7472 6561 6d5f 7365 656b 2873 7472   stream_seek(str
+00001490: 6561 6d2c 2070 6f73 2c20 3029 0a20 2020  eam, pos, 0).   
+000014a0: 2020 2020 2020 2020 2065 7863 6570 7420           except 
+000014b0: 5374 7265 616d 4572 726f 723a 0a20 2020  StreamError:.   
+000014c0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+000014d0: 7365 6c66 2e72 6571 7569 7265 3a0a 2020  self.require:.  
+000014e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000014f0: 2020 7261 6973 650a 2020 2020 2020 2020    raise.        
+00001500: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00001510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001520: 2020 7374 7265 616d 5f73 6565 6b28 7374    stream_seek(st
+00001530: 7265 616d 2c20 706f 732c 2030 290a 2020  ream, pos, 0).  
+00001540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001550: 2020 6461 7461 202b 3d20 7374 7265 616d    data += stream
+00001560: 5f72 6561 645f 656e 7469 7265 2873 7472  _read_entire(str
+00001570: 6561 6d29 0a20 2020 2020 2020 2020 2020  eam).           
+00001580: 2020 2020 2020 2020 2062 7265 616b 0a0a           break..
+00001590: 2020 2020 2020 2020 2020 2020 6966 2062              if b
+000015a0: 203d 3d20 7465 726d 3a0a 2020 2020 2020   == term:.      
+000015b0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+000015c0: 662e 696e 636c 7564 653a 0a20 2020 2020  f.include:.     
+000015d0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+000015e0: 6174 6120 2b3d 2062 0a20 2020 2020 2020  ata += b.       
+000015f0: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+00001600: 2e63 6f6e 7375 6d65 3a0a 2020 2020 2020  .consume:.      
+00001610: 2020 2020 2020 2020 2020 2020 2020 7374                st
+00001620: 7265 616d 5f72 6561 6428 7374 7265 616d  ream_read(stream
+00001630: 2c20 7465 726d 5f6c 656e 290a 2020 2020  , term_len).    
+00001640: 2020 2020 2020 2020 2020 2020 6272 6561              brea
+00001650: 6b0a 2020 2020 2020 2020 2020 2020 656c  k.            el
+00001660: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+00001670: 2020 2020 6461 7461 202b 3d20 7374 7265      data += stre
+00001680: 616d 5f72 6561 6428 7374 7265 616d 2c20  am_read(stream, 
+00001690: 3129 0a20 2020 2020 2020 2069 6620 7365  1).        if se
+000016a0: 6c66 2e73 7562 636f 6e20 6973 2047 7265  lf.subcon is Gre
+000016b0: 6564 7942 7974 6573 3a0a 2020 2020 2020  edyBytes:.      
+000016c0: 2020 2020 2020 7265 7475 726e 2064 6174        return dat
+000016d0: 610a 2020 2020 2020 2020 6966 2074 7970  a.        if typ
+000016e0: 6528 7365 6c66 2e73 7562 636f 6e29 2069  e(self.subcon) i
+000016f0: 7320 4772 6565 6479 5374 7269 6e67 3a0a  s GreedyString:.
+00001700: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00001710: 726e 2064 6174 612e 6465 636f 6465 2873  rn data.decode(s
+00001720: 656c 662e 7375 6263 6f6e 2e65 6e63 6f64  elf.subcon.encod
+00001730: 696e 6729 0a20 2020 2020 2020 2072 6574  ing).        ret
+00001740: 7572 6e20 7365 6c66 2e73 7562 636f 6e2e  urn self.subcon.
+00001750: 5f70 6172 7365 7265 706f 7274 2869 6f2e  _parsereport(io.
+00001760: 4279 7465 7349 4f28 6461 7461 292c 2063  BytesIO(data), c
+00001770: 6f6e 7465 7874 2c20 7061 7468 290a 0a0a  ontext, path)...
+00001780: 2320 544f 444f 3a20 4d61 6b65 2061 204c  # TODO: Make a L
+00001790: 5374 7269 7070 6564 3f0a 636c 6173 7320  Stripped?.class 
+000017a0: 5374 7269 7070 6564 2841 6461 7074 6572  Stripped(Adapter
+000017b0: 293a 0a20 2020 2072 2222 220a 2020 2020  ):.    r""".    
+000017c0: 416e 2061 6461 7074 6572 2074 6861 7420  An adapter that 
+000017d0: 7374 7269 7073 2063 6861 7261 6374 6572  strips character
+000017e0: 732f 6279 7465 7320 6672 6f6d 2074 6865  s/bytes from the
+000017f0: 2072 6967 6874 206f 6620 7468 6520 7061   right of the pa
+00001800: 7273 6564 2072 6573 756c 7473 2e0a 0a20  rsed results... 
+00001810: 2020 204e 4f54 453a 2057 6869 6c65 2074     NOTE: While t
+00001820: 6869 7320 6d61 7920 6c6f 6f6b 2073 696d  his may look sim
+00001830: 696c 6172 2074 6f20 5061 6464 6564 2829  ilar to Padded()
+00001840: 2074 6869 7320 6973 2064 6966 6665 7265   this is differe
+00001850: 6e74 2062 6563 6175 7365 2074 6869 730a  nt because this.
+00001860: 2020 2020 646f 6573 6e27 7420 7461 6b65      doesn't take
+00001870: 2061 206c 656e 6774 6820 616e 6420 696e   a length and in
+00001880: 7374 6561 6420 7374 7269 7073 206f 7574  stead strips out
+00001890: 2074 6865 206e 756c 6c73 2066 726f 6d20   the nulls from 
+000018a0: 7769 7468 696e 2074 6865 2061 6c72 6561  within the alrea
+000018b0: 6479 2070 6172 7365 6420 7375 6263 6f6e  dy parsed subcon
+000018c0: 7374 7275 6374 2e0a 0a20 2020 203a 7061  struct...    :pa
+000018d0: 7261 6d20 7375 6263 6f6e 3a20 5468 6520  ram subcon: The 
+000018e0: 7375 622d 636f 6e73 7472 7563 7420 746f  sub-construct to
+000018f0: 2077 7261 702e 0a20 2020 203a 7061 7261   wrap..    :para
+00001900: 6d20 7061 643a 2054 6865 2063 6861 7261  m pad: The chara
+00001910: 6374 6572 2f62 7974 6573 2074 6f20 7573  cter/bytes to us
+00001920: 6520 666f 7220 7374 7269 7070 696e 672e  e for stripping.
+00001930: 2044 6566 6175 6c74 7320 746f 206e 756c   Defaults to nul
+00001940: 6c20 6368 6172 6163 7465 722e 0a0a 2020  l character...  
+00001950: 2020 3e3e 3e20 5374 7269 7070 6564 2847    >>> Stripped(G
+00001960: 7265 6564 7942 7974 6573 292e 7061 7273  reedyBytes).pars
+00001970: 6528 6227 6865 6c6c 6f5c 7830 305c 7830  e(b'hello\x00\x0
+00001980: 305c 7830 3027 290a 2020 2020 2768 656c  0\x00').    'hel
+00001990: 6c6f 270a 2020 2020 3e3e 3e20 5374 7269  lo'.    >>> Stri
+000019a0: 7070 6564 2842 7974 6573 2831 3029 292e  pped(Bytes(10)).
+000019b0: 7061 7273 6528 6227 6865 6c6c 6f5c 7830  parse(b'hello\x0
+000019c0: 305c 7830 305c 7830 305c 7830 305c 7830  0\x00\x00\x00\x0
+000019d0: 3027 290a 2020 2020 2768 656c 6c6f 270a  0').    'hello'.
+000019e0: 2020 2020 3e3e 3e20 5374 7269 7070 6564      >>> Stripped
+000019f0: 2842 7974 6573 2831 3429 2c20 7061 643d  (Bytes(14), pad=
+00001a00: 6227 5041 4427 292e 7061 7273 6528 6227  b'PAD').parse(b'
+00001a10: 6865 6c6c 6f50 4144 5041 4450 4144 2729  helloPADPADPAD')
+00001a20: 0a20 2020 2027 6865 6c6c 6f27 0a20 2020  .    'hello'.   
+00001a30: 203e 3e3e 2053 7472 6970 7065 6428 4279   >>> Stripped(By
+00001a40: 7465 7328 3134 292c 2070 6164 3d62 2750  tes(14), pad=b'P
+00001a50: 4144 2729 2e62 7569 6c64 2862 2768 656c  AD').build(b'hel
+00001a60: 6c6f 2729 0a20 2020 2027 6865 6c6c 6f50  lo').    'helloP
+00001a70: 4144 5041 4450 4144 270a 2020 2020 3e3e  ADPADPAD'.    >>
+00001a80: 3e20 5374 7269 7070 6564 2843 5374 7269  > Stripped(CStri
+00001a90: 6e67 2829 2c20 7061 643d 7527 5041 4427  ng(), pad=u'PAD'
+00001aa0: 292e 7061 7273 6528 6227 6865 6c6c 6f50  ).parse(b'helloP
+00001ab0: 4144 5041 445c 7830 3027 290a 2020 2020  ADPAD\x00').    
+00001ac0: 7527 6865 6c6c 6f27 0a20 2020 203e 3e3e  u'hello'.    >>>
+00001ad0: 2053 7472 6970 7065 6428 5374 7269 6e67   Stripped(String
+00001ae0: 2831 3429 2c20 7061 643d 7527 5041 4427  (14), pad=u'PAD'
+00001af0: 292e 7061 7273 6528 6227 6865 6c6c 6f50  ).parse(b'helloP
+00001b00: 4144 5041 445c 7830 305c 7830 305c 7830  ADPAD\x00\x00\x0
+00001b10: 3027 290a 2020 2020 7527 6865 6c6c 6f27  0').    u'hello'
+00001b20: 0a0a 2020 2020 2320 5741 524e 494e 473a  ..    # WARNING:
+00001b30: 2049 6620 7061 6464 696e 6720 646f 6573   If padding does
+00001b40: 6e27 7420 6669 7420 696e 2074 6865 2070  n't fit in the p
+00001b50: 6572 7363 7269 6265 6420 6461 7461 2069  erscribed data i
+00001b60: 7420 7769 6c6c 206e 6f74 2073 7472 6970  t will not strip
+00001b70: 2069 7421 0a20 2020 203e 3e3e 2053 7472   it!.    >>> Str
+00001b80: 6970 7065 6428 4279 7465 7328 3133 292c  ipped(Bytes(13),
+00001b90: 2070 6164 3d62 2750 4144 2729 2e70 6172   pad=b'PAD').par
+00001ba0: 7365 2862 2768 656c 6c6f 5041 4450 4144  se(b'helloPADPAD
+00001bb0: 5041 2729 0a20 2020 2027 6865 6c6c 6f50  PA').    'helloP
+00001bc0: 4144 5041 4450 4127 0a20 2020 203e 3e3e  ADPADPA'.    >>>
+00001bd0: 2053 7472 6970 7065 6428 4279 7465 7328   Stripped(Bytes(
+00001be0: 3133 292c 2070 6164 3d62 2750 4144 2729  13), pad=b'PAD')
+00001bf0: 2e62 7569 6c64 2862 2768 656c 6c6f 2729  .build(b'hello')
+00001c00: 0a20 2020 2054 7261 6365 6261 636b 2028  .    Traceback (
+00001c10: 6d6f 7374 2072 6563 656e 7420 6361 6c6c  most recent call
+00001c20: 206c 6173 7429 3a0a 2020 2020 2020 2020   last):.        
+00001c30: 2e2e 2e0a 2020 2020 5374 7265 616d 4572  ....    StreamEr
+00001c40: 726f 723a 2062 7974 6573 206f 626a 6563  ror: bytes objec
+00001c50: 7420 6f66 2077 726f 6e67 206c 656e 6774  t of wrong lengt
+00001c60: 682c 2065 7870 6563 7465 6420 3133 2c20  h, expected 13, 
+00001c70: 666f 756e 6420 350a 0a20 2020 2023 2049  found 5..    # I
+00001c80: 6620 7468 6520 7772 6170 7065 6420 7375  f the wrapped su
+00001c90: 6263 6f6e 7374 7275 6374 2773 2073 697a  bconstruct's siz
+00001ca0: 6520 6361 6e27 7420 6265 2064 6574 6572  e can't be deter
+00001cb0: 6d69 6e65 2c20 6966 2064 6566 6175 6c74  mine, if default
+00001cc0: 7320 746f 206e 6f74 2070 726f 7669 6469  s to not providi
+00001cd0: 6e67 2061 2070 6164 2e0a 2020 2020 3e3e  ng a pad..    >>
+00001ce0: 3e20 5374 7269 7070 6564 2843 5374 7269  > Stripped(CStri
+00001cf0: 6e67 2829 2c20 7061 643d 7527 5041 4427  ng(), pad=u'PAD'
+00001d00: 292e 6275 696c 6428 7527 6865 6c6c 6f27  ).build(u'hello'
+00001d10: 290a 2020 2020 2768 656c 6c6f 5c78 3030  ).    'hello\x00
+00001d20: 270a 2020 2020 2222 220a 0a20 2020 2064  '.    """..    d
+00001d30: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
+00001d40: 2c20 7375 6263 6f6e 2c20 7061 643d 4e6f  , subcon, pad=No
+00001d50: 6e65 293a 0a20 2020 2020 2020 2073 7570  ne):.        sup
+00001d60: 6572 2853 7472 6970 7065 642c 2073 656c  er(Stripped, sel
+00001d70: 6629 2e5f 5f69 6e69 745f 5f28 7375 6263  f).__init__(subc
+00001d80: 6f6e 290a 2020 2020 2020 2020 7365 6c66  on).        self
+00001d90: 2e70 6164 203d 2070 6164 0a0a 2020 2020  .pad = pad..    
+00001da0: 6465 6620 5f64 6563 6f64 6528 7365 6c66  def _decode(self
+00001db0: 2c20 6f62 6a2c 2063 6f6e 7465 7874 2c20  , obj, context, 
+00001dc0: 7061 7468 293a 0a20 2020 2020 2020 2070  path):.        p
+00001dd0: 6164 203d 2073 656c 662e 7061 640a 0a20  ad = self.pad.. 
+00001de0: 2020 2020 2020 2069 6620 7061 6420 6973         if pad is
+00001df0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00001e00: 2020 2070 6164 203d 2075 275c 3027 2069     pad = u'\0' i
+00001e10: 6620 6973 696e 7374 616e 6365 286f 626a  f isinstance(obj
+00001e20: 2c20 756e 6963 6f64 6573 7472 696e 6774  , unicodestringt
+00001e30: 7970 6529 2065 6c73 6520 6227 5c78 3030  ype) else b'\x00
+00001e40: 270a 0a20 2020 2020 2020 2069 6620 6e6f  '..        if no
+00001e50: 7420 6973 696e 7374 616e 6365 2870 6164  t isinstance(pad
+00001e60: 2c20 7479 7065 286f 626a 2929 3a0a 2020  , type(obj)):.  
+00001e70: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00001e80: 5061 6464 696e 6745 7272 6f72 2822 4e75  PaddingError("Nu
+00001e90: 6c6c 5374 7269 7070 6564 2070 6164 206d  llStripped pad m
+00001ea0: 7573 7420 6265 206f 6620 7468 6520 7361  ust be of the sa
+00001eb0: 6d65 2074 7970 653a 207b 7d20 7673 207b  me type: {} vs {
+00001ec0: 7d22 2e66 6f72 6d61 7428 7479 7065 2870  }".format(type(p
+00001ed0: 6164 292c 2074 7970 6528 6f62 6a29 2929  ad), type(obj)))
+00001ee0: 0a0a 2020 2020 2020 2020 756e 6974 203d  ..        unit =
+00001ef0: 206c 656e 2870 6164 290a 2020 2020 2020   len(pad).      
+00001f00: 2020 6966 2075 6e69 7420 3c20 313a 0a20    if unit < 1:. 
+00001f10: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00001f20: 2050 6164 6469 6e67 4572 726f 7228 224e   PaddingError("N
+00001f30: 756c 6c53 7472 6970 7065 6420 7061 6420  ullStripped pad 
+00001f40: 6d75 7374 2062 6520 6174 206c 6561 7374  must be at least
+00001f50: 2031 2062 7974 6522 290a 0a20 2020 2020   1 byte")..     
+00001f60: 2020 206f 626a 203d 206f 626a 0a20 2020     obj = obj.   
+00001f70: 2020 2020 2069 6620 756e 6974 203d 3d20       if unit == 
+00001f80: 313a 0a20 2020 2020 2020 2020 2020 206f  1:.            o
+00001f90: 626a 203d 206f 626a 2e72 7374 7269 7028  bj = obj.rstrip(
+00001fa0: 7061 6429 0a20 2020 2020 2020 2065 6c73  pad).        els
+00001fb0: 653a 0a20 2020 2020 2020 2020 2020 2074  e:.            t
+00001fc0: 6169 6c75 6e69 7420 3d20 6c65 6e28 6f62  ailunit = len(ob
+00001fd0: 6a29 2025 2075 6e69 740a 2020 2020 2020  j) % unit.      
+00001fe0: 2020 2020 2020 656e 6420 3d20 6c65 6e28        end = len(
+00001ff0: 6f62 6a29 0a20 2020 2020 2020 2020 2020  obj).           
+00002000: 2069 6620 7461 696c 756e 6974 2061 6e64   if tailunit and
+00002010: 206f 626a 5b2d 7461 696c 756e 6974 3a5d   obj[-tailunit:]
+00002020: 203d 3d20 7061 645b 3a74 6169 6c75 6e69   == pad[:tailuni
+00002030: 745d 3a0a 2020 2020 2020 2020 2020 2020  t]:.            
+00002040: 2020 2020 656e 6420 2d3d 2074 6169 6c75      end -= tailu
+00002050: 6e69 740a 2020 2020 2020 2020 2020 2020  nit.            
+00002060: 7768 696c 6520 656e 642d 756e 6974 203e  while end-unit >
+00002070: 3d20 3020 616e 6420 6f62 6a5b 656e 642d  = 0 and obj[end-
+00002080: 756e 6974 3a65 6e64 5d20 3d3d 2070 6164  unit:end] == pad
+00002090: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000020a0: 2020 656e 6420 2d3d 2075 6e69 740a 2020    end -= unit.  
+000020b0: 2020 2020 2020 2020 2020 6f62 6a20 3d20            obj = 
+000020c0: 6f62 6a5b 3a65 6e64 5d0a 0a20 2020 2020  obj[:end]..     
+000020d0: 2020 2072 6574 7572 6e20 6f62 6a0a 0a20     return obj.. 
+000020e0: 2020 2064 6566 205f 656e 636f 6465 2873     def _encode(s
+000020f0: 656c 662c 206f 626a 2c20 636f 6e74 6578  elf, obj, contex
+00002100: 742c 2070 6174 6829 3a0a 2020 2020 2020  t, path):.      
+00002110: 2020 7061 6420 3d20 7365 6c66 2e70 6164    pad = self.pad
+00002120: 0a0a 2020 2020 2020 2020 6966 2070 6164  ..        if pad
+00002130: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+00002140: 2020 2020 2020 7061 6420 3d20 7527 5c30        pad = u'\0
+00002150: 2720 6966 2069 7369 6e73 7461 6e63 6528  ' if isinstance(
+00002160: 7365 6c66 2e73 7562 636f 6e2c 2053 7472  self.subcon, Str
+00002170: 696e 6745 6e63 6f64 6564 2920 656c 7365  ingEncoded) else
+00002180: 2062 275c 7830 3027 0a0a 2020 2020 2020   b'\x00'..      
+00002190: 2020 7472 793a 0a20 2020 2020 2020 2020    try:.         
+000021a0: 2020 2073 697a 6520 3d20 7365 6c66 2e73     size = self.s
+000021b0: 7562 636f 6e2e 5f73 697a 656f 6628 636f  ubcon._sizeof(co
+000021c0: 6e74 6578 742c 2070 6174 6829 0a20 2020  ntext, path).   
+000021d0: 2020 2020 2065 7863 6570 7420 5369 7a65       except Size
+000021e0: 6f66 4572 726f 723a 0a20 2020 2020 2020  ofError:.       
+000021f0: 2020 2020 2072 6574 7572 6e20 6f62 6a20       return obj 
+00002200: 2023 2044 6f6e 2774 2070 6164 2069 6620   # Don't pad if 
+00002210: 7765 2063 616e 2774 2066 6967 7572 6520  we can't figure 
+00002220: 6f75 7420 7369 7a65 2e0a 0a20 2020 2020  out size...     
+00002230: 2020 2075 6e69 7420 3d20 6c65 6e28 7061     unit = len(pa
+00002240: 6429 0a20 2020 2020 2020 2069 6620 756e  d).        if un
+00002250: 6974 203d 3d20 313a 0a20 2020 2020 2020  it == 1:.       
+00002260: 2020 2020 206f 626a 203d 206f 626a 2e6c       obj = obj.l
+00002270: 6a75 7374 2873 697a 652c 2070 6164 290a  just(size, pad).
+00002280: 2020 2020 2020 2020 2320 4f6e 6c79 2070          # Only p
+00002290: 6164 2069 6620 6974 2066 6974 7320 696e  ad if it fits in
+000022a0: 206e 6963 656c 792e 0a20 2020 2020 2020   nicely..       
+000022b0: 2065 6c69 6620 2873 697a 6520 2d20 6c65   elif (size - le
+000022c0: 6e28 6f62 6a29 2920 2520 756e 6974 203d  n(obj)) % unit =
+000022d0: 3d20 303a 0a20 2020 2020 2020 2020 2020  = 0:.           
+000022e0: 206f 626a 203d 2028 6f62 6a20 2b20 2870   obj = (obj + (p
+000022f0: 6164 202a 2028 7369 7a65 202d 206c 656e  ad * (size - len
+00002300: 286f 626a 2929 2929 5b3a 7369 7a65 5d0a  (obj))))[:size].
+00002310: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00002320: 6f62 6a0a 0a0a 636c 6173 7320 4865 7853  obj...class HexS
+00002330: 7472 696e 6728 4164 6170 7465 7229 3a0a  tring(Adapter):.
+00002340: 2020 2020 7222 2222 0a20 2020 2041 6461      r""".    Ada
+00002350: 7074 6572 2075 7365 6420 746f 2063 6f6e  pter used to con
+00002360: 7665 7274 2061 6e20 696e 7420 696e 746f  vert an int into
+00002370: 2061 2068 6578 2073 7472 696e 6720 6571   a hex string eq
+00002380: 7569 7661 6c65 6e74 2e0a 0a20 2020 2065  uivalent...    e
+00002390: 2e67 2e0a 2020 2020 3e3e 3e20 4865 7853  .g..    >>> HexS
+000023a0: 7472 696e 6728 496e 7433 3275 6c29 2e62  tring(Int32ul).b
+000023b0: 7569 6c64 2827 3078 3132 3327 290a 2020  uild('0x123').  
+000023c0: 2020 2723 5c78 3031 5c78 3030 5c78 3030    '#\x01\x00\x00
+000023d0: 270a 2020 2020 3e3e 3e20 4865 7853 7472  '.    >>> HexStr
+000023e0: 696e 6728 496e 7433 3275 6c29 2e70 6172  ing(Int32ul).par
+000023f0: 7365 2862 275c 7832 305c 7830 315c 7830  se(b'\x20\x01\x0
+00002400: 305c 7830 3027 290a 2020 2020 2730 7831  0\x00').    '0x1
+00002410: 3230 270a 2020 2020 3e3e 3e20 4865 7853  20'.    >>> HexS
+00002420: 7472 696e 6728 496e 7431 3675 6229 2e70  tring(Int16ub).p
+00002430: 6172 7365 2862 275c 7831 325c 7833 3427  arse(b'\x12\x34'
+00002440: 290a 2020 2020 2730 7831 3233 3427 0a20  ).    '0x1234'. 
+00002450: 2020 203e 3e3e 2048 6578 5374 7269 6e67     >>> HexString
+00002460: 2842 7974 6573 496e 7465 6765 7228 3230  (BytesInteger(20
+00002470: 2929 2e70 6172 7365 2862 275c 7830 3127  )).parse(b'\x01'
+00002480: 202a 2032 3029 0a20 2020 2027 3078 3130   * 20).    '0x10
+00002490: 3130 3130 3130 3130 3130 3130 3130 3130  1010101010101010
+000024a0: 3130 3130 3130 3130 3130 3130 3130 3130  1010101010101010
+000024b0: 3130 3130 3127 0a20 2020 2022 2222 0a0a  10101'.    """..
+000024c0: 2020 2020 6465 6620 5f65 6e63 6f64 6528      def _encode(
+000024d0: 7365 6c66 2c20 6f62 6a2c 2063 6f6e 7465  self, obj, conte
+000024e0: 7874 2c20 7061 7468 293a 0a20 2020 2020  xt, path):.     
+000024f0: 2020 2072 6574 7572 6e20 696e 7428 6f62     return int(ob
+00002500: 6a2c 2031 3629 0a0a 2020 2020 6465 6620  j, 16)..    def 
+00002510: 5f64 6563 6f64 6528 7365 6c66 2c20 6f62  _decode(self, ob
+00002520: 6a2c 2063 6f6e 7465 7874 2c20 7061 7468  j, context, path
+00002530: 293a 0a20 2020 2020 2020 2068 6578 5f73  ):.        hex_s
+00002540: 7472 696e 6720 3d20 6865 7828 6f62 6a29  tring = hex(obj)
+00002550: 0a20 2020 2020 2020 2069 6620 6865 785f  .        if hex_
+00002560: 7374 7269 6e67 2e65 6e64 7377 6974 6828  string.endswith(
+00002570: 274c 2729 3a0a 2020 2020 2020 2020 2020  'L'):.          
+00002580: 2020 6865 785f 7374 7269 6e67 203d 2068    hex_string = h
+00002590: 6578 5f73 7472 696e 675b 3a2d 315d 0a20  ex_string[:-1]. 
+000025a0: 2020 2020 2020 2072 6574 7572 6e20 6865         return he
+000025b0: 785f 7374 7269 6e67 0a0a 0a63 6c61 7373  x_string...class
+000025c0: 2042 6173 6536 3428 4164 6170 7465 7229   Base64(Adapter)
+000025d0: 3a0a 2020 2020 7222 2222 0a20 2020 2041  :.    r""".    A
+000025e0: 6461 7074 6572 2075 7365 6420 746f 2042  dapter used to B
+000025f0: 6173 6536 3420 656e 636f 6465 642f 6465  ase64 encoded/de
+00002600: 636f 6465 2061 2076 616c 7565 2e0a 0a20  code a value... 
+00002610: 2020 2057 4152 4e49 4e47 3a20 5468 6973     WARNING: This
+00002620: 2061 6461 7074 6572 206d 7573 7420 6265   adapter must be
+00002630: 2075 7365 6420 6f6e 2061 2075 6e69 636f   used on a unico
+00002640: 6465 2073 7472 696e 6720 7661 6c75 652e  de string value.
+00002650: 0a0a 2020 2020 3a70 6172 616d 2073 7562  ..    :param sub
+00002660: 636f 6e3a 2074 6865 2063 6f6e 7374 7275  con: the constru
+00002670: 6374 2074 6f20 7772 6170 0a20 2020 203a  ct to wrap.    :
+00002680: 7061 7261 6d20 6375 7374 6f6d 5f61 6c70  param custom_alp
+00002690: 6861 3a20 6f70 7469 6f6e 616c 2063 7573  ha: optional cus
+000026a0: 746f 6d20 616c 7068 6162 6574 2074 6f20  tom alphabet to 
+000026b0: 7573 650a 0a20 2020 2065 2e67 2e0a 2020  use..    e.g..  
+000026c0: 2020 3e3e 3e20 4261 7365 3634 2847 7265    >>> Base64(Gre
+000026d0: 6564 7953 7472 696e 6728 2929 2e62 7569  edyString()).bui
+000026e0: 6c64 2862 2768 656c 6c6f 2729 0a20 2020  ld(b'hello').   
+000026f0: 2027 6147 5673 6247 383d 270a 2020 2020   'aGVsbG8='.    
+00002700: 3e3e 3e20 4261 7365 3634 2847 7265 6564  >>> Base64(Greed
+00002710: 7953 7472 696e 6728 2929 2e70 6172 7365  yString()).parse
+00002720: 2862 2761 4756 7362 4738 3d27 290a 2020  (b'aGVsbG8=').  
+00002730: 2020 2768 656c 6c6f 270a 2020 2020 3e3e    'hello'.    >>
+00002740: 3e20 4261 7365 3634 2847 7265 6564 7942  > Base64(GreedyB
+00002750: 7974 6573 292e 6275 696c 6428 6227 5c78  ytes).build(b'\x
+00002760: 3031 5c78 3032 5c78 3033 5c78 3034 2729  01\x02\x03\x04')
+00002770: 0a20 2020 2027 4151 4944 4241 3d3d 270a  .    'AQIDBA=='.
+00002780: 2020 2020 3e3e 3e20 4261 7365 3634 2847      >>> Base64(G
+00002790: 7265 6564 7942 7974 6573 292e 7061 7273  reedyBytes).pars
+000027a0: 6528 6227 4151 4944 4241 3d3d 2729 0a20  e(b'AQIDBA=='). 
+000027b0: 2020 2027 5c78 3031 5c78 3032 5c78 3033     '\x01\x02\x03
+000027c0: 5c78 3034 270a 0a20 2020 204e 4f54 453a  \x04'..    NOTE:
+000027d0: 2053 7472 696e 6720 7369 7a65 2069 7320   String size is 
+000027e0: 6261 7365 6420 6f6e 2074 6865 2065 6e63  based on the enc
+000027f0: 6f64 6564 2076 6572 7369 6f6e 2e0a 2020  oded version..  
+00002800: 2020 3e3e 3e20 4261 7365 3634 2853 7472    >>> Base64(Str
+00002810: 696e 6728 3136 2929 2e62 7569 6c64 2875  ing(16)).build(u
+00002820: 2768 656c 6c6f 2077 6f72 6c64 2729 0a20  'hello world'). 
+00002830: 2020 2027 6147 5673 6247 3867 6432 3979     'aGVsbG8gd29y
+00002840: 6247 513d 270a 2020 2020 3e3e 3e20 4261  bGQ='.    >>> Ba
+00002850: 7365 3634 2853 7472 696e 6728 3136 2929  se64(String(16))
+00002860: 2e70 6172 7365 2862 2761 4756 7362 4738  .parse(b'aGVsbG8
+00002870: 6764 3239 7962 4751 3d27 290a 2020 2020  gd29ybGQ=').    
+00002880: 2768 656c 6c6f 2077 6f72 6c64 270a 0a20  'hello world'.. 
+00002890: 2020 2053 7570 706c 7969 6e67 2061 2063     Supplying a c
+000028a0: 7573 746f 6d20 616c 7068 6162 6574 2069  ustom alphabet i
+000028b0: 7320 616c 736f 2073 7570 706f 7274 6564  s also supported
+000028c0: 2e0a 2020 2020 3e3e 3e20 7370 6563 203d  ..    >>> spec =
+000028d0: 2042 6173 6536 3428 5374 7269 6e67 2831   Base64(String(1
+000028e0: 3629 2c20 6375 7374 6f6d 5f61 6c70 6861  6), custom_alpha
+000028f0: 3d27 4546 4748 5152 5354 5556 5765 6667  ='EFGHQRSTUVWefg
+00002900: 6869 6a6b 6c6d 6e6f 7049 4a4b 4c4d 4e4f  hijklmnopIJKLMNO
+00002910: 5041 4243 4471 7273 7475 7677 7879 5859  PABCDqrstuvwxyXY
+00002920: 5a61 6263 647a 3031 3233 3435 3637 3839  Zabcdz0123456789
+00002930: 2b2f 3d27 290a 2020 2020 3e3e 3e20 7370  +/=').    >>> sp
+00002940: 6563 2e62 7569 6c64 2875 2768 656c 6c6f  ec.build(u'hello
+00002950: 2077 6f72 6c64 2729 0a20 2020 2027 4c53   world').    'LS
+00002960: 6f58 4d53 3842 4f32 3964 4d53 6a3d 270a  oXMS8BO29dMSj='.
+00002970: 2020 2020 3e3e 3e20 7370 6563 2e70 6172      >>> spec.par
+00002980: 7365 2862 274c 536f 584d 5338 424f 3239  se(b'LSoXMS8BO29
+00002990: 644d 536a 3d27 290a 2020 2020 2768 656c  dMSj=').    'hel
+000029a0: 6c6f 2077 6f72 6c64 270a 2020 2020 2222  lo world'.    ""
+000029b0: 220a 2020 2020 5f5f 736c 6f74 735f 5f20  ".    __slots__ 
+000029c0: 3d20 5b27 7375 6263 6f6e 272c 2027 6375  = ['subcon', 'cu
+000029d0: 7374 6f6d 5f61 6c70 6861 275d 0a0a 2020  stom_alpha']..  
+000029e0: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
+000029f0: 656c 662c 2073 7562 636f 6e2c 2063 7573  elf, subcon, cus
+00002a00: 746f 6d5f 616c 7068 613d 4e6f 6e65 293a  tom_alpha=None):
+00002a10: 0a20 2020 2020 2020 2073 7570 6572 2842  .        super(B
+00002a20: 6173 6536 342c 2073 656c 6629 2e5f 5f69  ase64, self).__i
+00002a30: 6e69 745f 5f28 7375 6263 6f6e 290a 2020  nit__(subcon).  
+00002a40: 2020 2020 2020 7365 6c66 2e63 7573 746f        self.custo
+00002a50: 6d5f 616c 7068 6120 3d20 6375 7374 6f6d  m_alpha = custom
+00002a60: 5f61 6c70 6861 0a0a 2020 2020 6465 6620  _alpha..    def 
+00002a70: 5f65 6e63 6f64 6528 7365 6c66 2c20 6f62  _encode(self, ob
+00002a80: 6a2c 2063 6f6e 7465 7874 2c20 7061 7468  j, context, path
+00002a90: 293a 0a20 2020 2020 2020 206f 626a 203d  ):.        obj =
+00002aa0: 2063 7573 746f 6d62 6173 6536 342e 6236   custombase64.b6
+00002ab0: 3465 6e63 6f64 6528 6f62 6a2c 2061 6c70  4encode(obj, alp
+00002ac0: 6861 6265 743d 7365 6c66 2e63 7573 746f  habet=self.custo
+00002ad0: 6d5f 616c 7068 6129 0a20 2020 2020 2020  m_alpha).       
+00002ae0: 2023 2043 6f6e 7665 7274 2074 6f20 756e   # Convert to un
+00002af0: 6963 6f64 6520 6966 2077 7261 7070 6564  icode if wrapped
+00002b00: 2073 7562 636f 6e20 6578 7065 6374 7320   subcon expects 
+00002b10: 6974 2e0a 2020 2020 2020 2020 6966 2069  it..        if i
+00002b20: 7369 6e73 7461 6e63 6528 7365 6c66 2e73  sinstance(self.s
+00002b30: 7562 636f 6e2c 2053 7472 696e 6745 6e63  ubcon, StringEnc
+00002b40: 6f64 6564 293a 0a20 2020 2020 2020 2020  oded):.         
+00002b50: 2020 206f 626a 203d 206f 626a 2e64 6563     obj = obj.dec
+00002b60: 6f64 6528 2775 7466 2d38 2729 0a20 2020  ode('utf-8').   
+00002b70: 2020 2020 2072 6574 7572 6e20 6f62 6a0a       return obj.
+00002b80: 0a20 2020 2064 6566 205f 6465 636f 6465  .    def _decode
+00002b90: 2873 656c 662c 206f 626a 2c20 636f 6e74  (self, obj, cont
+00002ba0: 6578 742c 2070 6174 6829 3a0a 2020 2020  ext, path):.    
+00002bb0: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
+00002bc0: 6528 6f62 6a2c 2073 7472 293a 0a20 2020  e(obj, str):.   
+00002bd0: 2020 2020 2020 2020 206f 626a 203d 206f           obj = o
+00002be0: 626a 2e65 6e63 6f64 6528 2775 7466 2d38  bj.encode('utf-8
+00002bf0: 2729 0a20 2020 2020 2020 2072 6574 7572  ').        retur
+00002c00: 6e20 6375 7374 6f6d 6261 7365 3634 2e62  n custombase64.b
+00002c10: 3634 6465 636f 6465 286f 626a 2c20 616c  64decode(obj, al
+00002c20: 7068 6162 6574 3d73 656c 662e 6375 7374  phabet=self.cust
+00002c30: 6f6d 5f61 6c70 6861 290a 0a0a 636c 6173  om_alpha)...clas
+00002c40: 7320 5a4c 4942 2841 6461 7074 6572 293a  s ZLIB(Adapter):
+00002c50: 0a20 2020 2072 2222 220a 2020 2020 4164  .    r""".    Ad
+00002c60: 6170 7465 7220 7573 6564 2074 6f20 7a6c  apter used to zl
+00002c70: 6962 2063 6f6d 7072 6573 732f 6465 636f  ib compress/deco
+00002c80: 6d70 7265 7373 2061 2064 6174 6120 6275  mpress a data bu
+00002c90: 6666 6572 0a0a 2020 2020 3a70 6172 616d  ffer..    :param
+00002ca0: 2073 7562 636f 6e3a 2054 6865 2063 6f6e   subcon: The con
+00002cb0: 7374 7275 6374 2074 6f20 7772 6170 0a20  struct to wrap. 
+00002cc0: 2020 203a 7061 7261 6d20 696e 7420 6c65     :param int le
+00002cd0: 7665 6c3a 2054 6865 207a 6c69 6220 636f  vel: The zlib co
+00002ce0: 6d70 7265 7373 696f 6e20 6c65 7665 6c0a  mpression level.
+00002cf0: 2020 2020 3a70 6172 616d 2069 6e74 2077      :param int w
+00002d00: 6269 7473 3a20 5468 6520 7a6c 6962 2064  bits: The zlib d
+00002d10: 6563 6f6d 7072 6573 7369 6f6e 2077 696e  ecompression win
+00002d20: 646f 7720 7369 7a65 0a20 2020 203a 7061  dow size.    :pa
+00002d30: 7261 6d20 696e 7420 6275 6673 697a 653a  ram int bufsize:
+00002d40: 2054 6865 2069 6e69 7469 616c 206f 7574   The initial out
+00002d50: 7075 7420 6275 6666 6572 2073 697a 650a  put buffer size.
+00002d60: 0a20 2020 203e 3e3e 205a 4c49 4228 4279  .    >>> ZLIB(By
+00002d70: 7465 7328 3132 2929 2e62 7569 6c64 2862  tes(12)).build(b
+00002d80: 2764 6174 6127 290a 2020 2020 2778 5c78  'data').    'x\x
+00002d90: 3963 4b49 2c49 5c78 3034 5c78 3030 5c78  9cKI,I\x04\x00\x
+00002da0: 3034 5c78 3030 5c78 3031 5c78 3962 270a  04\x00\x01\x9b'.
+00002db0: 2020 2020 3e3e 3e20 5a4c 4942 2847 7265      >>> ZLIB(Gre
+00002dc0: 6564 7942 7974 6573 2c20 6c65 7665 6c3d  edyBytes, level=
+00002dd0: 3029 2e62 7569 6c64 2862 2764 6174 6127  0).build(b'data'
+00002de0: 290a 2020 2020 2778 5c78 3031 5c78 3031  ).    'x\x01\x01
+00002df0: 5c78 3034 5c78 3030 5c78 6662 5c78 6666  \x04\x00\xfb\xff
+00002e00: 6461 7461 5c78 3034 5c78 3030 5c78 3031  data\x04\x00\x01
+00002e10: 5c78 3962 270a 2020 2020 3e3e 3e20 5a4c  \x9b'.    >>> ZL
+00002e20: 4942 2847 7265 6564 7942 7974 6573 292e  IB(GreedyBytes).
+00002e30: 7061 7273 6528 6227 785e 4b49 2c49 5c78  parse(b'x^KI,I\x
+00002e40: 3034 5c78 3030 5c78 3034 5c78 3030 5c78  04\x00\x04\x00\x
+00002e50: 3031 5c78 3962 2729 0a20 2020 2027 6461  01\x9b').    'da
+00002e60: 7461 270a 2020 2020 2222 220a 2020 2020  ta'.    """.    
+00002e70: 5f5f 736c 6f74 735f 5f20 3d20 5b22 7375  __slots__ = ["su
+00002e80: 6263 6f6e 222c 2022 7762 6974 7322 2c20  bcon", "wbits", 
+00002e90: 2262 7566 7369 7a65 222c 2022 6c65 7665  "bufsize", "leve
+00002ea0: 6c22 5d0a 0a20 2020 2064 6566 205f 5f69  l"]..    def __i
+00002eb0: 6e69 745f 5f28 7365 6c66 2c20 7375 6263  nit__(self, subc
+00002ec0: 6f6e 2c20 7762 6974 733d 4e6f 6e65 2c20  on, wbits=None, 
+00002ed0: 6275 6673 697a 653d 4e6f 6e65 2c20 6c65  bufsize=None, le
+00002ee0: 7665 6c3d 4e6f 6e65 293a 0a20 2020 2020  vel=None):.     
+00002ef0: 2020 2073 7570 6572 285a 4c49 422c 2073     super(ZLIB, s
+00002f00: 656c 6629 2e5f 5f69 6e69 745f 5f28 7375  elf).__init__(su
+00002f10: 6263 6f6e 290a 2020 2020 2020 2020 7365  bcon).        se
+00002f20: 6c66 2e77 6269 7473 203d 2077 6269 7473  lf.wbits = wbits
+00002f30: 0a20 2020 2020 2020 2073 656c 662e 6275  .        self.bu
+00002f40: 6673 697a 6520 3d20 6275 6673 697a 650a  fsize = bufsize.
+00002f50: 2020 2020 2020 2020 7365 6c66 2e6c 6576          self.lev
+00002f60: 656c 203d 206c 6576 656c 0a0a 2020 2020  el = level..    
+00002f70: 6465 6620 5f65 6e63 6f64 6528 7365 6c66  def _encode(self
+00002f80: 2c20 6f62 6a2c 2063 6f6e 7465 7874 2c20  , obj, context, 
+00002f90: 7061 7468 293a 0a20 2020 2020 2020 206c  path):.        l
+00002fa0: 6576 656c 203d 2073 656c 662e 6c65 7665  evel = self.leve
+00002fb0: 6c28 636f 6e74 6578 7429 2069 6620 6361  l(context) if ca
+00002fc0: 6c6c 6162 6c65 2873 656c 662e 6c65 7665  llable(self.leve
+00002fd0: 6c29 2065 6c73 6520 7365 6c66 2e6c 6576  l) else self.lev
+00002fe0: 656c 0a20 2020 2020 2020 2069 6620 6c65  el.        if le
+00002ff0: 7665 6c20 6973 206e 6f74 204e 6f6e 653a  vel is not None:
+00003000: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00003010: 7572 6e20 7a6c 6962 2e63 6f6d 7072 6573  urn zlib.compres
+00003020: 7328 6f62 6a2c 206c 6576 656c 290a 2020  s(obj, level).  
+00003030: 2020 2020 2020 7265 7475 726e 207a 6c69        return zli
+00003040: 622e 636f 6d70 7265 7373 286f 626a 290a  b.compress(obj).
+00003050: 0a20 2020 2064 6566 205f 6465 636f 6465  .    def _decode
+00003060: 2873 656c 662c 206f 626a 2c20 636f 6e74  (self, obj, cont
+00003070: 6578 742c 2070 6174 6829 3a0a 2020 2020  ext, path):.    
+00003080: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+00003090: 5a4c 4942 2064 6563 6f6d 7072 6573 7320  ZLIB decompress 
+000030a0: 6120 6275 6666 6572 2c20 6361 6e6e 6f74  a buffer, cannot
+000030b0: 2075 7365 2062 7566 7369 7a65 2069 6620   use bufsize if 
+000030c0: 7762 6974 7320 6973 206e 6f74 2073 6574  wbits is not set
+000030d0: 0a0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+000030e0: 206f 626a 3a0a 2020 2020 2020 2020 3a70   obj:.        :p
+000030f0: 6172 616d 2063 6f6e 7465 7874 3a0a 0a20  aram context:.. 
+00003100: 2020 2020 2020 203a 7265 7475 726e 3a0a         :return:.
+00003110: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+00003120: 2020 2020 7762 6974 7320 3d20 7365 6c66      wbits = self
+00003130: 2e77 6269 7473 2863 6f6e 7465 7874 2920  .wbits(context) 
+00003140: 6966 2063 616c 6c61 626c 6528 7365 6c66  if callable(self
+00003150: 2e77 6269 7473 2920 656c 7365 2073 656c  .wbits) else sel
+00003160: 662e 7762 6974 730a 2020 2020 2020 2020  f.wbits.        
+00003170: 6275 6673 697a 6520 3d20 7365 6c66 2e62  bufsize = self.b
+00003180: 7566 7369 7a65 2863 6f6e 7465 7874 2920  ufsize(context) 
+00003190: 6966 2063 616c 6c61 626c 6528 7365 6c66  if callable(self
+000031a0: 2e62 7566 7369 7a65 2920 656c 7365 2073  .bufsize) else s
+000031b0: 656c 662e 6275 6673 697a 650a 2020 2020  elf.bufsize.    
+000031c0: 2020 2020 6966 2077 6269 7473 2069 7320      if wbits is 
+000031d0: 6e6f 7420 4e6f 6e65 2061 6e64 2062 7566  not None and buf
+000031e0: 7369 7a65 2069 7320 6e6f 7420 4e6f 6e65  size is not None
+000031f0: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
+00003200: 7475 726e 207a 6c69 622e 6465 636f 6d70  turn zlib.decomp
+00003210: 7265 7373 286f 626a 2c20 7762 6974 732c  ress(obj, wbits,
+00003220: 2062 7566 7369 7a65 290a 2020 2020 2020   bufsize).      
+00003230: 2020 656c 6966 2077 6269 7473 2069 7320    elif wbits is 
+00003240: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+00003250: 2020 2020 2020 7265 7475 726e 207a 6c69        return zli
+00003260: 622e 6465 636f 6d70 7265 7373 286f 626a  b.decompress(obj
+00003270: 2c20 7762 6974 7329 0a20 2020 2020 2020  , wbits).       
+00003280: 2072 6574 7572 6e20 7a6c 6962 2e64 6563   return zlib.dec
+00003290: 6f6d 7072 6573 7328 6f62 6a29 0a0a 0a63  ompress(obj)...c
+000032a0: 6c61 7373 2055 5549 4441 6461 7074 6572  lass UUIDAdapter
+000032b0: 2841 6461 7074 6572 293a 0a20 2020 2072  (Adapter):.    r
+000032c0: 2222 220a 2020 2020 4164 6170 7465 7220  """.    Adapter 
+000032d0: 7573 6564 2074 6f20 636f 6e76 6572 7420  used to convert 
+000032e0: 7061 7273 6564 2062 7974 6573 2074 6f20  parsed bytes to 
+000032f0: 6120 7374 7269 6e67 2072 6570 7265 7365  a string represe
+00003300: 6e74 696e 6720 7468 6520 5555 4944 2e0a  nting the UUID..
+00003310: 2020 2020 4164 6170 7465 7220 6361 6e20      Adapter can 
+00003320: 6465 636f 6465 2031 3620 6279 7465 7320  decode 16 bytes 
+00003330: 7374 7261 6967 6874 206f 7220 696e 206c  straight or in l
+00003340: 6974 746c 652d 656e 6469 616e 206f 7264  ittle-endian ord
+00003350: 6572 2069 6620 796f 7520 7365 7420 6c65  er if you set le
+00003360: 3d54 7275 652e 0a0a 2020 2020 652e 672e  =True...    e.g.
+00003370: 0a20 2020 203e 3e3e 2055 5549 4441 6461  .    >>> UUIDAda
+00003380: 7074 6572 2842 7974 6573 2831 3629 292e  pter(Bytes(16)).
+00003390: 6275 696c 6428 277b 3132 3334 3536 3738  build('{12345678
+000033a0: 2d31 3233 342d 3536 3738 2d31 3233 342d  -1234-5678-1234-
+000033b0: 3536 3738 3132 3334 3536 3738 7d27 290a  567812345678}').
+000033c0: 2020 2020 2778 5634 5c78 3132 345c 7831      'xV4\x124\x1
+000033d0: 3278 565c 7831 3234 5678 5c78 3132 3456  2xV\x124Vx\x124V
+000033e0: 7827 0a20 2020 203e 3e3e 2055 5549 4441  x'.    >>> UUIDA
+000033f0: 6461 7074 6572 2842 7974 6573 2831 3629  dapter(Bytes(16)
+00003400: 2c20 6c65 3d46 616c 7365 292e 6275 696c  , le=False).buil
+00003410: 6428 277b 3132 3334 3536 3738 2d31 3233  d('{12345678-123
+00003420: 342d 3536 3738 2d31 3233 342d 3536 3738  4-5678-1234-5678
+00003430: 3132 3334 3536 3738 7d27 290a 2020 2020  12345678}').    
+00003440: 275c 7831 3234 5678 5c78 3132 3456 785c  '\x124Vx\x124Vx\
+00003450: 7831 3234 5678 5c78 3132 3456 7827 0a20  x124Vx\x124Vx'. 
+00003460: 2020 203e 3e3e 2055 5549 4441 6461 7074     >>> UUIDAdapt
+00003470: 6572 2842 7974 6573 2831 3629 292e 7061  er(Bytes(16)).pa
+00003480: 7273 6528 6227 7856 345c 7831 3234 5c78  rse(b'xV4\x124\x
+00003490: 3132 7856 5c78 3132 3456 785c 7831 3234  12xV\x124Vx\x124
+000034a0: 5678 2729 0a20 2020 2027 7b31 3233 3435  Vx').    '{12345
+000034b0: 3637 382d 3132 3334 2d35 3637 382d 3132  678-1234-5678-12
+000034c0: 3334 2d35 3637 3831 3233 3435 3637 387d  34-567812345678}
+000034d0: 270a 2020 2020 2222 220a 2020 2020 5f5f  '.    """.    __
+000034e0: 736c 6f74 735f 5f20 3d20 5b27 7375 6263  slots__ = ['subc
+000034f0: 6f6e 272c 2027 6c65 275d 0a0a 2020 2020  on', 'le']..    
+00003500: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+00003510: 662c 2073 7562 636f 6e2c 206c 653d 5472  f, subcon, le=Tr
+00003520: 7565 293a 0a20 2020 2020 2020 2073 7570  ue):.        sup
+00003530: 6572 2855 5549 4441 6461 7074 6572 2c20  er(UUIDAdapter, 
+00003540: 7365 6c66 292e 5f5f 696e 6974 5f5f 2873  self).__init__(s
+00003550: 7562 636f 6e29 0a20 2020 2020 2020 2073  ubcon).        s
+00003560: 656c 662e 6c65 203d 206c 650a 0a20 2020  elf.le = le..   
+00003570: 2064 6566 205f 656e 636f 6465 2873 656c   def _encode(sel
+00003580: 662c 206f 626a 2c20 636f 6e74 6578 742c  f, obj, context,
+00003590: 2070 6174 6829 3a0a 2020 2020 2020 2020   path):.        
+000035a0: 6f62 6a20 3d20 7575 6964 2e55 5549 4428  obj = uuid.UUID(
+000035b0: 6f62 6a29 0a20 2020 2020 2020 2069 6620  obj).        if 
+000035c0: 7365 6c66 2e6c 653a 0a20 2020 2020 2020  self.le:.       
+000035d0: 2020 2020 2072 6574 7572 6e20 6f62 6a2e       return obj.
+000035e0: 6279 7465 735f 6c65 0a20 2020 2020 2020  bytes_le.       
+000035f0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00003600: 2020 2072 6574 7572 6e20 6f62 6a2e 6279     return obj.by
+00003610: 7465 730a 0a20 2020 2064 6566 205f 6465  tes..    def _de
+00003620: 636f 6465 2873 656c 662c 206f 626a 2c20  code(self, obj, 
+00003630: 636f 6e74 6578 742c 2070 6174 6829 3a0a  context, path):.
+00003640: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00003650: 6c65 3a0a 2020 2020 2020 2020 2020 2020  le:.            
+00003660: 5f75 7569 6420 3d20 7575 6964 2e55 5549  _uuid = uuid.UUI
+00003670: 4428 6279 7465 735f 6c65 3d6f 626a 290a  D(bytes_le=obj).
+00003680: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00003690: 2020 2020 2020 2020 2020 5f75 7569 6420            _uuid 
+000036a0: 3d20 7575 6964 2e55 5549 4428 6279 7465  = uuid.UUID(byte
+000036b0: 733d 6f62 6a29 0a20 2020 2020 2020 2072  s=obj).        r
+000036c0: 6574 7572 6e20 277b 2720 2b20 7374 7228  eturn '{' + str(
+000036d0: 5f75 7569 6429 202b 2027 7d27 0a0a 0a64  _uuid) + '}'...d
+000036e0: 6566 2055 5549 4428 6c65 3d54 7275 6529  ef UUID(le=True)
+000036f0: 3a0a 2020 2020 7222 2222 4120 636f 6e76  :.    r"""A conv
+00003700: 656e 6965 6e63 6520 6675 6e63 7469 6f6e  enience function
+00003710: 2066 6f72 2075 7369 6e67 2074 6865 2055   for using the U
+00003720: 5549 4441 6461 7074 6572 2077 6974 6820  UIDAdapter with 
+00003730: 3136 2062 7974 6573 2e0a 0a20 2020 203a  16 bytes...    :
+00003740: 7061 7261 6d20 6c65 3a20 5768 6574 6865  param le: Whethe
+00003750: 7220 746f 2075 7365 2022 6279 7465 735f  r to use "bytes_
+00003760: 6c65 2220 6f72 2022 6279 7465 7322 2077  le" or "bytes" w
+00003770: 6865 6e20 636f 6e73 7472 7563 7469 6e67  hen constructing
+00003780: 2074 6865 2055 5549 442e 0a0a 2020 2020   the UUID...    
+00003790: 652e 672e 0a20 2020 203e 3e3e 2055 5549  e.g..    >>> UUI
+000037a0: 4428 292e 6275 696c 6428 277b 3132 3334  D().build('{1234
+000037b0: 3536 3738 2d31 3233 342d 3536 3738 2d31  5678-1234-5678-1
+000037c0: 3233 342d 3536 3738 3132 3334 3536 3738  234-567812345678
+000037d0: 7d27 290a 2020 2020 2778 5634 5c78 3132  }').    'xV4\x12
+000037e0: 345c 7831 3278 565c 7831 3234 5678 5c78  4\x12xV\x124Vx\x
+000037f0: 3132 3456 7827 0a20 2020 203e 3e3e 2055  124Vx'.    >>> U
+00003800: 5549 4428 6c65 3d46 616c 7365 292e 6275  UID(le=False).bu
+00003810: 696c 6428 277b 3132 3334 3536 3738 2d31  ild('{12345678-1
+00003820: 3233 342d 3536 3738 2d31 3233 342d 3536  234-5678-1234-56
+00003830: 3738 3132 3334 3536 3738 7d27 290a 2020  7812345678}').  
+00003840: 2020 275c 7831 3234 5678 5c78 3132 3456    '\x124Vx\x124V
+00003850: 785c 7831 3234 5678 5c78 3132 3456 7827  x\x124Vx\x124Vx'
+00003860: 0a20 2020 203e 3e3e 2055 5549 4428 292e  .    >>> UUID().
+00003870: 7061 7273 6528 6227 7856 345c 7831 3234  parse(b'xV4\x124
+00003880: 5c78 3132 7856 5c78 3132 3456 785c 7831  \x12xV\x124Vx\x1
+00003890: 3234 5678 2729 0a20 2020 2027 7b31 3233  24Vx').    '{123
+000038a0: 3435 3637 382d 3132 3334 2d35 3637 382d  45678-1234-5678-
+000038b0: 3132 3334 2d35 3637 3831 3233 3435 3637  1234-56781234567
+000038c0: 387d 270a 2020 2020 3e3e 3e20 5555 4944  8}'.    >>> UUID
+000038d0: 286c 653d 4661 6c73 6529 2e70 6172 7365  (le=False).parse
+000038e0: 2862 275c 7831 3234 5678 5c78 3132 3456  (b'\x124Vx\x124V
+000038f0: 785c 7831 3234 5678 5c78 3132 3456 7827  x\x124Vx\x124Vx'
+00003900: 290a 2020 2020 277b 3132 3334 3536 3738  ).    '{12345678
+00003910: 2d31 3233 342d 3536 3738 2d31 3233 342d  -1234-5678-1234-
+00003920: 3536 3738 3132 3334 3536 3738 7d27 0a20  567812345678}'. 
+00003930: 2020 2022 2222 0a20 2020 2072 6574 7572     """.    retur
+00003940: 6e20 5555 4944 4164 6170 7465 7228 4279  n UUIDAdapter(By
+00003950: 7465 7328 3136 292c 206c 653d 6c65 290a  tes(16), le=le).
+00003960: 0a0a 6465 6620 454c 4650 6f69 6e74 6572  ..def ELFPointer
+00003970: 286d 656d 5f6f 6666 2c20 7375 6263 6f6e  (mem_off, subcon
+00003980: 2c20 656c 663d 4e6f 6e65 293a 0a20 2020  , elf=None):.   
+00003990: 2072 2222 220a 2020 2020 506f 696e 7465   r""".    Pointe
+000039a0: 7220 666f 7220 454c 4620 6669 6c65 732e  r for ELF files.
+000039b0: 2054 6869 7320 776f 726b 7320 666f 7220   This works for 
+000039c0: 626f 7468 206d 656d 6f72 7920 7369 7a65  both memory size
+000039d0: 732e 0a0a 2020 2020 4e4f 5445 3a20 5468  s...    NOTE: Th
+000039e0: 6973 206f 6e6c 7920 776f 726b 7320 666f  is only works fo
+000039f0: 7220 7838 3620 696e 7374 7275 6374 696f  r x86 instructio
+00003a00: 6e73 2e20 466f 7220 6f74 6865 7220 6172  ns. For other ar
+00003a10: 6368 6974 6563 7475 7265 732c 0a20 2020  chitectures,.   
+00003a20: 2070 6c65 6173 6520 7365 6520 7468 6520   please see the 
+00003a30: 2245 4c46 506f 696e 7465 7222 2077 6974  "ELFPointer" wit
+00003a40: 6869 6e20 7468 6569 7220 7265 7370 6563  hin their respec
+00003a50: 7469 7665 2073 7562 6d6f 6475 6c65 732e  tive submodules.
+00003a60: 2028 652e 672e 2063 6f6e 7374 7275 6374   (e.g. construct
+00003a70: 2e41 524d 2e45 4c46 506f 696e 7465 7229  .ARM.ELFPointer)
+00003a80: 0a0a 2020 2020 7370 6563 2e70 6172 7365  ..    spec.parse
+00003a90: 2866 696c 655f 6461 7461 2c20 7065 3d65  (file_data, pe=e
+00003aa0: 6c66 5f6f 626a 6563 7429 0a0a 2020 2020  lf_object)..    
+00003ab0: 3a70 6172 616d 206d 656d 5f6f 6666 3a20  :param mem_off: 
+00003ac0: 616e 2069 6e74 206f 7220 6120 6675 6e63  an int or a func
+00003ad0: 7469 6f6e 2074 6861 7420 7265 7072 6573  tion that repres
+00003ae0: 656e 7473 2074 6865 206d 656d 6f72 7920  ents the memory 
+00003af0: 6f66 6673 6574 2066 6f72 2074 6865 2065  offset for the e
+00003b00: 7175 6976 616c 656e 7420 7068 7973 6963  quivalent physic
+00003b10: 616c 206f 6666 7365 742e 0a20 2020 203a  al offset..    :
+00003b20: 7061 7261 6d20 7375 6263 6f6e 3a20 7468  param subcon: th
+00003b30: 6520 7375 6263 6f6e 2074 6f20 7573 6520  e subcon to use 
+00003b40: 6174 2074 6865 206f 6666 7365 740a 2020  at the offset.  
+00003b50: 2020 3a70 6172 616d 2065 6c66 3a20 4f70    :param elf: Op
+00003b60: 7469 6f6e 616c 2065 6c66 746f 6f6c 732e  tional elftools.
+00003b70: 454c 4646 696c 6520 6669 6c65 206f 626a  ELFFile file obj
+00003b80: 6563 742e 0a20 2020 2020 2020 2028 6966  ect..        (if
+00003b90: 206e 6f74 2073 7570 706c 6965 6420 6865   not supplied he
+00003ba0: 7265 2c20 7468 6973 206d 7573 7420 6265  re, this must be
+00003bb0: 2073 7570 706c 6965 6420 6475 7269 6e67   supplied during
+00003bc0: 2070 6172 7365 2829 2f62 7569 6c64 2829   parse()/build()
+00003bd0: 0a20 2020 2022 2222 0a20 2020 2064 6566  .    """.    def
+00003be0: 205f 6f62 7461 696e 5f70 6879 7369 6361   _obtain_physica
+00003bf0: 6c5f 6f66 6673 6574 2863 7478 293a 0a20  l_offset(ctx):. 
+00003c00: 2020 2020 2020 205f 656c 6620 3d20 656c         _elf = el
+00003c10: 6620 6f72 2063 7478 2e5f 7061 7261 6d73  f or ctx._params
+00003c20: 2e65 6c66 0a20 2020 2020 2020 205f 6d65  .elf.        _me
+00003c30: 6d5f 6f66 6620 3d20 6d65 6d5f 6f66 6628  m_off = mem_off(
+00003c40: 6374 7829 2069 6620 6361 6c6c 6162 6c65  ctx) if callable
+00003c50: 286d 656d 5f6f 6666 2920 656c 7365 206d  (mem_off) else m
+00003c60: 656d 5f6f 6666 0a20 2020 2020 2020 2070  em_off.        p
+00003c70: 6879 5f6f 6666 203d 2065 6c66 6669 6c65  hy_off = elffile
+00003c80: 7574 696c 732e 6f62 7461 696e 5f70 6879  utils.obtain_phy
+00003c90: 7369 6361 6c5f 6f66 6673 6574 285f 6d65  sical_offset(_me
+00003ca0: 6d5f 6f66 662c 2065 6c66 3d5f 656c 6629  m_off, elf=_elf)
+00003cb0: 0a20 2020 2020 2020 2069 6620 7068 795f  .        if phy_
+00003cc0: 6f66 6620 6973 204e 6f6e 653a 0a20 2020  off is None:.   
+00003cd0: 2020 2020 2020 2020 2072 6169 7365 2043           raise C
+00003ce0: 6f6e 7374 7275 6374 4572 726f 7228 2755  onstructError('U
+00003cf0: 6e61 626c 6520 746f 2064 6563 6f64 6520  nable to decode 
+00003d00: 7669 7274 7561 6c20 6164 6472 6573 7327  virtual address'
+00003d10: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00003d20: 2070 6879 5f6f 6666 0a0a 2020 2020 7265   phy_off..    re
+00003d30: 7475 726e 2050 6f69 6e74 6572 285f 6f62  turn Pointer(_ob
+00003d40: 7461 696e 5f70 6879 7369 6361 6c5f 6f66  tain_physical_of
+00003d50: 6673 6574 2c20 7375 6263 6f6e 290a 0a0a  fset, subcon)...
+00003d60: 636c 6173 7320 5045 5068 7973 6963 616c  class PEPhysical
+00003d70: 4164 6472 6573 7328 4164 6170 7465 7229  Address(Adapter)
+00003d80: 3a0a 2020 2020 7222 2222 0a20 2020 2041  :.    r""".    A
+00003d90: 6461 7074 6572 2075 7365 6420 746f 2063  dapter used to c
+00003da0: 6f6e 7665 7274 2061 6e20 696e 7420 7265  onvert an int re
+00003db0: 7072 6573 656e 7469 6e67 2061 2050 4520  presenting a PE 
+00003dc0: 6d65 6d6f 7279 2061 6464 7265 7373 2069  memory address i
+00003dd0: 6e74 6f20 6120 7068 7973 6963 616c 2061  nto a physical a
+00003de0: 6464 7265 7373 2e0a 0a20 2020 2054 6865  ddress...    The
+00003df0: 2050 4520 6f62 6a65 6374 2063 616e 2065   PE object can e
+00003e00: 6974 6865 7220 6265 2070 6173 7365 6420  ither be passed 
+00003e10: 696e 746f 2074 6865 2073 7065 6369 6669  into the specifi
+00003e20: 6320 636f 6e73 7472 7563 742c 206f 7220  c construct, or 
+00003e30: 6173 2061 206b 6579 776f 7264 2061 7275  as a keyword aru
+00003e40: 6d65 6e74 2069 6e0a 2020 2020 7468 6520  ment in.    the 
+00003e50: 7061 7273 6528 292f 6275 696c 6428 2920  parse()/build() 
+00003e60: 6675 6e63 7469 6f6e 732e 0a20 2020 2049  functions..    I
+00003e70: 6620 7061 7373 6564 2069 6e20 7468 726f  f passed in thro
+00003e80: 7567 6820 7061 7273 6528 292f 6275 696c  ugh parse()/buil
+00003e90: 6428 292c 2074 6865 2073 616d 6520 5045  d(), the same PE
+00003ea0: 206f 626a 6563 7420 7769 6c6c 2062 6520   object will be 
+00003eb0: 7573 6564 2066 6f72 2061 6c6c 2069 6e73  used for all ins
+00003ec0: 7461 6e63 6573 2e0a 0a20 2020 2054 6869  tances...    Thi
+00003ed0: 7320 4164 6170 7465 7220 6973 2075 7365  s Adapter is use
+00003ee0: 6675 6c20 7768 656e 2075 7365 6420 616c  ful when used al
+00003ef0: 6f6e 672d 7369 6465 2074 6865 2050 6f69  ong-side the Poi
+00003f00: 6e74 6572 2063 6f6e 7374 7275 6374 3a0a  nter construct:.
+00003f10: 2020 2020 7370 6563 203d 2053 7472 7563      spec = Struc
+00003f20: 7428 0a20 2020 2020 2020 2027 6f66 6673  t(.        'offs
+00003f30: 6574 2720 2f20 5045 5068 7973 6963 616c  et' / PEPhysical
+00003f40: 4164 6472 6573 7328 496e 7433 3275 6c29  Address(Int32ul)
+00003f50: 2c0a 2020 2020 2020 2020 2764 6174 6127  ,.        'data'
+00003f60: 202f 2050 6f69 6e74 6572 2874 6869 732e   / Pointer(this.
+00003f70: 6f66 6673 6574 2c20 4279 7465 7328 3130  offset, Bytes(10
+00003f80: 3029 290a 2020 2020 290a 0a20 2020 2065  0)).    )..    e
+00003f90: 2e67 2e0a 2020 2020 3e3e 2077 6974 6820  .g..    >> with 
+00003fa0: 6f70 656e 2872 2743 3a5c 3332 6269 745f  open(r'C:\32bit_
+00003fb0: 6578 6527 2c20 2772 6227 2920 6173 2066  exe', 'rb') as f
+00003fc0: 6f3a 0a20 2020 202e 2e2e 2020 2020 2066  o:.    ...     f
+00003fd0: 696c 655f 6461 7461 203d 2066 6f2e 7265  ile_data = fo.re
+00003fe0: 6164 2829 0a20 2020 203e 3e20 7065 203d  ad().    >> pe =
+00003ff0: 2070 6566 696c 6575 7469 6c73 2e6f 6274   pefileutils.obt
+00004000: 6169 6e5f 7065 2866 696c 655f 6461 7461  ain_pe(file_data
+00004010: 290a 2020 2020 3e3e 2050 4550 6879 7369  ).    >> PEPhysi
+00004020: 6361 6c41 6464 7265 7373 2849 6e74 3332  calAddress(Int32
+00004030: 756c 2c20 7065 3d70 6529 2e62 7569 6c64  ul, pe=pe).build
+00004040: 2831 3030 290a 2020 2020 2764 5c78 3030  (100).    'd\x00
+00004050: 405c 7830 3027 0a20 2020 203e 3e20 5045  @\x00'.    >> PE
+00004060: 5068 7973 6963 616c 4164 6472 6573 7328  PhysicalAddress(
+00004070: 496e 7433 3275 6c2c 2070 653d 7065 292e  Int32ul, pe=pe).
+00004080: 7061 7273 6528 6227 645c 7830 3040 5c78  parse(b'd\x00@\x
+00004090: 3030 2729 0a20 2020 2031 3030 0a20 2020  00').    100.   
+000040a0: 203e 3e20 5045 5068 7973 6963 616c 4164   >> PEPhysicalAd
+000040b0: 6472 6573 7328 496e 7433 3275 6c29 2e62  dress(Int32ul).b
+000040c0: 7569 6c64 2831 3030 2c20 7065 3d70 6529  uild(100, pe=pe)
+000040d0: 0a20 2020 2027 645c 7830 3040 5c78 3030  .    'd\x00@\x00
+000040e0: 270a 2020 2020 3e3e 2050 4550 6879 7369  '.    >> PEPhysi
+000040f0: 6361 6c41 6464 7265 7373 2849 6e74 3332  calAddress(Int32
+00004100: 756c 292e 7061 7273 6528 6227 645c 7830  ul).parse(b'd\x0
+00004110: 3040 5c78 3030 272c 2070 653d 7065 290a  0@\x00', pe=pe).
+00004120: 2020 2020 3130 300a 2020 2020 2222 220a      100.    """.
+00004130: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
+00004140: 2873 656c 662c 2073 7562 636f 6e2c 2070  (self, subcon, p
+00004150: 653d 4e6f 6e65 293a 0a20 2020 2020 2020  e=None):.       
+00004160: 2022 2222 0a20 2020 2020 2020 203a 7061   """.        :pa
+00004170: 7261 6d20 7065 3a20 4f70 7469 6f6e 616c  ram pe: Optional
+00004180: 2050 4520 6669 6c65 206f 626a 6563 742e   PE file object.
+00004190: 2028 6966 206e 6f74 2073 7570 706c 6965   (if not supplie
+000041a0: 6420 6865 7265 2c20 7468 6973 206d 7573  d here, this mus
+000041b0: 7420 6265 2073 7570 706c 6965 6420 6475  t be supplied du
+000041c0: 7269 6e67 2070 6172 7365 2829 2f62 7569  ring parse()/bui
+000041d0: 6c64 2829 0a20 2020 2020 2020 203a 7061  ld().        :pa
+000041e0: 7261 6d20 7375 6263 6f6e 3a20 7375 6263  ram subcon: subc
+000041f0: 6f6e 2074 6f20 7061 7273 6520 6d65 6d6f  on to parse memo
+00004200: 7279 206f 6666 7365 742e 0a20 2020 2020  ry offset..     
+00004210: 2020 2022 2222 0a20 2020 2020 2020 2073     """.        s
+00004220: 7570 6572 2850 4550 6879 7369 6361 6c41  uper(PEPhysicalA
+00004230: 6464 7265 7373 2c20 7365 6c66 292e 5f5f  ddress, self).__
+00004240: 696e 6974 5f5f 2873 7562 636f 6e29 0a20  init__(subcon). 
+00004250: 2020 2020 2020 2073 656c 662e 5f70 6520         self._pe 
+00004260: 3d20 7065 0a0a 2020 2020 6465 6620 5f65  = pe..    def _e
+00004270: 6e63 6f64 6528 7365 6c66 2c20 6f62 6a2c  ncode(self, obj,
+00004280: 2063 6f6e 7465 7874 2c20 7061 7468 293a   context, path):
+00004290: 0a20 2020 2020 2020 2070 6520 3d20 7365  .        pe = se
+000042a0: 6c66 2e5f 7065 206f 7220 636f 6e74 6578  lf._pe or contex
+000042b0: 742e 5f70 6172 616d 732e 7065 0a20 2020  t._params.pe.   
+000042c0: 2020 2020 2061 6464 7265 7373 203d 2070       address = p
+000042d0: 6566 696c 6575 7469 6c73 2e6f 6274 6169  efileutils.obtai
+000042e0: 6e5f 6d65 6d6f 7279 5f6f 6666 7365 7428  n_memory_offset(
+000042f0: 6f62 6a2c 2070 653d 7065 290a 2020 2020  obj, pe=pe).    
+00004300: 2020 2020 6966 2061 6464 7265 7373 2069      if address i
+00004310: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+00004320: 2020 2020 7261 6973 6520 436f 6e73 7472      raise Constr
+00004330: 7563 7445 7272 6f72 2827 556e 6162 6c65  uctError('Unable
+00004340: 2074 6f20 656e 636f 6465 2070 6879 7369   to encode physi
+00004350: 6361 6c20 6164 6472 6573 732e 2729 0a20  cal address.'). 
+00004360: 2020 2020 2020 2072 6574 7572 6e20 6164         return ad
+00004370: 6472 6573 730a 0a20 2020 2064 6566 205f  dress..    def _
+00004380: 6465 636f 6465 2873 656c 662c 206f 626a  decode(self, obj
+00004390: 2c20 636f 6e74 6578 742c 2070 6174 6829  , context, path)
+000043a0: 3a0a 2020 2020 2020 2020 7065 203d 2073  :.        pe = s
+000043b0: 656c 662e 5f70 6520 6f72 2063 6f6e 7465  elf._pe or conte
+000043c0: 7874 2e5f 7061 7261 6d73 2e70 650a 2020  xt._params.pe.  
+000043d0: 2020 2020 2020 6164 6472 6573 7320 3d20        address = 
+000043e0: 7065 6669 6c65 7574 696c 732e 6f62 7461  pefileutils.obta
+000043f0: 696e 5f70 6879 7369 6361 6c5f 6f66 6673  in_physical_offs
+00004400: 6574 286f 626a 2c20 7065 3d70 6529 0a20  et(obj, pe=pe). 
+00004410: 2020 2020 2020 2069 6620 6164 6472 6573         if addres
+00004420: 7320 6973 204e 6f6e 653a 0a20 2020 2020  s is None:.     
+00004430: 2020 2020 2020 2072 6169 7365 2043 6f6e         raise Con
+00004440: 7374 7275 6374 4572 726f 7228 2755 6e61  structError('Una
+00004450: 626c 6520 746f 2064 6563 6f64 6520 7669  ble to decode vi
+00004460: 7274 7561 6c20 6164 6472 6573 732e 2729  rtual address.')
+00004470: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00004480: 6164 6472 6573 730a 0a0a 6465 6620 5045  address...def PE
+00004490: 506f 696e 7465 7228 6d65 6d5f 6f66 662c  Pointer(mem_off,
+000044a0: 2073 7562 636f 6e2c 2070 653d 4e6f 6e65   subcon, pe=None
+000044b0: 293a 0a20 2020 2072 2222 220a 2020 2020  ):.    r""".    
+000044c0: 5468 6973 2069 7320 616e 2061 6c74 6572  This is an alter
+000044d0: 6e61 7469 7665 2074 6f20 5045 5068 7973  native to PEPhys
+000044e0: 6963 616c 4164 6472 6573 7320 7768 656e  icalAddress when
+000044f0: 2079 6f75 2061 7265 2075 7369 6e67 2074   you are using t
+00004500: 6865 2061 6464 7265 7373 2061 6c6f 6e67  he address along
+00004510: 2077 6974 6820 506f 696e 7465 720a 0a20   with Pointer.. 
+00004520: 2020 2053 696d 706c 6966 6965 733a 0a20     Simplifies:. 
+00004530: 2020 2073 7065 6320 3d20 5374 7275 6374     spec = Struct
+00004540: 280a 2020 2020 2020 2020 276f 6666 7365  (.        'offse
+00004550: 7427 202f 2050 4550 6879 7369 6361 6c41  t' / PEPhysicalA
+00004560: 6464 7265 7373 2849 6e74 3332 756c 292c  ddress(Int32ul),
+00004570: 0a20 2020 2020 2020 2027 6461 7461 2720  .        'data' 
+00004580: 2f20 506f 696e 7465 7228 7468 6973 2e6f  / Pointer(this.o
+00004590: 6666 7365 742c 2042 7974 6573 2831 3030  ffset, Bytes(100
+000045a0: 2929 0a20 2020 2029 0a20 2020 2074 6f3a  )).    ).    to:
+000045b0: 0a20 2020 2073 7065 6320 3d20 5374 7275  .    spec = Stru
+000045c0: 6374 280a 2020 2020 2020 2020 276f 6666  ct(.        'off
+000045d0: 7365 7427 202f 2049 6e74 3332 756c 2c0a  set' / Int32ul,.
+000045e0: 2020 2020 2020 2020 2764 6174 6127 202f          'data' /
+000045f0: 2050 4550 6f69 6e74 6572 2874 6869 732e   PEPointer(this.
+00004600: 6f66 6673 6574 2c20 4279 7465 7328 3130  offset, Bytes(10
+00004610: 3029 290a 2020 2020 290a 0a20 2020 2073  0)).    )..    s
+00004620: 7065 632e 7061 7273 6528 6669 6c65 5f64  pec.parse(file_d
+00004630: 6174 612c 2070 653d 7065 5f6f 626a 6563  ata, pe=pe_objec
+00004640: 7429 0a0a 2020 2020 3a70 6172 616d 206d  t)..    :param m
+00004650: 656d 5f6f 6666 3a20 616e 2069 6e74 206f  em_off: an int o
+00004660: 7220 6120 6675 6e63 7469 6f6e 2074 6861  r a function tha
+00004670: 7420 7265 7072 6573 656e 7473 2074 6865  t represents the
+00004680: 206d 656d 6f72 7920 6f66 6673 6574 2066   memory offset f
+00004690: 6f72 2074 6865 2065 7175 6976 616c 656e  or the equivalen
+000046a0: 7420 7068 7973 6963 616c 206f 6666 7365  t physical offse
+000046b0: 742e 0a20 2020 203a 7061 7261 6d20 7375  t..    :param su
+000046c0: 6263 6f6e 3a20 7468 6520 7375 6263 6f6e  bcon: the subcon
+000046d0: 2074 6f20 7573 6520 6174 2074 6865 206f   to use at the o
+000046e0: 6666 7365 740a 2020 2020 3a70 6172 616d  ffset.    :param
+000046f0: 2070 653a 204f 7074 696f 6e61 6c20 5045   pe: Optional PE
+00004700: 2066 696c 6520 6f62 6a65 6374 2e20 2869   file object. (i
+00004710: 6620 6e6f 7420 7375 7070 6c69 6564 2068  f not supplied h
+00004720: 6572 652c 2074 6869 7320 6d75 7374 2062  ere, this must b
+00004730: 6520 7375 7070 6c69 6564 2064 7572 696e  e supplied durin
+00004740: 6720 7061 7273 6528 292f 6275 696c 6428  g parse()/build(
+00004750: 290a 2020 2020 2222 220a 2020 2020 6465  ).    """.    de
+00004760: 6620 5f6f 6274 6169 6e5f 7068 7973 6963  f _obtain_physic
+00004770: 616c 5f6f 6666 7365 7428 6374 7829 3a0a  al_offset(ctx):.
+00004780: 2020 2020 2020 2020 5f70 6520 3d20 7065          _pe = pe
+00004790: 206f 7220 6374 782e 5f70 6172 616d 732e   or ctx._params.
+000047a0: 7065 0a20 2020 2020 2020 205f 6d65 6d5f  pe.        _mem_
+000047b0: 6f66 6620 3d20 6d65 6d5f 6f66 6628 6374  off = mem_off(ct
+000047c0: 7829 2069 6620 6361 6c6c 6162 6c65 286d  x) if callable(m
+000047d0: 656d 5f6f 6666 2920 656c 7365 206d 656d  em_off) else mem
+000047e0: 5f6f 6666 0a20 2020 2020 2020 2070 6879  _off.        phy
+000047f0: 5f6f 6666 203d 2070 6566 696c 6575 7469  _off = pefileuti
+00004800: 6c73 2e6f 6274 6169 6e5f 7068 7973 6963  ls.obtain_physic
+00004810: 616c 5f6f 6666 7365 7428 5f6d 656d 5f6f  al_offset(_mem_o
+00004820: 6666 2c20 7065 3d5f 7065 290a 2020 2020  ff, pe=_pe).    
+00004830: 2020 2020 6966 2070 6879 5f6f 6666 2069      if phy_off i
+00004840: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+00004850: 2020 2020 7261 6973 6520 436f 6e73 7472      raise Constr
+00004860: 7563 7445 7272 6f72 2827 556e 6162 6c65  uctError('Unable
+00004870: 2074 6f20 6465 636f 6465 2076 6972 7475   to decode virtu
+00004880: 616c 2061 6464 7265 7373 2729 0a20 2020  al address').   
+00004890: 2020 2020 2072 6574 7572 6e20 7068 795f       return phy_
+000048a0: 6f66 660a 0a20 2020 2072 6574 7572 6e20  off..    return 
+000048b0: 506f 696e 7465 7228 5f6f 6274 6169 6e5f  Pointer(_obtain_
+000048c0: 7068 7973 6963 616c 5f6f 6666 7365 742c  physical_offset,
+000048d0: 2073 7562 636f 6e29 0a0a 0a64 6566 2050   subcon)...def P
+000048e0: 4550 6f69 6e74 6572 3634 286d 656d 5f6f  EPointer64(mem_o
+000048f0: 6666 2c20 696e 7374 5f65 6e64 2c20 7375  ff, inst_end, su
+00004900: 6263 6f6e 2c20 7065 3d4e 6f6e 6529 3a0a  bcon, pe=None):.
+00004910: 2020 2020 7222 2222 0a20 2020 2054 6869      r""".    Thi
+00004920: 7320 6973 2074 6865 2036 342d 6269 7420  s is the 64-bit 
+00004930: 7665 7273 696f 6e20 6f66 2050 4550 6f69  version of PEPoi
+00004940: 6e74 6572 2e0a 2020 2020 5468 6973 2073  nter..    This s
+00004950: 7562 636f 6e73 7472 7563 7420 7461 6b65  ubconstruct take
+00004960: 7320 616e 2065 7874 7261 2061 7267 756d  s an extra argum
+00004970: 656e 7420 7768 6963 6820 7370 6563 6966  ent which specif
+00004980: 6965 730a 2020 2020 7468 6520 6c6f 6361  ies.    the loca
+00004990: 7469 6f6e 206f 6620 7468 6520 656e 6420  tion of the end 
+000049a0: 6f66 2074 6865 2069 6e73 7472 7563 7469  of the instructi
+000049b0: 6f6e 2066 6f72 2077 6869 6368 2074 6865  on for which the
+000049c0: 206d 656d 6f72 795f 6f66 6673 6574 2077   memory_offset w
+000049d0: 6173 2075 7365 642e 0a20 2020 2028 4120  as used..    (A 
+000049e0: 7061 7261 6d65 7465 7220 6e65 6365 7373  parameter necess
+000049f0: 6172 7920 666f 7220 3634 2d62 6974 290a  ary for 64-bit).
+00004a00: 0a20 2020 2045 7861 6d70 6c65 3a0a 2020  .    Example:.  
+00004a10: 2020 7370 6563 203d 2053 7472 7563 7428    spec = Struct(
+00004a20: 0a20 2020 2020 2020 2027 6f66 6673 6574  .        'offset
+00004a30: 2720 2f20 496e 7433 3275 6c2c 0a20 2020  ' / Int32ul,.   
+00004a40: 2020 2020 2050 6164 6469 6e67 2832 292c       Padding(2),
+00004a50: 0a20 2020 2020 2020 2027 696e 7374 5f65  .        'inst_e
+00004a60: 6e64 2720 2f20 5465 6c6c 2c0a 2020 2020  nd' / Tell,.    
+00004a70: 2020 2020 2764 6174 6127 202f 2050 4550      'data' / PEP
+00004a80: 6f69 6e74 6572 3634 2874 6869 732e 6f66  ointer64(this.of
+00004a90: 6673 6574 2c20 7468 6973 2e69 6e73 745f  fset, this.inst_
+00004aa0: 656e 642c 2042 7974 6528 3130 3029 290a  end, Byte(100)).
+00004ab0: 2020 2020 290a 0a20 2020 2073 7065 6320      )..    spec 
+00004ac0: 3d20 5374 7275 6374 280a 2020 2020 2020  = Struct(.      
+00004ad0: 2020 2769 6e73 7472 7563 7469 6f6e 2720    'instruction' 
+00004ae0: 2f20 5265 6765 7828 0a20 2020 2020 2020  / Regex(.       
+00004af0: 2020 2020 2027 5c78 3031 5c78 3033 283f       '\x01\x03(?
+00004b00: 503c 6461 7461 5f70 7472 3e2e 7b34 7d29  P<data_ptr>.{4})
+00004b10: 5c78 3034 5c78 3035 283f 503c 656e 643e  \x04\x05(?P<end>
+00004b20: 295c 7830 365c 7830 3727 2c20 6461 7461  )\x06\x07', data
+00004b30: 5f70 7472 3d44 574f 5244 2c20 656e 643d  _ptr=DWORD, end=
+00004b40: 5465 6c6c 292c 0a20 2020 2020 2020 2027  Tell),.        '
+00004b50: 6461 7461 2720 2f20 5045 506f 696e 7465  data' / PEPointe
+00004b60: 7236 3428 7468 6973 2e69 6e73 7472 7563  r64(this.instruc
+00004b70: 7469 6f6e 2e64 6174 615f 7074 722c 2074  tion.data_ptr, t
+00004b80: 6869 732e 696e 7374 7275 6374 696f 6e2e  his.instruction.
+00004b90: 656e 642c 2042 7974 6573 2831 3030 2929  end, Bytes(100))
+00004ba0: 0a20 2020 2029 0a0a 2020 2020 7370 6563  .    )..    spec
+00004bb0: 2e70 6172 7365 2866 696c 655f 6461 7461  .parse(file_data
+00004bc0: 2c20 7065 3d70 655f 6f62 6a65 6374 290a  , pe=pe_object).
+00004bd0: 0a20 2020 203a 7061 7261 6d20 6d65 6d5f  .    :param mem_
+00004be0: 6f66 663a 2061 6e20 696e 7420 6f72 2061  off: an int or a
+00004bf0: 2066 756e 6374 696f 6e20 7468 6174 2072   function that r
+00004c00: 6570 7265 7365 6e74 7320 7468 6520 6d65  epresents the me
+00004c10: 6d6f 7279 206f 6666 7365 7420 666f 7220  mory offset for 
+00004c20: 7468 6520 6571 7569 7665 6c65 6e74 2070  the equivelent p
+00004c30: 6879 7369 6361 6c20 6f66 6673 6574 2e0a  hysical offset..
+00004c40: 2020 2020 3a70 6172 616d 2069 6e73 745f      :param inst_
+00004c50: 656e 643a 2061 6e20 696e 7420 6f72 2061  end: an int or a
+00004c60: 2066 756e 6374 696f 6e20 7468 6174 2072   function that r
+00004c70: 6570 7265 7365 6e74 7320 7468 6520 6c6f  epresents the lo
+00004c80: 6361 7469 6f6e 206f 6620 7468 6520 656e  cation of the en
+00004c90: 6420 6f66 2074 6865 2069 6e73 7472 7563  d of the instruc
+00004ca0: 7469 6f6e 2074 6f20 6265 2072 656c 6174  tion to be relat
+00004cb0: 6976 6520 746f 2e0a 2020 2020 3a70 6172  ive to..    :par
+00004cc0: 616d 2073 7562 636f 6e3a 2074 6865 2073  am subcon: the s
+00004cd0: 7562 636f 6e20 746f 2075 7365 2061 7420  ubcon to use at 
+00004ce0: 7468 6520 6f66 6673 6574 0a20 2020 203a  the offset.    :
+00004cf0: 7061 7261 6d20 7065 3a20 4f70 7469 6f6e  param pe: Option
+00004d00: 616c 2050 4520 6669 6c65 206f 626a 6563  al PE file objec
+00004d10: 742e 2028 6966 206e 6f74 2073 7570 706c  t. (if not suppl
+00004d20: 6965 6420 6865 7265 2c20 7468 6973 206d  ied here, this m
+00004d30: 7573 7420 6265 2073 7570 706c 6965 6420  ust be supplied 
+00004d40: 6475 7269 6e67 2070 6172 7365 2829 2f62  during parse()/b
+00004d50: 7569 6c64 2829 0a20 2020 2022 2222 0a20  uild().    """. 
+00004d60: 2020 2064 6566 205f 6f62 7461 696e 5f70     def _obtain_p
+00004d70: 6879 7369 6361 6c5f 6f66 6673 6574 2863  hysical_offset(c
+00004d80: 7478 293a 0a20 2020 2020 2020 205f 7065  tx):.        _pe
+00004d90: 203d 2070 6520 6f72 2063 7478 2e5f 7061   = pe or ctx._pa
+00004da0: 7261 6d73 2e70 650a 2020 2020 2020 2020  rams.pe.        
+00004db0: 5f6d 656d 5f6f 6666 203d 206d 656d 5f6f  _mem_off = mem_o
+00004dc0: 6666 2863 7478 2920 6966 2063 616c 6c61  ff(ctx) if calla
+00004dd0: 626c 6528 6d65 6d5f 6f66 6629 2065 6c73  ble(mem_off) els
+00004de0: 6520 6d65 6d5f 6f66 660a 2020 2020 2020  e mem_off.      
+00004df0: 2020 5f69 6e73 745f 656e 6420 3d20 696e    _inst_end = in
+00004e00: 7374 5f65 6e64 2863 7478 2920 6966 2063  st_end(ctx) if c
+00004e10: 616c 6c61 626c 6528 696e 7374 5f65 6e64  allable(inst_end
+00004e20: 2920 656c 7365 2069 6e73 745f 656e 640a  ) else inst_end.
+00004e30: 2020 2020 2020 2020 7068 795f 6f66 6620          phy_off 
+00004e40: 3d20 7065 6669 6c65 7574 696c 732e 6f62  = pefileutils.ob
+00004e50: 7461 696e 5f70 6879 7369 6361 6c5f 6f66  tain_physical_of
+00004e60: 6673 6574 5f78 3634 285f 6d65 6d5f 6f66  fset_x64(_mem_of
+00004e70: 662c 205f 696e 7374 5f65 6e64 2c20 7065  f, _inst_end, pe
+00004e80: 3d5f 7065 290a 2020 2020 2020 2020 6966  =_pe).        if
+00004e90: 2070 6879 5f6f 6666 2069 7320 4e6f 6e65   phy_off is None
+00004ea0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+00004eb0: 6973 6520 436f 6e73 7472 7563 7445 7272  ise ConstructErr
+00004ec0: 6f72 2827 556e 6162 6c65 2074 6f20 6465  or('Unable to de
+00004ed0: 636f 6465 2076 6972 7475 616c 2061 6464  code virtual add
+00004ee0: 7265 7373 2729 0a20 2020 2020 2020 2072  ress').        r
+00004ef0: 6574 7572 6e20 7068 795f 6f66 660a 0a20  eturn phy_off.. 
+00004f00: 2020 2072 6574 7572 6e20 506f 696e 7465     return Pointe
+00004f10: 7228 5f6f 6274 6169 6e5f 7068 7973 6963  r(_obtain_physic
+00004f20: 616c 5f6f 6666 7365 742c 2073 7562 636f  al_offset, subco
+00004f30: 6e29 0a0a 0a63 6c61 7373 2044 656c 696d  n)...class Delim
+00004f40: 6974 6564 2843 6f6e 7374 7275 6374 293a  ited(Construct):
+00004f50: 0a20 2020 2072 2222 220a 2020 2020 4120  .    r""".    A 
+00004f60: 636f 6e73 7472 7563 7420 7573 6564 2074  construct used t
+00004f70: 6f20 7061 7273 6520 6465 6c69 6d69 7465  o parse delimite
+00004f80: 6420 6461 7461 2e0a 0a20 2020 204e 4f54  d data...    NOT
+00004f90: 453a 2054 6865 2070 6172 7365 6420 636f  E: The parsed co
+00004fa0: 6e73 7472 7563 7473 2077 696c 6c20 6265  nstructs will be
+00004fb0: 2062 7566 6665 7265 640a 0a20 2020 203e   buffered..    >
+00004fc0: 3e3e 2073 7065 6320 3d20 4465 6c69 6d69  >> spec = Delimi
+00004fd0: 7465 6428 6227 7c27 2c0a 2020 2020 2e2e  ted(b'|',.    ..
+00004fe0: 2e20 2020 2020 2766 6972 7374 2720 2f20  .     'first' / 
+00004ff0: 4353 7472 696e 6728 292c 0a20 2020 202e  CString(),.    .
+00005000: 2e2e 2020 2020 2027 7365 636f 6e64 2720  ..     'second' 
+00005010: 2f20 496e 7433 3275 6c2c 0a20 2020 202e  / Int32ul,.    .
+00005020: 2e2e 2020 2020 2023 2057 6865 6e20 7573  ..     # When us
+00005030: 696e 6720 6120 4772 6565 6479 2063 6f6e  ing a Greedy con
+00005040: 7374 7275 6374 2c20 6569 7468 6572 2061  struct, either a
+00005050: 6c6c 2064 6174 6120 7469 6c6c 2045 4f46  ll data till EOF
+00005060: 206f 7220 7468 6520 6e65 7874 2064 656c   or the next del
+00005070: 696d 6974 6572 2077 696c 6c20 6265 2063  imiter will be c
+00005080: 6f6e 7375 6d65 642e 0a20 2020 202e 2e2e  onsumed..    ...
+00005090: 2020 2020 2027 7468 6972 6427 202f 2047       'third' / G
+000050a0: 7265 6564 7942 7974 6573 2c0a 2020 2020  reedyBytes,.    
+000050b0: 2e2e 2e20 2020 2020 2766 6f75 7274 6827  ...     'fourth'
+000050c0: 202f 2042 7974 650a 2020 2020 2e2e 2e20   / Byte.    ... 
+000050d0: 290a 2020 2020 3e3e 3e20 7370 6563 2e70  ).    >>> spec.p
+000050e0: 6172 7365 2862 2748 656c 6c6f 5c78 3030  arse(b'Hello\x00
+000050f0: 5c78 3030 7c5c 7830 315c 7830 305c 7830  \x00|\x01\x00\x0
+00005100: 305c 7830 307c 776f 726c 6421 215c 7830  0\x00|world!!\x0
+00005110: 315c 7830 327c 5c78 6666 2729 0a20 2020  1\x02|\xff').   
+00005120: 2043 6f6e 7461 696e 6572 2866 6972 7374   Container(first
+00005130: 3d75 2748 656c 6c6f 272c 2073 6563 6f6e  =u'Hello', secon
+00005140: 643d 312c 2074 6869 7264 3d62 2777 6f72  d=1, third=b'wor
+00005150: 6c64 2121 5c78 3031 5c78 3032 272c 2066  ld!!\x01\x02', f
+00005160: 6f75 7274 683d 3235 3529 0a20 2020 203e  ourth=255).    >
+00005170: 3e3e 2073 7065 632e 6275 696c 6428 6469  >> spec.build(di
+00005180: 6374 2866 6972 7374 3d75 2748 656c 6c6f  ct(first=u'Hello
+00005190: 272c 2073 6563 6f6e 643d 312c 2074 6869  ', second=1, thi
+000051a0: 7264 3d62 2777 6f72 6c64 2121 5c78 3031  rd=b'world!!\x01
+000051b0: 5c78 3032 272c 2066 6f75 7274 683d 3235  \x02', fourth=25
+000051c0: 3529 290a 2020 2020 2748 656c 6c6f 5c78  5)).    'Hello\x
+000051d0: 3030 7c5c 7830 315c 7830 305c 7830 305c  00|\x01\x00\x00\
+000051e0: 7830 307c 776f 726c 6421 215c 7830 315c  x00|world!!\x01\
+000051f0: 7830 327c 5c78 6666 270a 0a20 2020 2049  x02|\xff'..    I
+00005200: 6620 796f 7520 646f 6e27 7420 6361 7265  f you don't care
+00005210: 2061 626f 7574 2061 2070 6172 7469 6375   about a particu
+00005220: 6c61 7220 656c 656d 656e 742c 2079 6f75  lar element, you
+00005230: 2063 616e 206c 6561 7665 2069 7420 6e61   can leave it na
+00005240: 6d65 6c65 7373 206a 7573 7420 6c69 6b65  meless just like
+00005250: 2069 6e20 5374 7275 6374 732e 0a20 2020   in Structs..   
+00005260: 2023 204e 4f54 453a 2059 6f75 2063 616e   # NOTE: You can
+00005270: 2774 2062 7569 6c64 2075 6e6c 6573 7320  't build unless 
+00005280: 796f 7520 6861 7665 2073 7570 706c 6965  you have supplie
+00005290: 6420 6576 6572 7920 6174 7472 6962 7574  d every attribut
+000052a0: 652e 0a20 2020 203e 3e3e 2073 7065 6320  e..    >>> spec 
+000052b0: 3d20 4465 6c69 6d69 7465 6428 6227 7c27  = Delimited(b'|'
+000052c0: 2c0a 2020 2020 2e2e 2e20 2020 2020 2766  ,.    ...     'f
+000052d0: 6972 7374 2720 2f20 4353 7472 696e 6728  irst' / CString(
+000052e0: 292c 0a20 2020 202e 2e2e 2020 2020 2027  ),.    ...     '
+000052f0: 7365 636f 6e64 2720 2f20 496e 7433 3275  second' / Int32u
+00005300: 6c2c 0a20 2020 202e 2e2e 2020 2020 2050  l,.    ...     P
+00005310: 6173 732c 0a20 2020 202e 2e2e 2020 2020  ass,.    ...    
+00005320: 2027 666f 7572 7468 2720 2f20 4279 7465   'fourth' / Byte
+00005330: 0a20 2020 202e 2e2e 2029 0a20 2020 203e  .    ... ).    >
+00005340: 3e3e 2073 7065 632e 7061 7273 6528 6227  >> spec.parse(b'
+00005350: 4865 6c6c 6f5c 7830 305c 7830 307c 5c78  Hello\x00\x00|\x
+00005360: 3031 5c78 3030 5c78 3030 5c78 3030 7c77  01\x00\x00\x00|w
+00005370: 6f72 6c64 2121 5c78 3031 5c78 3032 7c5c  orld!!\x01\x02|\
+00005380: 7866 6627 290a 2020 2020 436f 6e74 6169  xff').    Contai
 00005390: 6e65 7228 6669 7273 743d 7527 4865 6c6c  ner(first=u'Hell
-000053a0: 6f27 2c20 7365 636f 6e64 3d31 2c20 7468  o', second=1, th
-000053b0: 6972 643d 6227 776f 726c 6421 215c 7830  ird=b'world!!\x0
-000053c0: 315c 7830 3227 2c20 666f 7572 7468 3d32  1\x02', fourth=2
-000053d0: 3535 290d 0a20 2020 203e 3e3e 2073 7065  55)..    >>> spe
-000053e0: 632e 6275 696c 6428 6469 6374 2866 6972  c.build(dict(fir
-000053f0: 7374 3d75 2748 656c 6c6f 272c 2073 6563  st=u'Hello', sec
-00005400: 6f6e 643d 312c 2074 6869 7264 3d62 2777  ond=1, third=b'w
-00005410: 6f72 6c64 2121 5c78 3031 5c78 3032 272c  orld!!\x01\x02',
-00005420: 2066 6f75 7274 683d 3235 3529 290d 0a20   fourth=255)).. 
-00005430: 2020 2027 4865 6c6c 6f5c 7830 307c 5c78     'Hello\x00|\x
-00005440: 3031 5c78 3030 5c78 3030 5c78 3030 7c77  01\x00\x00\x00|w
-00005450: 6f72 6c64 2121 5c78 3031 5c78 3032 7c5c  orld!!\x01\x02|\
-00005460: 7866 6627 0d0a 0d0a 2020 2020 4966 2079  xff'....    If y
-00005470: 6f75 2064 6f6e 2774 2063 6172 6520 6162  ou don't care ab
-00005480: 6f75 7420 6120 7061 7274 6963 756c 6172  out a particular
-00005490: 2065 6c65 6d65 6e74 2c20 796f 7520 6361   element, you ca
-000054a0: 6e20 6c65 6176 6520 6974 206e 616d 656c  n leave it namel
-000054b0: 6573 7320 6a75 7374 206c 696b 6520 696e  ess just like in
-000054c0: 2053 7472 7563 7473 2e0d 0a20 2020 2023   Structs...    #
-000054d0: 204e 4f54 453a 2059 6f75 2063 616e 2774   NOTE: You can't
-000054e0: 2062 7569 6c64 2075 6e6c 6573 7320 796f   build unless yo
-000054f0: 7520 6861 7665 2073 7570 706c 6965 6420  u have supplied 
-00005500: 6576 6572 7920 6174 7472 6962 7574 652e  every attribute.
-00005510: 0d0a 2020 2020 3e3e 3e20 7370 6563 203d  ..    >>> spec =
-00005520: 2044 656c 696d 6974 6564 2862 277c 272c   Delimited(b'|',
-00005530: 0d0a 2020 2020 2e2e 2e20 2020 2020 2766  ..    ...     'f
-00005540: 6972 7374 2720 2f20 4353 7472 696e 6728  irst' / CString(
-00005550: 292c 0d0a 2020 2020 2e2e 2e20 2020 2020  ),..    ...     
-00005560: 2773 6563 6f6e 6427 202f 2049 6e74 3332  'second' / Int32
-00005570: 756c 2c0d 0a20 2020 202e 2e2e 2020 2020  ul,..    ...    
-00005580: 2050 6173 732c 0d0a 2020 2020 2e2e 2e20   Pass,..    ... 
-00005590: 2020 2020 2766 6f75 7274 6827 202f 2042      'fourth' / B
-000055a0: 7974 650d 0a20 2020 202e 2e2e 2029 0d0a  yte..    ... )..
-000055b0: 2020 2020 3e3e 3e20 7370 6563 2e70 6172      >>> spec.par
-000055c0: 7365 2862 2748 656c 6c6f 5c78 3030 5c78  se(b'Hello\x00\x
-000055d0: 3030 7c5c 7830 315c 7830 305c 7830 305c  00|\x01\x00\x00\
-000055e0: 7830 307c 776f 726c 6421 215c 7830 315c  x00|world!!\x01\
-000055f0: 7830 327c 5c78 6666 2729 0d0a 2020 2020  x02|\xff')..    
-00005600: 436f 6e74 6169 6e65 7228 6669 7273 743d  Container(first=
-00005610: 7527 4865 6c6c 6f27 2c20 7365 636f 6e64  u'Hello', second
-00005620: 3d31 2c20 666f 7572 7468 3d32 3535 290d  =1, fourth=255).
-00005630: 0a0d 0a20 2020 2049 7420 6d61 7920 616c  ...    It may al
-00005640: 736f 2062 6520 7573 6566 756c 2074 6f20  so be useful to 
-00005650: 7573 6520 5061 7373 206f 7220 4f70 7469  use Pass or Opti
-00005660: 6f6e 616c 2066 6f72 2066 6965 6c64 7320  onal for fields 
-00005670: 7468 6174 206d 6179 206e 6f74 2065 7869  that may not exi
-00005680: 7374 2e0d 0a20 2020 203e 3e3e 2073 7065  st...    >>> spe
-00005690: 6320 3d20 4465 6c69 6d69 7465 6428 6227  c = Delimited(b'
-000056a0: 7c27 2c0d 0a20 2020 202e 2e2e 2020 2020  |',..    ...    
-000056b0: 2027 6669 7273 7427 202f 2043 5374 7269   'first' / CStri
-000056c0: 6e67 2829 2c0d 0a20 2020 202e 2e2e 2020  ng(),..    ...  
-000056d0: 2020 2027 7365 636f 6e64 2720 2f20 5061     'second' / Pa
-000056e0: 7373 2c0d 0a20 2020 202e 2e2e 2020 2020  ss,..    ...    
-000056f0: 2027 7468 6972 6427 202f 204f 7074 696f   'third' / Optio
-00005700: 6e61 6c28 496e 7433 3275 6c29 0d0a 2020  nal(Int32ul)..  
-00005710: 2020 2e2e 2e20 290d 0a20 2020 203e 3e3e    ... )..    >>>
-00005720: 2073 7065 632e 7061 7273 6528 6227 4865   spec.parse(b'He
-00005730: 6c6c 6f5c 7830 305c 7830 307c 646f 6e74  llo\x00\x00|dont
-00005740: 2063 6172 657c 5c78 3031 5c78 3030 5c78   care|\x01\x00\x
-00005750: 3030 5c78 3030 2729 0d0a 2020 2020 436f  00\x00')..    Co
-00005760: 6e74 6169 6e65 7228 6669 7273 743d 7527  ntainer(first=u'
-00005770: 4865 6c6c 6f27 2c20 7365 636f 6e64 3d4e  Hello', second=N
-00005780: 6f6e 652c 2074 6869 7264 3d31 290d 0a20  one, third=1).. 
-00005790: 2020 203e 3e3e 2073 7065 632e 7061 7273     >>> spec.pars
-000057a0: 6528 6227 4865 6c6c 6f5c 7830 305c 7830  e(b'Hello\x00\x0
-000057b0: 307c 7c27 290d 0a20 2020 2043 6f6e 7461  0||')..    Conta
-000057c0: 696e 6572 2866 6972 7374 3d75 2748 656c  iner(first=u'Hel
-000057d0: 6c6f 272c 2073 6563 6f6e 643d 4e6f 6e65  lo', second=None
-000057e0: 2c20 7468 6972 643d 4e6f 6e65 290d 0a0d  , third=None)...
-000057f0: 0a20 2020 2064 656c 696d 6974 6572 7320  .    delimiters 
-00005800: 6d61 7920 6861 7665 2061 206c 656e 6774  may have a lengt
-00005810: 6820 3e20 310d 0a20 2020 203e 3e3e 2073  h > 1..    >>> s
-00005820: 7065 6320 3d20 4465 6c69 6d69 7465 6428  pec = Delimited(
-00005830: 6227 594f 594f 272c 0d0a 2020 2020 2e2e  b'YOYO',..    ..
-00005840: 2e20 2020 2020 2766 6972 7374 2720 2f20  .     'first' / 
-00005850: 4353 7472 696e 6728 292c 0d0a 2020 2020  CString(),..    
-00005860: 2e2e 2e20 2020 2020 2773 6563 6f6e 6427  ...     'second'
-00005870: 202f 2049 6e74 3332 756c 2c0d 0a20 2020   / Int32ul,..   
-00005880: 202e 2e2e 2020 2020 2023 2057 6865 6e20   ...     # When 
-00005890: 7573 696e 6720 6120 4772 6565 6479 2063  using a Greedy c
-000058a0: 6f6e 7374 7275 6374 2c20 6569 7468 6572  onstruct, either
-000058b0: 2061 6c6c 2064 6174 6120 7469 6c6c 2045   all data till E
-000058c0: 4f46 206f 7220 7468 6520 6e65 7874 2064  OF or the next d
-000058d0: 656c 696d 6974 6572 2077 696c 6c20 6265  elimiter will be
-000058e0: 2063 6f6e 7375 6d65 642e 0d0a 2020 2020   consumed...    
-000058f0: 2e2e 2e20 2020 2020 2774 6869 7264 2720  ...     'third' 
-00005900: 2f20 4772 6565 6479 4279 7465 732c 0d0a  / GreedyBytes,..
-00005910: 2020 2020 2e2e 2e20 2020 2020 2766 6f75      ...     'fou
-00005920: 7274 6827 202f 2042 7974 650d 0a20 2020  rth' / Byte..   
-00005930: 202e 2e2e 2029 0d0a 2020 2020 3e3e 3e20   ... )..    >>> 
-00005940: 7370 6563 2e70 6172 7365 2862 2748 656c  spec.parse(b'Hel
-00005950: 6c6f 5c78 3030 5c78 3030 594f 594f 5c78  lo\x00\x00YOYO\x
-00005960: 3031 5c78 3030 5c78 3030 5c78 3030 594f  01\x00\x00\x00YO
-00005970: 594f 776f 726c 6421 2159 4f21 215c 7830  YOworld!!YO!!\x0
-00005980: 315c 7830 3259 4f59 4f5c 7866 6627 290d  1\x02YOYO\xff').
-00005990: 0a20 2020 2043 6f6e 7461 696e 6572 2866  .    Container(f
-000059a0: 6972 7374 3d75 2748 656c 6c6f 272c 2073  irst=u'Hello', s
-000059b0: 6563 6f6e 643d 312c 2074 6869 7264 3d62  econd=1, third=b
-000059c0: 2777 6f72 6c64 2121 594f 2121 5c78 3031  'world!!YO!!\x01
-000059d0: 5c78 3032 272c 2066 6f75 7274 683d 3235  \x02', fourth=25
-000059e0: 3529 0d0a 2020 2020 3e3e 3e20 7370 6563  5)..    >>> spec
-000059f0: 2e62 7569 6c64 2864 6963 7428 6669 7273  .build(dict(firs
-00005a00: 743d 7527 4865 6c6c 6f27 2c20 7365 636f  t=u'Hello', seco
-00005a10: 6e64 3d31 2c20 7468 6972 643d 6227 776f  nd=1, third=b'wo
-00005a20: 726c 6421 2159 4f21 215c 7830 315c 7830  rld!!YO!!\x01\x0
-00005a30: 3227 2c20 666f 7572 7468 3d32 3535 2929  2', fourth=255))
-00005a40: 0d0a 2020 2020 2748 656c 6c6f 5c78 3030  ..    'Hello\x00
-00005a50: 594f 594f 5c78 3031 5c78 3030 5c78 3030  YOYO\x01\x00\x00
-00005a60: 5c78 3030 594f 594f 776f 726c 6421 2159  \x00YOYOworld!!Y
-00005a70: 4f21 215c 7830 315c 7830 3259 4f59 4f5c  O!!\x01\x02YOYO\
-00005a80: 7866 6627 0d0a 0d0a 2020 2020 2320 544f  xff'....    # TO
-00005a90: 444f 3a20 4164 6420 7375 7070 6f72 7420  DO: Add support 
-00005aa0: 666f 7220 7573 696e 6720 6120 7369 6e67  for using a sing
-00005ab0: 6c65 2063 6f6e 7374 7275 6374 2066 6f72  le construct for
-00005ac0: 2070 6172 7369 6e67 2061 6e20 756e 6b6e   parsing an unkn
-00005ad0: 6f77 6e20 6e75 6d62 6572 206f 6620 7469  own number of ti
-00005ae0: 6d65 730d 0a20 2020 2023 2028 6f72 2077  mes..    # (or w
-00005af0: 6974 6869 6e20 6120 6d69 6e2c 206d 6178  ithin a min, max
-00005b00: 2c20 6f72 2065 7861 6374 290d 0a20 2020  , or exact)..   
-00005b10: 2023 2028 5065 7268 6170 7320 6361 6c6c   # (Perhaps call
-00005b20: 2069 7420 2253 706c 6974 2220 746f 2061   it "Split" to a
-00005b30: 766f 6964 206f 7665 726c 6f61 6469 6e67  void overloading
-00005b40: 2074 6f6f 206d 7563 6820 6675 6e63 7469   too much functi
-00005b50: 6f6e 616c 6974 792e 290d 0a20 2020 2023  onality.)..    #
-00005b60: 2065 2e67 2e0d 0a20 2020 2023 203e 3e3e   e.g...    # >>>
-00005b70: 2073 7065 6320 3d20 4465 6c69 6d69 7465   spec = Delimite
-00005b80: 6428 6227 7c27 2c20 4772 6565 6479 5374  d(b'|', GreedySt
-00005b90: 7269 6e67 2829 290d 0a20 2020 2023 203e  ring())..    # >
-00005ba0: 3e3e 2073 7065 632e 7061 7273 6528 6227  >> spec.parse(b'
-00005bb0: 6865 6c6c 6f7c 776f 726c 6427 290d 0a20  hello|world').. 
-00005bc0: 2020 2023 205b 2768 656c 6c6f 272c 2027     # ['hello', '
-00005bd0: 776f 726c 6427 5d0d 0a20 2020 2023 203e  world']..    # >
-00005be0: 3e3e 2073 7065 632e 7061 7273 6528 6227  >> spec.parse(b'
-00005bf0: 6865 6c6c 6f7c 776f 726c 647c 6869 7c62  hello|world|hi|b
-00005c00: 6f62 2729 0d0a 2020 2020 2320 5b27 6865  ob')..    # ['he
-00005c10: 6c6c 6f27 2c20 2777 6f72 6c64 272c 2027  llo', 'world', '
-00005c20: 6869 272c 2027 626f 6227 5d0d 0a20 2020  hi', 'bob']..   
-00005c30: 2023 203e 3e3e 2073 7065 632e 7061 7273   # >>> spec.pars
-00005c40: 6528 6227 6865 6c6c 6f27 290d 0a20 2020  e(b'hello')..   
-00005c50: 2023 205b 2768 656c 6c6f 275d 0d0a 2020   # ['hello']..  
-00005c60: 2020 2222 220d 0a0d 0a20 2020 205f 5f73    """....    __s
-00005c70: 6c6f 7473 5f5f 203d 205b 2764 656c 696d  lots__ = ['delim
-00005c80: 6974 6572 272c 2027 7375 6263 6f6e 7327  iter', 'subcons'
-00005c90: 5d0d 0a0d 0a20 2020 2064 6566 205f 5f69  ]....    def __i
-00005ca0: 6e69 745f 5f28 7365 6c66 2c20 6465 6c69  nit__(self, deli
-00005cb0: 6d69 7465 722c 202a 7375 6263 6f6e 7329  miter, *subcons)
-00005cc0: 3a0d 0a20 2020 2020 2020 2022 2222 0d0a  :..        """..
-00005cd0: 2020 2020 2020 2020 3a70 6172 616d 2064          :param d
-00005ce0: 656c 696d 6974 6572 3a20 7369 6e67 6c65  elimiter: single
-00005cf0: 2063 6861 7261 6374 6f72 206f 7220 6120   charactor or a 
-00005d00: 6675 6e63 7469 6f6e 2074 6861 7420 7461  function that ta
-00005d10: 6b65 7320 636f 6e74 6578 7420 616e 6420  kes context and 
-00005d20: 7265 7475 726e 7320 7468 6520 6465 6c69  returns the deli
-00005d30: 6d69 7465 720d 0a20 2020 2020 2020 203a  miter..        :
-00005d40: 7061 7261 6d20 7375 6263 6f6e 733a 2063  param subcons: c
-00005d50: 6f6e 7374 7275 6374 7320 746f 2075 7365  onstructs to use
-00005d60: 2074 6f20 7061 7273 6520 6561 6368 2065   to parse each e
-00005d70: 6c65 6d65 6e74 2e0d 0a20 2020 2020 2020  lement...       
-00005d80: 2020 2020 2020 2020 2020 2020 204e 4f54               NOT
-00005d90: 453a 2054 6865 206e 756d 6265 7220 6f66  E: The number of
-00005da0: 2063 6f6e 7374 7275 6374 7320 7769 6c6c   constructs will
-00005db0: 2062 6520 7468 6520 6e75 6d62 6572 206f   be the number o
-00005dc0: 6620 656c 656d 656e 7473 2064 656c 696d  f elements delim
-00005dd0: 6974 6564 2e0d 0a20 2020 2020 2020 2020  ited...         
-00005de0: 2020 2020 2020 2020 2020 2028 6965 2e20             (ie. 
-00005df0: 6c65 6e28 7375 6263 6f6e 7329 203d 3d20  len(subcons) == 
-00005e00: 6e75 6d62 6572 206f 6620 6465 6c69 6d69  number of delimi
-00005e10: 7465 7273 202b 2031 290d 0a0d 0a20 2020  ters + 1)....   
-00005e20: 2020 2020 203a 7261 6973 6573 2056 616c       :raises Val
-00005e30: 7565 4572 726f 723a 2049 6620 6e6f 2073  ueError: If no s
-00005e40: 7562 636f 6e73 2061 7265 2064 6566 696e  ubcons are defin
-00005e50: 6564 2e0d 0a20 2020 2020 2020 2022 2222  ed...        """
-00005e60: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
-00005e70: 4465 6c69 6d69 7465 642c 2073 656c 6629  Delimited, self)
-00005e80: 2e5f 5f69 6e69 745f 5f28 290d 0a20 2020  .__init__()..   
-00005e90: 2020 2020 2073 656c 662e 6465 6c69 6d69       self.delimi
-00005ea0: 7465 7220 3d20 6465 6c69 6d69 7465 720d  ter = delimiter.
-00005eb0: 0a20 2020 2020 2020 2073 656c 662e 7375  .        self.su
-00005ec0: 6263 6f6e 7320 3d20 7375 6263 6f6e 730d  bcons = subcons.
-00005ed0: 0a20 2020 2020 2020 2069 6620 6c65 6e28  .        if len(
-00005ee0: 7375 6263 6f6e 7329 203c 2032 3a0d 0a20  subcons) < 2:.. 
-00005ef0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00005f00: 2056 616c 7565 4572 726f 7228 2741 7420   ValueError('At 
-00005f10: 6c65 6173 7420 7477 6f20 7375 6263 6f6e  least two subcon
-00005f20: 7374 7275 6374 206d 7573 7420 6265 2064  struct must be d
-00005f30: 6566 696e 6564 2e27 290d 0a0d 0a20 2020  efined.')....   
-00005f40: 2064 6566 205f 6669 6e64 5f64 656c 696d   def _find_delim
-00005f50: 6974 6572 2873 656c 662c 2073 7472 6561  iter(self, strea
-00005f60: 6d2c 2064 656c 696d 6974 6572 293a 0d0a  m, delimiter):..
-00005f70: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00005f80: 2020 2020 2046 696e 6473 2067 6976 656e       Finds given
-00005f90: 2064 656c 696d 6974 6572 2069 6e20 7374   delimiter in st
-00005fa0: 7265 616d 2e0d 0a0d 0a20 2020 2020 2020  ream.....       
-00005fb0: 203a 7265 7475 726e 733a 2053 7472 6561   :returns: Strea
-00005fc0: 6d20 6f66 6673 6574 2066 6f72 2064 656c  m offset for del
-00005fd0: 696d 6974 6572 2e0d 0a20 2020 2020 2020  imiter...       
-00005fe0: 203a 7261 6973 6573 2043 6f6e 7374 7275   :raises Constru
-00005ff0: 6374 4572 726f 723a 2049 6620 6465 6c69  ctError: If deli
-00006000: 6d69 7465 7220 6973 6e27 7420 666f 756e  miter isn't foun
-00006010: 642e 0d0a 2020 2020 2020 2020 2222 220d  d...        """.
-00006020: 0a20 2020 2020 2020 2066 616c 6c62 6163  .        fallbac
-00006030: 6b20 3d20 7374 7265 616d 2e74 656c 6c28  k = stream.tell(
-00006040: 290d 0a20 2020 2020 2020 2074 7279 3a0d  )..        try:.
-00006050: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
-00006060: 2062 7974 6520 696e 2069 7465 7228 6c61   byte in iter(la
-00006070: 6d62 6461 3a20 7374 7265 616d 2e72 6561  mbda: stream.rea
-00006080: 6428 3129 2c20 6227 2729 3a0d 0a20 2020  d(1), b''):..   
-00006090: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-000060a0: 6465 6c69 6d69 7465 725b 305d 203d 3d20  delimiter[0] == 
-000060b0: 6f72 6428 6279 7465 293a 0d0a 2020 2020  ord(byte):..    
-000060c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000060d0: 6465 6c69 6d69 7465 725f 6f66 6673 6574  delimiter_offset
-000060e0: 203d 2073 7472 6561 6d2e 7365 656b 282d   = stream.seek(-
-000060f0: 312c 206f 732e 5345 454b 5f43 5552 290d  1, os.SEEK_CUR).
-00006100: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00006110: 2020 2020 2069 6620 7374 7265 616d 2e72       if stream.r
-00006120: 6561 6428 6c65 6e28 6465 6c69 6d69 7465  ead(len(delimite
-00006130: 7229 2920 3d3d 2064 656c 696d 6974 6572  r)) == delimiter
-00006140: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00006150: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00006160: 6e20 6465 6c69 6d69 7465 725f 6f66 6673  n delimiter_offs
-00006170: 6574 0d0a 2020 2020 2020 2020 2020 2020  et..            
-00006180: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
-00006190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000061a0: 2020 2020 2020 2073 7472 6561 6d2e 7365         stream.se
-000061b0: 656b 2864 656c 696d 6974 6572 5f6f 6666  ek(delimiter_off
-000061c0: 7365 7420 2b20 3129 0d0a 2020 2020 2020  set + 1)..      
-000061d0: 2020 2020 2020 7261 6973 6520 436f 6e73        raise Cons
-000061e0: 7472 7563 7445 7272 6f72 2827 556e 6162  tructError('Unab
-000061f0: 6c65 2074 6f20 6669 6e64 2064 656c 696d  le to find delim
-00006200: 6974 6572 3a20 7b7d 272e 666f 726d 6174  iter: {}'.format
-00006210: 2864 656c 696d 6974 6572 2929 0d0a 2020  (delimiter))..  
-00006220: 2020 2020 2020 6669 6e61 6c6c 793a 0d0a        finally:..
-00006230: 2020 2020 2020 2020 2020 2020 7374 7265              stre
-00006240: 616d 2e73 6565 6b28 6661 6c6c 6261 636b  am.seek(fallback
-00006250: 290d 0a0d 0a20 2020 2064 6566 205f 7061  )....    def _pa
-00006260: 7273 655f 7375 6263 6f6e 2873 656c 662c  rse_subcon(self,
-00006270: 2073 7562 636f 6e2c 2073 7472 6561 6d2c   subcon, stream,
-00006280: 206f 626a 2c20 636f 6e74 6578 742c 2070   obj, context, p
-00006290: 6174 6829 3a0d 0a20 2020 2020 2020 2022  ath):..        "
-000062a0: 2222 5061 7273 6573 2061 6e64 2066 696c  ""Parses and fil
-000062b0: 6c73 206f 626a 2061 6e64 2063 6f6e 7465  ls obj and conte
-000062c0: 7874 2e22 2222 0d0a 2020 2020 2020 2020  xt."""..        
-000062d0: 7375 626f 626a 203d 2073 7562 636f 6e2e  subobj = subcon.
-000062e0: 5f70 6172 7365 7265 706f 7274 2873 7472  _parsereport(str
-000062f0: 6561 6d2c 2063 6f6e 7465 7874 2c20 7061  eam, context, pa
-00006300: 7468 290d 0a20 2020 2020 2020 2069 6620  th)..        if 
-00006310: 7375 6263 6f6e 2e66 6c61 6765 6d62 6564  subcon.flagembed
-00006320: 6465 643a 0d0a 2020 2020 2020 2020 2020  ded:..          
-00006330: 2020 6966 2073 7562 6f62 6a20 6973 206e    if subobj is n
-00006340: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
-00006350: 2020 2020 2020 2020 2020 6f62 6a2e 7570            obj.up
-00006360: 6461 7465 2873 7562 6f62 6a2e 6974 656d  date(subobj.item
-00006370: 7328 2929 0d0a 2020 2020 2020 2020 2020  s())..          
-00006380: 2020 2020 2020 636f 6e74 6578 742e 7570        context.up
-00006390: 6461 7465 2873 7562 6f62 6a2e 6974 656d  date(subobj.item
-000063a0: 7328 2929 0d0a 2020 2020 2020 2020 656c  s())..        el
-000063b0: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
-000063c0: 2069 6620 7375 6263 6f6e 2e6e 616d 6520   if subcon.name 
-000063d0: 6973 206e 6f74 204e 6f6e 653a 0d0a 2020  is not None:..  
-000063e0: 2020 2020 2020 2020 2020 2020 2020 6f62                ob
-000063f0: 6a5b 7375 6263 6f6e 2e6e 616d 655d 203d  j[subcon.name] =
-00006400: 2073 7562 6f62 6a0d 0a20 2020 2020 2020   subobj..       
-00006410: 2020 2020 2020 2020 2063 6f6e 7465 7874           context
-00006420: 5b73 7562 636f 6e2e 6e61 6d65 5d20 3d20  [subcon.name] = 
-00006430: 7375 626f 626a 0d0a 0d0a 2020 2020 6465  subobj....    de
-00006440: 6620 5f70 6172 7365 2873 656c 662c 2073  f _parse(self, s
-00006450: 7472 6561 6d2c 2063 6f6e 7465 7874 2c20  tream, context, 
-00006460: 7061 7468 293a 0d0a 2020 2020 2020 2020  path):..        
-00006470: 6465 6c69 6d69 7465 7220 3d20 7365 6c66  delimiter = self
-00006480: 2e64 656c 696d 6974 6572 2863 6f6e 7465  .delimiter(conte
-00006490: 7874 2920 6966 2063 616c 6c61 626c 6528  xt) if callable(
-000064a0: 7365 6c66 2e64 656c 696d 6974 6572 2920  self.delimiter) 
-000064b0: 656c 7365 2073 656c 662e 6465 6c69 6d69  else self.delimi
-000064c0: 7465 720d 0a20 2020 2020 2020 2069 6620  ter..        if 
-000064d0: 6e6f 7420 6973 696e 7374 616e 6365 2864  not isinstance(d
-000064e0: 656c 696d 6974 6572 2c20 6279 7465 7374  elimiter, bytest
-000064f0: 7269 6e67 7479 7065 2920 6f72 206e 6f74  ringtype) or not
-00006500: 2064 656c 696d 6974 6572 3a0d 0a20 2020   delimiter:..   
-00006510: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-00006520: 616c 7565 4572 726f 7228 2749 6e76 616c  alueError('Inval
-00006530: 6964 2064 656c 696d 6974 6572 2e27 290d  id delimiter.').
-00006540: 0a0d 0a20 2020 2020 2020 206f 626a 203d  ...        obj =
-00006550: 2043 6f6e 7461 696e 6572 2829 0d0a 2020   Container()..  
-00006560: 2020 2020 2020 636f 6e74 6578 7420 3d20        context = 
-00006570: 436f 6e74 6169 6e65 7228 5f3d 636f 6e74  Container(_=cont
-00006580: 6578 7429 0d0a 0d0a 2020 2020 2020 2020  ext)....        
-00006590: 2320 5061 7273 6520 616c 6c20 6275 7420  # Parse all but 
-000065a0: 7468 6520 6c61 7374 2065 6c65 6d65 6e74  the last element
-000065b0: 2e0d 0a20 2020 2020 2020 2066 6f72 2073  ...        for s
-000065c0: 6320 696e 2073 656c 662e 7375 6263 6f6e  c in self.subcon
-000065d0: 735b 3a2d 315d 3a0d 0a20 2020 2020 2020  s[:-1]:..       
-000065e0: 2020 2020 2023 2044 6f6e 2774 2063 6f75       # Don't cou
-000065f0: 6e74 2070 726f 6265 7320 6173 2061 6e20  nt probes as an 
-00006600: 656c 656d 656e 742e 0d0a 2020 2020 2020  element...      
-00006610: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
-00006620: 6e63 6528 7363 2c20 5072 6f62 6529 3a0d  nce(sc, Probe):.
-00006630: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00006640: 2073 632e 5f70 6172 7365 7265 706f 7274   sc._parsereport
-00006650: 2873 7472 6561 6d2c 2063 6f6e 7465 7874  (stream, context
-00006660: 2c20 7061 7468 290d 0a20 2020 2020 2020  , path)..       
-00006670: 2020 2020 2020 2020 2063 6f6e 7469 6e75           continu
-00006680: 650d 0a0d 0a20 2020 2020 2020 2020 2020  e....           
-00006690: 2064 656c 696d 6974 6572 5f6f 6666 7365   delimiter_offse
-000066a0: 7420 3d20 7365 6c66 2e5f 6669 6e64 5f64  t = self._find_d
-000066b0: 656c 696d 6974 6572 2873 7472 6561 6d2c  elimiter(stream,
-000066c0: 2064 656c 696d 6974 6572 290d 0a0d 0a20   delimiter).... 
-000066d0: 2020 2020 2020 2020 2020 2023 2054 656d             # Tem
-000066e0: 706f 7261 696c 7920 6661 6b65 2074 6865  poraily fake the
-000066f0: 2072 6561 6428 2920 736f 2074 6861 7420   read() so that 
-00006700: 7765 2063 616e 2066 6f72 6365 2045 4f46  we can force EOF
-00006710: 2062 6566 6f72 6520 6465 6c69 6d69 7465   before delimite
-00006720: 722e 0d0a 2020 2020 2020 2020 2020 2020  r...            
-00006730: 6f72 6967 5f72 6561 6420 3d20 7374 7265  orig_read = stre
-00006740: 616d 2e72 6561 640d 0a20 2020 2020 2020  am.read..       
-00006750: 2020 2020 2064 6566 206e 6577 5f72 6561       def new_rea
-00006760: 6428 7369 7a65 3d4e 6f6e 6529 3a0d 0a20  d(size=None):.. 
-00006770: 2020 2020 2020 2020 2020 2020 2020 206d                 m
-00006780: 6178 5f73 697a 6520 3d20 6465 6c69 6d69  ax_size = delimi
-00006790: 7465 725f 6f66 6673 6574 202d 2073 7472  ter_offset - str
-000067a0: 6561 6d2e 7465 6c6c 2829 0d0a 2020 2020  eam.tell()..    
-000067b0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-000067c0: 697a 6520 6973 204e 6f6e 653a 0d0a 2020  ize is None:..  
-000067d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000067e0: 2020 7369 7a65 203d 206d 6178 5f73 697a    size = max_siz
-000067f0: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
-00006800: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
-00006810: 2020 2020 2020 2020 2020 2020 2020 7369                si
-00006820: 7a65 203d 206d 696e 286d 6178 5f73 697a  ze = min(max_siz
-00006830: 652c 2073 697a 6529 0d0a 2020 2020 2020  e, size)..      
-00006840: 2020 2020 2020 2020 2020 7265 7475 726e            return
-00006850: 206f 7269 675f 7265 6164 2873 697a 6529   orig_read(size)
-00006860: 0d0a 2020 2020 2020 2020 2020 2020 7472  ..            tr
-00006870: 793a 0d0a 2020 2020 2020 2020 2020 2020  y:..            
-00006880: 2020 2020 7374 7265 616d 2e72 6561 6420      stream.read 
-00006890: 3d20 6e65 775f 7265 6164 0d0a 2020 2020  = new_read..    
-000068a0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-000068b0: 2e5f 7061 7273 655f 7375 6263 6f6e 2873  ._parse_subcon(s
-000068c0: 632c 2073 7472 6561 6d2c 206f 626a 2c20  c, stream, obj, 
-000068d0: 636f 6e74 6578 742c 2070 6174 6829 0d0a  context, path)..
-000068e0: 2020 2020 2020 2020 2020 2020 6669 6e61              fina
-000068f0: 6c6c 793a 0d0a 2020 2020 2020 2020 2020  lly:..          
-00006900: 2020 2020 2020 7374 7265 616d 2e72 6561        stream.rea
-00006910: 6420 3d20 6f72 6967 5f72 6561 640d 0a0d  d = orig_read...
-00006920: 0a20 2020 2020 2020 2020 2020 2023 2041  .            # A
-00006930: 6c69 676e 2074 6f20 6166 7465 7220 6465  lign to after de
-00006940: 6c69 6d69 7465 720d 0a20 2020 2020 2020  limiter..       
-00006950: 2020 2020 2073 7472 6561 6d2e 7365 656b       stream.seek
-00006960: 2864 656c 696d 6974 6572 5f6f 6666 7365  (delimiter_offse
-00006970: 7420 2b20 6c65 6e28 6465 6c69 6d69 7465  t + len(delimite
-00006980: 7229 290d 0a0d 0a20 2020 2020 2020 2023  r))....        #
-00006990: 2050 6172 7365 2074 6865 206c 6173 7420   Parse the last 
-000069a0: 656c 656d 656e 742e 0d0a 2020 2020 2020  element...      
-000069b0: 2020 7365 6c66 2e5f 7061 7273 655f 7375    self._parse_su
-000069c0: 6263 6f6e 2873 656c 662e 7375 6263 6f6e  bcon(self.subcon
-000069d0: 735b 2d31 5d2c 2073 7472 6561 6d2c 206f  s[-1], stream, o
-000069e0: 626a 2c20 636f 6e74 6578 742c 2070 6174  bj, context, pat
-000069f0: 6829 0d0a 0d0a 2020 2020 2020 2020 7265  h)....        re
-00006a00: 7475 726e 206f 626a 0d0a 0d0a 2020 2020  turn obj....    
-00006a10: 6465 6620 5f62 7569 6c64 2873 656c 662c  def _build(self,
-00006a20: 206f 626a 2c20 7374 7265 616d 2c20 636f   obj, stream, co
-00006a30: 6e74 6578 742c 2070 6174 6829 3a0d 0a20  ntext, path):.. 
-00006a40: 2020 2020 2020 2064 656c 696d 6974 6572         delimiter
-00006a50: 203d 2073 656c 662e 6465 6c69 6d69 7465   = self.delimite
-00006a60: 7228 636f 6e74 6578 7429 2069 6620 6361  r(context) if ca
-00006a70: 6c6c 6162 6c65 2873 656c 662e 6465 6c69  llable(self.deli
-00006a80: 6d69 7465 7229 2065 6c73 6520 7365 6c66  miter) else self
-00006a90: 2e64 656c 696d 6974 6572 0d0a 2020 2020  .delimiter..    
-00006aa0: 2020 2020 6966 206e 6f74 2069 7369 6e73      if not isins
-00006ab0: 7461 6e63 6528 6465 6c69 6d69 7465 722c  tance(delimiter,
-00006ac0: 2062 7974 6573 7472 696e 6774 7970 6529   bytestringtype)
-00006ad0: 206f 7220 6e6f 7420 6465 6c69 6d69 7465   or not delimite
-00006ae0: 723a 0d0a 2020 2020 2020 2020 2020 2020  r:..            
-00006af0: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
-00006b00: 2827 496e 7661 6c69 6420 6465 6c69 6d69  ('Invalid delimi
-00006b10: 7465 722e 2729 0d0a 0d0a 2020 2020 2020  ter.')....      
-00006b20: 2020 636f 6e74 6578 7420 3d20 436f 6e74    context = Cont
-00006b30: 6169 6e65 7228 5f3d 636f 6e74 6578 7429  ainer(_=context)
-00006b40: 0d0a 2020 2020 2020 2020 636f 6e74 6578  ..        contex
-00006b50: 742e 7570 6461 7465 286f 626a 290d 0a20  t.update(obj).. 
-00006b60: 2020 2020 2020 2066 6f72 2069 2c20 7363         for i, sc
-00006b70: 2069 6e20 656e 756d 6572 6174 6528 7365   in enumerate(se
-00006b80: 6c66 2e73 7562 636f 6e73 293a 0d0a 2020  lf.subcons):..  
-00006b90: 2020 2020 2020 2020 2020 6966 2073 632e            if sc.
-00006ba0: 666c 6167 656d 6265 6464 6564 3a0d 0a20  flagembedded:.. 
-00006bb0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00006bc0: 7562 6f62 6a20 3d20 6f62 6a0d 0a20 2020  ubobj = obj..   
-00006bd0: 2020 2020 2020 2020 2065 6c69 6620 7363           elif sc
-00006be0: 2e66 6c61 6762 7569 6c64 6e6f 6e65 3a0d  .flagbuildnone:.
-00006bf0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00006c00: 2073 7562 6f62 6a20 3d20 6f62 6a2e 6765   subobj = obj.ge
-00006c10: 7428 7363 2e6e 616d 652c 204e 6f6e 6529  t(sc.name, None)
-00006c20: 0d0a 2020 2020 2020 2020 2020 2020 656c  ..            el
-00006c30: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
-00006c40: 2020 2020 2073 7562 6f62 6a20 3d20 6f62       subobj = ob
-00006c50: 6a5b 7363 2e6e 616d 655d 0d0a 2020 2020  j[sc.name]..    
-00006c60: 2020 2020 2020 2020 6275 696c 6472 6574          buildret
-00006c70: 203d 2073 632e 5f62 7569 6c64 2873 7562   = sc._build(sub
-00006c80: 6f62 6a2c 2073 7472 6561 6d2c 2063 6f6e  obj, stream, con
-00006c90: 7465 7874 2c20 7061 7468 290d 0a20 2020  text, path)..   
-00006ca0: 2020 2020 2020 2020 2069 6620 6275 696c           if buil
-00006cb0: 6472 6574 2069 7320 6e6f 7420 4e6f 6e65  dret is not None
-00006cc0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00006cd0: 2020 2069 6620 7363 2e66 6c61 6765 6d62     if sc.flagemb
-00006ce0: 6564 6465 643a 0d0a 2020 2020 2020 2020  edded:..        
-00006cf0: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-00006d00: 6578 742e 7570 6461 7465 2862 7569 6c64  ext.update(build
-00006d10: 7265 7429 0d0a 2020 2020 2020 2020 2020  ret)..          
-00006d20: 2020 2020 2020 6966 2073 632e 6e61 6d65        if sc.name
-00006d30: 2069 7320 6e6f 7420 4e6f 6e65 3a0d 0a20   is not None:.. 
-00006d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006d50: 2020 2063 6f6e 7465 7874 5b73 632e 6e61     context[sc.na
-00006d60: 6d65 5d20 3d20 6275 696c 6472 6574 0d0a  me] = buildret..
-00006d70: 2020 2020 2020 2020 2020 2020 2320 4164              # Ad
-00006d80: 6420 6465 6c69 6d69 7465 7220 6966 206e  d delimiter if n
-00006d90: 6f74 206c 6173 7420 656c 656d 656e 7420  ot last element 
-00006da0: 616e 6420 6e6f 7420 5072 6f62 652e 0d0a  and not Probe...
-00006db0: 2020 2020 2020 2020 2020 2020 6966 2069              if i
-00006dc0: 203c 206c 656e 2873 656c 662e 7375 6263   < len(self.subc
-00006dd0: 6f6e 7329 202d 2031 2061 6e64 206e 6f74  ons) - 1 and not
-00006de0: 2069 7369 6e73 7461 6e63 6528 7363 2c20   isinstance(sc, 
-00006df0: 5072 6f62 6529 3a0d 0a20 2020 2020 2020  Probe):..       
-00006e00: 2020 2020 2020 2020 2073 7472 6561 6d2e           stream.
-00006e10: 7772 6974 6528 6465 6c69 6d69 7465 7229  write(delimiter)
-00006e20: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00006e30: 2063 6f6e 7465 7874 0d0a 0d0a 0d0a 636c   context......cl
-00006e40: 6173 7320 5265 6765 7828 436f 6e73 7472  ass Regex(Constr
-00006e50: 7563 7429 3a0d 0a20 2020 2072 2222 220d  uct):..    r""".
-00006e60: 0a20 2020 2041 2063 6f6e 7374 7275 6374  .    A construct
-00006e70: 2064 6573 6967 6e65 6420 6c6f 6f6b 2066   designed look f
-00006e80: 6f72 2074 6865 2066 6972 7374 206d 6174  or the first mat
-00006e90: 6368 2066 6f72 2074 6865 2067 6976 656e  ch for the given
-00006ea0: 2072 6567 6578 2c20 7468 656e 2070 6172   regex, then par
-00006eb0: 7365 2074 6865 2064 6174 6120 636f 6c6c  se the data coll
-00006ec0: 6563 7465 6420 696e 2074 6865 2067 726f  ected in the gro
-00006ed0: 7570 732e 0d0a 2020 2020 5265 7475 726e  ups...    Return
-00006ee0: 7320 7468 6520 6d61 7463 6865 6420 6361  s the matched ca
-00006ef0: 7074 7572 6520 6772 6f75 7073 2069 6e20  pture groups in 
-00006f00: 6174 7472 6962 7574 6573 2062 6173 6564  attributes based
-00006f10: 206f 6e20 7468 6569 7220 7265 7370 6563   on their respec
-00006f20: 7469 7665 206e 616d 6573 2e0d 0a20 2020  tive names...   
-00006f30: 2049 6620 6120 7375 6263 6f6e 7374 7275   If a subconstru
-00006f40: 6374 2069 7320 6465 6669 6e65 6420 666f  ct is defined fo
-00006f50: 7220 6120 6772 6f75 702c 2069 7420 7769  r a group, it wi
-00006f60: 6c6c 2072 756e 2074 6861 7420 636f 6e73  ll run that cons
-00006f70: 7472 7563 7420 6f6e 2074 6861 7420 7061  truct on that pa
-00006f80: 7274 6963 756c 6172 2070 6965 6365 206f  rticular piece o
-00006f90: 6620 6461 7461 2e0d 0a0d 0a20 2020 204e  f data.....    N
-00006fa0: 4f54 453a 2054 6865 2073 7562 636f 6e73  OTE: The subcons
-00006fb0: 7472 7563 7420 7769 6c6c 2072 756e 206f  truct will run o
-00006fc0: 6e20 7468 6520 6461 7461 2061 7320 6966  n the data as if
-00006fd0: 2069 7320 7468 6520 6f6e 6c79 2064 6174   is the only dat
-00006fe0: 6120 7468 6174 2065 7869 7374 732e 2054  a that exists. T
-00006ff0: 6865 7265 666f 7265 2c20 7573 696e 6720  herefore, using 
-00007000: 5365 656b 2061 6e64 2054 656c 6c0d 0a20  Seek and Tell.. 
-00007010: 2020 2077 696c 6c20 6265 2070 7572 656c     will be purel
-00007020: 7920 7265 6c61 7469 7665 2074 6f20 7468  y relative to th
-00007030: 6174 2070 6965 6365 206f 6620 6461 7461  at piece of data
-00007040: 206f 6e6c 792e 2054 6869 7320 7761 7320   only. This was 
-00007050: 646f 6e65 2074 6f20 656e 7375 7265 2079  done to ensure y
-00007060: 6f75 2061 7265 206f 6e6c 7920 7061 7273  ou are only pars
-00007070: 696e 6720 7768 6174 2068 6173 2062 6565  ing what has bee
-00007080: 6e0d 0a20 2020 2063 6170 7475 7265 642e  n..    captured.
-00007090: 2028 4966 2079 6f75 206e 6565 6420 746f   (If you need to
-000070a0: 2075 7365 2053 6565 6b20 6f72 2054 656c   use Seek or Tel
-000070b0: 6c2c 2079 6f75 2077 696c 6c20 6861 7665  l, you will have
-000070c0: 2074 6f20 696e 7374 6561 6420 6d61 6b65   to instead make
-000070d0: 2061 2063 6170 7475 7265 2067 726f 7570   a capture group
-000070e0: 2074 6861 7420 636f 6c6c 6563 7473 206e   that collects n
-000070f0: 6f20 6461 7461 2e29 0d0a 0d0a 0d0a 2020  o data.)......  
-00007100: 2020 4e4f 5445 3a20 4966 2079 6f75 2073    NOTE: If you s
-00007110: 7570 706c 7920 6120 7374 7269 6e67 2061  upply a string a
-00007120: 7320 7468 6520 7265 6775 6c61 7220 6578  s the regular ex
-00007130: 7072 6573 7369 6f6e 2c20 7468 6520 7265  pression, the re
-00007140: 2e44 4f54 414c 4c20 666c 6167 2077 696c  .DOTALL flag wil
-00007150: 6c20 6265 2061 7574 6f6d 6174 6963 616c  l be automatical
-00007160: 6c79 2073 7065 6369 6669 6564 2e0d 0a20  ly specified... 
-00007170: 2020 2049 6620 796f 7520 6e65 6564 2074     If you need t
-00007180: 6f20 7573 6520 6469 6666 6572 656e 7420  o use different 
-00007190: 666c 6167 732c 2079 6f75 206d 7573 7420  flags, you must 
-000071a0: 7061 7374 2061 2063 6f6d 7069 6c65 6420  past a compiled 
-000071b0: 7265 6765 782e 0d0a 0d0a 2020 2020 5468  regex.....    Th
-000071c0: 6520 7365 656b 2070 6f73 6974 696f 6e20  e seek position 
-000071d0: 6973 206c 6566 7420 6174 2074 6865 2065  is left at the e
-000071e0: 6e64 206f 6620 7468 6520 7375 6363 6573  nd of the succes
-000071f0: 7366 756c 206d 6174 6368 2028 6d61 7463  sful match (matc
-00007200: 682e 656e 6428 2929 2e0d 0a0d 0a20 2020  h.end()).....   
-00007210: 203e 3e3e 2072 6567 6578 203d 2072 652e   >>> regex = re.
-00007220: 636f 6d70 696c 6528 275c 7830 315c 7830  compile('\x01\x0
-00007230: 3228 3f50 3c73 697a 653e 2e7b 347d 295c  2(?P<size>.{4})\
-00007240: 7830 335c 7830 3428 3f50 3c70 6174 683e  x03\x04(?P<path>
-00007250: 5b41 2d5a 612d 7a5d 2e2a 5c78 3030 2927  [A-Za-z].*\x00)'
-00007260: 2c20 7265 2e44 4f54 414c 4c29 0d0a 2020  , re.DOTALL)..  
-00007270: 2020 3e3e 3e20 6461 7461 203d 2027 4741    >>> data = 'GA
-00007280: 5242 4147 4521 5c78 3031 5c78 3032 5c78  RBAGE!\x01\x02\x
-00007290: 3041 5c78 3030 5c78 3030 5c78 3030 5c78  0A\x00\x00\x00\x
-000072a0: 3033 5c78 3034 433a 5c57 696e 646f 7773  03\x04C:\Windows
-000072b0: 5c78 3030 4d4f 5245 2047 4152 4241 4745  \x00MORE GARBAGE
-000072c0: 2127 0d0a 2020 2020 3e3e 3e20 7220 3d20  !'..    >>> r = 
-000072d0: 5265 6765 7828 7265 6765 782c 2073 697a  Regex(regex, siz
-000072e0: 653d 496e 7433 3275 6c2c 2070 6174 683d  e=Int32ul, path=
-000072f0: 4353 7472 696e 6728 2929 2e70 6172 7365  CString()).parse
-00007300: 2864 6174 6129 0d0a 2020 2020 3e3e 3e20  (data)..    >>> 
-00007310: 7220 3d3d 2043 6f6e 7461 696e 6572 2870  r == Container(p
-00007320: 6174 683d 7527 433a 5c5c 5769 6e64 6f77  ath=u'C:\\Window
-00007330: 7327 2c20 7369 7a65 3d31 3029 0d0a 2020  s', size=10)..  
-00007340: 2020 5472 7565 0d0a 2020 2020 3e3e 3e20    True..    >>> 
-00007350: 7220 3d20 5265 6765 7828 7265 6765 7829  r = Regex(regex)
-00007360: 2e70 6172 7365 2864 6174 6129 0d0a 2020  .parse(data)..  
-00007370: 2020 3e3e 3e20 7220 3d3d 2043 6f6e 7461    >>> r == Conta
-00007380: 696e 6572 2870 6174 683d 6227 433a 5c5c  iner(path=b'C:\\
-00007390: 5769 6e64 6f77 735c 7830 3027 2c20 7369  Windows\x00', si
-000073a0: 7a65 3d62 275c 6e5c 7830 305c 7830 305c  ze=b'\n\x00\x00\
-000073b0: 7830 3027 290d 0a20 2020 2054 7275 650d  x00')..    True.
-000073c0: 0a20 2020 203e 3e3e 2072 203d 2053 7472  .    >>> r = Str
-000073d0: 7563 7428 0d0a 2020 2020 2e2e 2e20 2020  uct(..    ...   
-000073e0: 2020 2772 6527 202f 2052 6567 6578 2872    're' / Regex(r
-000073f0: 6567 6578 2c20 7369 7a65 3d49 6e74 3332  egex, size=Int32
-00007400: 756c 2c20 7061 7468 3d43 5374 7269 6e67  ul, path=CString
-00007410: 2829 292c 0d0a 2020 2020 2e2e 2e20 2020  ()),..    ...   
-00007420: 2020 2761 6674 6572 5f72 6527 202f 2054    'after_re' / T
-00007430: 656c 6c2c 0d0a 2020 2020 2e2e 2e20 2020  ell,..    ...   
-00007440: 2020 2767 6172 6261 6765 2720 2f20 4772    'garbage' / Gr
-00007450: 6565 6479 4279 7465 730d 0a20 2020 202e  eedyBytes..    .
-00007460: 2e2e 2029 2e70 6172 7365 2864 6174 6129  .. ).parse(data)
-00007470: 0d0a 2020 2020 3e3e 3e20 7220 3d3d 2043  ..    >>> r == C
-00007480: 6f6e 7461 696e 6572 2872 653d 436f 6e74  ontainer(re=Cont
-00007490: 6169 6e65 7228 7061 7468 3d75 2743 3a5c  ainer(path=u'C:\
-000074a0: 5c57 696e 646f 7773 272c 2073 697a 653d  \Windows', size=
-000074b0: 3130 292c 2061 6674 6572 5f72 653d 3237  10), after_re=27
-000074c0: 4c2c 2067 6172 6261 6765 3d62 274d 4f52  L, garbage=b'MOR
-000074d0: 4520 4741 5242 4147 4521 2729 0d0a 2020  E GARBAGE!')..  
-000074e0: 2020 5472 7565 0d0a 0d0a 2020 2020 2320    True....    # 
-000074f0: 544f 444f 3a20 556e 666f 7274 756e 6174  TODO: Unfortunat
-00007500: 656c 7920 456d 6265 6464 6564 2829 206e  ely Embedded() n
-00007510: 6f20 6c6f 6e67 6572 2077 6f72 6b73 2077  o longer works w
-00007520: 6974 6820 7468 6520 7570 6461 7465 2074  ith the update t
-00007530: 6f20 322e 390d 0a20 2020 2023 203e 3e3e  o 2.9..    # >>>
-00007540: 2053 7472 7563 7428 0d0a 2020 2020 2320   Struct(..    # 
-00007550: 2e2e 2e20 2020 2020 456d 6265 6464 6564  ...     Embedded
-00007560: 2852 6567 6578 2872 6567 6578 2c20 7369  (Regex(regex, si
-00007570: 7a65 3d49 6e74 3332 756c 2c20 7061 7468  ze=Int32ul, path
-00007580: 3d43 5374 7269 6e67 2829 2929 2c0d 0a20  =CString())),.. 
-00007590: 2020 2023 202e 2e2e 2020 2020 2027 6166     # ...     'af
-000075a0: 7465 725f 7265 2720 2f20 5465 6c6c 2c0d  ter_re' / Tell,.
-000075b0: 0a20 2020 2023 202e 2e2e 2020 2020 2027  .    # ...     '
-000075c0: 6761 7262 6167 6527 202f 2047 7265 6564  garbage' / Greed
-000075d0: 7942 7974 6573 0d0a 2020 2020 2320 2e2e  yBytes..    # ..
-000075e0: 2e20 292e 7061 7273 6528 6461 7461 290d  . ).parse(data).
-000075f0: 0a20 2020 2023 2043 6f6e 7461 696e 6572  .    # Container
-00007600: 2870 6174 683d 7527 433a 5c5c 5769 6e64  (path=u'C:\\Wind
-00007610: 6f77 7327 2c20 7369 7a65 3d31 302c 2061  ows', size=10, a
-00007620: 6674 6572 5f72 653d 3237 4c2c 2067 6172  fter_re=27L, gar
-00007630: 6261 6765 3d62 274d 4f52 4520 4741 5242  bage=b'MORE GARB
-00007640: 4147 4521 2729 0d0a 0d0a 2020 2020 596f  AGE!')....    Yo
-00007650: 7520 6361 6e20 7573 6520 5265 6765 7820  u can use Regex 
-00007660: 6173 2061 2074 7269 6767 6572 2074 6f20  as a trigger to 
-00007670: 6669 6e64 2061 2070 6172 7469 6375 6c61  find a particula
-00007680: 7220 7069 6563 6520 6f66 2064 6174 6120  r piece of data 
-00007690: 6265 666f 7265 2079 6f75 2073 7461 7274  before you start
-000076a0: 2070 6172 7369 6e67 2e0d 0a20 2020 203e   parsing...    >
-000076b0: 3e3e 2053 7472 7563 7428 0d0a 2020 2020  >> Struct(..    
-000076c0: 2e2e 2e20 2020 2020 5265 6765 7828 2754  ...     Regex('T
-000076d0: 5249 4747 4552 2729 2c0d 0a20 2020 202e  RIGGER'),..    .
-000076e0: 2e2e 2020 2020 2027 6772 6565 7469 6e67  ..     'greeting
-000076f0: 2720 2f20 4353 7472 696e 6728 290d 0a20  ' / CString().. 
-00007700: 2020 202e 2e2e 2029 2e70 6172 7365 2827     ... ).parse('
-00007710: 5c78 3031 5c78 3032 5c78 3034 4741 5242  \x01\x02\x04GARB
-00007720: 4147 455c 7830 3554 5249 4747 4552 6865  AGE\x05TRIGGERhe
-00007730: 6c6c 6f20 776f 726c 645c 7830 3027 290d  llo world\x00').
-00007740: 0a20 2020 2043 6f6e 7461 696e 6572 2867  .    Container(g
-00007750: 7265 6574 696e 673d 7527 6865 6c6c 6f20  reeting=u'hello 
-00007760: 776f 726c 6427 290d 0a0d 0a20 2020 2049  world')....    I
-00007770: 6620 6e6f 2064 6174 6120 6973 2063 6170  f no data is cap
-00007780: 7475 7265 642c 2074 6865 2061 7373 6f63  tured, the assoc
-00007790: 6961 7465 6420 7375 6263 6f6e 2077 696c  iated subcon wil
-000077a0: 6c20 7265 6365 6976 6564 2061 2073 7472  l received a str
-000077b0: 6561 6d20 7769 7468 2074 6865 2070 6f73  eam with the pos
-000077c0: 6974 696f 6e20 7365 7420 6174 2074 6865  ition set at the
-000077d0: 206c 6f63 6174 696f 6e0d 0a20 2020 206f   location..    o
-000077e0: 6620 7468 6174 2063 6170 7475 7265 6420  f that captured 
-000077f0: 6772 6f75 702e 2054 6875 732c 2061 6c6c  group. Thus, all
-00007800: 6f77 696e 6720 796f 7520 746f 2075 7365  owing you to use
-00007810: 2069 7420 6173 2061 6e20 616e 6368 6f72   it as an anchor
-00007820: 2070 6f69 6e74 2e0d 0a20 2020 203e 3e3e   point...    >>>
-00007830: 2072 203d 2052 6567 6578 2827 6865 6c6c   r = Regex('hell
-00007840: 6f20 283f 503c 616e 6368 6f72 3e29 776f  o (?P<anchor>)wo
-00007850: 726c 6428 3f50 3c65 7874 7261 5f64 6174  rld(?P<extra_dat
-00007860: 613e 2e2a 2927 2c20 616e 6368 6f72 3d54  a>.*)', anchor=T
-00007870: 656c 6c29 2e70 6172 7365 2827 6865 6c6c  ell).parse('hell
-00007880: 6f20 776f 726c 6421 2121 2127 290d 0a20  o world!!!!').. 
-00007890: 2020 203e 3e3e 2072 203d 3d20 436f 6e74     >>> r == Cont
-000078a0: 6169 6e65 7228 6578 7472 615f 6461 7461  ainer(extra_data
-000078b0: 3d62 2721 2121 2127 2c20 616e 6368 6f72  =b'!!!!', anchor
-000078c0: 3d36 4c29 0d0a 2020 2020 5472 7565 0d0a  =6L)..    True..
-000078d0: 0d0a 2020 2020 4966 206e 6f20 6e61 6d65  ..    If no name
-000078e0: 6420 6361 7074 7572 6520 6772 6f75 7073  d capture groups
-000078f0: 2061 7265 2075 7365 642c 2079 6f75 2063   are used, you c
-00007900: 616e 2069 6e73 7465 6164 2070 6172 7365  an instead parse
-00007910: 2074 6865 2065 6e74 6972 6520 6d61 7463   the entire matc
-00007920: 6865 6420 7374 7269 6e67 2062 7920 7375  hed string by su
-00007930: 7070 6c79 696e 670d 0a20 2020 2061 2073  pplying..    a s
-00007940: 7562 636f 6e73 7472 7563 7420 6173 2061  ubconstruct as a
-00007950: 2070 6f73 6974 696f 6e61 6c20 6172 6775   positional argu
-00007960: 6d65 6e74 2e20 2849 6620 6e6f 2073 7562  ment. (If no sub
-00007970: 636f 6e20 6973 2070 726f 7669 6465 642c  con is provided,
-00007980: 2074 6865 2072 6177 2062 7974 6573 2061   the raw bytes a
-00007990: 7265 2072 6574 7572 6e65 6420 696e 7374  re returned inst
-000079a0: 6561 642e 0d0a 2020 2020 3e3e 3e20 5265  ead...    >>> Re
-000079b0: 6765 7828 2768 656c 6c6f 2077 6f72 6c64  gex('hello world
-000079c0: 5c78 3030 272c 2043 5374 7269 6e67 2829  \x00', CString()
-000079d0: 292e 7061 7273 6528 2747 4152 4241 4745  ).parse('GARBAGE
-000079e0: 5c78 3031 5c78 3033 6865 6c6c 6f20 776f  \x01\x03hello wo
-000079f0: 726c 645c 7830 305c 7830 3427 290d 0a20  rld\x00\x04').. 
-00007a00: 2020 2075 2768 656c 6c6f 2077 6f72 6c64     u'hello world
-00007a10: 270d 0a20 2020 203e 3e3e 2052 6567 6578  '..    >>> Regex
-00007a20: 2827 6865 6c6c 6f20 776f 726c 645c 7830  ('hello world\x0
-00007a30: 3027 292e 7061 7273 6528 2747 4152 4241  0').parse('GARBA
-00007a40: 4745 5c78 3031 5c78 3033 6865 6c6c 6f20  GE\x01\x03hello 
-00007a50: 776f 726c 645c 7830 305c 7830 3427 290d  world\x00\x04').
-00007a60: 0a20 2020 2027 6865 6c6c 6f20 776f 726c  .    'hello worl
-00007a70: 645c 7830 3027 0d0a 0d0a 2020 2020 596f  d\x00'....    Yo
-00007a80: 7520 6361 6e20 616c 736f 2073 6574 2074  u can also set t
-00007a90: 6865 2072 6567 756c 6172 2065 7870 7265  he regular expre
-00007aa0: 7373 696f 6e20 746f 206d 6174 6368 2069  ssion to match i
-00007ab0: 6e2d 706c 6163 6520 2869 6e73 7465 6164  n-place (instead
-00007ac0: 206f 6620 7365 6172 6368 696e 6720 7468   of searching th
-00007ad0: 6520 6461 7461 290d 0a20 2020 2062 7920  e data)..    by 
-00007ae0: 7365 7474 696e 6720 7468 6520 6b65 7977  setting the keyw
-00007af0: 6f72 6420 6172 6775 6d65 6e74 205f 6d61  ord argument _ma
-00007b00: 7463 6820 746f 2054 7275 652e 0d0a 2020  tch to True...  
-00007b10: 2020 3e3e 3e20 5265 6765 7828 2768 656c    >>> Regex('hel
-00007b20: 6c6f 272c 205f 6d61 7463 683d 5472 7565  lo', _match=True
-00007b30: 292e 7061 7273 6528 6227 6865 6c6c 6f20  ).parse(b'hello 
-00007b40: 776f 726c 6421 2729 0d0a 2020 2020 2768  world!')..    'h
-00007b50: 656c 6c6f 270d 0a20 2020 203e 3e3e 2052  ello'..    >>> R
-00007b60: 6567 6578 2827 6865 6c6c 6f27 292e 7061  egex('hello').pa
-00007b70: 7273 6528 6227 626f 6775 7320 6865 6c6c  rse(b'bogus hell
-00007b80: 6f20 776f 726c 6427 290d 0a20 2020 2027  o world')..    '
-00007b90: 6865 6c6c 6f27 0d0a 2020 2020 3e3e 3e20  hello'..    >>> 
-00007ba0: 5265 6765 7828 2768 656c 6c6f 272c 205f  Regex('hello', _
-00007bb0: 6d61 7463 683d 5472 7565 292e 7061 7273  match=True).pars
-00007bc0: 6528 6227 626f 6775 7320 6865 6c6c 6f20  e(b'bogus hello 
-00007bd0: 776f 726c 6427 290d 0a20 2020 2054 7261  world')..    Tra
-00007be0: 6365 6261 636b 2028 6d6f 7374 2072 6563  ceback (most rec
-00007bf0: 656e 7420 6361 6c6c 206c 6173 7429 3a0d  ent call last):.
-00007c00: 0a20 2020 2020 2020 202e 2e2e 0d0a 2020  .        .....  
-00007c10: 2020 436f 6e73 7472 7563 7445 7272 6f72    ConstructError
-00007c20: 3a20 5b28 7061 7273 696e 6729 5d20 7265  : [(parsing)] re
-00007c30: 6765 7820 6469 6420 6e6f 7420 6d61 7463  gex did not matc
-00007c40: 680d 0a20 2020 2022 2222 0d0a 0d0a 2020  h..    """....  
-00007c50: 2020 5f5f 736c 6f74 735f 5f20 3d20 5b27    __slots__ = ['
-00007c60: 7265 6765 7827 2c20 2773 7562 636f 6e27  regex', 'subcon'
-00007c70: 2c20 2767 726f 7570 5f73 7562 636f 6e73  , 'group_subcons
-00007c80: 272c 2027 6d61 7463 6827 5d0d 0a0d 0a20  ', 'match'].... 
-00007c90: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00007ca0: 7365 6c66 2c20 7265 6765 782c 202a 7375  self, regex, *su
-00007cb0: 6263 6f6e 2c20 2a2a 6772 6f75 705f 7375  bcon, **group_su
-00007cc0: 6263 6f6e 7329 3a0d 0a20 2020 2020 2020  bcons):..       
-00007cd0: 2022 2222 0d0a 2020 2020 2020 2020 496e   """..        In
-00007ce0: 6974 6961 6c69 7a65 7320 7265 6765 7820  itializes regex 
-00007cf0: 636f 6e73 7472 7563 742e 0d0a 0d0a 2020  construct.....  
-00007d00: 2020 2020 2020 3a70 6172 616d 2072 6567        :param reg
-00007d10: 6578 3a20 4120 7265 6765 7820 746f 2075  ex: A regex to u
-00007d20: 7365 2028 6361 6e20 6265 2061 2073 7472  se (can be a str
-00007d30: 696e 6720 6f72 2063 6f6d 7069 6c65 6429  ing or compiled)
-00007d40: 2e0d 0a20 2020 2020 2020 203a 7061 7261  ...        :para
-00007d50: 6d20 7375 6263 6f6e 3a0d 0a20 2020 2020  m subcon:..     
-00007d60: 2020 2020 2020 2041 2073 7562 636f 6e20         A subcon 
-00007d70: 746f 2075 7365 206f 6e20 7468 6520 656e  to use on the en
-00007d80: 7469 7265 206d 6174 6368 696e 6720 7374  tire matching st
-00007d90: 7269 6e67 2077 6865 6e20 7468 6572 6520  ring when there 
-00007da0: 6172 6520 6e6f 206e 616d 6564 2063 6170  are no named cap
-00007db0: 7475 7265 2067 726f 7570 732e 0d0a 2020  ture groups...  
-00007dc0: 2020 2020 2020 2020 2020 284e 4f54 453a            (NOTE:
-00007dd0: 2054 6869 7320 6973 206f 6e6c 7920 7573   This is only us
-00007de0: 6564 2069 6620 7468 6572 6520 6172 6520  ed if there are 
-00007df0: 6e6f 2063 6170 7475 7265 2067 726f 7570  no capture group
-00007e00: 732e 0d0a 2020 2020 2020 2020 2020 2020  s...            
-00007e10: 4966 2079 6f75 2077 616e 7420 746f 2075  If you want to u
-00007e20: 7365 2063 6170 7475 7265 2067 726f 7570  se capture group
-00007e30: 7320 414e 4420 7468 6973 2074 6865 6e20  s AND this then 
-00007e40: 6861 7665 2061 2063 6170 7475 7265 2067  have a capture g
-00007e50: 726f 7570 2065 6e63 6170 7375 6c61 7469  roup encapsulati
-00007e60: 6e67 2074 6865 2065 6e74 6972 6520 7265  ng the entire re
-00007e70: 6765 782e 290d 0a20 2020 2020 2020 203a  gex.)..        :
-00007e80: 7061 7261 6d20 6772 6f75 705f 7375 6263  param group_subc
-00007e90: 6f6e 733a 0d0a 2020 2020 2020 2020 2020  ons:..          
-00007ea0: 2020 4b65 7977 6f72 6420 6172 6775 6d65    Keyword argume
-00007eb0: 6e74 2064 6963 7469 6f6e 6172 7920 7468  nt dictionary th
-00007ec0: 6174 2063 6f6e 7461 696e 7320 7468 6520  at contains the 
-00007ed0: 636f 6e73 7472 7563 7473 2074 6f20 7573  constructs to us
-00007ee0: 6520 666f 7220 7468 6520 636f 7272 6573  e for the corres
-00007ef0: 706f 6e64 696e 6720 6361 7074 7572 6520  ponding capture 
-00007f00: 6772 6f75 702e 0d0a 2020 2020 2020 2020  group...        
-00007f10: 2020 2020 4966 2061 2073 7562 636f 6e20      If a subcon 
-00007f20: 6973 206e 6f74 2073 7570 706c 6965 6420  is not supplied 
-00007f30: 666f 7220 6120 6361 7074 7572 6520 6772  for a capture gr
-00007f40: 6f75 702c 2069 7420 7769 6c6c 2064 6566  oup, it will def
-00007f50: 6175 6c74 2074 6f20 7265 7475 726e 696e  ault to returnin
-00007f60: 6720 6279 7465 730d 0a20 2020 2020 2020  g bytes..       
-00007f70: 2020 2020 2028 6571 7569 7661 6c65 6e74       (equivalent
-00007f80: 2074 6f20 7365 7474 696e 6720 636f 6e73   to setting cons
-00007f90: 7472 7563 742e 4279 7465 7328 2920 666f  truct.Bytes() fo
-00007fa0: 7220 7468 6174 2067 726f 7570 2e29 0d0a  r that group.)..
-00007fb0: 0d0a 2020 2020 2020 2020 3a72 6169 7365  ..        :raise
-00007fc0: 7320 5661 6c75 6545 7272 6f72 3a20 4966  s ValueError: If
-00007fd0: 2061 7267 756d 656e 7473 2061 7265 2069   arguments are i
-00007fe0: 6e76 616c 6964 2e0d 0a20 2020 2020 2020  nvalid...       
-00007ff0: 2022 2222 0d0a 2020 2020 2020 2020 7375   """..        su
-00008000: 7065 7228 5265 6765 782c 2073 656c 6629  per(Regex, self)
-00008010: 2e5f 5f69 6e69 745f 5f28 290d 0a20 2020  .__init__()..   
-00008020: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
-00008030: 6365 2872 6567 6578 2c20 7374 7229 3a0d  ce(regex, str):.
-00008040: 0a20 2020 2020 2020 2020 2020 2072 6567  .            reg
-00008050: 6578 203d 2072 6567 6578 2e65 6e63 6f64  ex = regex.encod
-00008060: 6528 2920 2023 2066 6f72 6365 2062 7974  e()  # force byt
-00008070: 6520 7374 7269 6e67 730d 0a20 2020 2020  e strings..     
-00008080: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
-00008090: 2872 6567 6578 2c20 6279 7465 7374 7269  (regex, bytestri
-000080a0: 6e67 7479 7065 293a 0d0a 2020 2020 2020  ngtype):..      
-000080b0: 2020 2020 2020 7265 6765 7820 3d20 7265        regex = re
-000080c0: 2e63 6f6d 7069 6c65 2872 6567 6578 2c20  .compile(regex, 
-000080d0: 7265 2e44 4f54 414c 4c29 0d0a 2020 2020  re.DOTALL)..    
-000080e0: 2020 2020 7365 6c66 2e72 6567 6578 203d      self.regex =
-000080f0: 2072 6567 6578 0d0a 2020 2020 2020 2020   regex..        
-00008100: 2320 544f 444f 3a20 5468 6973 2066 6561  # TODO: This fea
-00008110: 7475 7265 2073 6565 6d73 2062 6163 6b77  ture seems backw
-00008120: 6172 6473 2c20 7065 7268 6170 7320 6d61  ards, perhaps ma
-00008130: 6b65 2061 205f 7365 6172 6368 206b 6579  ke a _search key
-00008140: 776f 7264 2069 6e73 7465 6164 2061 6e64  word instead and
-00008150: 2064 6566 6175 6c74 2074 6f20 6d61 7463   default to matc
-00008160: 6820 6675 6e63 7469 6f6e 616c 6974 792e  h functionality.
-00008170: 0d0a 2020 2020 2020 2020 2320 416c 7465  ..        # Alte
-00008180: 726e 6174 6976 656c 792c 2077 6520 636f  rnatively, we co
-00008190: 756c 6420 6861 7665 2052 6567 6578 5365  uld have RegexSe
-000081a0: 6172 6368 2061 6e64 2052 6567 6578 4d61  arch and RegexMa
-000081b0: 7463 6820 636f 6e73 7472 7563 7473 2069  tch constructs i
-000081c0: 6e73 7465 6164 2e0d 0a20 2020 2020 2020  nstead...       
-000081d0: 2073 656c 662e 6d61 7463 6820 3d20 6772   self.match = gr
-000081e0: 6f75 705f 7375 6263 6f6e 732e 706f 7028  oup_subcons.pop(
-000081f0: 275f 6d61 7463 6827 2c20 4661 6c73 6529  '_match', False)
-00008200: 0d0a 2020 2020 2020 2020 7365 6c66 2e67  ..        self.g
-00008210: 726f 7570 5f73 7562 636f 6e73 203d 2067  roup_subcons = g
-00008220: 726f 7570 5f73 7562 636f 6e73 0d0a 2020  roup_subcons..  
-00008230: 2020 2020 2020 6966 2073 7562 636f 6e20        if subcon 
-00008240: 616e 6420 6c65 6e28 7375 6263 6f6e 2920  and len(subcon) 
-00008250: 3e20 313a 0d0a 2020 2020 2020 2020 2020  > 1:..          
-00008260: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-00008270: 6f72 2827 4f6e 6c79 206f 6e65 2073 7562  or('Only one sub
-00008280: 636f 6e20 6361 6e20 6265 2073 7570 706c  con can be suppl
-00008290: 6965 6420 666f 7220 7468 6520 656e 7469  ied for the enti
-000082a0: 7265 206d 6174 6368 2e27 290d 0a20 2020  re match.')..   
-000082b0: 2020 2020 2069 6620 7375 6263 6f6e 2061       if subcon a
-000082c0: 6e64 2067 726f 7570 5f73 7562 636f 6e73  nd group_subcons
-000082d0: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-000082e0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
-000082f0: 2773 7562 636f 6e20 616e 6420 6772 6f75  'subcon and grou
-00008300: 705f 7375 6263 6f6e 7320 6172 6775 6d65  p_subcons argume
-00008310: 6e74 7320 6361 6e6e 6f74 2062 6520 7573  nts cannot be us
-00008320: 6564 2061 7420 7468 6520 7361 6d65 2074  ed at the same t
-00008330: 696d 652e 2729 0d0a 2020 2020 2020 2020  ime.')..        
-00008340: 7365 6c66 2e73 7562 636f 6e20 3d20 7375  self.subcon = su
-00008350: 6263 6f6e 5b30 5d20 6966 2073 7562 636f  bcon[0] if subco
-00008360: 6e20 656c 7365 204e 6f6e 650d 0a0d 0a20  n else None.... 
-00008370: 2020 2064 6566 205f 7061 7273 6528 7365     def _parse(se
-00008380: 6c66 2c20 7374 7265 616d 2c20 636f 6e74  lf, stream, cont
-00008390: 6578 742c 2070 6174 6829 3a0d 0a20 2020  ext, path):..   
-000083a0: 2020 2020 2073 7461 7274 203d 2073 7472       start = str
-000083b0: 6561 6d2e 7465 6c6c 2829 0d0a 2020 2020  eam.tell()..    
-000083c0: 2020 2020 2320 4e4f 5445 3a20 7765 2061      # NOTE: we a
-000083d0: 7265 2067 6f69 6e67 2074 6f20 6861 7665  re going to have
-000083e0: 2074 6f20 7265 6164 2074 6865 2065 6e74   to read the ent
-000083f0: 6972 6520 7374 7265 616d 2064 7565 2074  ire stream due t
-00008400: 6f20 7265 6765 7820 7265 7175 6972 656d  o regex requirem
-00008410: 656e 7473 2e0d 0a20 2020 2020 2020 2023  ents...        #
-00008420: 2048 6f77 6576 6572 2c20 7468 6174 2773   However, that's
-00008430: 206f 6b61 7920 696e 2074 6869 7320 6361   okay in this ca
-00008440: 7365 2073 696e 6365 2077 6520 6172 6520  se since we are 
-00008450: 7061 7273 696e 6720 4279 7465 494f 2061  parsing ByteIO a
-00008460: 6e79 7761 792e 0d0a 2020 2020 2020 2020  nyway...        
-00008470: 6966 2073 656c 662e 6d61 7463 683a 0d0a  if self.match:..
-00008480: 2020 2020 2020 2020 2020 2020 6d61 7463              matc
-00008490: 6820 3d20 7365 6c66 2e72 6567 6578 2e6d  h = self.regex.m
-000084a0: 6174 6368 2873 7472 6561 6d2e 7265 6164  atch(stream.read
-000084b0: 2829 290d 0a20 2020 2020 2020 2065 6c73  ())..        els
-000084c0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-000084d0: 6d61 7463 6820 3d20 7365 6c66 2e72 6567  match = self.reg
-000084e0: 6578 2e73 6561 7263 6828 7374 7265 616d  ex.search(stream
-000084f0: 2e72 6561 6428 2929 0d0a 2020 2020 2020  .read())..      
-00008500: 2020 6966 206e 6f74 206d 6174 6368 3a0d    if not match:.
-00008510: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-00008520: 7365 2043 6f6e 7374 7275 6374 4572 726f  se ConstructErro
-00008530: 7228 275b 7b7d 5d20 7265 6765 7820 6469  r('[{}] regex di
-00008540: 6420 6e6f 7420 6d61 7463 6827 2e66 6f72  d not match'.for
-00008550: 6d61 7428 7061 7468 2929 0d0a 0d0a 2020  mat(path))....  
-00008560: 2020 2020 2020 7472 793a 0d0a 2020 2020        try:..    
-00008570: 2020 2020 2020 2020 6772 6f75 705f 6469          group_di
-00008580: 6374 203d 206d 6174 6368 2e67 726f 7570  ct = match.group
-00008590: 6469 6374 2829 0d0a 0d0a 2020 2020 2020  dict()....      
-000085a0: 2020 2020 2020 2320 4966 2074 6865 7265        # If there
-000085b0: 2061 7265 206e 6f20 6e61 6d65 6420 6772   are no named gr
-000085c0: 6f75 7073 2e20 5265 7475 726e 2070 6172  oups. Return par
-000085d0: 7365 6420 6675 6c6c 206d 6174 6368 2069  sed full match i
-000085e0: 6e73 7465 6164 2e0d 0a20 2020 2020 2020  nstead...       
-000085f0: 2020 2020 2069 6620 6e6f 7420 6772 6f75       if not grou
-00008600: 705f 6469 6374 3a0d 0a20 2020 2020 2020  p_dict:..       
-00008610: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-00008620: 2e73 7562 636f 6e3a 0d0a 2020 2020 2020  .subcon:..      
-00008630: 2020 2020 2020 2020 2020 2020 2020 7375                su
-00008640: 625f 7374 7265 616d 203d 2069 6f2e 4279  b_stream = io.By
-00008650: 7465 7349 4f28 6d61 7463 682e 6772 6f75  tesIO(match.grou
-00008660: 7028 2929 0d0a 2020 2020 2020 2020 2020  p())..          
-00008670: 2020 2020 2020 2020 2020 7265 7475 726e            return
-00008680: 2073 656c 662e 7375 6263 6f6e 2e5f 7061   self.subcon._pa
-00008690: 7273 6572 6570 6f72 7428 7375 625f 7374  rsereport(sub_st
-000086a0: 7265 616d 2c20 636f 6e74 6578 742c 2070  ream, context, p
-000086b0: 6174 6829 0d0a 2020 2020 2020 2020 2020  ath)..          
-000086c0: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
-000086d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000086e0: 2072 6574 7572 6e20 6d61 7463 682e 6772   return match.gr
-000086f0: 6f75 7028 290d 0a0d 0a20 2020 2020 2020  oup()....       
-00008700: 2020 2020 2023 204f 7468 6572 7769 7365       # Otherwise
-00008710: 2c20 7765 2061 7265 2067 6f69 6e67 2074  , we are going t
-00008720: 6f20 7061 7273 6520 6561 6368 206e 616d  o parse each nam
-00008730: 6564 2063 6170 7475 7265 2067 726f 7570  ed capture group
-00008740: 2e0d 0a20 2020 2020 2020 2020 2020 206f  ...            o
-00008750: 626a 203d 2043 6f6e 7461 696e 6572 2829  bj = Container()
-00008760: 0d0a 2020 2020 2020 2020 2020 2020 6f62  ..            ob
-00008770: 6a2e 5f69 6f20 3d20 7374 7265 616d 0d0a  j._io = stream..
-00008780: 0d0a 2020 2020 2020 2020 2020 2020 636f  ..            co
-00008790: 6e74 6578 7420 3d20 436f 6e74 6169 6e65  ntext = Containe
-000087a0: 7228 5f3d 636f 6e74 6578 742c 205f 7061  r(_=context, _pa
-000087b0: 7261 6d73 3d63 6f6e 7465 7874 2e5f 7061  rams=context._pa
-000087c0: 7261 6d73 2c20 5f72 6f6f 743d 4e6f 6e65  rams, _root=None
-000087d0: 2c20 5f70 6172 7369 6e67 3d63 6f6e 7465  , _parsing=conte
-000087e0: 7874 2e5f 7061 7273 696e 672c 0d0a 2020  xt._parsing,..  
-000087f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008800: 2020 2020 2020 2020 2020 2020 2020 5f62                _b
-00008810: 7569 6c64 696e 673d 636f 6e74 6578 742e  uilding=context.
-00008820: 5f62 7569 6c64 696e 672c 205f 7369 7a69  _building, _sizi
-00008830: 6e67 3d63 6f6e 7465 7874 2e5f 7369 7a69  ng=context._sizi
-00008840: 6e67 2c20 5f73 7562 636f 6e73 3d73 656c  ng, _subcons=sel
-00008850: 662e 6772 6f75 705f 7375 6263 6f6e 732c  f.group_subcons,
-00008860: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00008870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008880: 2020 5f69 6f3d 7374 7265 616d 2c20 5f69    _io=stream, _i
-00008890: 6e64 6578 3d63 6f6e 7465 7874 2e67 6574  ndex=context.get
-000088a0: 2822 5f69 6e64 6578 222c 204e 6f6e 6529  ("_index", None)
-000088b0: 290d 0a20 2020 2020 2020 2020 2020 2063  )..            c
-000088c0: 6f6e 7465 7874 2e5f 726f 6f74 203d 2063  ontext._root = c
-000088d0: 6f6e 7465 7874 2e5f 2e67 6574 2822 5f72  ontext._.get("_r
-000088e0: 6f6f 7422 2c20 636f 6e74 6578 7429 0d0a  oot", context)..
-000088f0: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-00008900: 4465 6661 756c 7420 746f 2064 6973 706c  Default to displ
-00008910: 6179 696e 6720 6d61 7463 6865 6420 6461  aying matched da
-00008920: 7461 2061 7320 7075 7265 2062 7974 6573  ta as pure bytes
-00008930: 2e0d 0a20 2020 2020 2020 2020 2020 206f  ...            o
-00008940: 626a 2e75 7064 6174 6528 6772 6f75 705f  bj.update(group_
-00008950: 6469 6374 290d 0a20 2020 2020 2020 2020  dict)..         
-00008960: 2020 2063 6f6e 7465 7874 2e75 7064 6174     context.updat
-00008970: 6528 6772 6f75 705f 6469 6374 290d 0a0d  e(group_dict)...
-00008980: 0a20 2020 2020 2020 2020 2020 2023 2050  .            # P
-00008990: 6172 7365 2067 726f 7570 7320 7573 696e  arse groups usin
-000089a0: 6720 7375 7070 6c69 6564 2063 6f6e 7374  g supplied const
-000089b0: 7275 6374 732e 0d0a 2020 2020 2020 2020  ructs...        
-000089c0: 2020 2020 666f 7220 6e61 6d65 2c20 7375      for name, su
-000089d0: 6263 6f6e 2069 6e20 7365 6c66 2e67 726f  bcon in self.gro
-000089e0: 7570 5f73 7562 636f 6e73 2e69 7465 6d73  up_subcons.items
-000089f0: 2829 3a0d 0a20 2020 2020 2020 2020 2020  ():..           
-00008a00: 2020 2020 2074 7279 3a0d 0a20 2020 2020       try:..     
-00008a10: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00008a20: 6174 6120 3d20 6d61 7463 682e 6772 6f75  ata = match.grou
-00008a30: 7028 6e61 6d65 290d 0a20 2020 2020 2020  p(name)..       
-00008a40: 2020 2020 2020 2020 2065 7863 6570 7420           except 
-00008a50: 496e 6465 7845 7272 6f72 3a0d 0a20 2020  IndexError:..   
-00008a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008a70: 2063 6f6e 7469 6e75 650d 0a0d 0a20 2020   continue....   
-00008a80: 2020 2020 2020 2020 2020 2020 2023 2049               # I
-00008a90: 6620 6461 7461 2069 7320 4e6f 6e65 2c20  f data is None, 
-00008aa0: 7468 656e 2077 6520 6172 6520 6d6f 7374  then we are most
-00008ab0: 206c 696b 656c 7920 6465 616c 696e 6720   likely dealing 
-00008ac0: 7769 7468 2061 6e20 6f70 7469 6f6e 616c  with an optional
-00008ad0: 2063 6170 7475 7265 2067 726f 7570 2e0d   capture group..
-00008ae0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00008af0: 2069 6620 6461 7461 2069 7320 4e6f 6e65   if data is None
-00008b00: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00008b10: 2020 2020 2020 206f 626a 5b6e 616d 655d         obj[name]
-00008b20: 203d 204e 6f6e 650d 0a20 2020 2020 2020   = None..       
-00008b30: 2020 2020 2020 2020 2020 2020 2063 6f6e               con
-00008b40: 7465 7874 5b6e 616d 655d 203d 204e 6f6e  text[name] = Non
-00008b50: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
-00008b60: 2020 2020 2020 2063 6f6e 7469 6e75 650d         continue.
-00008b70: 0a0d 0a20 2020 2020 2020 2020 2020 2020  ...             
-00008b80: 2020 2023 2049 6620 7765 2068 6176 6520     # If we have 
-00008b90: 616e 2065 6d70 7479 2063 6170 7475 7265  an empty capture
-00008ba0: 2067 726f 7570 2c20 7468 6520 7573 6572   group, the user
-00008bb0: 2077 6f75 6c64 206c 696b 6520 746f 2075   would like to u
-00008bc0: 7365 2069 7420 6173 2061 6e20 616e 6368  se it as an anch
-00008bd0: 6f72 2e0d 0a20 2020 2020 2020 2020 2020  or...           
-00008be0: 2020 2020 2069 6620 6e6f 7420 6461 7461       if not data
-00008bf0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00008c00: 2020 2020 2020 2073 7472 6561 6d2e 7365         stream.se
-00008c10: 656b 2873 7461 7274 202b 206d 6174 6368  ek(start + match
-00008c20: 2e73 7461 7274 286e 616d 6529 290d 0a20  .start(name)).. 
-00008c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008c40: 2020 2073 7562 5f73 7472 6561 6d20 3d20     sub_stream = 
-00008c50: 7374 7265 616d 0d0a 2020 2020 2020 2020  stream..        
-00008c60: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
-00008c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008c80: 2020 2073 7562 5f73 7472 6561 6d20 3d20     sub_stream = 
-00008c90: 696f 2e42 7974 6573 494f 2864 6174 6129  io.BytesIO(data)
-00008ca0: 0d0a 0d0a 2020 2020 2020 2020 2020 2020  ....            
-00008cb0: 2020 2020 7472 793a 0d0a 2020 2020 2020      try:..      
-00008cc0: 2020 2020 2020 2020 2020 2020 2020 7375                su
-00008cd0: 626f 626a 203d 2073 7562 636f 6e2e 5f70  bobj = subcon._p
-00008ce0: 6172 7365 7265 706f 7274 2873 7562 5f73  arsereport(sub_s
-00008cf0: 7472 6561 6d2c 2063 6f6e 7465 7874 2c20  tream, context, 
-00008d00: 7061 7468 290d 0a20 2020 2020 2020 2020  path)..         
-00008d10: 2020 2020 2020 2065 7863 6570 7420 436f         except Co
-00008d20: 6e73 7472 7563 7445 7272 6f72 2061 7320  nstructError as 
-00008d30: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00008d40: 2020 2020 2020 2020 2320 5261 6973 6520          # Raise 
-00008d50: 6120 6d6f 7265 2075 7365 6675 6c20 6572  a more useful er
-00008d60: 726f 7220 6d65 7373 6167 652e 0d0a 2020  ror message...  
-00008d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008d80: 2020 2320 544f 444f 3a20 5265 6d6f 7665    # TODO: Remove
-00008d90: 2077 6865 6e20 7061 7468 2069 7320 7072   when path is pr
-00008da0: 6f76 6964 6564 2069 6e20 6578 6365 7074  ovided in except
-00008db0: 696f 6e20 6d65 7373 6167 6573 2e0d 0a20  ion messages... 
-00008dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008dd0: 2020 2072 6169 7365 2043 6f6e 7374 7275     raise Constru
-00008de0: 6374 4572 726f 7228 2746 6169 6c65 6420  ctError('Failed 
-00008df0: 746f 2070 6172 7365 207b 7d20 6361 7074  to parse {} capt
-00008e00: 7572 6520 6772 6f75 7020 7769 7468 2065  ure group with e
-00008e10: 7272 6f72 3a20 7b7d 272e 666f 726d 6174  rror: {}'.format
-00008e20: 286e 616d 652c 2065 2929 0d0a 2020 2020  (name, e))..    
-00008e30: 2020 2020 2020 2020 2020 2020 6f62 6a5b              obj[
-00008e40: 6e61 6d65 5d20 3d20 7375 626f 626a 0d0a  name] = subobj..
-00008e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008e60: 636f 6e74 6578 745b 6e61 6d65 5d20 3d20  context[name] = 
-00008e70: 7375 626f 626a 0d0a 2020 2020 2020 2020  subobj..        
-00008e80: 2020 2020 7265 7475 726e 206f 626a 0d0a      return obj..
-00008e90: 0d0a 2020 2020 2020 2020 6669 6e61 6c6c  ..        finall
-00008ea0: 793a 0d0a 2020 2020 2020 2020 2020 2020  y:..            
-00008eb0: 2320 5265 7365 7420 706f 7369 7469 6f6e  # Reset position
-00008ec0: 2074 6f20 7269 6768 7420 6166 7465 7220   to right after 
-00008ed0: 7468 6520 6d61 7463 6865 6420 7265 6765  the matched rege
-00008ee0: 782e 0d0a 2020 2020 2020 2020 2020 2020  x...            
-00008ef0: 7374 7265 616d 2e73 6565 6b28 7374 6172  stream.seek(star
-00008f00: 7420 2b20 6d61 7463 682e 656e 6428 2929  t + match.end())
-00008f10: 0d0a 0d0a 2020 2020 6465 6620 5f62 7569  ....    def _bui
-00008f20: 6c64 2873 656c 662c 206f 626a 2c20 7374  ld(self, obj, st
-00008f30: 7265 616d 2c20 636f 6e74 6578 742c 2070  ream, context, p
-00008f40: 6174 6829 3a0d 0a20 2020 2020 2020 2072  ath):..        r
-00008f50: 6169 7365 2043 6f6e 7374 7275 6374 4572  aise ConstructEr
-00008f60: 726f 7228 2742 7569 6c64 696e 6720 666f  ror('Building fo
-00008f70: 7220 5265 6765 7820 6973 206e 6f74 2073  r Regex is not s
-00008f80: 7570 706f 7274 6564 2e27 290d 0a0d 0a20  upported.').... 
-00008f90: 2020 2064 6566 205f 7369 7a65 6f66 2873     def _sizeof(s
-00008fa0: 656c 662c 2063 6f6e 7465 7874 2c20 7061  elf, context, pa
-00008fb0: 7468 293a 0d0a 2020 2020 2020 2020 7261  th):..        ra
-00008fc0: 6973 6520 5369 7a65 6f66 4572 726f 7228  ise SizeofError(
-00008fd0: 2773 697a 656f 6628 2920 666f 7220 5265  'sizeof() for Re
-00008fe0: 6765 7820 6973 206e 6f74 2073 7570 706f  gex is not suppo
-00008ff0: 7274 6564 2e27 290d 0a0d 0a20 2020 2064  rted.')....    d
-00009000: 6566 205f 656d 6974 7061 7273 6528 7365  ef _emitparse(se
-00009010: 6c66 2c20 636f 6465 293a 0d0a 2020 2020  lf, code):..    
-00009020: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
-00009030: 6c65 6d65 6e74 6564 4572 726f 720d 0a0d  lementedError...
-00009040: 0a20 2020 2064 6566 205f 656d 6974 7365  .    def _emitse
-00009050: 7128 7365 6c66 2c20 6b73 792c 2062 6974  q(self, ksy, bit
-00009060: 7769 7365 293a 0d0a 2020 2020 2020 2020  wise):..        
-00009070: 7261 6973 6520 4e6f 7449 6d70 6c65 6d65  raise NotImpleme
-00009080: 6e74 6564 4572 726f 720d 0a0d 0a0d 0a63  ntedError......c
-00009090: 6c61 7373 2049 7465 7245 7272 6f72 2843  lass IterError(C
-000090a0: 6f6e 7374 7275 6374 4572 726f 7229 3a0d  onstructError):.
-000090b0: 0a20 2020 2070 6173 730d 0a0d 0a0d 0a23  .    pass......#
-000090c0: 2054 4f44 4f3a 2053 686f 756c 6420 7468   TODO: Should th
-000090d0: 6973 2062 6520 7265 6e61 6d65 6420 746f  is be renamed to
-000090e0: 204d 6170 3f0d 0a63 6c61 7373 2049 7465   Map?..class Ite
-000090f0: 7228 436f 6e73 7472 7563 7429 3a0d 0a20  r(Construct):.. 
-00009100: 2020 2072 2222 220d 0a20 2020 2043 6c61     r"""..    Cla
-00009110: 7373 2074 6861 7420 616c 6c6f 7773 2069  ss that allows i
-00009120: 7465 7261 7469 6e67 206f 7665 7220 616e  terating over an
-00009130: 206f 626a 6563 7420 616e 6420 6163 7469   object and acti
-00009140: 6e67 206f 6e20 6561 6368 2069 7465 6d2e  ng on each item.
-00009150: 0d0a 0d0a 2020 2020 652e 672e 0d0a 2020  ....    e.g...  
-00009160: 2020 3e3e 3e20 7370 6563 203d 2053 7472    >>> spec = Str
-00009170: 7563 7428 0d0a 2020 2020 2e2e 2e20 2020  uct(..    ...   
-00009180: 2020 2774 7970 6573 2720 2f20 4279 7465    'types' / Byte
-00009190: 5b33 5d2c 0d0a 2020 2020 2e2e 2e20 2020  [3],..    ...   
-000091a0: 2020 2765 6e74 7269 6573 2720 2f20 4974    'entries' / It
-000091b0: 6572 2874 6869 732e 7479 7065 732c 207b  er(this.types, {
-000091c0: 0d0a 2020 2020 2e2e 2e20 2020 2020 2020  ..    ...       
-000091d0: 2031 3a20 636f 6e73 7472 7563 742e 496e   1: construct.In
-000091e0: 7433 3275 6c2c 0d0a 2020 2020 2e2e 2e20  t32ul,..    ... 
-000091f0: 2020 2020 2020 2032 3a20 636f 6e73 7472         2: constr
-00009200: 7563 742e 496e 7431 3675 6c2c 0d0a 2020  uct.Int16ul,..  
-00009210: 2020 2e2e 2e20 2020 2020 7d2c 0d0a 2020    ...     },..  
-00009220: 2020 2e2e 2e20 2020 2020 6465 6661 756c    ...     defaul
-00009230: 743d 636f 6e73 7472 7563 742e 5061 7373  t=construct.Pass
-00009240: 0d0a 2020 2020 2e2e 2e20 2020 2020 290d  ..    ...     ).
-00009250: 0a20 2020 202e 2e2e 2029 0d0a 2020 2020  .    ... )..    
-00009260: 3e3e 3e20 7370 6563 2e70 6172 7365 2827  >>> spec.parse('
-00009270: 5c78 3031 5c78 3032 5c78 3039 5c78 3033  \x01\x02\x09\x03
-00009280: 5c78 3033 5c78 3033 5c78 3033 5c78 3036  \x03\x03\x03\x06
-00009290: 5c78 3036 2729 0d0a 2020 2020 436f 6e74  \x06')..    Cont
-000092a0: 6169 6e65 7228 7479 7065 733d 4c69 7374  ainer(types=List
-000092b0: 436f 6e74 6169 6e65 7228 5b31 2c20 322c  Container([1, 2,
-000092c0: 2039 5d29 2c20 656e 7472 6965 733d 4c69   9]), entries=Li
-000092d0: 7374 436f 6e74 6169 6e65 7228 5b35 3035  stContainer([505
-000092e0: 3239 3032 372c 2031 3534 322c 204e 6f6e  29027, 1542, Non
-000092f0: 655d 2929 0d0a 2020 2020 3e3e 3e20 4320  e]))..    >>> C 
-00009300: 3d20 5f0d 0a20 2020 203e 3e3e 2073 7065  = _..    >>> spe
-00009310: 632e 6275 696c 6428 4329 0d0a 2020 2020  c.build(C)..    
-00009320: 275c 7830 315c 7830 325c 745c 7830 335c  '\x01\x02\t\x03\
-00009330: 7830 335c 7830 335c 7830 335c 7830 365c  x03\x03\x03\x06\
-00009340: 7830 3627 0d0a 2020 2020 3e3e 3e20 7370  x06'..    >>> sp
-00009350: 6563 2e73 697a 656f 6628 2a2a 4329 0d0a  ec.sizeof(**C)..
-00009360: 2020 2020 390d 0a0d 0a20 2020 203e 3e3e      9....    >>>
-00009370: 2073 7065 6320 3d20 5374 7275 6374 280d   spec = Struct(.
-00009380: 0a20 2020 202e 2e2e 2020 2020 2027 7369  .    ...     'si
-00009390: 7a65 7327 202f 2049 6e74 3136 756c 5b34  zes' / Int16ul[4
-000093a0: 5d2c 0d0a 2020 2020 2e2e 2e20 2020 2020  ],..    ...     
-000093b0: 2765 6e74 7269 6573 2720 2f20 4974 6572  'entries' / Iter
-000093c0: 2874 6869 732e 7369 7a65 732c 2042 7974  (this.sizes, Byt
-000093d0: 6573 2920 2023 2065 7175 6976 616c 656e  es)  # equivalen
-000093e0: 7420 746f 2049 7465 7228 7468 6973 2e73  t to Iter(this.s
-000093f0: 697a 6573 2c20 6c61 6d62 6461 2073 697a  izes, lambda siz
-00009400: 653a 2042 7974 6573 2873 697a 6529 290d  e: Bytes(size)).
-00009410: 0a20 2020 202e 2e2e 2029 0d0a 2020 2020  .    ... )..    
-00009420: 3e3e 3e20 7370 6563 2e70 6172 7365 2827  >>> spec.parse('
-00009430: 5c78 3031 5c78 3030 5c78 3033 5c78 3030  \x01\x00\x03\x00
-00009440: 5c78 3030 5c78 3030 5c78 3035 5c78 3030  \x00\x00\x05\x00
-00009450: 6162 6262 6464 6464 6427 290d 0a20 2020  abbbddddd')..   
-00009460: 2043 6f6e 7461 696e 6572 2873 697a 6573   Container(sizes
-00009470: 3d4c 6973 7443 6f6e 7461 696e 6572 285b  =ListContainer([
-00009480: 312c 2033 2c20 302c 2035 5d29 2c20 656e  1, 3, 0, 5]), en
-00009490: 7472 6965 733d 4c69 7374 436f 6e74 6169  tries=ListContai
-000094a0: 6e65 7228 5b27 6127 2c20 2762 6262 272c  ner(['a', 'bbb',
-000094b0: 2027 272c 2027 6464 6464 6427 5d29 290d   '', 'ddddd'])).
-000094c0: 0a20 2020 203e 3e3e 2043 203d 205f 0d0a  .    >>> C = _..
-000094d0: 2020 2020 3e3e 3e20 7370 6563 2e62 7569      >>> spec.bui
-000094e0: 6c64 2843 290d 0a20 2020 2027 5c78 3031  ld(C)..    '\x01
-000094f0: 5c78 3030 5c78 3033 5c78 3030 5c78 3030  \x00\x03\x00\x00
-00009500: 5c78 3030 5c78 3035 5c78 3030 6162 6262  \x00\x05\x00abbb
-00009510: 6464 6464 6427 0d0a 2020 2020 3e3e 3e20  ddddd'..    >>> 
-00009520: 4974 6572 2874 6869 732e 7369 7a65 732c  Iter(this.sizes,
-00009530: 2042 7974 6573 292e 7369 7a65 6f66 2873   Bytes).sizeof(s
-00009540: 697a 6573 3d5b 312c 322c 332c 305d 290d  izes=[1,2,3,0]).
-00009550: 0a20 2020 2036 0d0a 2020 2020 3e3e 3e20  .    6..    >>> 
-00009560: 7370 6563 2e73 697a 656f 6628 2a2a 4329  spec.sizeof(**C)
-00009570: 0d0a 2020 2020 3137 0d0a 0d0a 2020 2020  ..    17....    
-00009580: 3a70 6172 616d 2069 7465 7261 626c 653a  :param iterable:
-00009590: 2069 7465 7261 626c 6520 6974 656d 7320   iterable items 
-000095a0: 746f 2061 6374 2075 706f 6e0d 0a20 2020  to act upon..   
-000095b0: 203a 7061 7261 6d20 6361 7365 733a 2041   :param cases: A
-000095c0: 2064 6963 7469 6f6e 6172 7920 6f66 2063   dictionary of c
-000095d0: 6173 6573 206f 7220 6120 6675 6e63 7469  ases or a functi
-000095e0: 6f6e 2074 6861 7420 7461 6b65 7320 7461  on that takes ta
-000095f0: 6b65 7320 6120 6b65 7920 616e 6420 7265  kes a key and re
-00009600: 7475 726e 7320 6120 636f 6e73 7472 7563  turns a construc
-00009610: 7420 7370 6563 2e0d 0a20 2020 203a 7061  t spec...    :pa
-00009620: 7261 6d20 6465 6661 756c 743a 2054 6865  ram default: The
-00009630: 2064 6566 6175 6c74 2063 6173 6520 286f   default case (o
-00009640: 6e6c 7920 6966 2063 6173 6573 2069 7320  nly if cases is 
-00009650: 6120 6469 6374 290d 0a20 2020 2022 2222  a dict)..    """
-00009660: 0d0a 2020 2020 5f5f 736c 6f74 735f 5f20  ..    __slots__ 
-00009670: 3d20 5b27 6974 6572 6162 6c65 272c 2027  = ['iterable', '
-00009680: 6361 7365 7327 2c20 2764 6566 6175 6c74  cases', 'default
-00009690: 275d 0d0a 2020 2020 0d0a 2020 2020 6465  ']..    ..    de
-000096a0: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
-000096b0: 2069 7465 7261 626c 652c 2063 6173 6573   iterable, cases
-000096c0: 2c20 6465 6661 756c 743d 4e6f 6e65 293a  , default=None):
-000096d0: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
-000096e0: 4974 6572 2c20 7365 6c66 292e 5f5f 696e  Iter, self).__in
-000096f0: 6974 5f5f 2829 0d0a 2020 2020 2020 2020  it__()..        
-00009700: 7365 6c66 2e69 7465 7261 626c 6520 3d20  self.iterable = 
-00009710: 6974 6572 6162 6c65 0d0a 2020 2020 2020  iterable..      
-00009720: 2020 7365 6c66 2e63 6173 6573 203d 2063    self.cases = c
-00009730: 6173 6573 0d0a 2020 2020 2020 2020 7365  ases..        se
-00009740: 6c66 2e64 6566 6175 6c74 203d 2064 6566  lf.default = def
-00009750: 6175 6c74 206f 7220 5061 7373 0d0a 2020  ault or Pass..  
-00009760: 2020 2020 2020 6966 206e 6f74 2063 616c        if not cal
-00009770: 6c61 626c 6528 6361 7365 7329 3a0d 0a20  lable(cases):.. 
-00009780: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00009790: 666c 6167 6275 696c 646e 6f6e 6520 3d20  flagbuildnone = 
-000097a0: 616c 6c28 7363 2e66 6c61 6762 7569 6c64  all(sc.flagbuild
-000097b0: 6e6f 6e65 2066 6f72 2073 6320 696e 2063  none for sc in c
-000097c0: 6173 6573 2e76 616c 7565 7328 2929 0d0a  ases.values())..
-000097d0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-000097e0: 2e66 6c61 6765 6d62 6564 6465 6420 3d20  .flagembedded = 
-000097f0: 616c 6c28 7363 2e66 6c61 6765 6d62 6564  all(sc.flagembed
-00009800: 6465 6420 666f 7220 7363 2069 6e20 6361  ded for sc in ca
-00009810: 7365 732e 7661 6c75 6573 2829 290d 0a20  ses.values()).. 
-00009820: 2020 2020 2020 200d 0a20 2020 2064 6566         ..    def
-00009830: 205f 7061 7273 6528 7365 6c66 2c20 7374   _parse(self, st
-00009840: 7265 616d 2c20 636f 6e74 6578 742c 2070  ream, context, p
-00009850: 6174 6829 3a0d 0a20 2020 2020 2020 2069  ath):..        i
-00009860: 7465 7261 746f 7220 3d20 6974 6572 2873  terator = iter(s
-00009870: 656c 662e 6974 6572 6162 6c65 2863 6f6e  elf.iterable(con
-00009880: 7465 7874 2929 2069 6620 6361 6c6c 6162  text)) if callab
-00009890: 6c65 2873 656c 662e 6974 6572 6162 6c65  le(self.iterable
-000098a0: 2920 656c 7365 2069 7465 7228 7365 6c66  ) else iter(self
-000098b0: 2e69 7465 7261 626c 6529 0d0a 2020 2020  .iterable)..    
-000098c0: 2020 2020 6966 2063 616c 6c61 626c 6528      if callable(
-000098d0: 7365 6c66 2e63 6173 6573 293a 0d0a 2020  self.cases):..  
-000098e0: 2020 2020 2020 2020 2020 7265 7475 726e            return
-000098f0: 204c 6973 7443 6f6e 7461 696e 6572 285b   ListContainer([
-00009900: 7365 6c66 2e63 6173 6573 286b 6579 292e  self.cases(key).
-00009910: 5f70 6172 7365 7265 706f 7274 2873 7472  _parsereport(str
-00009920: 6561 6d2c 2063 6f6e 7465 7874 2c20 7061  eam, context, pa
-00009930: 7468 2920 666f 7220 6b65 7920 696e 2069  th) for key in i
-00009940: 7465 7261 746f 725d 290d 0a20 2020 2020  terator])..     
-00009950: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
-00009960: 2020 2020 2020 7265 7475 726e 204c 6973        return Lis
-00009970: 7443 6f6e 7461 696e 6572 285b 7365 6c66  tContainer([self
-00009980: 2e63 6173 6573 2e67 6574 286b 6579 2c20  .cases.get(key, 
-00009990: 7365 6c66 2e64 6566 6175 6c74 292e 5f70  self.default)._p
-000099a0: 6172 7365 7265 706f 7274 2873 7472 6561  arsereport(strea
-000099b0: 6d2c 2063 6f6e 7465 7874 2c20 7061 7468  m, context, path
-000099c0: 2920 666f 7220 6b65 7920 696e 2069 7465  ) for key in ite
-000099d0: 7261 746f 725d 290d 0a20 2020 2020 2020  rator])..       
-000099e0: 200d 0a20 2020 2064 6566 205f 6275 696c   ..    def _buil
-000099f0: 6428 7365 6c66 2c20 6f62 6a2c 2073 7472  d(self, obj, str
-00009a00: 6561 6d2c 2063 6f6e 7465 7874 2c20 7061  eam, context, pa
-00009a10: 7468 293a 0d0a 2020 2020 2020 2020 6974  th):..        it
-00009a20: 6572 6174 6f72 203d 2069 7465 7228 7365  erator = iter(se
-00009a30: 6c66 2e69 7465 7261 626c 6528 636f 6e74  lf.iterable(cont
-00009a40: 6578 7429 2920 6966 2063 616c 6c61 626c  ext)) if callabl
-00009a50: 6528 7365 6c66 2e69 7465 7261 626c 6529  e(self.iterable)
-00009a60: 2065 6c73 6520 6974 6572 2873 656c 662e   else iter(self.
-00009a70: 6974 6572 6162 6c65 290d 0a20 2020 2020  iterable)..     
-00009a80: 2020 2066 6f72 2073 7562 5f6f 626a 2c20     for sub_obj, 
-00009a90: 6b65 7920 696e 207a 6970 286f 626a 2c20  key in zip(obj, 
-00009aa0: 6974 6572 6174 6f72 293a 0d0a 2020 2020  iterator):..    
-00009ab0: 2020 2020 2020 2020 6966 2063 616c 6c61          if calla
-00009ac0: 626c 6528 7365 6c66 2e63 6173 6573 293a  ble(self.cases):
-00009ad0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00009ae0: 2020 7365 6c66 2e63 6173 6573 286b 6579    self.cases(key
-00009af0: 292e 5f62 7569 6c64 2873 7562 5f6f 626a  )._build(sub_obj
-00009b00: 2c20 7374 7265 616d 2c20 636f 6e74 6578  , stream, contex
-00009b10: 742c 2070 6174 6829 0d0a 2020 2020 2020  t, path)..      
-00009b20: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
-00009b30: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-00009b40: 662e 6361 7365 732e 6765 7428 6b65 792c  f.cases.get(key,
-00009b50: 2073 656c 662e 6465 6661 756c 7429 2e5f   self.default)._
-00009b60: 6275 696c 6428 7375 625f 6f62 6a2c 2073  build(sub_obj, s
-00009b70: 7472 6561 6d2c 2063 6f6e 7465 7874 2c20  tream, context, 
-00009b80: 7061 7468 290d 0a20 2020 2020 2020 2020  path)..         
-00009b90: 2020 200d 0a20 2020 2064 6566 205f 7369     ..    def _si
-00009ba0: 7a65 6f66 2873 656c 662c 2063 6f6e 7465  zeof(self, conte
-00009bb0: 7874 2c20 7061 7468 293a 0d0a 2020 2020  xt, path):..    
-00009bc0: 2020 2020 6974 6572 6174 6f72 203d 2069      iterator = i
-00009bd0: 7465 7228 6576 616c 7561 7465 2873 656c  ter(evaluate(sel
-00009be0: 662e 6974 6572 6162 6c65 2c20 636f 6e74  f.iterable, cont
-00009bf0: 6578 7429 290d 0a20 2020 2020 2020 2073  ext))..        s
-00009c00: 697a 6520 3d20 300d 0a20 2020 2020 2020  ize = 0..       
-00009c10: 2066 6f72 206b 6579 2069 6e20 6974 6572   for key in iter
-00009c20: 6174 6f72 3a0d 0a20 2020 2020 2020 2020  ator:..         
-00009c30: 2020 2074 7279 3a0d 0a20 2020 2020 2020     try:..       
-00009c40: 2020 2020 2020 2020 2069 6620 6361 6c6c           if call
-00009c50: 6162 6c65 2873 656c 662e 6361 7365 7329  able(self.cases)
-00009c60: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00009c70: 2020 2020 2020 2073 697a 6520 2b3d 2073         size += s
-00009c80: 656c 662e 6361 7365 7328 6b65 7929 2e5f  elf.cases(key)._
-00009c90: 7369 7a65 6f66 2863 6f6e 7465 7874 2c20  sizeof(context, 
-00009ca0: 7061 7468 290d 0a20 2020 2020 2020 2020  path)..         
-00009cb0: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-00009cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009cd0: 2020 7369 7a65 202b 3d20 7365 6c66 2e63    size += self.c
-00009ce0: 6173 6573 2e67 6574 286b 6579 2c20 7365  ases.get(key, se
-00009cf0: 6c66 2e64 6566 6175 6c74 292e 5f73 697a  lf.default)._siz
-00009d00: 656f 6628 636f 6e74 6578 742c 2070 6174  eof(context, pat
-00009d10: 6829 0d0a 2020 2020 2020 2020 2020 2020  h)..            
-00009d20: 6578 6365 7074 2028 4b65 7945 7272 6f72  except (KeyError
-00009d30: 2c20 4174 7472 6962 7574 6545 7272 6f72  , AttributeError
-00009d40: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00009d50: 2020 2020 7261 6973 6520 5369 7a65 6f66      raise Sizeof
-00009d60: 4572 726f 7228 2263 616e 6e6f 7420 6361  Error("cannot ca
-00009d70: 6c63 756c 6174 6520 7369 7a65 2c20 7b21  lculate size, {!
-00009d80: 727d 206b 6579 206e 6f74 2066 6f75 6e64  r} key not found
-00009d90: 2069 6e20 636f 6e74 6578 7422 2e66 6f72   in context".for
-00009da0: 6d61 7428 6b65 7929 290d 0a20 2020 2020  mat(key))..     
-00009db0: 2020 2072 6574 7572 6e20 7369 7a65 0d0a     return size..
-00009dc0: 0d0a 0d0a 6465 6620 6669 6e64 5f63 6f6e  ....def find_con
-00009dd0: 7374 7275 6374 7328 7374 7275 6374 2c20  structs(struct, 
-00009de0: 6461 7461 293a 0d0a 2020 2020 7222 2222  data):..    r"""
-00009df0: 0d0a 2020 2020 4765 6e65 7261 746f 7220  ..    Generator 
-00009e00: 7468 6174 2079 6965 6c64 7320 7468 6520  that yields the 
-00009e10: 7265 7375 6c74 7320 6f66 2073 7563 6365  results of succe
-00009e20: 7373 6675 6c20 7061 7273 696e 6773 206f  ssful parsings o
-00009e30: 6620 7468 6520 6769 7665 6e0d 0a20 2020  f the given..   
-00009e40: 2063 6f6e 7374 7275 6374 2e0d 0a20 2020   construct...   
-00009e50: 204e 6f74 653a 2043 6f6e 7374 7275 6374   Note: Construct
-00009e60: 206d 7573 7420 6174 7465 6d70 7420 746f   must attempt to
-00009e70: 2072 6561 6420 736f 6d65 7468 696e 672e   read something.
-00009e80: 2049 652c 2064 6f6e 2774 2068 6176 6520   Ie, don't have 
-00009e90: 6120 5065 656b 0d0a 2020 2020 6173 2079  a Peek..    as y
-00009ea0: 6f75 7220 6669 7273 7420 7375 6263 6f6e  our first subcon
-00009eb0: 7374 7275 6374 2e0d 0a0d 0a20 2020 2041  struct.....    A
-00009ec0: 6c73 6f2c 2069 7427 7320 6265 7374 2069  lso, it's best i
-00009ed0: 6620 796f 7520 6861 7665 2073 6f6d 6520  f you have some 
-00009ee0: 7479 7065 206f 6620 7661 6c69 6461 7469  type of validati
-00009ef0: 6f6e 2028 436f 6e73 742c 204f 6e65 4f66  on (Const, OneOf
-00009f00: 2c20 4e6f 6e65 4f66 2c20 4368 6563 6b2c  , NoneOf, Check,
-00009f10: 2065 7463 2920 7769 7468 696e 2079 6f75   etc) within you
-00009f20: 7220 7374 7275 6374 2e0d 0a20 2020 204f  r struct...    O
-00009f30: 7468 6572 7769 7365 2c20 6974 206d 616b  therwise, it mak
-00009f40: 6573 206d 6f72 6520 7365 6e73 6520 746f  es more sense to
-00009f50: 2075 7365 2061 2047 7265 6564 7952 616e   use a GreedyRan
-00009f60: 6765 2028 7468 6520 275b 3a5d 2720 6e6f  ge (the '[:]' no
-00009f70: 7461 7469 6f6e 2920 696e 7374 6561 6420  tation) instead 
-00009f80: 6f66 2074 6869 7320 6675 6e63 7469 6f6e  of this function
-00009f90: 2e0d 0a0d 0a20 2020 2065 2e67 2e0d 0a20  .....    e.g... 
-00009fa0: 2020 203e 3e3e 2073 7472 7563 7420 3d20     >>> struct = 
-00009fb0: 5374 7275 6374 280d 0a20 2020 202e 2e2e  Struct(..    ...
-00009fc0: 2020 2020 2043 6f6e 7374 2862 274d 5a27       Const(b'MZ'
-00009fd0: 292c 0d0a 2020 2020 2e2e 2e20 2020 2020  ),..    ...     
-00009fe0: 2769 6e74 2720 2f20 496e 7431 3675 6c2c  'int' / Int16ul,
-00009ff0: 0d0a 2020 2020 2e2e 2e20 2020 2020 2773  ..    ...     's
-0000a000: 7472 696e 6727 202f 2043 5374 7269 6e67  tring' / CString
-0000a010: 2829 290d 0a20 2020 203e 3e3e 206c 6973  ())..    >>> lis
-0000a020: 7428 6669 6e64 5f63 6f6e 7374 7275 6374  t(find_construct
-0000a030: 7328 7374 7275 6374 2c20 6227 5c78 3031  s(struct, b'\x01
-0000a040: 5c78 3032 5c78 3033 4d5a 5c78 3041 5c78  \x02\x03MZ\x0A\x
-0000a050: 3030 6865 6c6c 6f5c 7830 305c 7830 335c  00hello\x00\x03\
-0000a060: 7830 344d 5a5c 7830 425c 7830 3077 6f72  x04MZ\x0B\x00wor
-0000a070: 6c64 5c78 3030 5c78 3030 2729 290d 0a20  ld\x00\x00')).. 
-0000a080: 2020 205b 2833 4c2c 2043 6f6e 7461 696e     [(3L, Contain
-0000a090: 6572 2869 6e74 3d31 302c 2073 7472 696e  er(int=10, strin
-0000a0a0: 673d 7527 6865 6c6c 6f27 2929 2c20 2831  g=u'hello')), (1
-0000a0b0: 354c 2c20 436f 6e74 6169 6e65 7228 696e  5L, Container(in
-0000a0c0: 743d 3131 2c20 7374 7269 6e67 3d75 2777  t=11, string=u'w
-0000a0d0: 6f72 6c64 2729 295d 0d0a 2020 2020 3e3e  orld'))]..    >>
-0000a0e0: 3e20 6c69 7374 2866 696e 645f 636f 6e73  > list(find_cons
-0000a0f0: 7472 7563 7473 2873 7472 7563 742c 2062  tructs(struct, b
-0000a100: 276e 6f70 6527 2929 0d0a 2020 2020 5b5d  'nope'))..    []
-0000a110: 0d0a 0d0a 2020 2020 3a70 6172 616d 2073  ....    :param s
-0000a120: 7472 7563 743a 2063 6f6e 7374 7275 6374  truct: construct
-0000a130: 2074 6f20 6170 706c 7920 2869 6e73 7461   to apply (insta
-0000a140: 6e63 6520 6f66 2063 6f6e 7374 7275 6374  nce of construct
-0000a150: 2e43 6f6e 7374 7275 6374 290d 0a20 2020  .Construct)..   
-0000a160: 203a 7061 7261 6d20 6461 7461 3a20 6279   :param data: by
-0000a170: 7465 2073 7472 696e 6720 6f66 2064 6174  te string of dat
-0000a180: 6120 746f 2073 6561 7263 682e 0d0a 0d0a  a to search.....
-0000a190: 2020 2020 3a79 6965 6c64 3a20 7475 706c      :yield: tupl
-0000a1a0: 6520 636f 6e74 6169 6e69 6e67 2028 6f66  e containing (of
-0000a1b0: 6673 6574 2077 6974 6820 6461 7461 2c20  fset with data, 
-0000a1c0: 7265 7375 6c74 2043 6f6e 7461 696e 6572  result Container
-0000a1d0: 2063 6c61 7373 290d 0a20 2020 2022 2222   class)..    """
-0000a1e0: 0d0a 2020 2020 6461 7461 203d 2069 6f2e  ..    data = io.
-0000a1f0: 4279 7465 7349 4f28 6461 7461 290d 0a0d  BytesIO(data)...
-0000a200: 0a20 2020 2077 6869 6c65 2054 7275 653a  .    while True:
-0000a210: 0d0a 2020 2020 2020 2020 6f66 6673 6574  ..        offset
-0000a220: 203d 2064 6174 612e 7465 6c6c 2829 0d0a   = data.tell()..
-0000a230: 2020 2020 2020 2020 7472 793a 0d0a 2020          try:..  
-0000a240: 2020 2020 2020 2020 2020 6461 7461 5f65            data_e
-0000a250: 6c65 6d65 6e74 203d 2073 7472 7563 742e  lement = struct.
-0000a260: 7061 7273 655f 7374 7265 616d 2864 6174  parse_stream(dat
-0000a270: 6129 0d0a 2020 2020 2020 2020 6578 6365  a)..        exce
-0000a280: 7074 2028 636f 6e73 7472 7563 742e 436f  pt (construct.Co
-0000a290: 6e73 7472 7563 7445 7272 6f72 2c20 4f76  nstructError, Ov
-0000a2a0: 6572 666c 6f77 4572 726f 7229 2061 7320  erflowError) as 
-0000a2b0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-0000a2c0: 6461 7461 2e73 6565 6b28 6f66 6673 6574  data.seek(offset
-0000a2d0: 202b 2031 290d 0a20 2020 2020 2020 2065   + 1)..        e
-0000a2e0: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
-0000a2f0: 2020 7969 656c 6420 6f66 6673 6574 2c20    yield offset, 
-0000a300: 6461 7461 5f65 6c65 6d65 6e74 0d0a 0d0a  data_element....
-0000a310: 2020 2020 2020 2020 2320 5465 7374 2069          # Test i
-0000a320: 6620 7765 2068 6974 2065 6e64 206f 6620  f we hit end of 
-0000a330: 6461 7461 2e0d 0a20 2020 2020 2020 2069  data...        i
-0000a340: 6620 6461 7461 2e72 6561 6428 3129 3a0d  f data.read(1):.
-0000a350: 0a20 2020 2020 2020 2020 2020 2064 6174  .            dat
-0000a360: 612e 7365 656b 282d 312c 206f 732e 5345  a.seek(-1, os.SE
-0000a370: 454b 5f43 5552 290d 0a20 2020 2020 2020  EK_CUR)..       
-0000a380: 2065 6c73 653a 0d0a 2020 2020 2020 2020   else:..        
-0000a390: 2020 2020 6272 6561 6b0d 0a0d 0a0d 0a63      break......c
-0000a3a0: 6c61 7373 2042 6163 6b77 6172 6473 2853  lass Backwards(S
-0000a3b0: 7562 636f 6e73 7472 7563 7429 3a0d 0a20  ubconstruct):.. 
-0000a3c0: 2020 2072 2222 220d 0a20 2020 2053 7562     r"""..    Sub
-0000a3d0: 636f 6e73 7472 7563 7420 7573 6564 2074  construct used t
-0000a3e0: 6f20 7061 7273 6520 6120 6769 7665 6e20  o parse a given 
-0000a3f0: 7375 6263 6f6e 7374 7275 6374 2062 6163  subconstruct bac
-0000a400: 6b77 6172 6473 2069 6e20 7468 6520 7374  kwards in the st
-0000a410: 7265 616d 2e0d 0a20 2020 2054 6869 7320  ream...    This 
-0000a420: 6961 2061 206d 6163 726f 2066 6f72 2073  ia a macro for s
-0000a430: 6565 6b69 6e67 2062 6163 6b77 6172 6473  eeking backwards
-0000a440: 2062 6566 6f72 6520 7061 7273 696e 6720   before parsing 
-0000a450: 7468 6520 636f 6e73 7472 7563 742e 0d0a  the construct...
-0000a460: 2020 2020 2854 6869 7320 7769 6c6c 206e      (This will n
-0000a470: 6f74 2077 6f72 6b20 666f 7220 7375 6263  ot work for subc
-0000a480: 6f6e 7320 7468 6174 2064 6f6e 2774 2068  ons that don't h
-0000a490: 6176 6520 6120 7661 6c69 6420 7369 7a65  ave a valid size
-0000a4a0: 6f66 2e0d 0a20 2020 2045 7863 6570 7420  of...    Except 
-0000a4b0: 666f 7220 4772 6565 6479 4279 7465 7320  for GreedyBytes 
-0000a4c0: 616e 6420 4772 6565 6479 5374 7269 6e67  and GreedyString
-0000a4d0: 290d 0a0d 0a20 2020 2054 6865 2073 7472  )....    The str
-0000a4e0: 6561 6d20 7769 6c6c 2062 6520 6c65 6674  eam will be left
-0000a4f0: 206f 6666 2061 7420 7468 6520 7374 6172   off at the star
-0000a500: 7420 6f66 2074 6865 2070 6172 7365 6420  t of the parsed 
-0000a510: 7265 7375 6c74 2062 7920 6465 7369 676e  result by design
-0000a520: 2e0d 0a20 2020 2054 6865 7265 666f 7265  ...    Therefore
-0000a530: 2c20 646f 696e 6720 736f 6d65 7468 696e  , doing somethin
-0000a540: 6720 6c69 6b65 2049 6e74 3332 756c 203e  g like Int32ul >
-0000a550: 3e20 4261 636b 7761 7264 7328 496e 7433  > Backwards(Int3
-0000a560: 3275 6c29 203e 3e20 496e 7433 3275 6c20  2ul) >> Int32ul 
-0000a570: 7769 6c6c 2070 6172 7365 0d0a 2020 2020  will parse..    
-0000a580: 7468 6520 7361 6d65 2064 6174 6120 3320  the same data 3 
-0000a590: 7469 6d65 732e 0d0a 0d0a 2020 2020 652e  times.....    e.
-0000a5a0: 672e 0d0a 2020 2020 3e3e 3e20 2842 7974  g...    >>> (Byt
-0000a5b0: 6573 2831 3429 203e 3e20 4261 636b 7761  es(14) >> Backwa
-0000a5c0: 7264 7328 496e 7433 3275 6c29 203e 3e20  rds(Int32ul) >> 
-0000a5d0: 5465 6c6c 292e 7061 7273 6528 6227 6a75  Tell).parse(b'ju
-0000a5e0: 6e6b 2073 7475 6666 5c78 3031 5c78 3032  nk stuff\x01\x02
-0000a5f0: 5c78 3030 5c78 3030 2729 0d0a 2020 2020  \x00\x00')..    
-0000a600: 4c69 7374 436f 6e74 6169 6e65 7228 5b27  ListContainer(['
-0000a610: 6a75 6e6b 2073 7475 6666 5c78 3031 5c78  junk stuff\x01\x
-0000a620: 3032 5c78 3030 5c78 3030 272c 2035 3133  02\x00\x00', 513
-0000a630: 2c20 3130 4c5d 290d 0a20 2020 203e 3e3e  , 10L])..    >>>
-0000a640: 2073 7065 6320 3d20 5374 7275 6374 2853   spec = Struct(S
-0000a650: 6565 6b28 302c 206f 732e 5345 454b 5f45  eek(0, os.SEEK_E
-0000a660: 4e44 292c 2027 6e61 6d65 2720 2f20 4261  ND), 'name' / Ba
-0000a670: 636b 7761 7264 7328 5374 7269 6e67 2839  ckwards(String(9
-0000a680: 2929 2c20 276e 756d 6265 7227 202f 2042  )), 'number' / B
-0000a690: 6163 6b77 6172 6473 2849 6e74 3332 756c  ackwards(Int32ul
-0000a6a0: 2929 0d0a 2020 2020 3e3e 3e20 7370 6563  ))..    >>> spec
-0000a6b0: 2e70 6172 7365 2862 2741 2042 554e 4348  .parse(b'A BUNCH
-0000a6c0: 204f 4620 4a55 4e4b 2044 4154 415c 7830   OF JUNK DATA\x0
-0000a6d0: 315c 7830 305c 7830 305c 7830 306a 6f65  1\x00\x00\x00joe
-0000a6e0: 2073 686d 6f65 2729 0d0a 2020 2020 436f   shmoe')..    Co
-0000a6f0: 6e74 6169 6e65 7228 6e61 6d65 3d75 276a  ntainer(name=u'j
-0000a700: 6f65 2073 686d 6f65 272c 206e 756d 6265  oe shmoe', numbe
-0000a710: 723d 3129 0d0a 0d0a 2020 2020 5741 524e  r=1)....    WARN
-0000a720: 494e 473a 2054 6869 7320 7769 6c6c 2062  ING: This will b
-0000a730: 7265 616b 2069 6620 7468 6520 7375 6263  reak if the subc
-0000a740: 6f6e 2064 6f65 736e 2774 2068 6176 6520  on doesn't have 
-0000a750: 6120 7661 6c69 6420 7369 7a65 6f66 2e0d  a valid sizeof..
-0000a760: 0a20 2020 203e 3e3e 2073 7065 6320 3d20  .    >>> spec = 
-0000a770: 5374 7275 6374 2853 6565 6b28 302c 206f  Struct(Seek(0, o
-0000a780: 732e 5345 454b 5f45 4e44 292c 2027 6e61  s.SEEK_END), 'na
-0000a790: 6d65 2720 2f20 4261 636b 7761 7264 7328  me' / Backwards(
-0000a7a0: 4353 7472 696e 6728 2929 2c20 276e 756d  CString()), 'num
-0000a7b0: 6265 7227 202f 2042 6163 6b77 6172 6473  ber' / Backwards
-0000a7c0: 2849 6e74 3332 756c 2929 0d0a 2020 2020  (Int32ul))..    
-0000a7d0: 3e3e 3e20 7370 6563 2e70 6172 7365 2862  >>> spec.parse(b
-0000a7e0: 2741 2042 554e 4348 204f 4620 4a55 4e4b  'A BUNCH OF JUNK
-0000a7f0: 2044 4154 415c 7830 315c 7830 305c 7830   DATA\x01\x00\x0
-0000a800: 305c 7830 306a 6f65 2073 686d 6f65 5c78  0\x00joe shmoe\x
-0000a810: 3030 2729 0d0a 2020 2020 5472 6163 6562  00')..    Traceb
-0000a820: 6163 6b20 286d 6f73 7420 7265 6365 6e74  ack (most recent
-0000a830: 2063 616c 6c20 6c61 7374 293a 0d0a 2020   call last):..  
-0000a840: 2020 2020 2e2e 2e0d 0a20 2020 2053 697a      .....    Siz
-0000a850: 656f 6645 7272 6f72 0d0a 0d0a 2020 2020  eofError....    
-0000a860: 486f 7765 7665 722c 2047 7265 6564 7942  However, GreedyB
-0000a870: 7974 6573 2061 6e64 2047 7265 6564 7953  ytes and GreedyS
-0000a880: 7472 696e 6720 6172 6520 616c 6c6f 7765  tring are allowe
-0000a890: 642e 0d0a 2020 2020 3e3e 3e20 7370 6563  d...    >>> spec
-0000a8a0: 203d 2053 7472 7563 7428 5365 656b 2830   = Struct(Seek(0
-0000a8b0: 2c20 6f73 2e53 4545 4b5f 454e 4429 2c20  , os.SEEK_END), 
-0000a8c0: 276e 616d 6527 202f 2042 6163 6b77 6172  'name' / Backwar
-0000a8d0: 6473 2853 7472 696e 6728 3929 292c 2027  ds(String(9)), '
-0000a8e0: 7265 7374 2720 2f20 4261 636b 7761 7264  rest' / Backward
-0000a8f0: 7328 4772 6565 6479 4279 7465 7329 290d  s(GreedyBytes)).
-0000a900: 0a20 2020 203e 3e3e 2073 7065 632e 7061  .    >>> spec.pa
-0000a910: 7273 6528 6227 4120 4255 4e43 4820 4f46  rse(b'A BUNCH OF
-0000a920: 204a 554e 4b20 4441 5441 5c78 3031 5c78   JUNK DATA\x01\x
-0000a930: 3030 5c78 3030 5c78 3030 6a6f 6520 7368  00\x00\x00joe sh
-0000a940: 6d6f 6527 290d 0a20 2020 2043 6f6e 7461  moe')..    Conta
-0000a950: 696e 6572 286e 616d 653d 7527 6a6f 6520  iner(name=u'joe 
-0000a960: 7368 6d6f 6527 2c20 7265 7374 3d62 2741  shmoe', rest=b'A
-0000a970: 2042 554e 4348 204f 4620 4a55 4e4b 2044   BUNCH OF JUNK D
-0000a980: 4154 415c 7830 315c 7830 305c 7830 305c  ATA\x01\x00\x00\
-0000a990: 7830 3027 290d 0a20 2020 203e 3e3e 2073  x00')..    >>> s
-0000a9a0: 7065 6320 3d20 5374 7275 6374 2853 6565  pec = Struct(See
-0000a9b0: 6b28 302c 206f 732e 5345 454b 5f45 4e44  k(0, os.SEEK_END
-0000a9c0: 292c 2027 6e61 6d65 2720 2f20 4261 636b  ), 'name' / Back
-0000a9d0: 7761 7264 7328 5374 7269 6e67 2839 2929  wards(String(9))
-0000a9e0: 2c20 2772 6573 7427 202f 2042 6163 6b77  , 'rest' / Backw
-0000a9f0: 6172 6473 2847 7265 6564 7953 7472 696e  ards(GreedyStrin
-0000aa00: 6728 656e 636f 6469 6e67 3d27 7574 662d  g(encoding='utf-
-0000aa10: 3136 2d6c 6527 2929 290d 0a20 2020 203e  16-le')))..    >
-0000aa20: 3e3e 2073 7065 632e 7061 7273 6528 6227  >> spec.parse(b'
-0000aa30: 685c 7830 3065 5c78 3030 6c5c 7830 306c  h\x00e\x00l\x00l
-0000aa40: 5c78 3030 6f5c 7830 306a 6f65 2073 686d  \x00o\x00joe shm
-0000aa50: 6f65 2729 0d0a 2020 2020 436f 6e74 6169  oe')..    Contai
-0000aa60: 6e65 7228 6e61 6d65 3d75 276a 6f65 2073  ner(name=u'joe s
-0000aa70: 686d 6f65 272c 2072 6573 743d 7527 6865  hmoe', rest=u'he
-0000aa80: 6c6c 6f27 290d 0a0d 0a20 2020 2057 4152  llo')....    WAR
-0000aa90: 4e49 4e47 3a20 5468 6973 2077 696c 6c20  NING: This will 
-0000aaa0: 616c 736f 2062 7265 616b 2069 6620 796f  also break if yo
-0000aab0: 7520 7265 6164 206d 6f72 6520 6461 7461  u read more data
-0000aac0: 2074 6861 7420 6973 2062 6568 696e 6420   that is behind 
-0000aad0: 7468 6520 6375 7272 656e 7420 706f 7369  the current posi
-0000aae0: 7469 6f6e 2e0d 0a20 2020 203e 3e3e 2028  tion...    >>> (
-0000aaf0: 5365 656b 2830 2c20 6f73 2e53 4545 4b5f  Seek(0, os.SEEK_
-0000ab00: 454e 4429 203e 3e20 4261 636b 7761 7264  END) >> Backward
-0000ab10: 7328 5374 7269 6e67 2831 3029 2929 2e70  s(String(10))).p
-0000ab20: 6172 7365 2827 796f 2729 0d0a 2020 2020  arse('yo')..    
-0000ab30: 5472 6163 6562 6163 6b20 286d 6f73 7420  Traceback (most 
-0000ab40: 7265 6365 6e74 2063 616c 6c20 6c61 7374  recent call last
-0000ab50: 293a 0d0a 2020 2020 2020 2e2e 2e0d 0a20  ):..      ..... 
-0000ab60: 2020 2046 6f72 6d61 7446 6965 6c64 4572     FormatFieldEr
-0000ab70: 726f 723a 2063 6f75 6c64 206e 6f74 2072  ror: could not r
-0000ab80: 6561 6420 656e 6f75 6768 2062 7974 6573  ead enough bytes
-0000ab90: 2c20 6578 7065 6374 6564 2031 302c 2066  , expected 10, f
-0000aba0: 6f75 6e64 2032 0d0a 2020 2020 2222 220d  ound 2..    """.
-0000abb0: 0a20 2020 205f 5f73 6c6f 7473 5f5f 203d  .    __slots__ =
-0000abc0: 205b 2767 7265 6564 7927 5d0d 0a0d 0a20   ['greedy'].... 
-0000abd0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-0000abe0: 7365 6c66 2c20 7375 6263 6f6e 293a 0d0a  self, subcon):..
-0000abf0: 2020 2020 2020 2020 7375 7065 7228 4261          super(Ba
-0000ac00: 636b 7761 7264 732c 2073 656c 6629 2e5f  ckwards, self)._
-0000ac10: 5f69 6e69 745f 5f28 7375 6263 6f6e 290d  _init__(subcon).
-0000ac20: 0a20 2020 2020 2020 2023 2047 7265 6564  .        # Greed
-0000ac30: 7942 7974 6573 2061 6e64 2047 7265 6564  yBytes and Greed
-0000ac40: 7953 7472 696e 6720 6172 6520 616c 6c6f  yString are allo
-0000ac50: 7765 6420 7370 6563 6961 6c20 6361 7365  wed special case
-0000ac60: 732e 0d0a 2020 2020 2020 2020 7365 6c66  s...        self
-0000ac70: 2e67 7265 6564 7920 3d20 7365 6c66 2e73  .greedy = self.s
-0000ac80: 7562 636f 6e20 6973 2047 7265 6564 7942  ubcon is GreedyB
-0000ac90: 7974 6573 206f 7220 280d 0a20 2020 2020  ytes or (..     
-0000aca0: 2020 2020 2020 2020 2020 2069 7369 6e73             isins
-0000acb0: 7461 6e63 6528 7365 6c66 2e73 7562 636f  tance(self.subco
-0000acc0: 6e2c 2063 6f6e 7374 7275 6374 2e53 7472  n, construct.Str
-0000acd0: 696e 6745 6e63 6f64 6564 2920 616e 6420  ingEncoded) and 
-0000ace0: 7365 6c66 2e73 7562 636f 6e2e 7375 6263  self.subcon.subc
-0000acf0: 6f6e 2069 7320 4772 6565 6479 4279 7465  on is GreedyByte
-0000ad00: 7329 0d0a 0d0a 2020 2020 6465 6620 5f70  s)....    def _p
-0000ad10: 6172 7365 2873 656c 662c 2073 7472 6561  arse(self, strea
-0000ad20: 6d2c 2063 6f6e 7465 7874 2c20 7061 7468  m, context, path
-0000ad30: 293a 0d0a 2020 2020 2020 2020 2320 5365  ):..        # Se
-0000ad40: 656b 2062 6163 6b20 746f 2073 7461 7274  ek back to start
-0000ad50: 206f 6620 7375 6263 6f6e 2e0d 0a20 2020   of subcon...   
-0000ad60: 2020 2020 206f 7269 675f 706f 7320 3d20       orig_pos = 
-0000ad70: 7374 7265 616d 2e74 656c 6c28 290d 0a20  stream.tell().. 
-0000ad80: 2020 2020 2020 2069 6620 7365 6c66 2e67         if self.g
-0000ad90: 7265 6564 793a 0d0a 2020 2020 2020 2020  reedy:..        
-0000ada0: 2020 2020 7374 6172 745f 706f 7320 3d20      start_pos = 
-0000adb0: 7374 7265 616d 2e73 6565 6b28 3029 0d0a  stream.seek(0)..
-0000adc0: 2020 2020 2020 2020 2020 2020 7369 7a65              size
-0000add0: 203d 206f 7269 675f 706f 7320 2d20 7374   = orig_pos - st
-0000ade0: 6172 745f 706f 730d 0a20 2020 2020 2020  art_pos..       
-0000adf0: 2020 2020 2074 7279 3a0d 0a20 2020 2020       try:..     
-0000ae00: 2020 2020 2020 2020 2020 2073 7562 5f73             sub_s
-0000ae10: 7472 6561 6d20 3d20 696f 2e42 7974 6573  tream = io.Bytes
-0000ae20: 494f 2873 7472 6561 6d5f 7265 6164 2873  IO(stream_read(s
-0000ae30: 7472 6561 6d2c 2073 697a 6529 290d 0a20  tream, size)).. 
-0000ae40: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0000ae50: 6574 7572 6e20 7365 6c66 2e73 7562 636f  eturn self.subco
-0000ae60: 6e2e 5f70 6172 7365 7265 706f 7274 2873  n._parsereport(s
-0000ae70: 7562 5f73 7472 6561 6d2c 2063 6f6e 7465  ub_stream, conte
-0000ae80: 7874 2c20 7061 7468 290d 0a20 2020 2020  xt, path)..     
-0000ae90: 2020 2020 2020 2066 696e 616c 6c79 3a0d         finally:.
-0000aea0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000aeb0: 2073 7472 6561 6d2e 7365 656b 2873 7461   stream.seek(sta
-0000aec0: 7274 5f70 6f73 290d 0a20 2020 2020 2020  rt_pos)..       
-0000aed0: 2065 6c73 653a 0d0a 2020 2020 2020 2020   else:..        
-0000aee0: 2020 2020 7369 7a65 203d 2073 656c 662e      size = self.
-0000aef0: 7375 6263 6f6e 2e5f 7369 7a65 6f66 2863  subcon._sizeof(c
-0000af00: 6f6e 7465 7874 2c20 7061 7468 290d 0a20  ontext, path).. 
-0000af10: 2020 2020 2020 2020 2020 2073 7461 7274             start
-0000af20: 5f70 6f73 203d 2073 7472 6561 6d2e 7365  _pos = stream.se
-0000af30: 656b 2873 697a 6520 2a20 2d31 2c20 6f73  ek(size * -1, os
-0000af40: 2e53 4545 4b5f 4355 5229 0d0a 2020 2020  .SEEK_CUR)..    
-0000af50: 2020 2020 2020 2020 2320 4465 7465 726d          # Determ
-0000af60: 696e 6520 6966 2077 6520 6665 6c6c 206f  ine if we fell o
-0000af70: 6666 2074 6865 2066 726f 6e74 2e0d 0a20  ff the front... 
-0000af80: 2020 2020 2020 2020 2020 2069 6620 6f72             if or
-0000af90: 6967 5f70 6f73 202d 2073 7461 7274 5f70  ig_pos - start_p
-0000afa0: 6f73 203c 2073 697a 653a 0d0a 2020 2020  os < size:..    
-0000afb0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-0000afc0: 6520 466f 726d 6174 4669 656c 6445 7272  e FormatFieldErr
-0000afd0: 6f72 2822 636f 756c 6420 6e6f 7420 7265  or("could not re
-0000afe0: 6164 2065 6e6f 7567 6820 6279 7465 732c  ad enough bytes,
-0000aff0: 2065 7870 6563 7465 6420 2564 2c20 666f   expected %d, fo
-0000b000: 756e 6420 2564 2220 2520 2873 697a 652c  und %d" % (size,
-0000b010: 206f 7269 675f 706f 7320 2d20 7374 6172   orig_pos - star
-0000b020: 745f 706f 7329 290d 0a20 2020 2020 2020  t_pos))..       
-0000b030: 2020 2020 2074 7279 3a0d 0a20 2020 2020       try:..     
-0000b040: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-0000b050: 6e20 7365 6c66 2e73 7562 636f 6e2e 5f70  n self.subcon._p
-0000b060: 6172 7365 7265 706f 7274 2873 7472 6561  arsereport(strea
-0000b070: 6d2c 2063 6f6e 7465 7874 2c20 7061 7468  m, context, path
-0000b080: 290d 0a20 2020 2020 2020 2020 2020 2066  )..            f
-0000b090: 696e 616c 6c79 3a0d 0a20 2020 2020 2020  inally:..       
-0000b0a0: 2020 2020 2020 2020 2073 7472 6561 6d2e           stream.
-0000b0b0: 7365 656b 2873 7461 7274 5f70 6f73 290d  seek(start_pos).
-0000b0c0: 0a0d 0a20 2020 2064 6566 205f 6275 696c  ...    def _buil
-0000b0d0: 6428 7365 6c66 2c20 6f62 6a2c 2073 7472  d(self, obj, str
-0000b0e0: 6561 6d2c 2063 6f6e 7465 7874 2c20 7061  eam, context, pa
-0000b0f0: 7468 293a 0d0a 2020 2020 2020 2020 2320  th):..        # 
-0000b100: 544f 444f 3a20 4164 6420 7375 7070 6f72  TODO: Add suppor
-0000b110: 7420 666f 7220 6275 696c 6469 6e67 2e0d  t for building..
-0000b120: 0a20 2020 2020 2020 2072 6169 7365 204e  .        raise N
-0000b130: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
-0000b140: 6f72 2827 4275 696c 6469 6e67 2069 7320  or('Building is 
-0000b150: 6e6f 7420 7375 7070 6f72 7465 642e 2729  not supported.')
-0000b160: 0d0a 0d0a 0d0a 2320 4d6f 6e6b 6579 2070  ......# Monkey p
-0000b170: 6174 6368 2052 6177 436f 7079 2073 6f20  atch RawCopy so 
-0000b180: 7468 6174 2069 7420 6361 6e20 6861 6e64  that it can hand
-0000b190: 6c65 2077 6865 6e20 7765 2072 6561 6420  le when we read 
-0000b1a0: 7468 6520 7374 7265 616d 2062 6163 6b77  the stream backw
-0000b1b0: 6172 6473 2e0d 0a64 6566 205f 7061 7273  ards...def _pars
-0000b1c0: 6528 7365 6c66 2c20 7374 7265 616d 2c20  e(self, stream, 
-0000b1d0: 636f 6e74 6578 742c 2070 6174 6829 3a0d  context, path):.
-0000b1e0: 0a20 2020 206f 6666 7365 7431 203d 2073  .    offset1 = s
-0000b1f0: 7472 6561 6d2e 7465 6c6c 2829 0d0a 2020  tream.tell()..  
-0000b200: 2020 6f62 6a20 3d20 7365 6c66 2e73 7562    obj = self.sub
-0000b210: 636f 6e2e 5f70 6172 7365 7265 706f 7274  con._parsereport
-0000b220: 2873 7472 6561 6d2c 2063 6f6e 7465 7874  (stream, context
-0000b230: 2c20 7061 7468 290d 0a20 2020 206f 6666  , path)..    off
-0000b240: 7365 7432 203d 2073 7472 6561 6d2e 7465  set2 = stream.te
-0000b250: 6c6c 2829 0d0a 2020 2020 2320 5377 6170  ll()..    # Swap
-0000b260: 2069 6620 7375 6263 6f6e 2072 6561 6420   if subcon read 
-0000b270: 6261 636b 7761 7264 732e 0d0a 2020 2020  backwards...    
-0000b280: 6966 206f 6666 7365 7431 203e 206f 6666  if offset1 > off
-0000b290: 7365 7432 3a0d 0a20 2020 2020 2020 206f  set2:..        o
-0000b2a0: 6666 7365 7431 2c20 6f66 6673 6574 3220  ffset1, offset2 
-0000b2b0: 3d20 6f66 6673 6574 322c 206f 6666 7365  = offset2, offse
-0000b2c0: 7431 0d0a 2020 2020 6661 6c6c 6261 636b  t1..    fallback
-0000b2d0: 203d 2073 7472 6561 6d2e 7465 6c6c 2829   = stream.tell()
-0000b2e0: 0d0a 2020 2020 7374 7265 616d 5f73 6565  ..    stream_see
-0000b2f0: 6b28 7374 7265 616d 2c20 6f66 6673 6574  k(stream, offset
-0000b300: 3129 0d0a 2020 2020 6461 7461 203d 2073  1)..    data = s
-0000b310: 7472 6561 6d5f 7265 6164 2873 7472 6561  tream_read(strea
-0000b320: 6d2c 206f 6666 7365 7432 2d6f 6666 7365  m, offset2-offse
-0000b330: 7431 290d 0a20 2020 2073 7472 6561 6d2e  t1)..    stream.
-0000b340: 7365 656b 2866 616c 6c62 6163 6b29 0d0a  seek(fallback)..
-0000b350: 2020 2020 7265 7475 726e 2043 6f6e 7461      return Conta
-0000b360: 696e 6572 2864 6174 613d 6461 7461 2c20  iner(data=data, 
-0000b370: 7661 6c75 653d 6f62 6a2c 206f 6666 7365  value=obj, offse
-0000b380: 7431 3d6f 6666 7365 7431 2c20 6f66 6673  t1=offset1, offs
-0000b390: 6574 323d 6f66 6673 6574 322c 206c 656e  et2=offset2, len
-0000b3a0: 6774 683d 286f 6666 7365 7432 2d6f 6666  gth=(offset2-off
-0000b3b0: 7365 7431 2929 0d0a 0d0a 0d0a 636f 6e73  set1))......cons
-0000b3c0: 7472 7563 742e 5261 7743 6f70 792e 5f70  truct.RawCopy._p
-0000b3d0: 6172 7365 203d 205f 7061 7273 650d 0a0d  arse = _parse...
-0000b3e0: 0a0d 0a64 6566 2046 6f63 7573 4c61 7374  ...def FocusLast
-0000b3f0: 282a 7375 6263 6f6e 732c 202a 2a6b 7729  (*subcons, **kw)
-0000b400: 3a0d 0a20 2020 2072 2222 220d 0a20 2020  :..    r"""..   
-0000b410: 2041 2068 656c 7065 7220 666f 7220 7065   A helper for pe
-0000b420: 7266 6f72 6d69 6e67 2074 6865 2063 6f6d  rforming the com
-0000b430: 6d6f 6e20 7465 6368 6e69 7175 6520 6f66  mon technique of
-0000b440: 2075 7369 6e67 2046 6f63 7573 6564 5365   using FocusedSe
-0000b450: 7120 746f 0d0a 2020 2020 7061 7273 6520  q to..    parse 
-0000b460: 6120 6275 6e63 6820 6f66 2073 7562 636f  a bunch of subco
-0000b470: 6e73 7472 7563 7473 2061 6e64 2074 6865  nstructs and the
-0000b480: 6e20 6772 6162 2074 6865 206c 6173 7420  n grab the last 
-0000b490: 656c 656d 656e 742e 0d0a 0d0a 2020 2020  element.....    
-0000b4a0: 3e3e 3e20 466f 6375 734c 6173 7428 4279  >>> FocusLast(By
-0000b4b0: 7465 2c20 4279 7465 2c20 5374 7269 6e67  te, Byte, String
-0000b4c0: 2832 2929 2e70 6172 7365 2862 275c 7830  (2)).parse(b'\x0
-0000b4d0: 315c 7830 3268 6927 290d 0a20 2020 2075  1\x02hi')..    u
-0000b4e0: 2768 6927 0d0a 0d0a 2020 2020 3e3e 3e20  'hi'....    >>> 
-0000b4f0: 7370 6563 203d 2046 6f63 7573 4c61 7374  spec = FocusLast
-0000b500: 280d 0a20 2020 202e 2e2e 2020 2020 2027  (..    ...     '
-0000b510: 6127 202f 2042 7974 652c 0d0a 2020 2020  a' / Byte,..    
-0000b520: 2e2e 2e20 2020 2020 2762 2720 2f20 4279  ...     'b' / By
-0000b530: 7465 2c0d 0a20 2020 202e 2e2e 2020 2020  te,..    ...    
-0000b540: 2053 7472 696e 6728 7468 6973 2e61 202b   String(this.a +
-0000b550: 2074 6869 732e 6229 2c0d 0a20 2020 202e   this.b),..    .
-0000b560: 2e2e 2029 0d0a 2020 2020 3e3e 3e20 7370  .. )..    >>> sp
-0000b570: 6563 2e70 6172 7365 2862 275c 7830 315c  ec.parse(b'\x01\
-0000b580: 7830 3268 6921 2729 0d0a 2020 2020 7527  x02hi!')..    u'
-0000b590: 6869 2127 0d0a 2020 2020 3e3e 3e20 7370  hi!'..    >>> sp
-0000b5a0: 6563 2e62 7569 6c64 2875 2768 6921 272c  ec.build(u'hi!',
-0000b5b0: 2061 3d31 2c20 623d 3229 0d0a 2020 2020   a=1, b=2)..    
-0000b5c0: 275c 7830 315c 7830 3268 6921 270d 0a0d  '\x01\x02hi!'...
-0000b5d0: 0a0d 0a20 2020 2065 2e67 2e3a 0d0a 2020  ...    e.g.:..  
-0000b5e0: 2020 2020 2020 2320 5369 6d70 6c69 6669        # Simplifi
-0000b5f0: 6573 2074 6869 733a 0d0a 2020 2020 2020  es this:..      
-0000b600: 2020 636f 6e73 7472 7563 742e 466f 6375    construct.Focu
-0000b610: 7365 6453 6571 280d 0a20 2020 2020 2020  sedSeq(..       
-0000b620: 2020 2020 2027 7661 6c75 6527 2c0d 0a20       'value',.. 
-0000b630: 2020 2020 2020 2020 2020 2027 7265 2720             're' 
-0000b640: 2f20 636f 6e73 7472 7563 742e 5265 6765  / construct.Rege
-0000b650: 7828 2e2e 2c20 6f66 6673 6574 3d63 6f6e  x(.., offset=con
-0000b660: 7374 7275 6374 2e49 6e74 3332 756c 2c20  struct.Int32ul, 
-0000b670: 7369 7a65 3d63 6f6e 7374 7275 6374 2e42  size=construct.B
-0000b680: 7974 6529 2c0d 0a20 2020 2020 2020 2020  yte),..         
-0000b690: 2020 2027 7661 6c75 6527 202f 2063 6f6e     'value' / con
-0000b6a0: 7374 7275 6374 2e50 4550 6f69 6e74 6572  struct.PEPointer
-0000b6b0: 2874 6869 732e 7265 2e6f 6666 7365 742c  (this.re.offset,
-0000b6c0: 2063 6f6e 7374 7275 6374 2e42 7974 6573   construct.Bytes
-0000b6d0: 2874 6869 732e 7265 2e73 697a 6529 0d0a  (this.re.size)..
-0000b6e0: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
-0000b6f0: 2020 2023 2054 6f20 7468 6973 3a0d 0a20     # To this:.. 
-0000b700: 2020 2020 2020 2063 6f6e 7374 7275 6374         construct
-0000b710: 2e46 6f63 7573 4c61 7374 280d 0a20 2020  .FocusLast(..   
-0000b720: 2020 2020 2020 2020 2027 7265 2720 2f20           're' / 
-0000b730: 636f 6e73 7472 7563 742e 5265 6765 7828  construct.Regex(
-0000b740: 2e2e 2c20 6f66 6673 6574 3d63 6f6e 7374  .., offset=const
-0000b750: 7275 6374 2e49 6e74 3332 756c 2c20 7369  ruct.Int32ul, si
-0000b760: 7a65 3d63 6f6e 7374 7275 6374 2e42 7974  ze=construct.Byt
-0000b770: 6529 2c0d 0a20 2020 2020 2020 2020 2020  e),..           
-0000b780: 2063 6f6e 7374 7275 6374 2e50 4550 6f69   construct.PEPoi
-0000b790: 6e74 6572 2874 6869 732e 7265 2e6f 6666  nter(this.re.off
-0000b7a0: 7365 742c 2063 6f6e 7374 7275 6374 2e42  set, construct.B
-0000b7b0: 7974 6573 2874 6869 732e 7265 2e73 697a  ytes(this.re.siz
-0000b7c0: 6529 0d0a 2020 2020 2020 2020 290d 0a20  e)..        ).. 
-0000b7d0: 2020 2022 2222 0d0a 2020 2020 7265 7475     """..    retu
-0000b7e0: 726e 2046 6f63 7573 6564 5365 7128 6c65  rn FocusedSeq(le
-0000b7f0: 6e28 7375 6263 6f6e 7329 202d 2031 2c20  n(subcons) - 1, 
-0000b800: 2a73 7562 636f 6e73 2c20 2a2a 6b77 290d  *subcons, **kw).
-0000b810: 0a                                       .
+000053a0: 6f27 2c20 7365 636f 6e64 3d31 2c20 666f  o', second=1, fo
+000053b0: 7572 7468 3d32 3535 290a 0a20 2020 2049  urth=255)..    I
+000053c0: 7420 6d61 7920 616c 736f 2062 6520 7573  t may also be us
+000053d0: 6566 756c 2074 6f20 7573 6520 5061 7373  eful to use Pass
+000053e0: 206f 7220 4f70 7469 6f6e 616c 2066 6f72   or Optional for
+000053f0: 2066 6965 6c64 7320 7468 6174 206d 6179   fields that may
+00005400: 206e 6f74 2065 7869 7374 2e0a 2020 2020   not exist..    
+00005410: 3e3e 3e20 7370 6563 203d 2044 656c 696d  >>> spec = Delim
+00005420: 6974 6564 2862 277c 272c 0a20 2020 202e  ited(b'|',.    .
+00005430: 2e2e 2020 2020 2027 6669 7273 7427 202f  ..     'first' /
+00005440: 2043 5374 7269 6e67 2829 2c0a 2020 2020   CString(),.    
+00005450: 2e2e 2e20 2020 2020 2773 6563 6f6e 6427  ...     'second'
+00005460: 202f 2050 6173 732c 0a20 2020 202e 2e2e   / Pass,.    ...
+00005470: 2020 2020 2027 7468 6972 6427 202f 204f       'third' / O
+00005480: 7074 696f 6e61 6c28 496e 7433 3275 6c29  ptional(Int32ul)
+00005490: 0a20 2020 202e 2e2e 2029 0a20 2020 203e  .    ... ).    >
+000054a0: 3e3e 2073 7065 632e 7061 7273 6528 6227  >> spec.parse(b'
+000054b0: 4865 6c6c 6f5c 7830 305c 7830 307c 646f  Hello\x00\x00|do
+000054c0: 6e74 2063 6172 657c 5c78 3031 5c78 3030  nt care|\x01\x00
+000054d0: 5c78 3030 5c78 3030 2729 0a20 2020 2043  \x00\x00').    C
+000054e0: 6f6e 7461 696e 6572 2866 6972 7374 3d75  ontainer(first=u
+000054f0: 2748 656c 6c6f 272c 2073 6563 6f6e 643d  'Hello', second=
+00005500: 4e6f 6e65 2c20 7468 6972 643d 3129 0a20  None, third=1). 
+00005510: 2020 203e 3e3e 2073 7065 632e 7061 7273     >>> spec.pars
+00005520: 6528 6227 4865 6c6c 6f5c 7830 305c 7830  e(b'Hello\x00\x0
+00005530: 307c 7c27 290a 2020 2020 436f 6e74 6169  0||').    Contai
+00005540: 6e65 7228 6669 7273 743d 7527 4865 6c6c  ner(first=u'Hell
+00005550: 6f27 2c20 7365 636f 6e64 3d4e 6f6e 652c  o', second=None,
+00005560: 2074 6869 7264 3d4e 6f6e 6529 0a0a 2020   third=None)..  
+00005570: 2020 6465 6c69 6d69 7465 7273 206d 6179    delimiters may
+00005580: 2068 6176 6520 6120 6c65 6e67 7468 203e   have a length >
+00005590: 2031 0a20 2020 203e 3e3e 2073 7065 6320   1.    >>> spec 
+000055a0: 3d20 4465 6c69 6d69 7465 6428 6227 594f  = Delimited(b'YO
+000055b0: 594f 272c 0a20 2020 202e 2e2e 2020 2020  YO',.    ...    
+000055c0: 2027 6669 7273 7427 202f 2043 5374 7269   'first' / CStri
+000055d0: 6e67 2829 2c0a 2020 2020 2e2e 2e20 2020  ng(),.    ...   
+000055e0: 2020 2773 6563 6f6e 6427 202f 2049 6e74    'second' / Int
+000055f0: 3332 756c 2c0a 2020 2020 2e2e 2e20 2020  32ul,.    ...   
+00005600: 2020 2320 5768 656e 2075 7369 6e67 2061    # When using a
+00005610: 2047 7265 6564 7920 636f 6e73 7472 7563   Greedy construc
+00005620: 742c 2065 6974 6865 7220 616c 6c20 6461  t, either all da
+00005630: 7461 2074 696c 6c20 454f 4620 6f72 2074  ta till EOF or t
+00005640: 6865 206e 6578 7420 6465 6c69 6d69 7465  he next delimite
+00005650: 7220 7769 6c6c 2062 6520 636f 6e73 756d  r will be consum
+00005660: 6564 2e0a 2020 2020 2e2e 2e20 2020 2020  ed..    ...     
+00005670: 2774 6869 7264 2720 2f20 4772 6565 6479  'third' / Greedy
+00005680: 4279 7465 732c 0a20 2020 202e 2e2e 2020  Bytes,.    ...  
+00005690: 2020 2027 666f 7572 7468 2720 2f20 4279     'fourth' / By
+000056a0: 7465 0a20 2020 202e 2e2e 2029 0a20 2020  te.    ... ).   
+000056b0: 203e 3e3e 2073 7065 632e 7061 7273 6528   >>> spec.parse(
+000056c0: 6227 4865 6c6c 6f5c 7830 305c 7830 3059  b'Hello\x00\x00Y
+000056d0: 4f59 4f5c 7830 315c 7830 305c 7830 305c  OYO\x01\x00\x00\
+000056e0: 7830 3059 4f59 4f77 6f72 6c64 2121 594f  x00YOYOworld!!YO
+000056f0: 2121 5c78 3031 5c78 3032 594f 594f 5c78  !!\x01\x02YOYO\x
+00005700: 6666 2729 0a20 2020 2043 6f6e 7461 696e  ff').    Contain
+00005710: 6572 2866 6972 7374 3d75 2748 656c 6c6f  er(first=u'Hello
+00005720: 272c 2073 6563 6f6e 643d 312c 2074 6869  ', second=1, thi
+00005730: 7264 3d62 2777 6f72 6c64 2121 594f 2121  rd=b'world!!YO!!
+00005740: 5c78 3031 5c78 3032 272c 2066 6f75 7274  \x01\x02', fourt
+00005750: 683d 3235 3529 0a20 2020 203e 3e3e 2073  h=255).    >>> s
+00005760: 7065 632e 6275 696c 6428 6469 6374 2866  pec.build(dict(f
+00005770: 6972 7374 3d75 2748 656c 6c6f 272c 2073  irst=u'Hello', s
+00005780: 6563 6f6e 643d 312c 2074 6869 7264 3d62  econd=1, third=b
+00005790: 2777 6f72 6c64 2121 594f 2121 5c78 3031  'world!!YO!!\x01
+000057a0: 5c78 3032 272c 2066 6f75 7274 683d 3235  \x02', fourth=25
+000057b0: 3529 290a 2020 2020 2748 656c 6c6f 5c78  5)).    'Hello\x
+000057c0: 3030 594f 594f 5c78 3031 5c78 3030 5c78  00YOYO\x01\x00\x
+000057d0: 3030 5c78 3030 594f 594f 776f 726c 6421  00\x00YOYOworld!
+000057e0: 2159 4f21 215c 7830 315c 7830 3259 4f59  !YO!!\x01\x02YOY
+000057f0: 4f5c 7866 6627 0a0a 2020 2020 2320 544f  O\xff'..    # TO
+00005800: 444f 3a20 4164 6420 7375 7070 6f72 7420  DO: Add support 
+00005810: 666f 7220 7573 696e 6720 6120 7369 6e67  for using a sing
+00005820: 6c65 2063 6f6e 7374 7275 6374 2066 6f72  le construct for
+00005830: 2070 6172 7369 6e67 2061 6e20 756e 6b6e   parsing an unkn
+00005840: 6f77 6e20 6e75 6d62 6572 206f 6620 7469  own number of ti
+00005850: 6d65 730a 2020 2020 2320 286f 7220 7769  mes.    # (or wi
+00005860: 7468 696e 2061 206d 696e 2c20 6d61 782c  thin a min, max,
+00005870: 206f 7220 6578 6163 7429 0a20 2020 2023   or exact).    #
+00005880: 2028 5065 7268 6170 7320 6361 6c6c 2069   (Perhaps call i
+00005890: 7420 2253 706c 6974 2220 746f 2061 766f  t "Split" to avo
+000058a0: 6964 206f 7665 726c 6f61 6469 6e67 2074  id overloading t
+000058b0: 6f6f 206d 7563 6820 6675 6e63 7469 6f6e  oo much function
+000058c0: 616c 6974 792e 290a 2020 2020 2320 652e  ality.).    # e.
+000058d0: 672e 0a20 2020 2023 203e 3e3e 2073 7065  g..    # >>> spe
+000058e0: 6320 3d20 4465 6c69 6d69 7465 6428 6227  c = Delimited(b'
+000058f0: 7c27 2c20 4772 6565 6479 5374 7269 6e67  |', GreedyString
+00005900: 2829 290a 2020 2020 2320 3e3e 3e20 7370  ()).    # >>> sp
+00005910: 6563 2e70 6172 7365 2862 2768 656c 6c6f  ec.parse(b'hello
+00005920: 7c77 6f72 6c64 2729 0a20 2020 2023 205b  |world').    # [
+00005930: 2768 656c 6c6f 272c 2027 776f 726c 6427  'hello', 'world'
+00005940: 5d0a 2020 2020 2320 3e3e 3e20 7370 6563  ].    # >>> spec
+00005950: 2e70 6172 7365 2862 2768 656c 6c6f 7c77  .parse(b'hello|w
+00005960: 6f72 6c64 7c68 697c 626f 6227 290a 2020  orld|hi|bob').  
+00005970: 2020 2320 5b27 6865 6c6c 6f27 2c20 2777    # ['hello', 'w
+00005980: 6f72 6c64 272c 2027 6869 272c 2027 626f  orld', 'hi', 'bo
+00005990: 6227 5d0a 2020 2020 2320 3e3e 3e20 7370  b'].    # >>> sp
+000059a0: 6563 2e70 6172 7365 2862 2768 656c 6c6f  ec.parse(b'hello
+000059b0: 2729 0a20 2020 2023 205b 2768 656c 6c6f  ').    # ['hello
+000059c0: 275d 0a20 2020 2022 2222 0a0a 2020 2020  '].    """..    
+000059d0: 5f5f 736c 6f74 735f 5f20 3d20 5b27 6465  __slots__ = ['de
+000059e0: 6c69 6d69 7465 7227 2c20 2773 7562 636f  limiter', 'subco
+000059f0: 6e73 275d 0a0a 2020 2020 6465 6620 5f5f  ns']..    def __
+00005a00: 696e 6974 5f5f 2873 656c 662c 2064 656c  init__(self, del
+00005a10: 696d 6974 6572 2c20 2a73 7562 636f 6e73  imiter, *subcons
+00005a20: 293a 0a20 2020 2020 2020 2022 2222 0a20  ):.        """. 
+00005a30: 2020 2020 2020 203a 7061 7261 6d20 6465         :param de
+00005a40: 6c69 6d69 7465 723a 2073 696e 676c 6520  limiter: single 
+00005a50: 6368 6172 6163 746f 7220 6f72 2061 2066  charactor or a f
+00005a60: 756e 6374 696f 6e20 7468 6174 2074 616b  unction that tak
+00005a70: 6573 2063 6f6e 7465 7874 2061 6e64 2072  es context and r
+00005a80: 6574 7572 6e73 2074 6865 2064 656c 696d  eturns the delim
+00005a90: 6974 6572 0a20 2020 2020 2020 203a 7061  iter.        :pa
+00005aa0: 7261 6d20 7375 6263 6f6e 733a 2063 6f6e  ram subcons: con
+00005ab0: 7374 7275 6374 7320 746f 2075 7365 2074  structs to use t
+00005ac0: 6f20 7061 7273 6520 6561 6368 2065 6c65  o parse each ele
+00005ad0: 6d65 6e74 2e0a 2020 2020 2020 2020 2020  ment..          
+00005ae0: 2020 2020 2020 2020 2020 4e4f 5445 3a20            NOTE: 
+00005af0: 5468 6520 6e75 6d62 6572 206f 6620 636f  The number of co
+00005b00: 6e73 7472 7563 7473 2077 696c 6c20 6265  nstructs will be
+00005b10: 2074 6865 206e 756d 6265 7220 6f66 2065   the number of e
+00005b20: 6c65 6d65 6e74 7320 6465 6c69 6d69 7465  lements delimite
+00005b30: 642e 0a20 2020 2020 2020 2020 2020 2020  d..             
+00005b40: 2020 2020 2020 2028 6965 2e20 6c65 6e28         (ie. len(
+00005b50: 7375 6263 6f6e 7329 203d 3d20 6e75 6d62  subcons) == numb
+00005b60: 6572 206f 6620 6465 6c69 6d69 7465 7273  er of delimiters
+00005b70: 202b 2031 290a 0a20 2020 2020 2020 203a   + 1)..        :
+00005b80: 7261 6973 6573 2056 616c 7565 4572 726f  raises ValueErro
+00005b90: 723a 2049 6620 6e6f 2073 7562 636f 6e73  r: If no subcons
+00005ba0: 2061 7265 2064 6566 696e 6564 2e0a 2020   are defined..  
+00005bb0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+00005bc0: 2020 7375 7065 7228 4465 6c69 6d69 7465    super(Delimite
+00005bd0: 642c 2073 656c 6629 2e5f 5f69 6e69 745f  d, self).__init_
+00005be0: 5f28 290a 2020 2020 2020 2020 7365 6c66  _().        self
+00005bf0: 2e64 656c 696d 6974 6572 203d 2064 656c  .delimiter = del
+00005c00: 696d 6974 6572 0a20 2020 2020 2020 2073  imiter.        s
+00005c10: 656c 662e 7375 6263 6f6e 7320 3d20 7375  elf.subcons = su
+00005c20: 6263 6f6e 730a 2020 2020 2020 2020 6966  bcons.        if
+00005c30: 206c 656e 2873 7562 636f 6e73 2920 3c20   len(subcons) < 
+00005c40: 323a 0a20 2020 2020 2020 2020 2020 2072  2:.            r
+00005c50: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+00005c60: 2741 7420 6c65 6173 7420 7477 6f20 7375  'At least two su
+00005c70: 6263 6f6e 7374 7275 6374 206d 7573 7420  bconstruct must 
+00005c80: 6265 2064 6566 696e 6564 2e27 290a 0a20  be defined.').. 
+00005c90: 2020 2064 6566 205f 6669 6e64 5f64 656c     def _find_del
+00005ca0: 696d 6974 6572 2873 656c 662c 2073 7472  imiter(self, str
+00005cb0: 6561 6d2c 2064 656c 696d 6974 6572 293a  eam, delimiter):
+00005cc0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00005cd0: 2020 2020 2046 696e 6473 2067 6976 656e       Finds given
+00005ce0: 2064 656c 696d 6974 6572 2069 6e20 7374   delimiter in st
+00005cf0: 7265 616d 2e0a 0a20 2020 2020 2020 203a  ream...        :
+00005d00: 7265 7475 726e 733a 2053 7472 6561 6d20  returns: Stream 
+00005d10: 6f66 6673 6574 2066 6f72 2064 656c 696d  offset for delim
+00005d20: 6974 6572 2e0a 2020 2020 2020 2020 3a72  iter..        :r
+00005d30: 6169 7365 7320 436f 6e73 7472 7563 7445  aises ConstructE
+00005d40: 7272 6f72 3a20 4966 2064 656c 696d 6974  rror: If delimit
+00005d50: 6572 2069 736e 2774 2066 6f75 6e64 2e0a  er isn't found..
+00005d60: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+00005d70: 2020 2020 6661 6c6c 6261 636b 203d 2073      fallback = s
+00005d80: 7472 6561 6d2e 7465 6c6c 2829 0a20 2020  tream.tell().   
+00005d90: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
+00005da0: 2020 2020 2020 666f 7220 6279 7465 2069        for byte i
+00005db0: 6e20 6974 6572 286c 616d 6264 613a 2073  n iter(lambda: s
+00005dc0: 7472 6561 6d2e 7265 6164 2831 292c 2062  tream.read(1), b
+00005dd0: 2727 293a 0a20 2020 2020 2020 2020 2020  ''):.           
+00005de0: 2020 2020 2069 6620 6465 6c69 6d69 7465       if delimite
+00005df0: 725b 305d 203d 3d20 6f72 6428 6279 7465  r[0] == ord(byte
+00005e00: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+00005e10: 2020 2020 2020 2064 656c 696d 6974 6572         delimiter
+00005e20: 5f6f 6666 7365 7420 3d20 7374 7265 616d  _offset = stream
+00005e30: 2e73 6565 6b28 2d31 2c20 6f73 2e53 4545  .seek(-1, os.SEE
+00005e40: 4b5f 4355 5229 0a20 2020 2020 2020 2020  K_CUR).         
+00005e50: 2020 2020 2020 2020 2020 2069 6620 7374             if st
+00005e60: 7265 616d 2e72 6561 6428 6c65 6e28 6465  ream.read(len(de
+00005e70: 6c69 6d69 7465 7229 2920 3d3d 2064 656c  limiter)) == del
+00005e80: 696d 6974 6572 3a0a 2020 2020 2020 2020  imiter:.        
+00005e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005ea0: 7265 7475 726e 2064 656c 696d 6974 6572  return delimiter
+00005eb0: 5f6f 6666 7365 740a 2020 2020 2020 2020  _offset.        
+00005ec0: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00005ed0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00005ee0: 2020 2020 2020 2020 2020 7374 7265 616d            stream
+00005ef0: 2e73 6565 6b28 6465 6c69 6d69 7465 725f  .seek(delimiter_
+00005f00: 6f66 6673 6574 202b 2031 290a 2020 2020  offset + 1).    
+00005f10: 2020 2020 2020 2020 7261 6973 6520 436f          raise Co
+00005f20: 6e73 7472 7563 7445 7272 6f72 2827 556e  nstructError('Un
+00005f30: 6162 6c65 2074 6f20 6669 6e64 2064 656c  able to find del
+00005f40: 696d 6974 6572 3a20 7b7d 272e 666f 726d  imiter: {}'.form
+00005f50: 6174 2864 656c 696d 6974 6572 2929 0a20  at(delimiter)). 
+00005f60: 2020 2020 2020 2066 696e 616c 6c79 3a0a         finally:.
+00005f70: 2020 2020 2020 2020 2020 2020 7374 7265              stre
+00005f80: 616d 2e73 6565 6b28 6661 6c6c 6261 636b  am.seek(fallback
+00005f90: 290a 0a20 2020 2064 6566 205f 7061 7273  )..    def _pars
+00005fa0: 655f 7375 6263 6f6e 2873 656c 662c 2073  e_subcon(self, s
+00005fb0: 7562 636f 6e2c 2073 7472 6561 6d2c 206f  ubcon, stream, o
+00005fc0: 626a 2c20 636f 6e74 6578 742c 2070 6174  bj, context, pat
+00005fd0: 6829 3a0a 2020 2020 2020 2020 2222 2250  h):.        """P
+00005fe0: 6172 7365 7320 616e 6420 6669 6c6c 7320  arses and fills 
+00005ff0: 6f62 6a20 616e 6420 636f 6e74 6578 742e  obj and context.
+00006000: 2222 220a 2020 2020 2020 2020 7375 626f  """.        subo
+00006010: 626a 203d 2073 7562 636f 6e2e 5f70 6172  bj = subcon._par
+00006020: 7365 7265 706f 7274 2873 7472 6561 6d2c  sereport(stream,
+00006030: 2063 6f6e 7465 7874 2c20 7061 7468 290a   context, path).
+00006040: 2020 2020 2020 2020 6966 2073 7562 636f          if subco
+00006050: 6e2e 666c 6167 656d 6265 6464 6564 3a0a  n.flagembedded:.
+00006060: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00006070: 7562 6f62 6a20 6973 206e 6f74 204e 6f6e  ubobj is not Non
+00006080: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00006090: 2020 206f 626a 2e75 7064 6174 6528 7375     obj.update(su
+000060a0: 626f 626a 2e69 7465 6d73 2829 290a 2020  bobj.items()).  
+000060b0: 2020 2020 2020 2020 2020 2020 2020 636f                co
+000060c0: 6e74 6578 742e 7570 6461 7465 2873 7562  ntext.update(sub
+000060d0: 6f62 6a2e 6974 656d 7328 2929 0a20 2020  obj.items()).   
+000060e0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+000060f0: 2020 2020 2020 2069 6620 7375 6263 6f6e         if subcon
+00006100: 2e6e 616d 6520 6973 206e 6f74 204e 6f6e  .name is not Non
+00006110: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00006120: 2020 206f 626a 5b73 7562 636f 6e2e 6e61     obj[subcon.na
+00006130: 6d65 5d20 3d20 7375 626f 626a 0a20 2020  me] = subobj.   
+00006140: 2020 2020 2020 2020 2020 2020 2063 6f6e               con
+00006150: 7465 7874 5b73 7562 636f 6e2e 6e61 6d65  text[subcon.name
+00006160: 5d20 3d20 7375 626f 626a 0a0a 2020 2020  ] = subobj..    
+00006170: 6465 6620 5f70 6172 7365 2873 656c 662c  def _parse(self,
+00006180: 2073 7472 6561 6d2c 2063 6f6e 7465 7874   stream, context
+00006190: 2c20 7061 7468 293a 0a20 2020 2020 2020  , path):.       
+000061a0: 2064 656c 696d 6974 6572 203d 2073 656c   delimiter = sel
+000061b0: 662e 6465 6c69 6d69 7465 7228 636f 6e74  f.delimiter(cont
+000061c0: 6578 7429 2069 6620 6361 6c6c 6162 6c65  ext) if callable
+000061d0: 2873 656c 662e 6465 6c69 6d69 7465 7229  (self.delimiter)
+000061e0: 2065 6c73 6520 7365 6c66 2e64 656c 696d   else self.delim
+000061f0: 6974 6572 0a20 2020 2020 2020 2069 6620  iter.        if 
+00006200: 6e6f 7420 6973 696e 7374 616e 6365 2864  not isinstance(d
+00006210: 656c 696d 6974 6572 2c20 6279 7465 7374  elimiter, bytest
+00006220: 7269 6e67 7479 7065 2920 6f72 206e 6f74  ringtype) or not
+00006230: 2064 656c 696d 6974 6572 3a0a 2020 2020   delimiter:.    
+00006240: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+00006250: 6c75 6545 7272 6f72 2827 496e 7661 6c69  lueError('Invali
+00006260: 6420 6465 6c69 6d69 7465 722e 2729 0a0a  d delimiter.')..
+00006270: 2020 2020 2020 2020 6f62 6a20 3d20 436f          obj = Co
+00006280: 6e74 6169 6e65 7228 290a 2020 2020 2020  ntainer().      
+00006290: 2020 636f 6e74 6578 7420 3d20 436f 6e74    context = Cont
+000062a0: 6169 6e65 7228 5f3d 636f 6e74 6578 7429  ainer(_=context)
+000062b0: 0a0a 2020 2020 2020 2020 2320 5061 7273  ..        # Pars
+000062c0: 6520 616c 6c20 6275 7420 7468 6520 6c61  e all but the la
+000062d0: 7374 2065 6c65 6d65 6e74 2e0a 2020 2020  st element..    
+000062e0: 2020 2020 666f 7220 7363 2069 6e20 7365      for sc in se
+000062f0: 6c66 2e73 7562 636f 6e73 5b3a 2d31 5d3a  lf.subcons[:-1]:
+00006300: 0a20 2020 2020 2020 2020 2020 2023 2044  .            # D
+00006310: 6f6e 2774 2063 6f75 6e74 2070 726f 6265  on't count probe
+00006320: 7320 6173 2061 6e20 656c 656d 656e 742e  s as an element.
+00006330: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00006340: 6973 696e 7374 616e 6365 2873 632c 2050  isinstance(sc, P
+00006350: 726f 6265 293a 0a20 2020 2020 2020 2020  robe):.         
+00006360: 2020 2020 2020 2073 632e 5f70 6172 7365         sc._parse
+00006370: 7265 706f 7274 2873 7472 6561 6d2c 2063  report(stream, c
+00006380: 6f6e 7465 7874 2c20 7061 7468 290a 2020  ontext, path).  
+00006390: 2020 2020 2020 2020 2020 2020 2020 636f                co
+000063a0: 6e74 696e 7565 0a0a 2020 2020 2020 2020  ntinue..        
+000063b0: 2020 2020 6465 6c69 6d69 7465 725f 6f66      delimiter_of
+000063c0: 6673 6574 203d 2073 656c 662e 5f66 696e  fset = self._fin
+000063d0: 645f 6465 6c69 6d69 7465 7228 7374 7265  d_delimiter(stre
+000063e0: 616d 2c20 6465 6c69 6d69 7465 7229 0a0a  am, delimiter)..
+000063f0: 2020 2020 2020 2020 2020 2020 2320 5465              # Te
+00006400: 6d70 6f72 6169 6c79 2066 616b 6520 7468  mporaily fake th
+00006410: 6520 7265 6164 2829 2073 6f20 7468 6174  e read() so that
+00006420: 2077 6520 6361 6e20 666f 7263 6520 454f   we can force EO
+00006430: 4620 6265 666f 7265 2064 656c 696d 6974  F before delimit
+00006440: 6572 2e0a 2020 2020 2020 2020 2020 2020  er..            
+00006450: 6f72 6967 5f72 6561 6420 3d20 7374 7265  orig_read = stre
+00006460: 616d 2e72 6561 640a 2020 2020 2020 2020  am.read.        
+00006470: 2020 2020 6465 6620 6e65 775f 7265 6164      def new_read
+00006480: 2873 697a 653d 4e6f 6e65 293a 0a20 2020  (size=None):.   
+00006490: 2020 2020 2020 2020 2020 2020 206d 6178               max
+000064a0: 5f73 697a 6520 3d20 6465 6c69 6d69 7465  _size = delimite
+000064b0: 725f 6f66 6673 6574 202d 2073 7472 6561  r_offset - strea
+000064c0: 6d2e 7465 6c6c 2829 0a20 2020 2020 2020  m.tell().       
+000064d0: 2020 2020 2020 2020 2069 6620 7369 7a65           if size
+000064e0: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+000064f0: 2020 2020 2020 2020 2020 2020 2020 7369                si
+00006500: 7a65 203d 206d 6178 5f73 697a 650a 2020  ze = max_size.  
+00006510: 2020 2020 2020 2020 2020 2020 2020 656c                el
+00006520: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+00006530: 2020 2020 2020 2020 7369 7a65 203d 206d          size = m
+00006540: 696e 286d 6178 5f73 697a 652c 2073 697a  in(max_size, siz
+00006550: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+00006560: 2020 2072 6574 7572 6e20 6f72 6967 5f72     return orig_r
+00006570: 6561 6428 7369 7a65 290a 2020 2020 2020  ead(size).      
+00006580: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
+00006590: 2020 2020 2020 2020 2020 2073 7472 6561             strea
+000065a0: 6d2e 7265 6164 203d 206e 6577 5f72 6561  m.read = new_rea
+000065b0: 640a 2020 2020 2020 2020 2020 2020 2020  d.              
+000065c0: 2020 7365 6c66 2e5f 7061 7273 655f 7375    self._parse_su
+000065d0: 6263 6f6e 2873 632c 2073 7472 6561 6d2c  bcon(sc, stream,
+000065e0: 206f 626a 2c20 636f 6e74 6578 742c 2070   obj, context, p
+000065f0: 6174 6829 0a20 2020 2020 2020 2020 2020  ath).           
+00006600: 2066 696e 616c 6c79 3a0a 2020 2020 2020   finally:.      
+00006610: 2020 2020 2020 2020 2020 7374 7265 616d            stream
+00006620: 2e72 6561 6420 3d20 6f72 6967 5f72 6561  .read = orig_rea
+00006630: 640a 0a20 2020 2020 2020 2020 2020 2023  d..            #
+00006640: 2041 6c69 676e 2074 6f20 6166 7465 7220   Align to after 
+00006650: 6465 6c69 6d69 7465 720a 2020 2020 2020  delimiter.      
+00006660: 2020 2020 2020 7374 7265 616d 2e73 6565        stream.see
+00006670: 6b28 6465 6c69 6d69 7465 725f 6f66 6673  k(delimiter_offs
+00006680: 6574 202b 206c 656e 2864 656c 696d 6974  et + len(delimit
+00006690: 6572 2929 0a0a 2020 2020 2020 2020 2320  er))..        # 
+000066a0: 5061 7273 6520 7468 6520 6c61 7374 2065  Parse the last e
+000066b0: 6c65 6d65 6e74 2e0a 2020 2020 2020 2020  lement..        
+000066c0: 7365 6c66 2e5f 7061 7273 655f 7375 6263  self._parse_subc
+000066d0: 6f6e 2873 656c 662e 7375 6263 6f6e 735b  on(self.subcons[
+000066e0: 2d31 5d2c 2073 7472 6561 6d2c 206f 626a  -1], stream, obj
+000066f0: 2c20 636f 6e74 6578 742c 2070 6174 6829  , context, path)
+00006700: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00006710: 206f 626a 0a0a 2020 2020 6465 6620 5f62   obj..    def _b
+00006720: 7569 6c64 2873 656c 662c 206f 626a 2c20  uild(self, obj, 
+00006730: 7374 7265 616d 2c20 636f 6e74 6578 742c  stream, context,
+00006740: 2070 6174 6829 3a0a 2020 2020 2020 2020   path):.        
+00006750: 6465 6c69 6d69 7465 7220 3d20 7365 6c66  delimiter = self
+00006760: 2e64 656c 696d 6974 6572 2863 6f6e 7465  .delimiter(conte
+00006770: 7874 2920 6966 2063 616c 6c61 626c 6528  xt) if callable(
+00006780: 7365 6c66 2e64 656c 696d 6974 6572 2920  self.delimiter) 
+00006790: 656c 7365 2073 656c 662e 6465 6c69 6d69  else self.delimi
+000067a0: 7465 720a 2020 2020 2020 2020 6966 206e  ter.        if n
+000067b0: 6f74 2069 7369 6e73 7461 6e63 6528 6465  ot isinstance(de
+000067c0: 6c69 6d69 7465 722c 2062 7974 6573 7472  limiter, bytestr
+000067d0: 696e 6774 7970 6529 206f 7220 6e6f 7420  ingtype) or not 
+000067e0: 6465 6c69 6d69 7465 723a 0a20 2020 2020  delimiter:.     
+000067f0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+00006800: 7565 4572 726f 7228 2749 6e76 616c 6964  ueError('Invalid
+00006810: 2064 656c 696d 6974 6572 2e27 290a 0a20   delimiter.').. 
+00006820: 2020 2020 2020 2063 6f6e 7465 7874 203d         context =
+00006830: 2043 6f6e 7461 696e 6572 285f 3d63 6f6e   Container(_=con
+00006840: 7465 7874 290a 2020 2020 2020 2020 636f  text).        co
+00006850: 6e74 6578 742e 7570 6461 7465 286f 626a  ntext.update(obj
+00006860: 290a 2020 2020 2020 2020 666f 7220 692c  ).        for i,
+00006870: 2073 6320 696e 2065 6e75 6d65 7261 7465   sc in enumerate
+00006880: 2873 656c 662e 7375 6263 6f6e 7329 3a0a  (self.subcons):.
+00006890: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+000068a0: 632e 666c 6167 656d 6265 6464 6564 3a0a  c.flagembedded:.
+000068b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000068c0: 7375 626f 626a 203d 206f 626a 0a20 2020  subobj = obj.   
+000068d0: 2020 2020 2020 2020 2065 6c69 6620 7363           elif sc
+000068e0: 2e66 6c61 6762 7569 6c64 6e6f 6e65 3a0a  .flagbuildnone:.
+000068f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006900: 7375 626f 626a 203d 206f 626a 2e67 6574  subobj = obj.get
+00006910: 2873 632e 6e61 6d65 2c20 4e6f 6e65 290a  (sc.name, None).
+00006920: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00006930: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00006940: 2020 7375 626f 626a 203d 206f 626a 5b73    subobj = obj[s
+00006950: 632e 6e61 6d65 5d0a 2020 2020 2020 2020  c.name].        
+00006960: 2020 2020 6275 696c 6472 6574 203d 2073      buildret = s
+00006970: 632e 5f62 7569 6c64 2873 7562 6f62 6a2c  c._build(subobj,
+00006980: 2073 7472 6561 6d2c 2063 6f6e 7465 7874   stream, context
+00006990: 2c20 7061 7468 290a 2020 2020 2020 2020  , path).        
+000069a0: 2020 2020 6966 2062 7569 6c64 7265 7420      if buildret 
+000069b0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
+000069c0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+000069d0: 7363 2e66 6c61 6765 6d62 6564 6465 643a  sc.flagembedded:
+000069e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000069f0: 2020 2020 2063 6f6e 7465 7874 2e75 7064       context.upd
+00006a00: 6174 6528 6275 696c 6472 6574 290a 2020  ate(buildret).  
+00006a10: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00006a20: 2073 632e 6e61 6d65 2069 7320 6e6f 7420   sc.name is not 
+00006a30: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+00006a40: 2020 2020 2020 2020 2020 636f 6e74 6578            contex
+00006a50: 745b 7363 2e6e 616d 655d 203d 2062 7569  t[sc.name] = bui
+00006a60: 6c64 7265 740a 2020 2020 2020 2020 2020  ldret.          
+00006a70: 2020 2320 4164 6420 6465 6c69 6d69 7465    # Add delimite
+00006a80: 7220 6966 206e 6f74 206c 6173 7420 656c  r if not last el
+00006a90: 656d 656e 7420 616e 6420 6e6f 7420 5072  ement and not Pr
+00006aa0: 6f62 652e 0a20 2020 2020 2020 2020 2020  obe..           
+00006ab0: 2069 6620 6920 3c20 6c65 6e28 7365 6c66   if i < len(self
+00006ac0: 2e73 7562 636f 6e73 2920 2d20 3120 616e  .subcons) - 1 an
+00006ad0: 6420 6e6f 7420 6973 696e 7374 616e 6365  d not isinstance
+00006ae0: 2873 632c 2050 726f 6265 293a 0a20 2020  (sc, Probe):.   
+00006af0: 2020 2020 2020 2020 2020 2020 2073 7472               str
+00006b00: 6561 6d2e 7772 6974 6528 6465 6c69 6d69  eam.write(delimi
+00006b10: 7465 7229 0a20 2020 2020 2020 2072 6574  ter).        ret
+00006b20: 7572 6e20 636f 6e74 6578 740a 0a0a 636c  urn context...cl
+00006b30: 6173 7320 5265 6765 7828 436f 6e73 7472  ass Regex(Constr
+00006b40: 7563 7429 3a0a 2020 2020 7222 2222 0a20  uct):.    r""". 
+00006b50: 2020 2041 2063 6f6e 7374 7275 6374 2064     A construct d
+00006b60: 6573 6967 6e65 6420 6c6f 6f6b 2066 6f72  esigned look for
+00006b70: 2074 6865 2066 6972 7374 206d 6174 6368   the first match
+00006b80: 2066 6f72 2074 6865 2067 6976 656e 2072   for the given r
+00006b90: 6567 6578 2c20 7468 656e 2070 6172 7365  egex, then parse
+00006ba0: 2074 6865 2064 6174 6120 636f 6c6c 6563   the data collec
+00006bb0: 7465 6420 696e 2074 6865 2067 726f 7570  ted in the group
+00006bc0: 732e 0a20 2020 2052 6574 7572 6e73 2074  s..    Returns t
+00006bd0: 6865 206d 6174 6368 6564 2063 6170 7475  he matched captu
+00006be0: 7265 2067 726f 7570 7320 696e 2061 7474  re groups in att
+00006bf0: 7269 6275 7465 7320 6261 7365 6420 6f6e  ributes based on
+00006c00: 2074 6865 6972 2072 6573 7065 6374 6976   their respectiv
+00006c10: 6520 6e61 6d65 732e 0a20 2020 2049 6620  e names..    If 
+00006c20: 6120 7375 6263 6f6e 7374 7275 6374 2069  a subconstruct i
+00006c30: 7320 6465 6669 6e65 6420 666f 7220 6120  s defined for a 
+00006c40: 6772 6f75 702c 2069 7420 7769 6c6c 2072  group, it will r
+00006c50: 756e 2074 6861 7420 636f 6e73 7472 7563  un that construc
+00006c60: 7420 6f6e 2074 6861 7420 7061 7274 6963  t on that partic
+00006c70: 756c 6172 2070 6965 6365 206f 6620 6461  ular piece of da
+00006c80: 7461 2e0a 0a20 2020 204e 4f54 453a 2054  ta...    NOTE: T
+00006c90: 6865 2073 7562 636f 6e73 7472 7563 7420  he subconstruct 
+00006ca0: 7769 6c6c 2072 756e 206f 6e20 7468 6520  will run on the 
+00006cb0: 6461 7461 2061 7320 6966 2069 7320 7468  data as if is th
+00006cc0: 6520 6f6e 6c79 2064 6174 6120 7468 6174  e only data that
+00006cd0: 2065 7869 7374 732e 2054 6865 7265 666f   exists. Therefo
+00006ce0: 7265 2c20 7573 696e 6720 5365 656b 2061  re, using Seek a
+00006cf0: 6e64 2054 656c 6c0a 2020 2020 7769 6c6c  nd Tell.    will
+00006d00: 2062 6520 7075 7265 6c79 2072 656c 6174   be purely relat
+00006d10: 6976 6520 746f 2074 6861 7420 7069 6563  ive to that piec
+00006d20: 6520 6f66 2064 6174 6120 6f6e 6c79 2e20  e of data only. 
+00006d30: 5468 6973 2077 6173 2064 6f6e 6520 746f  This was done to
+00006d40: 2065 6e73 7572 6520 796f 7520 6172 6520   ensure you are 
+00006d50: 6f6e 6c79 2070 6172 7369 6e67 2077 6861  only parsing wha
+00006d60: 7420 6861 7320 6265 656e 0a20 2020 2063  t has been.    c
+00006d70: 6170 7475 7265 642e 2028 4966 2079 6f75  aptured. (If you
+00006d80: 206e 6565 6420 746f 2075 7365 2053 6565   need to use See
+00006d90: 6b20 6f72 2054 656c 6c2c 2079 6f75 2077  k or Tell, you w
+00006da0: 696c 6c20 6861 7665 2074 6f20 696e 7374  ill have to inst
+00006db0: 6561 6420 6d61 6b65 2061 2063 6170 7475  ead make a captu
+00006dc0: 7265 2067 726f 7570 2074 6861 7420 636f  re group that co
+00006dd0: 6c6c 6563 7473 206e 6f20 6461 7461 2e29  llects no data.)
+00006de0: 0a0a 0a20 2020 204e 4f54 453a 2049 6620  ...    NOTE: If 
+00006df0: 796f 7520 7375 7070 6c79 2061 2073 7472  you supply a str
+00006e00: 696e 6720 6173 2074 6865 2072 6567 756c  ing as the regul
+00006e10: 6172 2065 7870 7265 7373 696f 6e2c 2074  ar expression, t
+00006e20: 6865 2072 652e 444f 5441 4c4c 2066 6c61  he re.DOTALL fla
+00006e30: 6720 7769 6c6c 2062 6520 6175 746f 6d61  g will be automa
+00006e40: 7469 6361 6c6c 7920 7370 6563 6966 6965  tically specifie
+00006e50: 642e 0a20 2020 2049 6620 796f 7520 6e65  d..    If you ne
+00006e60: 6564 2074 6f20 7573 6520 6469 6666 6572  ed to use differ
+00006e70: 656e 7420 666c 6167 732c 2079 6f75 206d  ent flags, you m
+00006e80: 7573 7420 7061 7374 2061 2063 6f6d 7069  ust past a compi
+00006e90: 6c65 6420 7265 6765 782e 0a0a 2020 2020  led regex...    
+00006ea0: 5468 6520 7365 656b 2070 6f73 6974 696f  The seek positio
+00006eb0: 6e20 6973 206c 6566 7420 6174 2074 6865  n is left at the
+00006ec0: 2065 6e64 206f 6620 7468 6520 7375 6363   end of the succ
+00006ed0: 6573 7366 756c 206d 6174 6368 2028 6d61  essful match (ma
+00006ee0: 7463 682e 656e 6428 2929 2e0a 0a20 2020  tch.end())...   
+00006ef0: 203e 3e3e 2072 6567 6578 203d 2072 652e   >>> regex = re.
+00006f00: 636f 6d70 696c 6528 275c 7830 315c 7830  compile('\x01\x0
+00006f10: 3228 3f50 3c73 697a 653e 2e7b 347d 295c  2(?P<size>.{4})\
+00006f20: 7830 335c 7830 3428 3f50 3c70 6174 683e  x03\x04(?P<path>
+00006f30: 5b41 2d5a 612d 7a5d 2e2a 5c78 3030 2927  [A-Za-z].*\x00)'
+00006f40: 2c20 7265 2e44 4f54 414c 4c29 0a20 2020  , re.DOTALL).   
+00006f50: 203e 3e3e 2064 6174 6120 3d20 2747 4152   >>> data = 'GAR
+00006f60: 4241 4745 215c 7830 315c 7830 325c 7830  BAGE!\x01\x02\x0
+00006f70: 415c 7830 305c 7830 305c 7830 305c 7830  A\x00\x00\x00\x0
+00006f80: 335c 7830 3443 3a5c 5769 6e64 6f77 735c  3\x04C:\Windows\
+00006f90: 7830 304d 4f52 4520 4741 5242 4147 4521  x00MORE GARBAGE!
+00006fa0: 270a 2020 2020 3e3e 3e20 7220 3d20 5265  '.    >>> r = Re
+00006fb0: 6765 7828 7265 6765 782c 2073 697a 653d  gex(regex, size=
+00006fc0: 496e 7433 3275 6c2c 2070 6174 683d 4353  Int32ul, path=CS
+00006fd0: 7472 696e 6728 2929 2e70 6172 7365 2864  tring()).parse(d
+00006fe0: 6174 6129 0a20 2020 203e 3e3e 2072 203d  ata).    >>> r =
+00006ff0: 3d20 436f 6e74 6169 6e65 7228 7061 7468  = Container(path
+00007000: 3d75 2743 3a5c 5c57 696e 646f 7773 272c  =u'C:\\Windows',
+00007010: 2073 697a 653d 3130 290a 2020 2020 5472   size=10).    Tr
+00007020: 7565 0a20 2020 203e 3e3e 2072 203d 2052  ue.    >>> r = R
+00007030: 6567 6578 2872 6567 6578 292e 7061 7273  egex(regex).pars
+00007040: 6528 6461 7461 290a 2020 2020 3e3e 3e20  e(data).    >>> 
+00007050: 7220 3d3d 2043 6f6e 7461 696e 6572 2870  r == Container(p
+00007060: 6174 683d 6227 433a 5c5c 5769 6e64 6f77  ath=b'C:\\Window
+00007070: 735c 7830 3027 2c20 7369 7a65 3d62 275c  s\x00', size=b'\
+00007080: 6e5c 7830 305c 7830 305c 7830 3027 290a  n\x00\x00\x00').
+00007090: 2020 2020 5472 7565 0a20 2020 203e 3e3e      True.    >>>
+000070a0: 2072 203d 2053 7472 7563 7428 0a20 2020   r = Struct(.   
+000070b0: 202e 2e2e 2020 2020 2027 7265 2720 2f20   ...     're' / 
+000070c0: 5265 6765 7828 7265 6765 782c 2073 697a  Regex(regex, siz
+000070d0: 653d 496e 7433 3275 6c2c 2070 6174 683d  e=Int32ul, path=
+000070e0: 4353 7472 696e 6728 2929 2c0a 2020 2020  CString()),.    
+000070f0: 2e2e 2e20 2020 2020 2761 6674 6572 5f72  ...     'after_r
+00007100: 6527 202f 2054 656c 6c2c 0a20 2020 202e  e' / Tell,.    .
+00007110: 2e2e 2020 2020 2027 6761 7262 6167 6527  ..     'garbage'
+00007120: 202f 2047 7265 6564 7942 7974 6573 0a20   / GreedyBytes. 
+00007130: 2020 202e 2e2e 2029 2e70 6172 7365 2864     ... ).parse(d
+00007140: 6174 6129 0a20 2020 203e 3e3e 2072 203d  ata).    >>> r =
+00007150: 3d20 436f 6e74 6169 6e65 7228 7265 3d43  = Container(re=C
+00007160: 6f6e 7461 696e 6572 2870 6174 683d 7527  ontainer(path=u'
+00007170: 433a 5c5c 5769 6e64 6f77 7327 2c20 7369  C:\\Windows', si
+00007180: 7a65 3d31 3029 2c20 6166 7465 725f 7265  ze=10), after_re
+00007190: 3d32 374c 2c20 6761 7262 6167 653d 6227  =27L, garbage=b'
+000071a0: 4d4f 5245 2047 4152 4241 4745 2127 290a  MORE GARBAGE!').
+000071b0: 2020 2020 5472 7565 0a0a 2020 2020 2320      True..    # 
+000071c0: 544f 444f 3a20 556e 666f 7274 756e 6174  TODO: Unfortunat
+000071d0: 656c 7920 456d 6265 6464 6564 2829 206e  ely Embedded() n
+000071e0: 6f20 6c6f 6e67 6572 2077 6f72 6b73 2077  o longer works w
+000071f0: 6974 6820 7468 6520 7570 6461 7465 2074  ith the update t
+00007200: 6f20 322e 390a 2020 2020 2320 3e3e 3e20  o 2.9.    # >>> 
+00007210: 5374 7275 6374 280a 2020 2020 2320 2e2e  Struct(.    # ..
+00007220: 2e20 2020 2020 456d 6265 6464 6564 2852  .     Embedded(R
+00007230: 6567 6578 2872 6567 6578 2c20 7369 7a65  egex(regex, size
+00007240: 3d49 6e74 3332 756c 2c20 7061 7468 3d43  =Int32ul, path=C
+00007250: 5374 7269 6e67 2829 2929 2c0a 2020 2020  String())),.    
+00007260: 2320 2e2e 2e20 2020 2020 2761 6674 6572  # ...     'after
+00007270: 5f72 6527 202f 2054 656c 6c2c 0a20 2020  _re' / Tell,.   
+00007280: 2023 202e 2e2e 2020 2020 2027 6761 7262   # ...     'garb
+00007290: 6167 6527 202f 2047 7265 6564 7942 7974  age' / GreedyByt
+000072a0: 6573 0a20 2020 2023 202e 2e2e 2029 2e70  es.    # ... ).p
+000072b0: 6172 7365 2864 6174 6129 0a20 2020 2023  arse(data).    #
+000072c0: 2043 6f6e 7461 696e 6572 2870 6174 683d   Container(path=
+000072d0: 7527 433a 5c5c 5769 6e64 6f77 7327 2c20  u'C:\\Windows', 
+000072e0: 7369 7a65 3d31 302c 2061 6674 6572 5f72  size=10, after_r
+000072f0: 653d 3237 4c2c 2067 6172 6261 6765 3d62  e=27L, garbage=b
+00007300: 274d 4f52 4520 4741 5242 4147 4521 2729  'MORE GARBAGE!')
+00007310: 0a0a 2020 2020 596f 7520 6361 6e20 7573  ..    You can us
+00007320: 6520 5265 6765 7820 6173 2061 2074 7269  e Regex as a tri
+00007330: 6767 6572 2074 6f20 6669 6e64 2061 2070  gger to find a p
+00007340: 6172 7469 6375 6c61 7220 7069 6563 6520  articular piece 
+00007350: 6f66 2064 6174 6120 6265 666f 7265 2079  of data before y
+00007360: 6f75 2073 7461 7274 2070 6172 7369 6e67  ou start parsing
+00007370: 2e0a 2020 2020 3e3e 3e20 5374 7275 6374  ..    >>> Struct
+00007380: 280a 2020 2020 2e2e 2e20 2020 2020 5265  (.    ...     Re
+00007390: 6765 7828 2754 5249 4747 4552 2729 2c0a  gex('TRIGGER'),.
+000073a0: 2020 2020 2e2e 2e20 2020 2020 2767 7265      ...     'gre
+000073b0: 6574 696e 6727 202f 2043 5374 7269 6e67  eting' / CString
+000073c0: 2829 0a20 2020 202e 2e2e 2029 2e70 6172  ().    ... ).par
+000073d0: 7365 2827 5c78 3031 5c78 3032 5c78 3034  se('\x01\x02\x04
+000073e0: 4741 5242 4147 455c 7830 3554 5249 4747  GARBAGE\x05TRIGG
+000073f0: 4552 6865 6c6c 6f20 776f 726c 645c 7830  ERhello world\x0
+00007400: 3027 290a 2020 2020 436f 6e74 6169 6e65  0').    Containe
+00007410: 7228 6772 6565 7469 6e67 3d75 2768 656c  r(greeting=u'hel
+00007420: 6c6f 2077 6f72 6c64 2729 0a0a 2020 2020  lo world')..    
+00007430: 4966 206e 6f20 6461 7461 2069 7320 6361  If no data is ca
+00007440: 7074 7572 6564 2c20 7468 6520 6173 736f  ptured, the asso
+00007450: 6369 6174 6564 2073 7562 636f 6e20 7769  ciated subcon wi
+00007460: 6c6c 2072 6563 6569 7665 6420 6120 7374  ll received a st
+00007470: 7265 616d 2077 6974 6820 7468 6520 706f  ream with the po
+00007480: 7369 7469 6f6e 2073 6574 2061 7420 7468  sition set at th
+00007490: 6520 6c6f 6361 7469 6f6e 0a20 2020 206f  e location.    o
+000074a0: 6620 7468 6174 2063 6170 7475 7265 6420  f that captured 
+000074b0: 6772 6f75 702e 2054 6875 732c 2061 6c6c  group. Thus, all
+000074c0: 6f77 696e 6720 796f 7520 746f 2075 7365  owing you to use
+000074d0: 2069 7420 6173 2061 6e20 616e 6368 6f72   it as an anchor
+000074e0: 2070 6f69 6e74 2e0a 2020 2020 3e3e 3e20   point..    >>> 
+000074f0: 7220 3d20 5265 6765 7828 2768 656c 6c6f  r = Regex('hello
+00007500: 2028 3f50 3c61 6e63 686f 723e 2977 6f72   (?P<anchor>)wor
+00007510: 6c64 283f 503c 6578 7472 615f 6461 7461  ld(?P<extra_data
+00007520: 3e2e 2a29 272c 2061 6e63 686f 723d 5465  >.*)', anchor=Te
+00007530: 6c6c 292e 7061 7273 6528 2768 656c 6c6f  ll).parse('hello
+00007540: 2077 6f72 6c64 2121 2121 2729 0a20 2020   world!!!!').   
+00007550: 203e 3e3e 2072 203d 3d20 436f 6e74 6169   >>> r == Contai
+00007560: 6e65 7228 6578 7472 615f 6461 7461 3d62  ner(extra_data=b
+00007570: 2721 2121 2127 2c20 616e 6368 6f72 3d36  '!!!!', anchor=6
+00007580: 4c29 0a20 2020 2054 7275 650a 0a20 2020  L).    True..   
+00007590: 2049 6620 6e6f 206e 616d 6564 2063 6170   If no named cap
+000075a0: 7475 7265 2067 726f 7570 7320 6172 6520  ture groups are 
+000075b0: 7573 6564 2c20 796f 7520 6361 6e20 696e  used, you can in
+000075c0: 7374 6561 6420 7061 7273 6520 7468 6520  stead parse the 
+000075d0: 656e 7469 7265 206d 6174 6368 6564 2073  entire matched s
+000075e0: 7472 696e 6720 6279 2073 7570 706c 7969  tring by supplyi
+000075f0: 6e67 0a20 2020 2061 2073 7562 636f 6e73  ng.    a subcons
+00007600: 7472 7563 7420 6173 2061 2070 6f73 6974  truct as a posit
+00007610: 696f 6e61 6c20 6172 6775 6d65 6e74 2e20  ional argument. 
+00007620: 2849 6620 6e6f 2073 7562 636f 6e20 6973  (If no subcon is
+00007630: 2070 726f 7669 6465 642c 2074 6865 2072   provided, the r
+00007640: 6177 2062 7974 6573 2061 7265 2072 6574  aw bytes are ret
+00007650: 7572 6e65 6420 696e 7374 6561 642e 0a20  urned instead.. 
+00007660: 2020 203e 3e3e 2052 6567 6578 2827 6865     >>> Regex('he
+00007670: 6c6c 6f20 776f 726c 645c 7830 3027 2c20  llo world\x00', 
+00007680: 4353 7472 696e 6728 2929 2e70 6172 7365  CString()).parse
+00007690: 2827 4741 5242 4147 455c 7830 315c 7830  ('GARBAGE\x01\x0
+000076a0: 3368 656c 6c6f 2077 6f72 6c64 5c78 3030  3hello world\x00
+000076b0: 5c78 3034 2729 0a20 2020 2075 2768 656c  \x04').    u'hel
+000076c0: 6c6f 2077 6f72 6c64 270a 2020 2020 3e3e  lo world'.    >>
+000076d0: 3e20 5265 6765 7828 2768 656c 6c6f 2077  > Regex('hello w
+000076e0: 6f72 6c64 5c78 3030 2729 2e70 6172 7365  orld\x00').parse
+000076f0: 2827 4741 5242 4147 455c 7830 315c 7830  ('GARBAGE\x01\x0
+00007700: 3368 656c 6c6f 2077 6f72 6c64 5c78 3030  3hello world\x00
+00007710: 5c78 3034 2729 0a20 2020 2027 6865 6c6c  \x04').    'hell
+00007720: 6f20 776f 726c 645c 7830 3027 0a0a 2020  o world\x00'..  
+00007730: 2020 596f 7520 6361 6e20 616c 736f 2073    You can also s
+00007740: 6574 2074 6865 2072 6567 756c 6172 2065  et the regular e
+00007750: 7870 7265 7373 696f 6e20 746f 206d 6174  xpression to mat
+00007760: 6368 2069 6e2d 706c 6163 6520 2869 6e73  ch in-place (ins
+00007770: 7465 6164 206f 6620 7365 6172 6368 696e  tead of searchin
+00007780: 6720 7468 6520 6461 7461 290a 2020 2020  g the data).    
+00007790: 6279 2073 6574 7469 6e67 2074 6865 206b  by setting the k
+000077a0: 6579 776f 7264 2061 7267 756d 656e 7420  eyword argument 
+000077b0: 5f6d 6174 6368 2074 6f20 5472 7565 2e0a  _match to True..
+000077c0: 2020 2020 3e3e 3e20 5265 6765 7828 2768      >>> Regex('h
+000077d0: 656c 6c6f 272c 205f 6d61 7463 683d 5472  ello', _match=Tr
+000077e0: 7565 292e 7061 7273 6528 6227 6865 6c6c  ue).parse(b'hell
+000077f0: 6f20 776f 726c 6421 2729 0a20 2020 2027  o world!').    '
+00007800: 6865 6c6c 6f27 0a20 2020 203e 3e3e 2052  hello'.    >>> R
+00007810: 6567 6578 2827 6865 6c6c 6f27 292e 7061  egex('hello').pa
+00007820: 7273 6528 6227 626f 6775 7320 6865 6c6c  rse(b'bogus hell
+00007830: 6f20 776f 726c 6427 290a 2020 2020 2768  o world').    'h
+00007840: 656c 6c6f 270a 2020 2020 3e3e 3e20 5265  ello'.    >>> Re
+00007850: 6765 7828 2768 656c 6c6f 272c 205f 6d61  gex('hello', _ma
+00007860: 7463 683d 5472 7565 292e 7061 7273 6528  tch=True).parse(
+00007870: 6227 626f 6775 7320 6865 6c6c 6f20 776f  b'bogus hello wo
+00007880: 726c 6427 290a 2020 2020 5472 6163 6562  rld').    Traceb
+00007890: 6163 6b20 286d 6f73 7420 7265 6365 6e74  ack (most recent
+000078a0: 2063 616c 6c20 6c61 7374 293a 0a20 2020   call last):.   
+000078b0: 2020 2020 202e 2e2e 0a20 2020 2043 6f6e       ....    Con
+000078c0: 7374 7275 6374 4572 726f 723a 205b 2870  structError: [(p
+000078d0: 6172 7369 6e67 295d 2072 6567 6578 2064  arsing)] regex d
+000078e0: 6964 206e 6f74 206d 6174 6368 0a20 2020  id not match.   
+000078f0: 2022 2222 0a0a 2020 2020 5f5f 736c 6f74   """..    __slot
+00007900: 735f 5f20 3d20 5b27 7265 6765 7827 2c20  s__ = ['regex', 
+00007910: 2773 7562 636f 6e27 2c20 2767 726f 7570  'subcon', 'group
+00007920: 5f73 7562 636f 6e73 272c 2027 6d61 7463  _subcons', 'matc
+00007930: 6827 5d0a 0a20 2020 2064 6566 205f 5f69  h']..    def __i
+00007940: 6e69 745f 5f28 7365 6c66 2c20 7265 6765  nit__(self, rege
+00007950: 782c 202a 7375 6263 6f6e 2c20 2a2a 6772  x, *subcon, **gr
+00007960: 6f75 705f 7375 6263 6f6e 7329 3a0a 2020  oup_subcons):.  
+00007970: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+00007980: 2020 496e 6974 6961 6c69 7a65 7320 7265    Initializes re
+00007990: 6765 7820 636f 6e73 7472 7563 742e 0a0a  gex construct...
+000079a0: 2020 2020 2020 2020 3a70 6172 616d 2072          :param r
+000079b0: 6567 6578 3a20 4120 7265 6765 7820 746f  egex: A regex to
+000079c0: 2075 7365 2028 6361 6e20 6265 2061 2073   use (can be a s
+000079d0: 7472 696e 6720 6f72 2063 6f6d 7069 6c65  tring or compile
+000079e0: 6429 2e0a 2020 2020 2020 2020 3a70 6172  d)..        :par
+000079f0: 616d 2073 7562 636f 6e3a 0a20 2020 2020  am subcon:.     
+00007a00: 2020 2020 2020 2041 2073 7562 636f 6e20         A subcon 
+00007a10: 746f 2075 7365 206f 6e20 7468 6520 656e  to use on the en
+00007a20: 7469 7265 206d 6174 6368 696e 6720 7374  tire matching st
+00007a30: 7269 6e67 2077 6865 6e20 7468 6572 6520  ring when there 
+00007a40: 6172 6520 6e6f 206e 616d 6564 2063 6170  are no named cap
+00007a50: 7475 7265 2067 726f 7570 732e 0a20 2020  ture groups..   
+00007a60: 2020 2020 2020 2020 2028 4e4f 5445 3a20           (NOTE: 
+00007a70: 5468 6973 2069 7320 6f6e 6c79 2075 7365  This is only use
+00007a80: 6420 6966 2074 6865 7265 2061 7265 206e  d if there are n
+00007a90: 6f20 6361 7074 7572 6520 6772 6f75 7073  o capture groups
+00007aa0: 2e0a 2020 2020 2020 2020 2020 2020 4966  ..            If
+00007ab0: 2079 6f75 2077 616e 7420 746f 2075 7365   you want to use
+00007ac0: 2063 6170 7475 7265 2067 726f 7570 7320   capture groups 
+00007ad0: 414e 4420 7468 6973 2074 6865 6e20 6861  AND this then ha
+00007ae0: 7665 2061 2063 6170 7475 7265 2067 726f  ve a capture gro
+00007af0: 7570 2065 6e63 6170 7375 6c61 7469 6e67  up encapsulating
+00007b00: 2074 6865 2065 6e74 6972 6520 7265 6765   the entire rege
+00007b10: 782e 290a 2020 2020 2020 2020 3a70 6172  x.).        :par
+00007b20: 616d 2067 726f 7570 5f73 7562 636f 6e73  am group_subcons
+00007b30: 3a0a 2020 2020 2020 2020 2020 2020 4b65  :.            Ke
+00007b40: 7977 6f72 6420 6172 6775 6d65 6e74 2064  yword argument d
+00007b50: 6963 7469 6f6e 6172 7920 7468 6174 2063  ictionary that c
+00007b60: 6f6e 7461 696e 7320 7468 6520 636f 6e73  ontains the cons
+00007b70: 7472 7563 7473 2074 6f20 7573 6520 666f  tructs to use fo
+00007b80: 7220 7468 6520 636f 7272 6573 706f 6e64  r the correspond
+00007b90: 696e 6720 6361 7074 7572 6520 6772 6f75  ing capture grou
+00007ba0: 702e 0a20 2020 2020 2020 2020 2020 2049  p..            I
+00007bb0: 6620 6120 7375 6263 6f6e 2069 7320 6e6f  f a subcon is no
+00007bc0: 7420 7375 7070 6c69 6564 2066 6f72 2061  t supplied for a
+00007bd0: 2063 6170 7475 7265 2067 726f 7570 2c20   capture group, 
+00007be0: 6974 2077 696c 6c20 6465 6661 756c 7420  it will default 
+00007bf0: 746f 2072 6574 7572 6e69 6e67 2062 7974  to returning byt
+00007c00: 6573 0a20 2020 2020 2020 2020 2020 2028  es.            (
+00007c10: 6571 7569 7661 6c65 6e74 2074 6f20 7365  equivalent to se
+00007c20: 7474 696e 6720 636f 6e73 7472 7563 742e  tting construct.
+00007c30: 4279 7465 7328 2920 666f 7220 7468 6174  Bytes() for that
+00007c40: 2067 726f 7570 2e29 0a0a 2020 2020 2020   group.)..      
+00007c50: 2020 3a72 6169 7365 7320 5661 6c75 6545    :raises ValueE
+00007c60: 7272 6f72 3a20 4966 2061 7267 756d 656e  rror: If argumen
+00007c70: 7473 2061 7265 2069 6e76 616c 6964 2e0a  ts are invalid..
+00007c80: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+00007c90: 2020 2020 7375 7065 7228 5265 6765 782c      super(Regex,
+00007ca0: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
+00007cb0: 290a 2020 2020 2020 2020 6966 2069 7369  ).        if isi
+00007cc0: 6e73 7461 6e63 6528 7265 6765 782c 2073  nstance(regex, s
+00007cd0: 7472 293a 0a20 2020 2020 2020 2020 2020  tr):.           
+00007ce0: 2072 6567 6578 203d 2072 6567 6578 2e65   regex = regex.e
+00007cf0: 6e63 6f64 6528 2920 2023 2066 6f72 6365  ncode()  # force
+00007d00: 2062 7974 6520 7374 7269 6e67 730a 2020   byte strings.  
+00007d10: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
+00007d20: 6e63 6528 7265 6765 782c 2062 7974 6573  nce(regex, bytes
+00007d30: 7472 696e 6774 7970 6529 3a0a 2020 2020  tringtype):.    
+00007d40: 2020 2020 2020 2020 7265 6765 7820 3d20          regex = 
+00007d50: 7265 2e63 6f6d 7069 6c65 2872 6567 6578  re.compile(regex
+00007d60: 2c20 7265 2e44 4f54 414c 4c29 0a20 2020  , re.DOTALL).   
+00007d70: 2020 2020 2073 656c 662e 7265 6765 7820       self.regex 
+00007d80: 3d20 7265 6765 780a 2020 2020 2020 2020  = regex.        
+00007d90: 2320 544f 444f 3a20 5468 6973 2066 6561  # TODO: This fea
+00007da0: 7475 7265 2073 6565 6d73 2062 6163 6b77  ture seems backw
+00007db0: 6172 6473 2c20 7065 7268 6170 7320 6d61  ards, perhaps ma
+00007dc0: 6b65 2061 205f 7365 6172 6368 206b 6579  ke a _search key
+00007dd0: 776f 7264 2069 6e73 7465 6164 2061 6e64  word instead and
+00007de0: 2064 6566 6175 6c74 2074 6f20 6d61 7463   default to matc
+00007df0: 6820 6675 6e63 7469 6f6e 616c 6974 792e  h functionality.
+00007e00: 0a20 2020 2020 2020 2023 2041 6c74 6572  .        # Alter
+00007e10: 6e61 7469 7665 6c79 2c20 7765 2063 6f75  natively, we cou
+00007e20: 6c64 2068 6176 6520 5265 6765 7853 6561  ld have RegexSea
+00007e30: 7263 6820 616e 6420 5265 6765 784d 6174  rch and RegexMat
+00007e40: 6368 2063 6f6e 7374 7275 6374 7320 696e  ch constructs in
+00007e50: 7374 6561 642e 0a20 2020 2020 2020 2073  stead..        s
+00007e60: 656c 662e 6d61 7463 6820 3d20 6772 6f75  elf.match = grou
+00007e70: 705f 7375 6263 6f6e 732e 706f 7028 275f  p_subcons.pop('_
+00007e80: 6d61 7463 6827 2c20 4661 6c73 6529 0a20  match', False). 
+00007e90: 2020 2020 2020 2073 656c 662e 6772 6f75         self.grou
+00007ea0: 705f 7375 6263 6f6e 7320 3d20 6772 6f75  p_subcons = grou
+00007eb0: 705f 7375 6263 6f6e 730a 2020 2020 2020  p_subcons.      
+00007ec0: 2020 6966 2073 7562 636f 6e20 616e 6420    if subcon and 
+00007ed0: 6c65 6e28 7375 6263 6f6e 2920 3e20 313a  len(subcon) > 1:
+00007ee0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+00007ef0: 7365 2056 616c 7565 4572 726f 7228 274f  se ValueError('O
+00007f00: 6e6c 7920 6f6e 6520 7375 6263 6f6e 2063  nly one subcon c
+00007f10: 616e 2062 6520 7375 7070 6c69 6564 2066  an be supplied f
+00007f20: 6f72 2074 6865 2065 6e74 6972 6520 6d61  or the entire ma
+00007f30: 7463 682e 2729 0a20 2020 2020 2020 2069  tch.').        i
+00007f40: 6620 7375 6263 6f6e 2061 6e64 2067 726f  f subcon and gro
+00007f50: 7570 5f73 7562 636f 6e73 3a0a 2020 2020  up_subcons:.    
+00007f60: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+00007f70: 6c75 6545 7272 6f72 2827 7375 6263 6f6e  lueError('subcon
+00007f80: 2061 6e64 2067 726f 7570 5f73 7562 636f   and group_subco
+00007f90: 6e73 2061 7267 756d 656e 7473 2063 616e  ns arguments can
+00007fa0: 6e6f 7420 6265 2075 7365 6420 6174 2074  not be used at t
+00007fb0: 6865 2073 616d 6520 7469 6d65 2e27 290a  he same time.').
+00007fc0: 2020 2020 2020 2020 7365 6c66 2e73 7562          self.sub
+00007fd0: 636f 6e20 3d20 7375 6263 6f6e 5b30 5d20  con = subcon[0] 
+00007fe0: 6966 2073 7562 636f 6e20 656c 7365 204e  if subcon else N
+00007ff0: 6f6e 650a 0a20 2020 2064 6566 205f 7061  one..    def _pa
+00008000: 7273 6528 7365 6c66 2c20 7374 7265 616d  rse(self, stream
+00008010: 2c20 636f 6e74 6578 742c 2070 6174 6829  , context, path)
+00008020: 3a0a 2020 2020 2020 2020 7374 6172 7420  :.        start 
+00008030: 3d20 7374 7265 616d 2e74 656c 6c28 290a  = stream.tell().
+00008040: 2020 2020 2020 2020 2320 4e4f 5445 3a20          # NOTE: 
+00008050: 7765 2061 7265 2067 6f69 6e67 2074 6f20  we are going to 
+00008060: 6861 7665 2074 6f20 7265 6164 2074 6865  have to read the
+00008070: 2065 6e74 6972 6520 7374 7265 616d 2064   entire stream d
+00008080: 7565 2074 6f20 7265 6765 7820 7265 7175  ue to regex requ
+00008090: 6972 656d 656e 7473 2e0a 2020 2020 2020  irements..      
+000080a0: 2020 2320 486f 7765 7665 722c 2074 6861    # However, tha
+000080b0: 7427 7320 6f6b 6179 2069 6e20 7468 6973  t's okay in this
+000080c0: 2063 6173 6520 7369 6e63 6520 7765 2061   case since we a
+000080d0: 7265 2070 6172 7369 6e67 2042 7974 6549  re parsing ByteI
+000080e0: 4f20 616e 7977 6179 2e0a 2020 2020 2020  O anyway..      
+000080f0: 2020 6966 2073 656c 662e 6d61 7463 683a    if self.match:
+00008100: 0a20 2020 2020 2020 2020 2020 206d 6174  .            mat
+00008110: 6368 203d 2073 656c 662e 7265 6765 782e  ch = self.regex.
+00008120: 6d61 7463 6828 7374 7265 616d 2e72 6561  match(stream.rea
+00008130: 6428 2929 0a20 2020 2020 2020 2065 6c73  d()).        els
+00008140: 653a 0a20 2020 2020 2020 2020 2020 206d  e:.            m
+00008150: 6174 6368 203d 2073 656c 662e 7265 6765  atch = self.rege
+00008160: 782e 7365 6172 6368 2873 7472 6561 6d2e  x.search(stream.
+00008170: 7265 6164 2829 290a 2020 2020 2020 2020  read()).        
+00008180: 6966 206e 6f74 206d 6174 6368 3a0a 2020  if not match:.  
+00008190: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+000081a0: 436f 6e73 7472 7563 7445 7272 6f72 2827  ConstructError('
+000081b0: 5b7b 7d5d 2072 6567 6578 2064 6964 206e  [{}] regex did n
+000081c0: 6f74 206d 6174 6368 272e 666f 726d 6174  ot match'.format
+000081d0: 2870 6174 6829 290a 0a20 2020 2020 2020  (path))..       
+000081e0: 2074 7279 3a0a 2020 2020 2020 2020 2020   try:.          
+000081f0: 2020 6772 6f75 705f 6469 6374 203d 206d    group_dict = m
+00008200: 6174 6368 2e67 726f 7570 6469 6374 2829  atch.groupdict()
+00008210: 0a0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
+00008220: 4966 2074 6865 7265 2061 7265 206e 6f20  If there are no 
+00008230: 6e61 6d65 6420 6772 6f75 7073 2e20 5265  named groups. Re
+00008240: 7475 726e 2070 6172 7365 6420 6675 6c6c  turn parsed full
+00008250: 206d 6174 6368 2069 6e73 7465 6164 2e0a   match instead..
+00008260: 2020 2020 2020 2020 2020 2020 6966 206e              if n
+00008270: 6f74 2067 726f 7570 5f64 6963 743a 0a20  ot group_dict:. 
+00008280: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00008290: 6620 7365 6c66 2e73 7562 636f 6e3a 0a20  f self.subcon:. 
+000082a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000082b0: 2020 2073 7562 5f73 7472 6561 6d20 3d20     sub_stream = 
+000082c0: 696f 2e42 7974 6573 494f 286d 6174 6368  io.BytesIO(match
+000082d0: 2e67 726f 7570 2829 290a 2020 2020 2020  .group()).      
+000082e0: 2020 2020 2020 2020 2020 2020 2020 7265                re
+000082f0: 7475 726e 2073 656c 662e 7375 6263 6f6e  turn self.subcon
+00008300: 2e5f 7061 7273 6572 6570 6f72 7428 7375  ._parsereport(su
+00008310: 625f 7374 7265 616d 2c20 636f 6e74 6578  b_stream, contex
+00008320: 742c 2070 6174 6829 0a20 2020 2020 2020  t, path).       
+00008330: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+00008340: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008350: 2020 2072 6574 7572 6e20 6d61 7463 682e     return match.
+00008360: 6772 6f75 7028 290a 0a20 2020 2020 2020  group()..       
+00008370: 2020 2020 2023 204f 7468 6572 7769 7365       # Otherwise
+00008380: 2c20 7765 2061 7265 2067 6f69 6e67 2074  , we are going t
+00008390: 6f20 7061 7273 6520 6561 6368 206e 616d  o parse each nam
+000083a0: 6564 2063 6170 7475 7265 2067 726f 7570  ed capture group
+000083b0: 2e0a 2020 2020 2020 2020 2020 2020 6f62  ..            ob
+000083c0: 6a20 3d20 436f 6e74 6169 6e65 7228 290a  j = Container().
+000083d0: 2020 2020 2020 2020 2020 2020 6f62 6a2e              obj.
+000083e0: 5f69 6f20 3d20 7374 7265 616d 0a0a 2020  _io = stream..  
+000083f0: 2020 2020 2020 2020 2020 636f 6e74 6578            contex
+00008400: 7420 3d20 436f 6e74 6169 6e65 7228 5f3d  t = Container(_=
+00008410: 636f 6e74 6578 742c 205f 7061 7261 6d73  context, _params
+00008420: 3d63 6f6e 7465 7874 2e5f 7061 7261 6d73  =context._params
+00008430: 2c20 5f72 6f6f 743d 4e6f 6e65 2c20 5f70  , _root=None, _p
+00008440: 6172 7369 6e67 3d63 6f6e 7465 7874 2e5f  arsing=context._
+00008450: 7061 7273 696e 672c 0a20 2020 2020 2020  parsing,.       
+00008460: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008470: 2020 2020 2020 2020 205f 6275 696c 6469           _buildi
+00008480: 6e67 3d63 6f6e 7465 7874 2e5f 6275 696c  ng=context._buil
+00008490: 6469 6e67 2c20 5f73 697a 696e 673d 636f  ding, _sizing=co
+000084a0: 6e74 6578 742e 5f73 697a 696e 672c 205f  ntext._sizing, _
+000084b0: 7375 6263 6f6e 733d 7365 6c66 2e67 726f  subcons=self.gro
+000084c0: 7570 5f73 7562 636f 6e73 2c0a 2020 2020  up_subcons,.    
+000084d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000084e0: 2020 2020 2020 2020 2020 2020 5f69 6f3d              _io=
+000084f0: 7374 7265 616d 2c20 5f69 6e64 6578 3d63  stream, _index=c
+00008500: 6f6e 7465 7874 2e67 6574 2822 5f69 6e64  ontext.get("_ind
+00008510: 6578 222c 204e 6f6e 6529 290a 2020 2020  ex", None)).    
+00008520: 2020 2020 2020 2020 636f 6e74 6578 742e          context.
+00008530: 5f72 6f6f 7420 3d20 636f 6e74 6578 742e  _root = context.
+00008540: 5f2e 6765 7428 225f 726f 6f74 222c 2063  _.get("_root", c
+00008550: 6f6e 7465 7874 290a 0a20 2020 2020 2020  ontext)..       
+00008560: 2020 2020 2023 2044 6566 6175 6c74 2074       # Default t
+00008570: 6f20 6469 7370 6c61 7969 6e67 206d 6174  o displaying mat
+00008580: 6368 6564 2064 6174 6120 6173 2070 7572  ched data as pur
+00008590: 6520 6279 7465 732e 0a20 2020 2020 2020  e bytes..       
+000085a0: 2020 2020 206f 626a 2e75 7064 6174 6528       obj.update(
+000085b0: 6772 6f75 705f 6469 6374 290a 2020 2020  group_dict).    
+000085c0: 2020 2020 2020 2020 636f 6e74 6578 742e          context.
+000085d0: 7570 6461 7465 2867 726f 7570 5f64 6963  update(group_dic
+000085e0: 7429 0a0a 2020 2020 2020 2020 2020 2020  t)..            
+000085f0: 2320 5061 7273 6520 6772 6f75 7073 2075  # Parse groups u
+00008600: 7369 6e67 2073 7570 706c 6965 6420 636f  sing supplied co
+00008610: 6e73 7472 7563 7473 2e0a 2020 2020 2020  nstructs..      
+00008620: 2020 2020 2020 666f 7220 6e61 6d65 2c20        for name, 
+00008630: 7375 6263 6f6e 2069 6e20 7365 6c66 2e67  subcon in self.g
+00008640: 726f 7570 5f73 7562 636f 6e73 2e69 7465  roup_subcons.ite
+00008650: 6d73 2829 3a0a 2020 2020 2020 2020 2020  ms():.          
+00008660: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
+00008670: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00008680: 6174 6120 3d20 6d61 7463 682e 6772 6f75  ata = match.grou
+00008690: 7028 6e61 6d65 290a 2020 2020 2020 2020  p(name).        
+000086a0: 2020 2020 2020 2020 6578 6365 7074 2049          except I
+000086b0: 6e64 6578 4572 726f 723a 0a20 2020 2020  ndexError:.     
+000086c0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+000086d0: 6f6e 7469 6e75 650a 0a20 2020 2020 2020  ontinue..       
+000086e0: 2020 2020 2020 2020 2023 2049 6620 6461           # If da
+000086f0: 7461 2069 7320 4e6f 6e65 2c20 7468 656e  ta is None, then
+00008700: 2077 6520 6172 6520 6d6f 7374 206c 696b   we are most lik
+00008710: 656c 7920 6465 616c 696e 6720 7769 7468  ely dealing with
+00008720: 2061 6e20 6f70 7469 6f6e 616c 2063 6170   an optional cap
+00008730: 7475 7265 2067 726f 7570 2e0a 2020 2020  ture group..    
+00008740: 2020 2020 2020 2020 2020 2020 6966 2064              if d
+00008750: 6174 6120 6973 204e 6f6e 653a 0a20 2020  ata is None:.   
+00008760: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008770: 206f 626a 5b6e 616d 655d 203d 204e 6f6e   obj[name] = Non
+00008780: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
+00008790: 2020 2020 2020 636f 6e74 6578 745b 6e61        context[na
+000087a0: 6d65 5d20 3d20 4e6f 6e65 0a20 2020 2020  me] = None.     
+000087b0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+000087c0: 6f6e 7469 6e75 650a 0a20 2020 2020 2020  ontinue..       
+000087d0: 2020 2020 2020 2020 2023 2049 6620 7765           # If we
+000087e0: 2068 6176 6520 616e 2065 6d70 7479 2063   have an empty c
+000087f0: 6170 7475 7265 2067 726f 7570 2c20 7468  apture group, th
+00008800: 6520 7573 6572 2077 6f75 6c64 206c 696b  e user would lik
+00008810: 6520 746f 2075 7365 2069 7420 6173 2061  e to use it as a
+00008820: 6e20 616e 6368 6f72 2e0a 2020 2020 2020  n anchor..      
+00008830: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
+00008840: 2064 6174 613a 0a20 2020 2020 2020 2020   data:.         
+00008850: 2020 2020 2020 2020 2020 2073 7472 6561             strea
+00008860: 6d2e 7365 656b 2873 7461 7274 202b 206d  m.seek(start + m
+00008870: 6174 6368 2e73 7461 7274 286e 616d 6529  atch.start(name)
+00008880: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00008890: 2020 2020 2020 7375 625f 7374 7265 616d        sub_stream
+000088a0: 203d 2073 7472 6561 6d0a 2020 2020 2020   = stream.      
+000088b0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+000088c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000088d0: 2020 2020 7375 625f 7374 7265 616d 203d      sub_stream =
+000088e0: 2069 6f2e 4279 7465 7349 4f28 6461 7461   io.BytesIO(data
+000088f0: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
+00008900: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
+00008910: 2020 2020 2020 2020 2020 2020 7375 626f              subo
+00008920: 626a 203d 2073 7562 636f 6e2e 5f70 6172  bj = subcon._par
+00008930: 7365 7265 706f 7274 2873 7562 5f73 7472  sereport(sub_str
+00008940: 6561 6d2c 2063 6f6e 7465 7874 2c20 7061  eam, context, pa
+00008950: 7468 290a 2020 2020 2020 2020 2020 2020  th).            
+00008960: 2020 2020 6578 6365 7074 2043 6f6e 7374      except Const
+00008970: 7275 6374 4572 726f 7220 6173 2065 3a0a  ructError as e:.
+00008980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008990: 2020 2020 2320 5261 6973 6520 6120 6d6f      # Raise a mo
+000089a0: 7265 2075 7365 6675 6c20 6572 726f 7220  re useful error 
+000089b0: 6d65 7373 6167 652e 0a20 2020 2020 2020  message..       
+000089c0: 2020 2020 2020 2020 2020 2020 2023 2054               # T
+000089d0: 4f44 4f3a 2052 656d 6f76 6520 7768 656e  ODO: Remove when
+000089e0: 2070 6174 6820 6973 2070 726f 7669 6465   path is provide
+000089f0: 6420 696e 2065 7863 6570 7469 6f6e 206d  d in exception m
+00008a00: 6573 7361 6765 732e 0a20 2020 2020 2020  essages..       
+00008a10: 2020 2020 2020 2020 2020 2020 2072 6169               rai
+00008a20: 7365 2043 6f6e 7374 7275 6374 4572 726f  se ConstructErro
+00008a30: 7228 2746 6169 6c65 6420 746f 2070 6172  r('Failed to par
+00008a40: 7365 207b 7d20 6361 7074 7572 6520 6772  se {} capture gr
+00008a50: 6f75 7020 7769 7468 2065 7272 6f72 3a20  oup with error: 
+00008a60: 7b7d 272e 666f 726d 6174 286e 616d 652c  {}'.format(name,
+00008a70: 2065 2929 0a20 2020 2020 2020 2020 2020   e)).           
+00008a80: 2020 2020 206f 626a 5b6e 616d 655d 203d       obj[name] =
+00008a90: 2073 7562 6f62 6a0a 2020 2020 2020 2020   subobj.        
+00008aa0: 2020 2020 2020 2020 636f 6e74 6578 745b          context[
+00008ab0: 6e61 6d65 5d20 3d20 7375 626f 626a 0a20  name] = subobj. 
+00008ac0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+00008ad0: 6e20 6f62 6a0a 0a20 2020 2020 2020 2066  n obj..        f
+00008ae0: 696e 616c 6c79 3a0a 2020 2020 2020 2020  inally:.        
+00008af0: 2020 2020 2320 5265 7365 7420 706f 7369      # Reset posi
+00008b00: 7469 6f6e 2074 6f20 7269 6768 7420 6166  tion to right af
+00008b10: 7465 7220 7468 6520 6d61 7463 6865 6420  ter the matched 
+00008b20: 7265 6765 782e 0a20 2020 2020 2020 2020  regex..         
+00008b30: 2020 2073 7472 6561 6d2e 7365 656b 2873     stream.seek(s
+00008b40: 7461 7274 202b 206d 6174 6368 2e65 6e64  tart + match.end
+00008b50: 2829 290a 0a20 2020 2064 6566 205f 6275  ())..    def _bu
+00008b60: 696c 6428 7365 6c66 2c20 6f62 6a2c 2073  ild(self, obj, s
+00008b70: 7472 6561 6d2c 2063 6f6e 7465 7874 2c20  tream, context, 
+00008b80: 7061 7468 293a 0a20 2020 2020 2020 2072  path):.        r
+00008b90: 6169 7365 2043 6f6e 7374 7275 6374 4572  aise ConstructEr
+00008ba0: 726f 7228 2742 7569 6c64 696e 6720 666f  ror('Building fo
+00008bb0: 7220 5265 6765 7820 6973 206e 6f74 2073  r Regex is not s
+00008bc0: 7570 706f 7274 6564 2e27 290a 0a20 2020  upported.')..   
+00008bd0: 2064 6566 205f 7369 7a65 6f66 2873 656c   def _sizeof(sel
+00008be0: 662c 2063 6f6e 7465 7874 2c20 7061 7468  f, context, path
+00008bf0: 293a 0a20 2020 2020 2020 2072 6169 7365  ):.        raise
+00008c00: 2053 697a 656f 6645 7272 6f72 2827 7369   SizeofError('si
+00008c10: 7a65 6f66 2829 2066 6f72 2052 6567 6578  zeof() for Regex
+00008c20: 2069 7320 6e6f 7420 7375 7070 6f72 7465   is not supporte
+00008c30: 642e 2729 0a0a 2020 2020 6465 6620 5f65  d.')..    def _e
+00008c40: 6d69 7470 6172 7365 2873 656c 662c 2063  mitparse(self, c
+00008c50: 6f64 6529 3a0a 2020 2020 2020 2020 7261  ode):.        ra
+00008c60: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
+00008c70: 6564 4572 726f 720a 0a20 2020 2064 6566  edError..    def
+00008c80: 205f 656d 6974 7365 7128 7365 6c66 2c20   _emitseq(self, 
+00008c90: 6b73 792c 2062 6974 7769 7365 293a 0a20  ksy, bitwise):. 
+00008ca0: 2020 2020 2020 2072 6169 7365 204e 6f74         raise Not
+00008cb0: 496d 706c 656d 656e 7465 6445 7272 6f72  ImplementedError
+00008cc0: 0a0a 0a63 6c61 7373 2049 7465 7245 7272  ...class IterErr
+00008cd0: 6f72 2843 6f6e 7374 7275 6374 4572 726f  or(ConstructErro
+00008ce0: 7229 3a0a 2020 2020 7061 7373 0a0a 0a23  r):.    pass...#
+00008cf0: 2054 4f44 4f3a 2053 686f 756c 6420 7468   TODO: Should th
+00008d00: 6973 2062 6520 7265 6e61 6d65 6420 746f  is be renamed to
+00008d10: 204d 6170 3f0a 636c 6173 7320 4974 6572   Map?.class Iter
+00008d20: 2843 6f6e 7374 7275 6374 293a 0a20 2020  (Construct):.   
+00008d30: 2072 2222 220a 2020 2020 436c 6173 7320   r""".    Class 
+00008d40: 7468 6174 2061 6c6c 6f77 7320 6974 6572  that allows iter
+00008d50: 6174 696e 6720 6f76 6572 2061 6e20 6f62  ating over an ob
+00008d60: 6a65 6374 2061 6e64 2061 6374 696e 6720  ject and acting 
+00008d70: 6f6e 2065 6163 6820 6974 656d 2e0a 0a20  on each item... 
+00008d80: 2020 2065 2e67 2e0a 2020 2020 3e3e 3e20     e.g..    >>> 
+00008d90: 7370 6563 203d 2053 7472 7563 7428 0a20  spec = Struct(. 
+00008da0: 2020 202e 2e2e 2020 2020 2027 7479 7065     ...     'type
+00008db0: 7327 202f 2042 7974 655b 335d 2c0a 2020  s' / Byte[3],.  
+00008dc0: 2020 2e2e 2e20 2020 2020 2765 6e74 7269    ...     'entri
+00008dd0: 6573 2720 2f20 4974 6572 2874 6869 732e  es' / Iter(this.
+00008de0: 7479 7065 732c 207b 0a20 2020 202e 2e2e  types, {.    ...
+00008df0: 2020 2020 2020 2020 313a 2063 6f6e 7374          1: const
+00008e00: 7275 6374 2e49 6e74 3332 756c 2c0a 2020  ruct.Int32ul,.  
+00008e10: 2020 2e2e 2e20 2020 2020 2020 2032 3a20    ...        2: 
+00008e20: 636f 6e73 7472 7563 742e 496e 7431 3675  construct.Int16u
+00008e30: 6c2c 0a20 2020 202e 2e2e 2020 2020 207d  l,.    ...     }
+00008e40: 2c0a 2020 2020 2e2e 2e20 2020 2020 6465  ,.    ...     de
+00008e50: 6661 756c 743d 636f 6e73 7472 7563 742e  fault=construct.
+00008e60: 5061 7373 0a20 2020 202e 2e2e 2020 2020  Pass.    ...    
+00008e70: 2029 0a20 2020 202e 2e2e 2029 0a20 2020   ).    ... ).   
+00008e80: 203e 3e3e 2073 7065 632e 7061 7273 6528   >>> spec.parse(
+00008e90: 275c 7830 315c 7830 325c 7830 395c 7830  '\x01\x02\x09\x0
+00008ea0: 335c 7830 335c 7830 335c 7830 335c 7830  3\x03\x03\x03\x0
+00008eb0: 365c 7830 3627 290a 2020 2020 436f 6e74  6\x06').    Cont
+00008ec0: 6169 6e65 7228 7479 7065 733d 4c69 7374  ainer(types=List
+00008ed0: 436f 6e74 6169 6e65 7228 5b31 2c20 322c  Container([1, 2,
+00008ee0: 2039 5d29 2c20 656e 7472 6965 733d 4c69   9]), entries=Li
+00008ef0: 7374 436f 6e74 6169 6e65 7228 5b35 3035  stContainer([505
+00008f00: 3239 3032 372c 2031 3534 322c 204e 6f6e  29027, 1542, Non
+00008f10: 655d 2929 0a20 2020 203e 3e3e 2043 203d  e])).    >>> C =
+00008f20: 205f 0a20 2020 203e 3e3e 2073 7065 632e   _.    >>> spec.
+00008f30: 6275 696c 6428 4329 0a20 2020 2027 5c78  build(C).    '\x
+00008f40: 3031 5c78 3032 5c74 5c78 3033 5c78 3033  01\x02\t\x03\x03
+00008f50: 5c78 3033 5c78 3033 5c78 3036 5c78 3036  \x03\x03\x06\x06
+00008f60: 270a 2020 2020 3e3e 3e20 7370 6563 2e73  '.    >>> spec.s
+00008f70: 697a 656f 6628 2a2a 4329 0a20 2020 2039  izeof(**C).    9
+00008f80: 0a0a 2020 2020 3e3e 3e20 7370 6563 203d  ..    >>> spec =
+00008f90: 2053 7472 7563 7428 0a20 2020 202e 2e2e   Struct(.    ...
+00008fa0: 2020 2020 2027 7369 7a65 7327 202f 2049       'sizes' / I
+00008fb0: 6e74 3136 756c 5b34 5d2c 0a20 2020 202e  nt16ul[4],.    .
+00008fc0: 2e2e 2020 2020 2027 656e 7472 6965 7327  ..     'entries'
+00008fd0: 202f 2049 7465 7228 7468 6973 2e73 697a   / Iter(this.siz
+00008fe0: 6573 2c20 4279 7465 7329 2020 2320 6571  es, Bytes)  # eq
+00008ff0: 7569 7661 6c65 6e74 2074 6f20 4974 6572  uivalent to Iter
+00009000: 2874 6869 732e 7369 7a65 732c 206c 616d  (this.sizes, lam
+00009010: 6264 6120 7369 7a65 3a20 4279 7465 7328  bda size: Bytes(
+00009020: 7369 7a65 2929 0a20 2020 202e 2e2e 2029  size)).    ... )
+00009030: 0a20 2020 203e 3e3e 2073 7065 632e 7061  .    >>> spec.pa
+00009040: 7273 6528 275c 7830 315c 7830 305c 7830  rse('\x01\x00\x0
+00009050: 335c 7830 305c 7830 305c 7830 305c 7830  3\x00\x00\x00\x0
+00009060: 355c 7830 3061 6262 6264 6464 6464 2729  5\x00abbbddddd')
+00009070: 0a20 2020 2043 6f6e 7461 696e 6572 2873  .    Container(s
+00009080: 697a 6573 3d4c 6973 7443 6f6e 7461 696e  izes=ListContain
+00009090: 6572 285b 312c 2033 2c20 302c 2035 5d29  er([1, 3, 0, 5])
+000090a0: 2c20 656e 7472 6965 733d 4c69 7374 436f  , entries=ListCo
+000090b0: 6e74 6169 6e65 7228 5b27 6127 2c20 2762  ntainer(['a', 'b
+000090c0: 6262 272c 2027 272c 2027 6464 6464 6427  bb', '', 'ddddd'
+000090d0: 5d29 290a 2020 2020 3e3e 3e20 4320 3d20  ])).    >>> C = 
+000090e0: 5f0a 2020 2020 3e3e 3e20 7370 6563 2e62  _.    >>> spec.b
+000090f0: 7569 6c64 2843 290a 2020 2020 275c 7830  uild(C).    '\x0
+00009100: 315c 7830 305c 7830 335c 7830 305c 7830  1\x00\x03\x00\x0
+00009110: 305c 7830 305c 7830 355c 7830 3061 6262  0\x00\x05\x00abb
+00009120: 6264 6464 6464 270a 2020 2020 3e3e 3e20  bddddd'.    >>> 
+00009130: 4974 6572 2874 6869 732e 7369 7a65 732c  Iter(this.sizes,
+00009140: 2042 7974 6573 292e 7369 7a65 6f66 2873   Bytes).sizeof(s
+00009150: 697a 6573 3d5b 312c 322c 332c 305d 290a  izes=[1,2,3,0]).
+00009160: 2020 2020 360a 2020 2020 3e3e 3e20 7370      6.    >>> sp
+00009170: 6563 2e73 697a 656f 6628 2a2a 4329 0a20  ec.sizeof(**C). 
+00009180: 2020 2031 370a 0a20 2020 203a 7061 7261     17..    :para
+00009190: 6d20 6974 6572 6162 6c65 3a20 6974 6572  m iterable: iter
+000091a0: 6162 6c65 2069 7465 6d73 2074 6f20 6163  able items to ac
+000091b0: 7420 7570 6f6e 0a20 2020 203a 7061 7261  t upon.    :para
+000091c0: 6d20 6361 7365 733a 2041 2064 6963 7469  m cases: A dicti
+000091d0: 6f6e 6172 7920 6f66 2063 6173 6573 206f  onary of cases o
+000091e0: 7220 6120 6675 6e63 7469 6f6e 2074 6861  r a function tha
+000091f0: 7420 7461 6b65 7320 7461 6b65 7320 6120  t takes takes a 
+00009200: 6b65 7920 616e 6420 7265 7475 726e 7320  key and returns 
+00009210: 6120 636f 6e73 7472 7563 7420 7370 6563  a construct spec
+00009220: 2e0a 2020 2020 3a70 6172 616d 2064 6566  ..    :param def
+00009230: 6175 6c74 3a20 5468 6520 6465 6661 756c  ault: The defaul
+00009240: 7420 6361 7365 2028 6f6e 6c79 2069 6620  t case (only if 
+00009250: 6361 7365 7320 6973 2061 2064 6963 7429  cases is a dict)
+00009260: 0a20 2020 2022 2222 0a20 2020 205f 5f73  .    """.    __s
+00009270: 6c6f 7473 5f5f 203d 205b 2769 7465 7261  lots__ = ['itera
+00009280: 626c 6527 2c20 2763 6173 6573 272c 2027  ble', 'cases', '
+00009290: 6465 6661 756c 7427 5d0a 2020 2020 0a20  default'].    . 
+000092a0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+000092b0: 7365 6c66 2c20 6974 6572 6162 6c65 2c20  self, iterable, 
+000092c0: 6361 7365 732c 2064 6566 6175 6c74 3d4e  cases, default=N
+000092d0: 6f6e 6529 3a0a 2020 2020 2020 2020 7375  one):.        su
+000092e0: 7065 7228 4974 6572 2c20 7365 6c66 292e  per(Iter, self).
+000092f0: 5f5f 696e 6974 5f5f 2829 0a20 2020 2020  __init__().     
+00009300: 2020 2073 656c 662e 6974 6572 6162 6c65     self.iterable
+00009310: 203d 2069 7465 7261 626c 650a 2020 2020   = iterable.    
+00009320: 2020 2020 7365 6c66 2e63 6173 6573 203d      self.cases =
+00009330: 2063 6173 6573 0a20 2020 2020 2020 2073   cases.        s
+00009340: 656c 662e 6465 6661 756c 7420 3d20 6465  elf.default = de
+00009350: 6661 756c 7420 6f72 2050 6173 730a 2020  fault or Pass.  
+00009360: 2020 2020 2020 6966 206e 6f74 2063 616c        if not cal
+00009370: 6c61 626c 6528 6361 7365 7329 3a0a 2020  lable(cases):.  
+00009380: 2020 2020 2020 2020 2020 7365 6c66 2e66            self.f
+00009390: 6c61 6762 7569 6c64 6e6f 6e65 203d 2061  lagbuildnone = a
+000093a0: 6c6c 2873 632e 666c 6167 6275 696c 646e  ll(sc.flagbuildn
+000093b0: 6f6e 6520 666f 7220 7363 2069 6e20 6361  one for sc in ca
+000093c0: 7365 732e 7661 6c75 6573 2829 290a 2020  ses.values()).  
+000093d0: 2020 2020 2020 2020 2020 7365 6c66 2e66            self.f
+000093e0: 6c61 6765 6d62 6564 6465 6420 3d20 616c  lagembedded = al
+000093f0: 6c28 7363 2e66 6c61 6765 6d62 6564 6465  l(sc.flagembedde
+00009400: 6420 666f 7220 7363 2069 6e20 6361 7365  d for sc in case
+00009410: 732e 7661 6c75 6573 2829 290a 2020 2020  s.values()).    
+00009420: 2020 2020 0a20 2020 2064 6566 205f 7061      .    def _pa
+00009430: 7273 6528 7365 6c66 2c20 7374 7265 616d  rse(self, stream
+00009440: 2c20 636f 6e74 6578 742c 2070 6174 6829  , context, path)
+00009450: 3a0a 2020 2020 2020 2020 6974 6572 6174  :.        iterat
+00009460: 6f72 203d 2069 7465 7228 7365 6c66 2e69  or = iter(self.i
+00009470: 7465 7261 626c 6528 636f 6e74 6578 7429  terable(context)
+00009480: 2920 6966 2063 616c 6c61 626c 6528 7365  ) if callable(se
+00009490: 6c66 2e69 7465 7261 626c 6529 2065 6c73  lf.iterable) els
+000094a0: 6520 6974 6572 2873 656c 662e 6974 6572  e iter(self.iter
+000094b0: 6162 6c65 290a 2020 2020 2020 2020 6966  able).        if
+000094c0: 2063 616c 6c61 626c 6528 7365 6c66 2e63   callable(self.c
+000094d0: 6173 6573 293a 0a20 2020 2020 2020 2020  ases):.         
+000094e0: 2020 2072 6574 7572 6e20 4c69 7374 436f     return ListCo
+000094f0: 6e74 6169 6e65 7228 5b73 656c 662e 6361  ntainer([self.ca
+00009500: 7365 7328 6b65 7929 2e5f 7061 7273 6572  ses(key)._parser
+00009510: 6570 6f72 7428 7374 7265 616d 2c20 636f  eport(stream, co
+00009520: 6e74 6578 742c 2070 6174 6829 2066 6f72  ntext, path) for
+00009530: 206b 6579 2069 6e20 6974 6572 6174 6f72   key in iterator
+00009540: 5d29 0a20 2020 2020 2020 2065 6c73 653a  ]).        else:
+00009550: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00009560: 7572 6e20 4c69 7374 436f 6e74 6169 6e65  urn ListContaine
+00009570: 7228 5b73 656c 662e 6361 7365 732e 6765  r([self.cases.ge
+00009580: 7428 6b65 792c 2073 656c 662e 6465 6661  t(key, self.defa
+00009590: 756c 7429 2e5f 7061 7273 6572 6570 6f72  ult)._parserepor
+000095a0: 7428 7374 7265 616d 2c20 636f 6e74 6578  t(stream, contex
+000095b0: 742c 2070 6174 6829 2066 6f72 206b 6579  t, path) for key
+000095c0: 2069 6e20 6974 6572 6174 6f72 5d29 0a20   in iterator]). 
+000095d0: 2020 2020 2020 200a 2020 2020 6465 6620         .    def 
+000095e0: 5f62 7569 6c64 2873 656c 662c 206f 626a  _build(self, obj
+000095f0: 2c20 7374 7265 616d 2c20 636f 6e74 6578  , stream, contex
+00009600: 742c 2070 6174 6829 3a0a 2020 2020 2020  t, path):.      
+00009610: 2020 6974 6572 6174 6f72 203d 2069 7465    iterator = ite
+00009620: 7228 7365 6c66 2e69 7465 7261 626c 6528  r(self.iterable(
+00009630: 636f 6e74 6578 7429 2920 6966 2063 616c  context)) if cal
+00009640: 6c61 626c 6528 7365 6c66 2e69 7465 7261  lable(self.itera
+00009650: 626c 6529 2065 6c73 6520 6974 6572 2873  ble) else iter(s
+00009660: 656c 662e 6974 6572 6162 6c65 290a 2020  elf.iterable).  
+00009670: 2020 2020 2020 666f 7220 7375 625f 6f62        for sub_ob
+00009680: 6a2c 206b 6579 2069 6e20 7a69 7028 6f62  j, key in zip(ob
+00009690: 6a2c 2069 7465 7261 746f 7229 3a0a 2020  j, iterator):.  
+000096a0: 2020 2020 2020 2020 2020 6966 2063 616c            if cal
+000096b0: 6c61 626c 6528 7365 6c66 2e63 6173 6573  lable(self.cases
+000096c0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+000096d0: 2020 2073 656c 662e 6361 7365 7328 6b65     self.cases(ke
+000096e0: 7929 2e5f 6275 696c 6428 7375 625f 6f62  y)._build(sub_ob
+000096f0: 6a2c 2073 7472 6561 6d2c 2063 6f6e 7465  j, stream, conte
+00009700: 7874 2c20 7061 7468 290a 2020 2020 2020  xt, path).      
+00009710: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00009720: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00009730: 2e63 6173 6573 2e67 6574 286b 6579 2c20  .cases.get(key, 
+00009740: 7365 6c66 2e64 6566 6175 6c74 292e 5f62  self.default)._b
+00009750: 7569 6c64 2873 7562 5f6f 626a 2c20 7374  uild(sub_obj, st
+00009760: 7265 616d 2c20 636f 6e74 6578 742c 2070  ream, context, p
+00009770: 6174 6829 0a20 2020 2020 2020 2020 2020  ath).           
+00009780: 200a 2020 2020 6465 6620 5f73 697a 656f   .    def _sizeo
+00009790: 6628 7365 6c66 2c20 636f 6e74 6578 742c  f(self, context,
+000097a0: 2070 6174 6829 3a0a 2020 2020 2020 2020   path):.        
+000097b0: 6974 6572 6174 6f72 203d 2069 7465 7228  iterator = iter(
+000097c0: 6576 616c 7561 7465 2873 656c 662e 6974  evaluate(self.it
+000097d0: 6572 6162 6c65 2c20 636f 6e74 6578 7429  erable, context)
+000097e0: 290a 2020 2020 2020 2020 7369 7a65 203d  ).        size =
+000097f0: 2030 0a20 2020 2020 2020 2066 6f72 206b   0.        for k
+00009800: 6579 2069 6e20 6974 6572 6174 6f72 3a0a  ey in iterator:.
+00009810: 2020 2020 2020 2020 2020 2020 7472 793a              try:
+00009820: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00009830: 2069 6620 6361 6c6c 6162 6c65 2873 656c   if callable(sel
+00009840: 662e 6361 7365 7329 3a0a 2020 2020 2020  f.cases):.      
+00009850: 2020 2020 2020 2020 2020 2020 2020 7369                si
+00009860: 7a65 202b 3d20 7365 6c66 2e63 6173 6573  ze += self.cases
+00009870: 286b 6579 292e 5f73 697a 656f 6628 636f  (key)._sizeof(co
+00009880: 6e74 6578 742c 2070 6174 6829 0a20 2020  ntext, path).   
+00009890: 2020 2020 2020 2020 2020 2020 2065 6c73               els
+000098a0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+000098b0: 2020 2020 2020 2073 697a 6520 2b3d 2073         size += s
+000098c0: 656c 662e 6361 7365 732e 6765 7428 6b65  elf.cases.get(ke
+000098d0: 792c 2073 656c 662e 6465 6661 756c 7429  y, self.default)
+000098e0: 2e5f 7369 7a65 6f66 2863 6f6e 7465 7874  ._sizeof(context
+000098f0: 2c20 7061 7468 290a 2020 2020 2020 2020  , path).        
+00009900: 2020 2020 6578 6365 7074 2028 4b65 7945      except (KeyE
+00009910: 7272 6f72 2c20 4174 7472 6962 7574 6545  rror, AttributeE
+00009920: 7272 6f72 293a 0a20 2020 2020 2020 2020  rror):.         
+00009930: 2020 2020 2020 2072 6169 7365 2053 697a         raise Siz
+00009940: 656f 6645 7272 6f72 2822 6361 6e6e 6f74  eofError("cannot
+00009950: 2063 616c 6375 6c61 7465 2073 697a 652c   calculate size,
+00009960: 207b 2172 7d20 6b65 7920 6e6f 7420 666f   {!r} key not fo
+00009970: 756e 6420 696e 2063 6f6e 7465 7874 222e  und in context".
+00009980: 666f 726d 6174 286b 6579 2929 0a20 2020  format(key)).   
+00009990: 2020 2020 2072 6574 7572 6e20 7369 7a65       return size
+000099a0: 0a0a 0a64 6566 2066 696e 645f 636f 6e73  ...def find_cons
+000099b0: 7472 7563 7473 2873 7472 7563 742c 2064  tructs(struct, d
+000099c0: 6174 6129 3a0a 2020 2020 7222 2222 0a20  ata):.    r""". 
+000099d0: 2020 2047 656e 6572 6174 6f72 2074 6861     Generator tha
+000099e0: 7420 7969 656c 6473 2074 6865 2072 6573  t yields the res
+000099f0: 756c 7473 206f 6620 7375 6363 6573 7366  ults of successf
+00009a00: 756c 2070 6172 7369 6e67 7320 6f66 2074  ul parsings of t
+00009a10: 6865 2067 6976 656e 0a20 2020 2063 6f6e  he given.    con
+00009a20: 7374 7275 6374 2e0a 2020 2020 4e6f 7465  struct..    Note
+00009a30: 3a20 436f 6e73 7472 7563 7420 6d75 7374  : Construct must
+00009a40: 2061 7474 656d 7074 2074 6f20 7265 6164   attempt to read
+00009a50: 2073 6f6d 6574 6869 6e67 2e20 4965 2c20   something. Ie, 
+00009a60: 646f 6e27 7420 6861 7665 2061 2050 6565  don't have a Pee
+00009a70: 6b0a 2020 2020 6173 2079 6f75 7220 6669  k.    as your fi
+00009a80: 7273 7420 7375 6263 6f6e 7374 7275 6374  rst subconstruct
+00009a90: 2e0a 0a20 2020 2041 6c73 6f2c 2069 7427  ...    Also, it'
+00009aa0: 7320 6265 7374 2069 6620 796f 7520 6861  s best if you ha
+00009ab0: 7665 2073 6f6d 6520 7479 7065 206f 6620  ve some type of 
+00009ac0: 7661 6c69 6461 7469 6f6e 2028 436f 6e73  validation (Cons
+00009ad0: 742c 204f 6e65 4f66 2c20 4e6f 6e65 4f66  t, OneOf, NoneOf
+00009ae0: 2c20 4368 6563 6b2c 2065 7463 2920 7769  , Check, etc) wi
+00009af0: 7468 696e 2079 6f75 7220 7374 7275 6374  thin your struct
+00009b00: 2e0a 2020 2020 4f74 6865 7277 6973 652c  ..    Otherwise,
+00009b10: 2069 7420 6d61 6b65 7320 6d6f 7265 2073   it makes more s
+00009b20: 656e 7365 2074 6f20 7573 6520 6120 4772  ense to use a Gr
+00009b30: 6565 6479 5261 6e67 6520 2874 6865 2027  eedyRange (the '
+00009b40: 5b3a 5d27 206e 6f74 6174 696f 6e29 2069  [:]' notation) i
+00009b50: 6e73 7465 6164 206f 6620 7468 6973 2066  nstead of this f
+00009b60: 756e 6374 696f 6e2e 0a0a 2020 2020 652e  unction...    e.
+00009b70: 672e 0a20 2020 203e 3e3e 2073 7472 7563  g..    >>> struc
+00009b80: 7420 3d20 5374 7275 6374 280a 2020 2020  t = Struct(.    
+00009b90: 2e2e 2e20 2020 2020 436f 6e73 7428 6227  ...     Const(b'
+00009ba0: 4d5a 2729 2c0a 2020 2020 2e2e 2e20 2020  MZ'),.    ...   
+00009bb0: 2020 2769 6e74 2720 2f20 496e 7431 3675    'int' / Int16u
+00009bc0: 6c2c 0a20 2020 202e 2e2e 2020 2020 2027  l,.    ...     '
+00009bd0: 7374 7269 6e67 2720 2f20 4353 7472 696e  string' / CStrin
+00009be0: 6728 2929 0a20 2020 203e 3e3e 206c 6973  g()).    >>> lis
+00009bf0: 7428 6669 6e64 5f63 6f6e 7374 7275 6374  t(find_construct
+00009c00: 7328 7374 7275 6374 2c20 6227 5c78 3031  s(struct, b'\x01
+00009c10: 5c78 3032 5c78 3033 4d5a 5c78 3041 5c78  \x02\x03MZ\x0A\x
+00009c20: 3030 6865 6c6c 6f5c 7830 305c 7830 335c  00hello\x00\x03\
+00009c30: 7830 344d 5a5c 7830 425c 7830 3077 6f72  x04MZ\x0B\x00wor
+00009c40: 6c64 5c78 3030 5c78 3030 2729 290a 2020  ld\x00\x00')).  
+00009c50: 2020 5b28 334c 2c20 436f 6e74 6169 6e65    [(3L, Containe
+00009c60: 7228 696e 743d 3130 2c20 7374 7269 6e67  r(int=10, string
+00009c70: 3d75 2768 656c 6c6f 2729 292c 2028 3135  =u'hello')), (15
+00009c80: 4c2c 2043 6f6e 7461 696e 6572 2869 6e74  L, Container(int
+00009c90: 3d31 312c 2073 7472 696e 673d 7527 776f  =11, string=u'wo
+00009ca0: 726c 6427 2929 5d0a 2020 2020 3e3e 3e20  rld'))].    >>> 
+00009cb0: 6c69 7374 2866 696e 645f 636f 6e73 7472  list(find_constr
+00009cc0: 7563 7473 2873 7472 7563 742c 2062 276e  ucts(struct, b'n
+00009cd0: 6f70 6527 2929 0a20 2020 205b 5d0a 0a20  ope')).    [].. 
+00009ce0: 2020 203a 7061 7261 6d20 7374 7275 6374     :param struct
+00009cf0: 3a20 636f 6e73 7472 7563 7420 746f 2061  : construct to a
+00009d00: 7070 6c79 2028 696e 7374 616e 6365 206f  pply (instance o
+00009d10: 6620 636f 6e73 7472 7563 742e 436f 6e73  f construct.Cons
+00009d20: 7472 7563 7429 0a20 2020 203a 7061 7261  truct).    :para
+00009d30: 6d20 6461 7461 3a20 6279 7465 2073 7472  m data: byte str
+00009d40: 696e 6720 6f66 2064 6174 6120 746f 2073  ing of data to s
+00009d50: 6561 7263 682e 0a0a 2020 2020 3a79 6965  earch...    :yie
+00009d60: 6c64 3a20 7475 706c 6520 636f 6e74 6169  ld: tuple contai
+00009d70: 6e69 6e67 2028 6f66 6673 6574 2077 6974  ning (offset wit
+00009d80: 6820 6461 7461 2c20 7265 7375 6c74 2043  h data, result C
+00009d90: 6f6e 7461 696e 6572 2063 6c61 7373 290a  ontainer class).
+00009da0: 2020 2020 2222 220a 2020 2020 6461 7461      """.    data
+00009db0: 203d 2069 6f2e 4279 7465 7349 4f28 6461   = io.BytesIO(da
+00009dc0: 7461 290a 0a20 2020 2077 6869 6c65 2054  ta)..    while T
+00009dd0: 7275 653a 0a20 2020 2020 2020 206f 6666  rue:.        off
+00009de0: 7365 7420 3d20 6461 7461 2e74 656c 6c28  set = data.tell(
+00009df0: 290a 2020 2020 2020 2020 7472 793a 0a20  ).        try:. 
+00009e00: 2020 2020 2020 2020 2020 2064 6174 615f             data_
+00009e10: 656c 656d 656e 7420 3d20 7374 7275 6374  element = struct
+00009e20: 2e70 6172 7365 5f73 7472 6561 6d28 6461  .parse_stream(da
+00009e30: 7461 290a 2020 2020 2020 2020 6578 6365  ta).        exce
+00009e40: 7074 2028 636f 6e73 7472 7563 742e 436f  pt (construct.Co
+00009e50: 6e73 7472 7563 7445 7272 6f72 2c20 4f76  nstructError, Ov
+00009e60: 6572 666c 6f77 4572 726f 7229 2061 7320  erflowError) as 
+00009e70: 653a 0a20 2020 2020 2020 2020 2020 2064  e:.            d
+00009e80: 6174 612e 7365 656b 286f 6666 7365 7420  ata.seek(offset 
+00009e90: 2b20 3129 0a20 2020 2020 2020 2065 6c73  + 1).        els
+00009ea0: 653a 0a20 2020 2020 2020 2020 2020 2079  e:.            y
+00009eb0: 6965 6c64 206f 6666 7365 742c 2064 6174  ield offset, dat
+00009ec0: 615f 656c 656d 656e 740a 0a20 2020 2020  a_element..     
+00009ed0: 2020 2023 2054 6573 7420 6966 2077 6520     # Test if we 
+00009ee0: 6869 7420 656e 6420 6f66 2064 6174 612e  hit end of data.
+00009ef0: 0a20 2020 2020 2020 2069 6620 6461 7461  .        if data
+00009f00: 2e72 6561 6428 3129 3a0a 2020 2020 2020  .read(1):.      
+00009f10: 2020 2020 2020 6461 7461 2e73 6565 6b28        data.seek(
+00009f20: 2d31 2c20 6f73 2e53 4545 4b5f 4355 5229  -1, os.SEEK_CUR)
+00009f30: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+00009f40: 2020 2020 2020 2020 2020 2062 7265 616b             break
+00009f50: 0a0a 0a63 6c61 7373 2042 6163 6b77 6172  ...class Backwar
+00009f60: 6473 2853 7562 636f 6e73 7472 7563 7429  ds(Subconstruct)
+00009f70: 3a0a 2020 2020 7222 2222 0a20 2020 2053  :.    r""".    S
+00009f80: 7562 636f 6e73 7472 7563 7420 7573 6564  ubconstruct used
+00009f90: 2074 6f20 7061 7273 6520 6120 6769 7665   to parse a give
+00009fa0: 6e20 7375 6263 6f6e 7374 7275 6374 2062  n subconstruct b
+00009fb0: 6163 6b77 6172 6473 2069 6e20 7468 6520  ackwards in the 
+00009fc0: 7374 7265 616d 2e0a 2020 2020 5468 6973  stream..    This
+00009fd0: 2069 6120 6120 6d61 6372 6f20 666f 7220   ia a macro for 
+00009fe0: 7365 656b 696e 6720 6261 636b 7761 7264  seeking backward
+00009ff0: 7320 6265 666f 7265 2070 6172 7369 6e67  s before parsing
+0000a000: 2074 6865 2063 6f6e 7374 7275 6374 2e0a   the construct..
+0000a010: 2020 2020 2854 6869 7320 7769 6c6c 206e      (This will n
+0000a020: 6f74 2077 6f72 6b20 666f 7220 7375 6263  ot work for subc
+0000a030: 6f6e 7320 7468 6174 2064 6f6e 2774 2068  ons that don't h
+0000a040: 6176 6520 6120 7661 6c69 6420 7369 7a65  ave a valid size
+0000a050: 6f66 2e0a 2020 2020 4578 6365 7074 2066  of..    Except f
+0000a060: 6f72 2047 7265 6564 7942 7974 6573 2061  or GreedyBytes a
+0000a070: 6e64 2047 7265 6564 7953 7472 696e 6729  nd GreedyString)
+0000a080: 0a0a 2020 2020 5468 6520 7374 7265 616d  ..    The stream
+0000a090: 2077 696c 6c20 6265 206c 6566 7420 6f66   will be left of
+0000a0a0: 6620 6174 2074 6865 2073 7461 7274 206f  f at the start o
+0000a0b0: 6620 7468 6520 7061 7273 6564 2072 6573  f the parsed res
+0000a0c0: 756c 7420 6279 2064 6573 6967 6e2e 0a20  ult by design.. 
+0000a0d0: 2020 2054 6865 7265 666f 7265 2c20 646f     Therefore, do
+0000a0e0: 696e 6720 736f 6d65 7468 696e 6720 6c69  ing something li
+0000a0f0: 6b65 2049 6e74 3332 756c 203e 3e20 4261  ke Int32ul >> Ba
+0000a100: 636b 7761 7264 7328 496e 7433 3275 6c29  ckwards(Int32ul)
+0000a110: 203e 3e20 496e 7433 3275 6c20 7769 6c6c   >> Int32ul will
+0000a120: 2070 6172 7365 0a20 2020 2074 6865 2073   parse.    the s
+0000a130: 616d 6520 6461 7461 2033 2074 696d 6573  ame data 3 times
+0000a140: 2e0a 0a20 2020 2065 2e67 2e0a 2020 2020  ...    e.g..    
+0000a150: 3e3e 3e20 2842 7974 6573 2831 3429 203e  >>> (Bytes(14) >
+0000a160: 3e20 4261 636b 7761 7264 7328 496e 7433  > Backwards(Int3
+0000a170: 3275 6c29 203e 3e20 5465 6c6c 292e 7061  2ul) >> Tell).pa
+0000a180: 7273 6528 6227 6a75 6e6b 2073 7475 6666  rse(b'junk stuff
+0000a190: 5c78 3031 5c78 3032 5c78 3030 5c78 3030  \x01\x02\x00\x00
+0000a1a0: 2729 0a20 2020 204c 6973 7443 6f6e 7461  ').    ListConta
+0000a1b0: 696e 6572 285b 276a 756e 6b20 7374 7566  iner(['junk stuf
+0000a1c0: 665c 7830 315c 7830 325c 7830 305c 7830  f\x01\x02\x00\x0
+0000a1d0: 3027 2c20 3531 332c 2031 304c 5d29 0a20  0', 513, 10L]). 
+0000a1e0: 2020 203e 3e3e 2073 7065 6320 3d20 5374     >>> spec = St
+0000a1f0: 7275 6374 2853 6565 6b28 302c 206f 732e  ruct(Seek(0, os.
+0000a200: 5345 454b 5f45 4e44 292c 2027 6e61 6d65  SEEK_END), 'name
+0000a210: 2720 2f20 4261 636b 7761 7264 7328 5374  ' / Backwards(St
+0000a220: 7269 6e67 2839 2929 2c20 276e 756d 6265  ring(9)), 'numbe
+0000a230: 7227 202f 2042 6163 6b77 6172 6473 2849  r' / Backwards(I
+0000a240: 6e74 3332 756c 2929 0a20 2020 203e 3e3e  nt32ul)).    >>>
+0000a250: 2073 7065 632e 7061 7273 6528 6227 4120   spec.parse(b'A 
+0000a260: 4255 4e43 4820 4f46 204a 554e 4b20 4441  BUNCH OF JUNK DA
+0000a270: 5441 5c78 3031 5c78 3030 5c78 3030 5c78  TA\x01\x00\x00\x
+0000a280: 3030 6a6f 6520 7368 6d6f 6527 290a 2020  00joe shmoe').  
+0000a290: 2020 436f 6e74 6169 6e65 7228 6e61 6d65    Container(name
+0000a2a0: 3d75 276a 6f65 2073 686d 6f65 272c 206e  =u'joe shmoe', n
+0000a2b0: 756d 6265 723d 3129 0a0a 2020 2020 5741  umber=1)..    WA
+0000a2c0: 524e 494e 473a 2054 6869 7320 7769 6c6c  RNING: This will
+0000a2d0: 2062 7265 616b 2069 6620 7468 6520 7375   break if the su
+0000a2e0: 6263 6f6e 2064 6f65 736e 2774 2068 6176  bcon doesn't hav
+0000a2f0: 6520 6120 7661 6c69 6420 7369 7a65 6f66  e a valid sizeof
+0000a300: 2e0a 2020 2020 3e3e 3e20 7370 6563 203d  ..    >>> spec =
+0000a310: 2053 7472 7563 7428 5365 656b 2830 2c20   Struct(Seek(0, 
+0000a320: 6f73 2e53 4545 4b5f 454e 4429 2c20 276e  os.SEEK_END), 'n
+0000a330: 616d 6527 202f 2042 6163 6b77 6172 6473  ame' / Backwards
+0000a340: 2843 5374 7269 6e67 2829 292c 2027 6e75  (CString()), 'nu
+0000a350: 6d62 6572 2720 2f20 4261 636b 7761 7264  mber' / Backward
+0000a360: 7328 496e 7433 3275 6c29 290a 2020 2020  s(Int32ul)).    
+0000a370: 3e3e 3e20 7370 6563 2e70 6172 7365 2862  >>> spec.parse(b
+0000a380: 2741 2042 554e 4348 204f 4620 4a55 4e4b  'A BUNCH OF JUNK
+0000a390: 2044 4154 415c 7830 315c 7830 305c 7830   DATA\x01\x00\x0
+0000a3a0: 305c 7830 306a 6f65 2073 686d 6f65 5c78  0\x00joe shmoe\x
+0000a3b0: 3030 2729 0a20 2020 2054 7261 6365 6261  00').    Traceba
+0000a3c0: 636b 2028 6d6f 7374 2072 6563 656e 7420  ck (most recent 
+0000a3d0: 6361 6c6c 206c 6173 7429 3a0a 2020 2020  call last):.    
+0000a3e0: 2020 2e2e 2e0a 2020 2020 5369 7a65 6f66    ....    Sizeof
+0000a3f0: 4572 726f 720a 0a20 2020 2048 6f77 6576  Error..    Howev
+0000a400: 6572 2c20 4772 6565 6479 4279 7465 7320  er, GreedyBytes 
+0000a410: 616e 6420 4772 6565 6479 5374 7269 6e67  and GreedyString
+0000a420: 2061 7265 2061 6c6c 6f77 6564 2e0a 2020   are allowed..  
+0000a430: 2020 3e3e 3e20 7370 6563 203d 2053 7472    >>> spec = Str
+0000a440: 7563 7428 5365 656b 2830 2c20 6f73 2e53  uct(Seek(0, os.S
+0000a450: 4545 4b5f 454e 4429 2c20 276e 616d 6527  EEK_END), 'name'
+0000a460: 202f 2042 6163 6b77 6172 6473 2853 7472   / Backwards(Str
+0000a470: 696e 6728 3929 292c 2027 7265 7374 2720  ing(9)), 'rest' 
+0000a480: 2f20 4261 636b 7761 7264 7328 4772 6565  / Backwards(Gree
+0000a490: 6479 4279 7465 7329 290a 2020 2020 3e3e  dyBytes)).    >>
+0000a4a0: 3e20 7370 6563 2e70 6172 7365 2862 2741  > spec.parse(b'A
+0000a4b0: 2042 554e 4348 204f 4620 4a55 4e4b 2044   BUNCH OF JUNK D
+0000a4c0: 4154 415c 7830 315c 7830 305c 7830 305c  ATA\x01\x00\x00\
+0000a4d0: 7830 306a 6f65 2073 686d 6f65 2729 0a20  x00joe shmoe'). 
+0000a4e0: 2020 2043 6f6e 7461 696e 6572 286e 616d     Container(nam
+0000a4f0: 653d 7527 6a6f 6520 7368 6d6f 6527 2c20  e=u'joe shmoe', 
+0000a500: 7265 7374 3d62 2741 2042 554e 4348 204f  rest=b'A BUNCH O
+0000a510: 4620 4a55 4e4b 2044 4154 415c 7830 315c  F JUNK DATA\x01\
+0000a520: 7830 305c 7830 305c 7830 3027 290a 2020  x00\x00\x00').  
+0000a530: 2020 3e3e 3e20 7370 6563 203d 2053 7472    >>> spec = Str
+0000a540: 7563 7428 5365 656b 2830 2c20 6f73 2e53  uct(Seek(0, os.S
+0000a550: 4545 4b5f 454e 4429 2c20 276e 616d 6527  EEK_END), 'name'
+0000a560: 202f 2042 6163 6b77 6172 6473 2853 7472   / Backwards(Str
+0000a570: 696e 6728 3929 292c 2027 7265 7374 2720  ing(9)), 'rest' 
+0000a580: 2f20 4261 636b 7761 7264 7328 4772 6565  / Backwards(Gree
+0000a590: 6479 5374 7269 6e67 2865 6e63 6f64 696e  dyString(encodin
+0000a5a0: 673d 2775 7466 2d31 362d 6c65 2729 2929  g='utf-16-le')))
+0000a5b0: 0a20 2020 203e 3e3e 2073 7065 632e 7061  .    >>> spec.pa
+0000a5c0: 7273 6528 6227 685c 7830 3065 5c78 3030  rse(b'h\x00e\x00
+0000a5d0: 6c5c 7830 306c 5c78 3030 6f5c 7830 306a  l\x00l\x00o\x00j
+0000a5e0: 6f65 2073 686d 6f65 2729 0a20 2020 2043  oe shmoe').    C
+0000a5f0: 6f6e 7461 696e 6572 286e 616d 653d 7527  ontainer(name=u'
+0000a600: 6a6f 6520 7368 6d6f 6527 2c20 7265 7374  joe shmoe', rest
+0000a610: 3d75 2768 656c 6c6f 2729 0a0a 2020 2020  =u'hello')..    
+0000a620: 5741 524e 494e 473a 2054 6869 7320 7769  WARNING: This wi
+0000a630: 6c6c 2061 6c73 6f20 6272 6561 6b20 6966  ll also break if
+0000a640: 2079 6f75 2072 6561 6420 6d6f 7265 2064   you read more d
+0000a650: 6174 6120 7468 6174 2069 7320 6265 6869  ata that is behi
+0000a660: 6e64 2074 6865 2063 7572 7265 6e74 2070  nd the current p
+0000a670: 6f73 6974 696f 6e2e 0a20 2020 203e 3e3e  osition..    >>>
+0000a680: 2028 5365 656b 2830 2c20 6f73 2e53 4545   (Seek(0, os.SEE
+0000a690: 4b5f 454e 4429 203e 3e20 4261 636b 7761  K_END) >> Backwa
+0000a6a0: 7264 7328 5374 7269 6e67 2831 3029 2929  rds(String(10)))
+0000a6b0: 2e70 6172 7365 2827 796f 2729 0a20 2020  .parse('yo').   
+0000a6c0: 2054 7261 6365 6261 636b 2028 6d6f 7374   Traceback (most
+0000a6d0: 2072 6563 656e 7420 6361 6c6c 206c 6173   recent call las
+0000a6e0: 7429 3a0a 2020 2020 2020 2e2e 2e0a 2020  t):.      ....  
+0000a6f0: 2020 466f 726d 6174 4669 656c 6445 7272    FormatFieldErr
+0000a700: 6f72 3a20 636f 756c 6420 6e6f 7420 7265  or: could not re
+0000a710: 6164 2065 6e6f 7567 6820 6279 7465 732c  ad enough bytes,
+0000a720: 2065 7870 6563 7465 6420 3130 2c20 666f   expected 10, fo
+0000a730: 756e 6420 320a 2020 2020 2222 220a 2020  und 2.    """.  
+0000a740: 2020 5f5f 736c 6f74 735f 5f20 3d20 5b27    __slots__ = ['
+0000a750: 6772 6565 6479 275d 0a0a 2020 2020 6465  greedy']..    de
+0000a760: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
+0000a770: 2073 7562 636f 6e29 3a0a 2020 2020 2020   subcon):.      
+0000a780: 2020 7375 7065 7228 4261 636b 7761 7264    super(Backward
+0000a790: 732c 2073 656c 6629 2e5f 5f69 6e69 745f  s, self).__init_
+0000a7a0: 5f28 7375 6263 6f6e 290a 2020 2020 2020  _(subcon).      
+0000a7b0: 2020 2320 4772 6565 6479 4279 7465 7320    # GreedyBytes 
+0000a7c0: 616e 6420 4772 6565 6479 5374 7269 6e67  and GreedyString
+0000a7d0: 2061 7265 2061 6c6c 6f77 6564 2073 7065   are allowed spe
+0000a7e0: 6369 616c 2063 6173 6573 2e0a 2020 2020  cial cases..    
+0000a7f0: 2020 2020 7365 6c66 2e67 7265 6564 7920      self.greedy 
+0000a800: 3d20 7365 6c66 2e73 7562 636f 6e20 6973  = self.subcon is
+0000a810: 2047 7265 6564 7942 7974 6573 206f 7220   GreedyBytes or 
+0000a820: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+0000a830: 2020 6973 696e 7374 616e 6365 2873 656c    isinstance(sel
+0000a840: 662e 7375 6263 6f6e 2c20 636f 6e73 7472  f.subcon, constr
+0000a850: 7563 742e 5374 7269 6e67 456e 636f 6465  uct.StringEncode
+0000a860: 6429 2061 6e64 2073 656c 662e 7375 6263  d) and self.subc
+0000a870: 6f6e 2e73 7562 636f 6e20 6973 2047 7265  on.subcon is Gre
+0000a880: 6564 7942 7974 6573 290a 0a20 2020 2064  edyBytes)..    d
+0000a890: 6566 205f 7061 7273 6528 7365 6c66 2c20  ef _parse(self, 
+0000a8a0: 7374 7265 616d 2c20 636f 6e74 6578 742c  stream, context,
+0000a8b0: 2070 6174 6829 3a0a 2020 2020 2020 2020   path):.        
+0000a8c0: 2320 5365 656b 2062 6163 6b20 746f 2073  # Seek back to s
+0000a8d0: 7461 7274 206f 6620 7375 6263 6f6e 2e0a  tart of subcon..
+0000a8e0: 2020 2020 2020 2020 6f72 6967 5f70 6f73          orig_pos
+0000a8f0: 203d 2073 7472 6561 6d2e 7465 6c6c 2829   = stream.tell()
+0000a900: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+0000a910: 2e67 7265 6564 793a 0a20 2020 2020 2020  .greedy:.       
+0000a920: 2020 2020 2073 7461 7274 5f70 6f73 203d       start_pos =
+0000a930: 2073 7472 6561 6d2e 7365 656b 2830 290a   stream.seek(0).
+0000a940: 2020 2020 2020 2020 2020 2020 7369 7a65              size
+0000a950: 203d 206f 7269 675f 706f 7320 2d20 7374   = orig_pos - st
+0000a960: 6172 745f 706f 730a 2020 2020 2020 2020  art_pos.        
+0000a970: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
+0000a980: 2020 2020 2020 2020 2073 7562 5f73 7472           sub_str
+0000a990: 6561 6d20 3d20 696f 2e42 7974 6573 494f  eam = io.BytesIO
+0000a9a0: 2873 7472 6561 6d5f 7265 6164 2873 7472  (stream_read(str
+0000a9b0: 6561 6d2c 2073 697a 6529 290a 2020 2020  eam, size)).    
+0000a9c0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+0000a9d0: 726e 2073 656c 662e 7375 6263 6f6e 2e5f  rn self.subcon._
+0000a9e0: 7061 7273 6572 6570 6f72 7428 7375 625f  parsereport(sub_
+0000a9f0: 7374 7265 616d 2c20 636f 6e74 6578 742c  stream, context,
+0000aa00: 2070 6174 6829 0a20 2020 2020 2020 2020   path).         
+0000aa10: 2020 2066 696e 616c 6c79 3a0a 2020 2020     finally:.    
+0000aa20: 2020 2020 2020 2020 2020 2020 7374 7265              stre
+0000aa30: 616d 2e73 6565 6b28 7374 6172 745f 706f  am.seek(start_po
+0000aa40: 7329 0a20 2020 2020 2020 2065 6c73 653a  s).        else:
+0000aa50: 0a20 2020 2020 2020 2020 2020 2073 697a  .            siz
+0000aa60: 6520 3d20 7365 6c66 2e73 7562 636f 6e2e  e = self.subcon.
+0000aa70: 5f73 697a 656f 6628 636f 6e74 6578 742c  _sizeof(context,
+0000aa80: 2070 6174 6829 0a20 2020 2020 2020 2020   path).         
+0000aa90: 2020 2073 7461 7274 5f70 6f73 203d 2073     start_pos = s
+0000aaa0: 7472 6561 6d2e 7365 656b 2873 697a 6520  tream.seek(size 
+0000aab0: 2a20 2d31 2c20 6f73 2e53 4545 4b5f 4355  * -1, os.SEEK_CU
+0000aac0: 5229 0a20 2020 2020 2020 2020 2020 2023  R).            #
+0000aad0: 2044 6574 6572 6d69 6e65 2069 6620 7765   Determine if we
+0000aae0: 2066 656c 6c20 6f66 6620 7468 6520 6672   fell off the fr
+0000aaf0: 6f6e 742e 0a20 2020 2020 2020 2020 2020  ont..           
+0000ab00: 2069 6620 6f72 6967 5f70 6f73 202d 2073   if orig_pos - s
+0000ab10: 7461 7274 5f70 6f73 203c 2073 697a 653a  tart_pos < size:
+0000ab20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ab30: 2072 6169 7365 2046 6f72 6d61 7446 6965   raise FormatFie
+0000ab40: 6c64 4572 726f 7228 2263 6f75 6c64 206e  ldError("could n
+0000ab50: 6f74 2072 6561 6420 656e 6f75 6768 2062  ot read enough b
+0000ab60: 7974 6573 2c20 6578 7065 6374 6564 2025  ytes, expected %
+0000ab70: 642c 2066 6f75 6e64 2025 6422 2025 2028  d, found %d" % (
+0000ab80: 7369 7a65 2c20 6f72 6967 5f70 6f73 202d  size, orig_pos -
+0000ab90: 2073 7461 7274 5f70 6f73 2929 0a20 2020   start_pos)).   
+0000aba0: 2020 2020 2020 2020 2074 7279 3a0a 2020           try:.  
+0000abb0: 2020 2020 2020 2020 2020 2020 2020 7265                re
+0000abc0: 7475 726e 2073 656c 662e 7375 6263 6f6e  turn self.subcon
+0000abd0: 2e5f 7061 7273 6572 6570 6f72 7428 7374  ._parsereport(st
+0000abe0: 7265 616d 2c20 636f 6e74 6578 742c 2070  ream, context, p
+0000abf0: 6174 6829 0a20 2020 2020 2020 2020 2020  ath).           
+0000ac00: 2066 696e 616c 6c79 3a0a 2020 2020 2020   finally:.      
+0000ac10: 2020 2020 2020 2020 2020 7374 7265 616d            stream
+0000ac20: 2e73 6565 6b28 7374 6172 745f 706f 7329  .seek(start_pos)
+0000ac30: 0a0a 2020 2020 6465 6620 5f62 7569 6c64  ..    def _build
+0000ac40: 2873 656c 662c 206f 626a 2c20 7374 7265  (self, obj, stre
+0000ac50: 616d 2c20 636f 6e74 6578 742c 2070 6174  am, context, pat
+0000ac60: 6829 3a0a 2020 2020 2020 2020 2320 544f  h):.        # TO
+0000ac70: 444f 3a20 4164 6420 7375 7070 6f72 7420  DO: Add support 
+0000ac80: 666f 7220 6275 696c 6469 6e67 2e0a 2020  for building..  
+0000ac90: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+0000aca0: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
+0000acb0: 2742 7569 6c64 696e 6720 6973 206e 6f74  'Building is not
+0000acc0: 2073 7570 706f 7274 6564 2e27 290a 0a0a   supported.')...
+0000acd0: 2320 4d6f 6e6b 6579 2070 6174 6368 2052  # Monkey patch R
+0000ace0: 6177 436f 7079 2073 6f20 7468 6174 2069  awCopy so that i
+0000acf0: 7420 6361 6e20 6861 6e64 6c65 2077 6865  t can handle whe
+0000ad00: 6e20 7765 2072 6561 6420 7468 6520 7374  n we read the st
+0000ad10: 7265 616d 2062 6163 6b77 6172 6473 2e0a  ream backwards..
+0000ad20: 6465 6620 5f70 6172 7365 2873 656c 662c  def _parse(self,
+0000ad30: 2073 7472 6561 6d2c 2063 6f6e 7465 7874   stream, context
+0000ad40: 2c20 7061 7468 293a 0a20 2020 206f 6666  , path):.    off
+0000ad50: 7365 7431 203d 2073 7472 6561 6d2e 7465  set1 = stream.te
+0000ad60: 6c6c 2829 0a20 2020 206f 626a 203d 2073  ll().    obj = s
+0000ad70: 656c 662e 7375 6263 6f6e 2e5f 7061 7273  elf.subcon._pars
+0000ad80: 6572 6570 6f72 7428 7374 7265 616d 2c20  ereport(stream, 
+0000ad90: 636f 6e74 6578 742c 2070 6174 6829 0a20  context, path). 
+0000ada0: 2020 206f 6666 7365 7432 203d 2073 7472     offset2 = str
+0000adb0: 6561 6d2e 7465 6c6c 2829 0a20 2020 2023  eam.tell().    #
+0000adc0: 2053 7761 7020 6966 2073 7562 636f 6e20   Swap if subcon 
+0000add0: 7265 6164 2062 6163 6b77 6172 6473 2e0a  read backwards..
+0000ade0: 2020 2020 6966 206f 6666 7365 7431 203e      if offset1 >
+0000adf0: 206f 6666 7365 7432 3a0a 2020 2020 2020   offset2:.      
+0000ae00: 2020 6f66 6673 6574 312c 206f 6666 7365    offset1, offse
+0000ae10: 7432 203d 206f 6666 7365 7432 2c20 6f66  t2 = offset2, of
+0000ae20: 6673 6574 310a 2020 2020 6661 6c6c 6261  fset1.    fallba
+0000ae30: 636b 203d 2073 7472 6561 6d2e 7465 6c6c  ck = stream.tell
+0000ae40: 2829 0a20 2020 2073 7472 6561 6d5f 7365  ().    stream_se
+0000ae50: 656b 2873 7472 6561 6d2c 206f 6666 7365  ek(stream, offse
+0000ae60: 7431 290a 2020 2020 6461 7461 203d 2073  t1).    data = s
+0000ae70: 7472 6561 6d5f 7265 6164 2873 7472 6561  tream_read(strea
+0000ae80: 6d2c 206f 6666 7365 7432 2d6f 6666 7365  m, offset2-offse
+0000ae90: 7431 290a 2020 2020 7374 7265 616d 2e73  t1).    stream.s
+0000aea0: 6565 6b28 6661 6c6c 6261 636b 290a 2020  eek(fallback).  
+0000aeb0: 2020 7265 7475 726e 2043 6f6e 7461 696e    return Contain
+0000aec0: 6572 2864 6174 613d 6461 7461 2c20 7661  er(data=data, va
+0000aed0: 6c75 653d 6f62 6a2c 206f 6666 7365 7431  lue=obj, offset1
+0000aee0: 3d6f 6666 7365 7431 2c20 6f66 6673 6574  =offset1, offset
+0000aef0: 323d 6f66 6673 6574 322c 206c 656e 6774  2=offset2, lengt
+0000af00: 683d 286f 6666 7365 7432 2d6f 6666 7365  h=(offset2-offse
+0000af10: 7431 2929 0a0a 0a63 6f6e 7374 7275 6374  t1))...construct
+0000af20: 2e52 6177 436f 7079 2e5f 7061 7273 6520  .RawCopy._parse 
+0000af30: 3d20 5f70 6172 7365 0a0a 0a64 6566 2046  = _parse...def F
+0000af40: 6f63 7573 4c61 7374 282a 7375 6263 6f6e  ocusLast(*subcon
+0000af50: 732c 202a 2a6b 7729 3a0a 2020 2020 7222  s, **kw):.    r"
+0000af60: 2222 0a20 2020 2041 2068 656c 7065 7220  "".    A helper 
+0000af70: 666f 7220 7065 7266 6f72 6d69 6e67 2074  for performing t
+0000af80: 6865 2063 6f6d 6d6f 6e20 7465 6368 6e69  he common techni
+0000af90: 7175 6520 6f66 2075 7369 6e67 2046 6f63  que of using Foc
+0000afa0: 7573 6564 5365 7120 746f 0a20 2020 2070  usedSeq to.    p
+0000afb0: 6172 7365 2061 2062 756e 6368 206f 6620  arse a bunch of 
+0000afc0: 7375 6263 6f6e 7374 7275 6374 7320 616e  subconstructs an
+0000afd0: 6420 7468 656e 2067 7261 6220 7468 6520  d then grab the 
+0000afe0: 6c61 7374 2065 6c65 6d65 6e74 2e0a 0a20  last element... 
+0000aff0: 2020 203e 3e3e 2046 6f63 7573 4c61 7374     >>> FocusLast
+0000b000: 2842 7974 652c 2042 7974 652c 2053 7472  (Byte, Byte, Str
+0000b010: 696e 6728 3229 292e 7061 7273 6528 6227  ing(2)).parse(b'
+0000b020: 5c78 3031 5c78 3032 6869 2729 0a20 2020  \x01\x02hi').   
+0000b030: 2075 2768 6927 0a0a 2020 2020 3e3e 3e20   u'hi'..    >>> 
+0000b040: 7370 6563 203d 2046 6f63 7573 4c61 7374  spec = FocusLast
+0000b050: 280a 2020 2020 2e2e 2e20 2020 2020 2761  (.    ...     'a
+0000b060: 2720 2f20 4279 7465 2c0a 2020 2020 2e2e  ' / Byte,.    ..
+0000b070: 2e20 2020 2020 2762 2720 2f20 4279 7465  .     'b' / Byte
+0000b080: 2c0a 2020 2020 2e2e 2e20 2020 2020 5374  ,.    ...     St
+0000b090: 7269 6e67 2874 6869 732e 6120 2b20 7468  ring(this.a + th
+0000b0a0: 6973 2e62 292c 0a20 2020 202e 2e2e 2029  is.b),.    ... )
+0000b0b0: 0a20 2020 203e 3e3e 2073 7065 632e 7061  .    >>> spec.pa
+0000b0c0: 7273 6528 6227 5c78 3031 5c78 3032 6869  rse(b'\x01\x02hi
+0000b0d0: 2127 290a 2020 2020 7527 6869 2127 0a20  !').    u'hi!'. 
+0000b0e0: 2020 203e 3e3e 2073 7065 632e 6275 696c     >>> spec.buil
+0000b0f0: 6428 7527 6869 2127 2c20 613d 312c 2062  d(u'hi!', a=1, b
+0000b100: 3d32 290a 2020 2020 275c 7830 315c 7830  =2).    '\x01\x0
+0000b110: 3268 6921 270a 0a0a 2020 2020 652e 672e  2hi!'...    e.g.
+0000b120: 3a0a 2020 2020 2020 2020 2320 5369 6d70  :.        # Simp
+0000b130: 6c69 6669 6573 2074 6869 733a 0a20 2020  lifies this:.   
+0000b140: 2020 2020 2063 6f6e 7374 7275 6374 2e46       construct.F
+0000b150: 6f63 7573 6564 5365 7128 0a20 2020 2020  ocusedSeq(.     
+0000b160: 2020 2020 2020 2027 7661 6c75 6527 2c0a         'value',.
+0000b170: 2020 2020 2020 2020 2020 2020 2772 6527              're'
+0000b180: 202f 2063 6f6e 7374 7275 6374 2e52 6567   / construct.Reg
+0000b190: 6578 282e 2e2c 206f 6666 7365 743d 636f  ex(.., offset=co
+0000b1a0: 6e73 7472 7563 742e 496e 7433 3275 6c2c  nstruct.Int32ul,
+0000b1b0: 2073 697a 653d 636f 6e73 7472 7563 742e   size=construct.
+0000b1c0: 4279 7465 292c 0a20 2020 2020 2020 2020  Byte),.         
+0000b1d0: 2020 2027 7661 6c75 6527 202f 2063 6f6e     'value' / con
+0000b1e0: 7374 7275 6374 2e50 4550 6f69 6e74 6572  struct.PEPointer
+0000b1f0: 2874 6869 732e 7265 2e6f 6666 7365 742c  (this.re.offset,
+0000b200: 2063 6f6e 7374 7275 6374 2e42 7974 6573   construct.Bytes
+0000b210: 2874 6869 732e 7265 2e73 697a 6529 0a20  (this.re.size). 
+0000b220: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0000b230: 2023 2054 6f20 7468 6973 3a0a 2020 2020   # To this:.    
+0000b240: 2020 2020 636f 6e73 7472 7563 742e 466f      construct.Fo
+0000b250: 6375 734c 6173 7428 0a20 2020 2020 2020  cusLast(.       
+0000b260: 2020 2020 2027 7265 2720 2f20 636f 6e73       're' / cons
+0000b270: 7472 7563 742e 5265 6765 7828 2e2e 2c20  truct.Regex(.., 
+0000b280: 6f66 6673 6574 3d63 6f6e 7374 7275 6374  offset=construct
+0000b290: 2e49 6e74 3332 756c 2c20 7369 7a65 3d63  .Int32ul, size=c
+0000b2a0: 6f6e 7374 7275 6374 2e42 7974 6529 2c0a  onstruct.Byte),.
+0000b2b0: 2020 2020 2020 2020 2020 2020 636f 6e73              cons
+0000b2c0: 7472 7563 742e 5045 506f 696e 7465 7228  truct.PEPointer(
+0000b2d0: 7468 6973 2e72 652e 6f66 6673 6574 2c20  this.re.offset, 
+0000b2e0: 636f 6e73 7472 7563 742e 4279 7465 7328  construct.Bytes(
+0000b2f0: 7468 6973 2e72 652e 7369 7a65 290a 2020  this.re.size).  
+0000b300: 2020 2020 2020 290a 2020 2020 2222 220a        ).    """.
+0000b310: 2020 2020 7265 7475 726e 2046 6f63 7573      return Focus
+0000b320: 6564 5365 7128 6c65 6e28 7375 6263 6f6e  edSeq(len(subcon
+0000b330: 7329 202d 2031 2c20 2a73 7562 636f 6e73  s) - 1, *subcons
+0000b340: 2c20 2a2a 6b77 290a                      , **kw).
```

### Comparing `mwcp-3.8.0/mwcp/utils/construct/version28.py` & `mwcp-3.9.0/mwcp/utils/construct/version28.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,658 +1,658 @@
-"""
-Collection of patches done to bring back some of the removed features of 2.8 back into 2.9
-as well as generally fix lingering issues with construct.
-
-To activate, replace your standard import with this:
-    from mwcp.utils.construct import version28 as construct
-
-Patches:
-    - slicing mechanism ([:], [min:], [:max], etc)
-    - allows default value for pop() in Containers
-    - allow any encoding for string constructs.
-    - patch Embedded to remove hardcoded limitation of supported classes.
-    - fixes issue with sizeof used with dynamic Structs (issue #771)
-    - patch StringEncoded to make UnicodeDecodeErrors as StringError (issue #743)
-
-Also contains fixes for few constructs. (Use these versions to get the benefits.)
-    - Range() - was removed in 2.9
-    - PaddedString() - provides default encoding of 'utf-8' and fixes limitation on encoding codecs
-    - String() - alias to PaddedString
-    - GreedyString - default encoding to 'utf-8'
-    - Compressed() - add ability to provide any algorithm (provided it has a compress() and decompress() function)
-    - Union() - Allows for the parsefrom parameter to be optional.
-    - Probe() - changed to show lookahead stream by default since that is almost always preferred.
-              - Also converted back to use hexdump instead of just showing a hex string.
-    - FocusedSeq() - Adds back support for supplying an index and fixes building.
-    - Mapping() - Patches Mapping to allow non-symmetric mappings again.
-
-
-Wishlist: (the following are things we would like to fix in version 2.9 but are out of scope for now)
-    - Go back to merging embedded fields after parsing instead of before. This change breaks the ability
-        to embed any Construct type. (e.g. Regex)
-    - PaddedString() should allow providing a different padding character.
-    - NullStripped() should not be a subconstruct that reads the entire stream instead it should be an
-        Adapter that strips off the wrapped result.
-    - Redefine String() to be the non-padded version of PaddedString()
-        - (This will break compatibility with 2.8 but it seems to make the most sense)
-        - Alternatively, rename PaddedString() back to String() and provide an flag parameter to determine if
-          null characters should be stripped.
-    - Add the path to ConstructError exceptions. This will greatly help with debugging.
-    - Add deepcopy functionality for Container classes.
-    - Embedding should also embed the context.
-        - Also, Embedded should just be a function that toggles flagembedded instead of being it's own class.
-    - remove _io from resulting Container objects after a parse. Doesn't look to be used for anything.
-"""
-
-from __future__ import absolute_import
-
-from future.builtins import bytes, str
-
-import codecs
-import collections.abc
-import sys
-
-import construct
-import construct.core
-import construct.debug
-from construct import *
-from construct.core import *
-
-
-class Range(Subconstruct):
-    r"""
-    A homogenous array of elements. The array will iterate through between ``min`` to ``max`` times. If an exception occurs (EOF, validation error), the repeater exits cleanly. If less than ``min`` units have been successfully parsed, a RangeError is raised.
-
-    .. seealso:: Analog :func:`~construct.core.GreedyRange` that parses until end of stream.
-
-    .. note:: This object requires a seekable stream for parsing.
-
-    :param min: the minimal count
-    :param max: the maximal count
-    :param subcon: the subcon to process individual elements
-
-    Example::
-
-        >>> Range(3, 5, Byte).build([1,2,3,4])
-        '\x01\x02\x03\x04'
-        >>> Range(3, 5, Byte).parse(_)
-        ListContainer([1, 2, 3, 4])
-
-        >>> Range(3, 5, Byte).build([1,2])
-        Traceback (most recent call last):
-            ...
-        RangeError: expected from 3 to 5 elements, found 2
-        >>> Range(3, 5, Byte).build([1,2,3,4,5,6])
-        Traceback (most recent call last):
-            ...
-        RangeError: expected from 3 to 5 elements, found 6
-    """
-    __slots__ = ["min", "max"]
-
-    def __init__(self, min, max, subcon):
-        super(Range, self).__init__(subcon)
-        self.min = min
-        self.max = max
-
-    def _parse(self, stream, context, path):
-        min_ = evaluate(self.min, context)
-        max_ = evaluate(self.max, context)
-        if not 0 <= min_ <= max_ <= sys.maxsize:
-            raise RangeError("[{}] unsane min {} and max {}".format(path, min_, max_))
-        obj = ListContainer()
-        try:
-            i = 0
-            while len(obj) < max_:
-                context._index = i
-                fallback = stream.tell()
-                obj.append(self.subcon._parsereport(stream, context, path))
-                if stream.tell() == fallback:
-                    raise ExplicitError("[{}] Infinite loop detected.".format(path))
-                i += 1
-        except StopIteration:
-            pass
-        except ExplicitError:
-            raise
-        except Exception:  # TODO: catch ConstructError instead?
-            if len(obj) < min_:
-                raise RangeError("[{}] expected {} to {}, found {}".format(path, min_, max_, len(obj)))
-            stream.seek(fallback)
-        return obj
-
-    def _build(self, obj, stream, context, path):
-        min_ = evaluate(self.min, context)
-        max_ = evaluate(self.max, context)
-        if not 0 <= min_ <= max_ <= sys.maxsize:
-            raise RangeError("[{}] unsane min {} and max {}".format(path, min_, max_))
-        if not isinstance(obj, collections.abc.Sequence):
-            raise RangeError("[{}] expected sequence type, found {}".format(path, type(obj)))
-        if not min_ <= len(obj) <= max_:
-            raise RangeError("[{}] expected from {} to {} elements, found {}".format(path, min_, max_, len(obj)))
-        retlist = ListContainer()
-        try:
-            for i, subobj in enumerate(obj):
-                context._index = i
-                buildret = self.subcon._build(subobj, stream, context, path)
-                retlist.append(buildret)
-        except StopIteration:
-            pass
-        except ExplicitError:
-            raise
-        except Exception:
-            if len(obj) < min_:
-                raise RangeError("[{}] expected {} to {}, found {}".format(path, min_, max_, len(obj)))
-            else:
-                raise
-        return retlist
-
-    def _sizeof(self, context, path):
-        # WARNING: possibly broken by StopIf
-        try:
-            min_ = evaluate(self.min, context)
-            max_ = evaluate(self.max, context)
-        except (KeyError, AttributeError):
-            raise SizeofError("cannot calculate size, key not found in context")
-        if min_ == max_:
-            return min_ * self.subcon._sizeof(context, path)
-        else:
-            raise SizeofError("cannot calculate size")
-
-
-def CString(encoding='utf-8'):
-    r"""
-    Adds default encoding option to CString().
-
-    >>> CString().parse(b'hello\x00')
-    u'hello'
-    >>> CString().parse(b'hello\x00\xff\xff')
-    u'hello'
-    >>> CString(encoding='utf-16').parse(b'\xff\xfeh\x00e\x00l\x00l\x00o\x00\x00\x00')  # FFFE is BOM for utf-16-le
-    u'hello'
-    >>> CString(encoding='utf-16').parse(b'h\x00e\x00l\x00l\x00o\x00\x00\x00')
-    u'hello'
-    >>> CString(encoding='utf-16').build(u'hello')
-    '\xff\xfeh\x00e\x00l\x00l\x00o\x00\x00\x00'
-    >>> CString(encoding='utf-32').build(u'hello')
-    '\xff\xfe\x00\x00h\x00\x00\x00e\x00\x00\x00l\x00\x00\x00l\x00\x00\x00o\x00\x00\x00\x00\x00\x00\x00'
-
-    Make sure to specify 'le' or 'be' in the encoding if you don't want BOM markers when building.
-    >>> CString(encoding='utf-32-le').build(u'hello')
-    'h\x00\x00\x00e\x00\x00\x00l\x00\x00\x00l\x00\x00\x00o\x00\x00\x00\x00\x00\x00\x00'
-    >>> CString(encoding='utf-32-be').build(u'hello')
-    '\x00\x00\x00h\x00\x00\x00e\x00\x00\x00l\x00\x00\x00l\x00\x00\x00o\x00\x00\x00\x00'
-    """
-    return construct.CString(encoding)
-
-
-def PaddedString(length, encoding='utf-8'):
-    r"""
-    Adds default encoding option to PaddedString().
-
-    NOTE: When using this to build a multi-byte encoded string you need to be aware of the extra space that can be taken
-    up by BOM markings when specifying the length.
-    If you don't want BOM. Make sure to explicitly specify "le" or "be" at the end of your encoding.
-    >>> u'hi'.encode('utf-16')
-    '\xff\xfeh\x00i\x00'
-    >>> u'hi'.encode('utf-16-le')
-    'h\x00i\x00'
-
-    :param length: length in bytes (not unicode characters), as int or context function
-    :param encoding: encoding (e.g. "utf8") or None for bytes
-
-    e.g.
-    >>> StringEncoded(Bytes(10), 'utf-16').parse(b'h\x00e\x00l\x00l\x00o\x00')
-    u'hello'
-    >>> PaddedString(10, encoding='utf-16').parse(b'h\x00e\x00l\x00l\x00o\x00')
-    u'hello'
-    >>> PaddedString(12, encoding='utf-16').build(u'hello')
-    '\xff\xfeh\x00e\x00l\x00l\x00o\x00'
-    >>> PaddedString(10, encoding='utf-16le').build(u'hello')
-    'h\x00e\x00l\x00l\x00o\x00'
-    >>> PaddedString(16, encoding='utf-16le').build(u'hello')
-    'h\x00e\x00l\x00l\x00o\x00\x00\x00\x00\x00\x00\x00'
-    >>> PaddedString(16, encoding='utf-16').parse(b'h\x00e\x00l\x00l\x00o\x00\x00\x00\x00\x00\x00\x00')
-    u'hello'
-
-    Works with utf-32 in the same way.
-    >>> PaddedString(20, encoding='utf-32-le').build(u'hello')
-    'h\x00\x00\x00e\x00\x00\x00l\x00\x00\x00l\x00\x00\x00o\x00\x00\x00'
-    >>> PaddedString(20, encoding='utf-32').parse(b'h\x00\x00\x00e\x00\x00\x00l\x00\x00\x00l\x00\x00\x00o\x00\x00\x00')
-    u'hello'
-
-    Also, still works with regular single byte encodings.
-    >>> PaddedString(5).build(u'hello')
-    'hello'
-    >>> PaddedString(5).parse(b'hello')
-    u'hello'
-
-    A StringError (type of ConstructError) will be raised if the string cannot be decoded with the given encoding.
-    >>> PaddedString(8).parse(b'hello\x00\xff\xff')
-    Traceback (most recent call last):
-        ...
-    StringError: string decoding failed: 'utf8' codec can't decode byte 0xff in position 6: invalid start byte
-    """
-    return construct.PaddedString(length, encoding)
-
-# Alias for original 2.8 name
-# FIXME: String() should not remove the null padding!
-String = PaddedString
-
-
-def GreedyString(encoding='utf-8'):
-    """Adds default encoding option to PaddedString()."""
-    return construct.GreedyString(encoding)
-
-
-class Compressed(Adapter):
-    r"""
-    Replaces the original Compressed construct to improve functionality:
-        - supports providing a custom encoding module or object.
-            - (provide any object that has a "decompress" and "compress" function in the lib parameter.)
-        - produces a ConstructError if compressed/decompression fails.
-            - (You can turn this off by setting wrap_exception=False)
-        - uses Adapter instead of Tunnel in order to allow it be embedded within other constructs.
-            - (Original one read entire stream, no matter the subcon you provide.)
-
-    e.g.
-    >>> import zlib
-    >>> Compressed(GreedyBytes, zlib).build('hello world')
-    'x\x9c\xcbH\xcd\xc9\xc9W(\xcf/\xcaI\x01\x00\x1a\x0b\x04]'
-    >>> Compressed(GreedyBytes, zlib).parse(_)
-    'hello world'
-    >>> import dc3cipher
-    >>> lzma = dc3cipher.new('lzma')
-    >>> Compressed(GreedyBytes, lzma).build('hello world')
-    ']\x00\x00\x80\x00\x004\x19I\xee\x8d\xe9\x17\x89:3`\x05\xf7\xcfd\xff\xfbx \x00'
-    >>> Compressed(GreedyBytes, lzma).parse(_)
-    'hello world'
-
-    Now that this is an Adapter, it can be become part of a larger struct.
-    >>> spec = Struct(
-    ...     'magic' / Const('YUP'),
-    ...     'data' / Compressed(Bytes(26), lzma),
-    ...     'trailer' / Int32ul,
-    ... )
-    >>> spec.parse('YUP]\x00\x00\x80\x00\x004\x19I\xee\x8d\xe9\x17\x89:3`\x05\xf7\xcfd\xff\xfbx \x00\x03\x00\x00\x00')
-    Container(magic='YUP')(data='hello world')(trailer=3)
-    >>> spec.build(_)
-    'YUP]\x00\x00\x80\x00\x004\x19I\xee\x8d\xe9\x17\x89:3`\x05\xf7\xcfd\xff\xfbx \x00\x03\x00\x00\x00'
-    """
-    __slots__ = ["lib", "wrap_exception"]
-
-    def __init__(self, subcon, lib, wrap_exception=True):
-        super(Compressed, self).__init__(subcon)
-        self.wrap_exception = wrap_exception
-        if hasattr(lib, "compress") and hasattr(lib, "decompress"):
-            self.lib = lib
-        elif lib == "zlib":
-            import zlib
-            self.lib = zlib
-        elif lib == "gzip":
-            import gzip
-            self.lib = gzip
-        elif lib == "bzip2":
-            import bz2
-            self.lib = bz2
-        else:
-            raise ValueError('Invalid lib parameter: {}'.format(lib))
-
-    def _decode(self, data, context, path):
-        try:
-            return self.lib.decompress(data)
-        except Exception as e:
-            if self.wrap_exception:
-                raise ConstructError('Decompression failed with error: {}'.format(e))
-            else:
-                raise
-
-    def _encode(self, data, context, path):
-        try:
-            return self.lib.compress(data)
-        except Exception as e:
-            if self.wrap_exception:
-                raise ConstructError('Compression failed with error: {}'.format(e))
-            else:
-                raise
-
-
-class Union(construct.Union):
-    """
-    Patches the Union() Construct to not require the parsefrom parameter. (defaults to None)
-    """
-
-    def __init__(self, parsefrom_or_subcon, *subcons, **subconskw):
-        if isinstance(parsefrom_or_subcon, Construct):
-            parsefrom = None
-            subcons = (parsefrom_or_subcon,) + subcons
-        else:
-            parsefrom = parsefrom_or_subcon
-        super(Union, self).__init__(parsefrom, *subcons, **subconskw)
-
-
-# Map an integer in the inclusive range 0-255 to its string byte representation
-PRINTABLE = [bytes2str(int2byte(i)) if 32 <= i < 128 else '.' for i in range(256)]
-HEXPRINT = [format(i, '02X') for i in range(256)]
-
-# Copy of construct.lib.hex.hexdump but removes the "hexundump(" string.
-# Not sure why that was added....
-def hexdump(data, linesize):
-    r"""
-    Turns bytes into a unicode string of the format:
-
-    ::
-
-        >>> print(hexdump(b'0' * 100, 16))
-        hexundump(\"\"\"
-        0000   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
-        0010   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
-        0020   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
-        0030   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
-        0040   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
-        0050   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
-        0060   30 30 30 30                                       0000
-        \"\"\")
-    """
-    if len(data) < 16**4:
-        fmt = "%%04X   %%-%ds   %%s" % (3*linesize-1,)
-    elif len(data) < 16**8:
-        fmt = "%%08X   %%-%ds   %%s" % (3*linesize-1,)
-    else:
-        raise ValueError("hexdump cannot process more than 16**8 or 4294967296 bytes")
-    prettylines = []
-    for i in range(0, len(data), linesize):
-        line = data[i:i+linesize]
-        hextext = " ".join(HEXPRINT[b] for b in iterateints(line))
-        rawtext = "".join(PRINTABLE[b] for b in iterateints(line))
-        prettylines.append(fmt % (i, str(hextext), str(rawtext)))
-    return "\n".join(prettylines)
-
-
-class Probe(construct.Probe):
-    """
-    Patches back some of the features of Probe() that were removed:
-
-        - The lookahead stream is enabled by default
-        - Use hexdump instead of hexlify to display lookahead stream
-        - Allows for setting a name
-    """
-    def __init__(self, into=None, lookahead=128, name=None):
-        self.print_name = name
-        super(Probe, self).__init__(into=into, lookahead=lookahead)
-
-    def printout(self, stream, context, path):
-        print("--------------------------------------------------")
-        print("Probe {}".format(self.print_name or ''))
-        print("Path: {}".format(path))
-        if self.into:
-            print("Into: {!r}".format(self.into))
-
-        if self.lookahead and stream is not None:
-            fallback = stream.tell()
-            stream_bytes = stream.read(self.lookahead)
-            stream.seek(fallback)
-            if stream_bytes:
-                print("Stream peek:\n{}".format(hexdump(stream_bytes, 32)))
-            else:
-                print("Stream peek: EOF reached")
-
-        if context is not None:
-            if self.into:
-                try:
-                    subcontext = self.into(context)
-                    print(subcontext)
-                except Exception:
-                    print("Failed to compute {!r} on the context {!r}".format(self.into, context))
-            else:
-                print(context)
-        print("--------------------------------------------------")
-
-
-class FocusedSeq(construct.FocusedSeq):
-    """
-    Patches FocusedSeq to add back support for supplying an index.
-
-    Also fixes the build and parse functions.
-    """
-
-    def _parse(self, stream, context, path):
-        context = Container(_ = context, _params = context._params, _root = None, _parsing = context._parsing, _building = context._building, _sizing = context._sizing, _subcons = self._subcons, _io = stream, _index = context.get("_index", None))
-        context._root = context._.get("_root", context)
-        parsebuildfrom = evaluate(self.parsebuildfrom, context)
-
-        found = False  # Must use separate flag because returning a parse result of None is valid.
-        finalret = None
-        for i, sc in enumerate(self.subcons):
-            parseret = sc._parsereport(stream, context, path)
-            context[i] = parseret  # PATCH: re-added ability to reference by index.
-            if sc.name:
-                context[sc.name] = parseret
-            if sc.name == parsebuildfrom or i == parsebuildfrom:
-                finalret = parseret
-                found = True
-
-        if not found:
-            raise ConstructError("Unable to find entry: {}".format(parsebuildfrom))
-
-        return finalret
-
-    def _build(self, obj, stream, context, path):
-        context = Container(_ = context, _params = context._params, _root = None, _parsing = context._parsing, _building = context._building, _sizing = context._sizing, _subcons = self._subcons, _io = stream, _index = context.get("_index", None))
-        context._root = context._.get("_root", context)
-        parsebuildfrom = evaluate(self.parsebuildfrom, context)
-
-        found = False
-        finalret = None
-        for i, sc in enumerate(self.subcons):
-            if sc.name == parsebuildfrom or i == parsebuildfrom:
-                sub_obj = obj
-            else:
-                sub_obj = context._.get(sc.name, context._.get(i, None))
-            try:
-                buildret = sc._build(sub_obj, stream, context, path)
-            except ConstructError as e:
-                raise ConstructError("Unable to build field at index: {}".format(i))
-
-            context[i] = buildret
-            if sc.name:
-                context[sc.name] = buildret
-
-            if sc.name == parsebuildfrom or i == parsebuildfrom:
-                finalret = buildret
-                found = True
-
-        if not found:
-            raise ConstructError("Unable to find entry: {}".format(parsebuildfrom))
-
-        return finalret
-
-
-class Mapping(construct.Mapping):
-    r"""
-    Patches Mapping to allow non-symmetric mappings by swapping the mapping
-    from encoding (building) to decoding (parsing) and allow for an optional mapping in the other direction.
-
-    :param subcon: Construct instance
-    :param mapping: dict, for decoding (parsing) mapping
-    :param enc_mapping: Optional mapping for encoding (building), otherwise the reversed decoding mapping it used
-
-    Example::
-        >>> spec = Mapping(Byte, {0: u'a', 1: u'b', 2: u'b'})
-        >>> spec.parse(b'\x02')
-        u'b'
-
-        # Reverse mapping is sorted so 1 will be used instead of 2.
-        >>> spec.build(u'b')
-        '\x01'
-    """
-
-    def __init__(self, subcon, dec_mapping, enc_mapping=None):
-        super(Mapping, self).__init__(subcon, {})
-        self.decmapping = dec_mapping
-        self.encmapping = enc_mapping or {v: k for k, v in sorted(dec_mapping.items(), reverse=True)}
-
-
-
-def _patch_pop():
-    """
-    Patches the pop() function in Container to allow for a default value.
-    """
-    def pop(self, key, *default):
-        try:
-            val = dict.pop(self, key, *default)
-            self.__keys_order__.remove(key)
-            return val
-        except ValueError:
-            if default:
-                return default[0]
-            else:
-                raise KeyError
-
-    Container.pop = pop
-
-
-def _patch_slice():
-    """Patches the slicing mechanism to use Range"""
-    orig_get_item = Construct.__getitem__
-
-    def __getitem__(self, count):
-        if isinstance(count, slice):
-            if count.step is not None:
-                raise ValueError("slice must not contain a step: %r" % count)
-            min = 0 if count.start is None else count.start
-            max = sys.maxsize if count.stop is None else count.stop
-            return Range(min, max, self)
-        else:
-            return orig_get_item(self, count)
-
-    Construct.__getitem__ = __getitem__
-
-
-def _patch_StringEncoded():
-    """
-    Patches StringEncoded to throw a ConstructError type exception if decoding fails.
-
-    Fixes: github.com/construct/construct/issues/743
-    """
-    orig_decode = construct.StringEncoded._decode
-
-    def _decode(self, obj, context, path):
-        try:
-            return orig_decode(self, obj, context, path)
-        except UnicodeDecodeError as e:
-            raise StringError("[{}] string decoding failed: {}".format(path, e))
-
-    construct.StringEncoded._decode = _decode
-
-
-def _patch_sizeof():
-    """
-    Patches the sizeof() function in Struct, Sequence, and FocusedSeq to properly provide context.
-
-    Fixes: github.com/construct/construct/issues/771
-    """
-    def _sizeof(self, context, path):
-        # Removed the context manipulation.
-        try:
-            # Added back dereferencing nested context that was incorrectly removed.
-            def isStruct(sc):
-                return isStruct(sc.subcon) if isinstance(sc, Renamed) else isinstance(sc, Struct)
-            def nest(context, sc):
-                if isStruct(sc) and not sc.flagembedded and sc.name in context:
-                    context2 = context[sc.name]
-                    context2["_"] = context
-                    return context2
-                else:
-                    return context
-            return sum(sc._sizeof(nest(context, sc), path) for sc in self.subcons)
-        except (KeyError, AttributeError):
-            raise SizeofError("cannot calculate size, key not found in context")
-
-    # Conveniently, all 3 Constructs are implemented in the same way.
-    construct.Struct._sizeof = _sizeof
-    construct.Sequence._sizeof = _sizeof
-    construct.FocusedSeq._sizeof = _sizeof
-
-
-def _patch_encodingunit():
-    """
-    Patches the encodingunit() function that is used to calculate
-    sizes for null terminated strings.
-
-    This fixes the limitation of having a hardcoded set of supported encodings found in the original
-    implementation.
-    """
-    # must be ordered largest to smallest
-    _BOM_BYTES = (
-        codecs.BOM_UTF32_LE,
-        codecs.BOM_UTF32_BE,
-        codecs.BOM_UTF16_LE,
-        codecs.BOM_UTF16_BE,
-        codecs.BOM_UTF8,
-    )
-
-    # NOTE: We can't patch in our version of encodingunit() so we are going to have to reimplement
-    # the functions that use it (seen below)
-    def encodingunit(encoding):
-        r"""
-        >>> encodingunit('utf-8')
-        b'\x00'
-        >>> encodingunit('utf-16le')
-        b'\x00\x00'
-        >>> encodingunit('utf-16')
-        b'\x00\x00'
-        >>> encodingunit('utf-32')
-        b'\x00\x00\x00\x00'
-        >>> encodingunit('cp950')
-        b'\x00'
-        """
-        # Check "basic" byte size without BOM mark
-        encoding = encoding.lower()
-        encoded = u'\0'.encode(encoding)
-        for bom_bytes in _BOM_BYTES:
-            if encoded.startswith(bom_bytes) and len(bom_bytes) < len(encoded):
-                encoded = encoded[len(bom_bytes):]
-                break
-        return bytes(len(encoded))
-
-    construct.core.encodingunit = encodingunit
-
-
-def _patch_mergefields():
-    """
-    Patches the mergefields() function to remove the hardcoded list of embeddable classes.
-
-    This fixes the issue of trying to wrap Embedded around a Bitwise component.
-
-    Fixes: github.com/construct/construct/issues/TODO
-    """
-    def mergefields(*subcons):
-        def select(sc):
-            # If it quacks like a duck...
-            if hasattr(sc, 'subcons'):
-                return sc.subcons
-            elif hasattr(sc, 'subcon'):
-                return select(sc.subcon)
-            raise ConstructError(
-                "Embedding only works with: Struct Sequence FocusedSeq Union LazyStruct: {!r}".format(sc))
-
-        result = []
-        for sc in subcons:
-            if sc.flagembedded:
-                result.extend(select(sc))
-            else:
-                result.append(sc)
-        return result
-
-    construct.core.mergefields = mergefields
-
-
-def _patch():
-    """Patches 2.9 with 2.8 features and other general fixes."""
-    _patch_pop()
-    _patch_slice()
-    _patch_StringEncoded()
-    _patch_sizeof()
-    _patch_encodingunit()
-    _patch_mergefields()
-
-
-_patch()
+"""
+Collection of patches done to bring back some of the removed features of 2.8 back into 2.9
+as well as generally fix lingering issues with construct.
+
+To activate, replace your standard import with this:
+    from mwcp.utils.construct import version28 as construct
+
+Patches:
+    - slicing mechanism ([:], [min:], [:max], etc)
+    - allows default value for pop() in Containers
+    - allow any encoding for string constructs.
+    - patch Embedded to remove hardcoded limitation of supported classes.
+    - fixes issue with sizeof used with dynamic Structs (issue #771)
+    - patch StringEncoded to make UnicodeDecodeErrors as StringError (issue #743)
+
+Also contains fixes for few constructs. (Use these versions to get the benefits.)
+    - Range() - was removed in 2.9
+    - PaddedString() - provides default encoding of 'utf-8' and fixes limitation on encoding codecs
+    - String() - alias to PaddedString
+    - GreedyString - default encoding to 'utf-8'
+    - Compressed() - add ability to provide any algorithm (provided it has a compress() and decompress() function)
+    - Union() - Allows for the parsefrom parameter to be optional.
+    - Probe() - changed to show lookahead stream by default since that is almost always preferred.
+              - Also converted back to use hexdump instead of just showing a hex string.
+    - FocusedSeq() - Adds back support for supplying an index and fixes building.
+    - Mapping() - Patches Mapping to allow non-symmetric mappings again.
+
+
+Wishlist: (the following are things we would like to fix in version 2.9 but are out of scope for now)
+    - Go back to merging embedded fields after parsing instead of before. This change breaks the ability
+        to embed any Construct type. (e.g. Regex)
+    - PaddedString() should allow providing a different padding character.
+    - NullStripped() should not be a subconstruct that reads the entire stream instead it should be an
+        Adapter that strips off the wrapped result.
+    - Redefine String() to be the non-padded version of PaddedString()
+        - (This will break compatibility with 2.8 but it seems to make the most sense)
+        - Alternatively, rename PaddedString() back to String() and provide an flag parameter to determine if
+          null characters should be stripped.
+    - Add the path to ConstructError exceptions. This will greatly help with debugging.
+    - Add deepcopy functionality for Container classes.
+    - Embedding should also embed the context.
+        - Also, Embedded should just be a function that toggles flagembedded instead of being it's own class.
+    - remove _io from resulting Container objects after a parse. Doesn't look to be used for anything.
+"""
+
+from __future__ import absolute_import
+
+from future.builtins import bytes, str
+
+import codecs
+import collections.abc
+import sys
+
+import construct
+import construct.core
+import construct.debug
+from construct import *
+from construct.core import *
+
+
+class Range(Subconstruct):
+    r"""
+    A homogenous array of elements. The array will iterate through between ``min`` to ``max`` times. If an exception occurs (EOF, validation error), the repeater exits cleanly. If less than ``min`` units have been successfully parsed, a RangeError is raised.
+
+    .. seealso:: Analog :func:`~construct.core.GreedyRange` that parses until end of stream.
+
+    .. note:: This object requires a seekable stream for parsing.
+
+    :param min: the minimal count
+    :param max: the maximal count
+    :param subcon: the subcon to process individual elements
+
+    Example::
+
+        >>> Range(3, 5, Byte).build([1,2,3,4])
+        '\x01\x02\x03\x04'
+        >>> Range(3, 5, Byte).parse(_)
+        ListContainer([1, 2, 3, 4])
+
+        >>> Range(3, 5, Byte).build([1,2])
+        Traceback (most recent call last):
+            ...
+        RangeError: expected from 3 to 5 elements, found 2
+        >>> Range(3, 5, Byte).build([1,2,3,4,5,6])
+        Traceback (most recent call last):
+            ...
+        RangeError: expected from 3 to 5 elements, found 6
+    """
+    __slots__ = ["min", "max"]
+
+    def __init__(self, min, max, subcon):
+        super(Range, self).__init__(subcon)
+        self.min = min
+        self.max = max
+
+    def _parse(self, stream, context, path):
+        min_ = evaluate(self.min, context)
+        max_ = evaluate(self.max, context)
+        if not 0 <= min_ <= max_ <= sys.maxsize:
+            raise RangeError("[{}] unsane min {} and max {}".format(path, min_, max_))
+        obj = ListContainer()
+        try:
+            i = 0
+            while len(obj) < max_:
+                context._index = i
+                fallback = stream.tell()
+                obj.append(self.subcon._parsereport(stream, context, path))
+                if stream.tell() == fallback:
+                    raise ExplicitError("[{}] Infinite loop detected.".format(path))
+                i += 1
+        except StopIteration:
+            pass
+        except ExplicitError:
+            raise
+        except Exception:  # TODO: catch ConstructError instead?
+            if len(obj) < min_:
+                raise RangeError("[{}] expected {} to {}, found {}".format(path, min_, max_, len(obj)))
+            stream.seek(fallback)
+        return obj
+
+    def _build(self, obj, stream, context, path):
+        min_ = evaluate(self.min, context)
+        max_ = evaluate(self.max, context)
+        if not 0 <= min_ <= max_ <= sys.maxsize:
+            raise RangeError("[{}] unsane min {} and max {}".format(path, min_, max_))
+        if not isinstance(obj, collections.abc.Sequence):
+            raise RangeError("[{}] expected sequence type, found {}".format(path, type(obj)))
+        if not min_ <= len(obj) <= max_:
+            raise RangeError("[{}] expected from {} to {} elements, found {}".format(path, min_, max_, len(obj)))
+        retlist = ListContainer()
+        try:
+            for i, subobj in enumerate(obj):
+                context._index = i
+                buildret = self.subcon._build(subobj, stream, context, path)
+                retlist.append(buildret)
+        except StopIteration:
+            pass
+        except ExplicitError:
+            raise
+        except Exception:
+            if len(obj) < min_:
+                raise RangeError("[{}] expected {} to {}, found {}".format(path, min_, max_, len(obj)))
+            else:
+                raise
+        return retlist
+
+    def _sizeof(self, context, path):
+        # WARNING: possibly broken by StopIf
+        try:
+            min_ = evaluate(self.min, context)
+            max_ = evaluate(self.max, context)
+        except (KeyError, AttributeError):
+            raise SizeofError("cannot calculate size, key not found in context")
+        if min_ == max_:
+            return min_ * self.subcon._sizeof(context, path)
+        else:
+            raise SizeofError("cannot calculate size")
+
+
+def CString(encoding='utf-8'):
+    r"""
+    Adds default encoding option to CString().
+
+    >>> CString().parse(b'hello\x00')
+    u'hello'
+    >>> CString().parse(b'hello\x00\xff\xff')
+    u'hello'
+    >>> CString(encoding='utf-16').parse(b'\xff\xfeh\x00e\x00l\x00l\x00o\x00\x00\x00')  # FFFE is BOM for utf-16-le
+    u'hello'
+    >>> CString(encoding='utf-16').parse(b'h\x00e\x00l\x00l\x00o\x00\x00\x00')
+    u'hello'
+    >>> CString(encoding='utf-16').build(u'hello')
+    '\xff\xfeh\x00e\x00l\x00l\x00o\x00\x00\x00'
+    >>> CString(encoding='utf-32').build(u'hello')
+    '\xff\xfe\x00\x00h\x00\x00\x00e\x00\x00\x00l\x00\x00\x00l\x00\x00\x00o\x00\x00\x00\x00\x00\x00\x00'
+
+    Make sure to specify 'le' or 'be' in the encoding if you don't want BOM markers when building.
+    >>> CString(encoding='utf-32-le').build(u'hello')
+    'h\x00\x00\x00e\x00\x00\x00l\x00\x00\x00l\x00\x00\x00o\x00\x00\x00\x00\x00\x00\x00'
+    >>> CString(encoding='utf-32-be').build(u'hello')
+    '\x00\x00\x00h\x00\x00\x00e\x00\x00\x00l\x00\x00\x00l\x00\x00\x00o\x00\x00\x00\x00'
+    """
+    return construct.CString(encoding)
+
+
+def PaddedString(length, encoding='utf-8'):
+    r"""
+    Adds default encoding option to PaddedString().
+
+    NOTE: When using this to build a multi-byte encoded string you need to be aware of the extra space that can be taken
+    up by BOM markings when specifying the length.
+    If you don't want BOM. Make sure to explicitly specify "le" or "be" at the end of your encoding.
+    >>> u'hi'.encode('utf-16')
+    '\xff\xfeh\x00i\x00'
+    >>> u'hi'.encode('utf-16-le')
+    'h\x00i\x00'
+
+    :param length: length in bytes (not unicode characters), as int or context function
+    :param encoding: encoding (e.g. "utf8") or None for bytes
+
+    e.g.
+    >>> StringEncoded(Bytes(10), 'utf-16').parse(b'h\x00e\x00l\x00l\x00o\x00')
+    u'hello'
+    >>> PaddedString(10, encoding='utf-16').parse(b'h\x00e\x00l\x00l\x00o\x00')
+    u'hello'
+    >>> PaddedString(12, encoding='utf-16').build(u'hello')
+    '\xff\xfeh\x00e\x00l\x00l\x00o\x00'
+    >>> PaddedString(10, encoding='utf-16le').build(u'hello')
+    'h\x00e\x00l\x00l\x00o\x00'
+    >>> PaddedString(16, encoding='utf-16le').build(u'hello')
+    'h\x00e\x00l\x00l\x00o\x00\x00\x00\x00\x00\x00\x00'
+    >>> PaddedString(16, encoding='utf-16').parse(b'h\x00e\x00l\x00l\x00o\x00\x00\x00\x00\x00\x00\x00')
+    u'hello'
+
+    Works with utf-32 in the same way.
+    >>> PaddedString(20, encoding='utf-32-le').build(u'hello')
+    'h\x00\x00\x00e\x00\x00\x00l\x00\x00\x00l\x00\x00\x00o\x00\x00\x00'
+    >>> PaddedString(20, encoding='utf-32').parse(b'h\x00\x00\x00e\x00\x00\x00l\x00\x00\x00l\x00\x00\x00o\x00\x00\x00')
+    u'hello'
+
+    Also, still works with regular single byte encodings.
+    >>> PaddedString(5).build(u'hello')
+    'hello'
+    >>> PaddedString(5).parse(b'hello')
+    u'hello'
+
+    A StringError (type of ConstructError) will be raised if the string cannot be decoded with the given encoding.
+    >>> PaddedString(8).parse(b'hello\x00\xff\xff')
+    Traceback (most recent call last):
+        ...
+    StringError: string decoding failed: 'utf8' codec can't decode byte 0xff in position 6: invalid start byte
+    """
+    return construct.PaddedString(length, encoding)
+
+# Alias for original 2.8 name
+# FIXME: String() should not remove the null padding!
+String = PaddedString
+
+
+def GreedyString(encoding='utf-8'):
+    """Adds default encoding option to PaddedString()."""
+    return construct.GreedyString(encoding)
+
+
+class Compressed(Adapter):
+    r"""
+    Replaces the original Compressed construct to improve functionality:
+        - supports providing a custom encoding module or object.
+            - (provide any object that has a "decompress" and "compress" function in the lib parameter.)
+        - produces a ConstructError if compressed/decompression fails.
+            - (You can turn this off by setting wrap_exception=False)
+        - uses Adapter instead of Tunnel in order to allow it be embedded within other constructs.
+            - (Original one read entire stream, no matter the subcon you provide.)
+
+    e.g.
+    >>> import zlib
+    >>> Compressed(GreedyBytes, zlib).build('hello world')
+    'x\x9c\xcbH\xcd\xc9\xc9W(\xcf/\xcaI\x01\x00\x1a\x0b\x04]'
+    >>> Compressed(GreedyBytes, zlib).parse(_)
+    'hello world'
+    >>> import dc3cipher
+    >>> lzma = dc3cipher.new('lzma')
+    >>> Compressed(GreedyBytes, lzma).build('hello world')
+    ']\x00\x00\x80\x00\x004\x19I\xee\x8d\xe9\x17\x89:3`\x05\xf7\xcfd\xff\xfbx \x00'
+    >>> Compressed(GreedyBytes, lzma).parse(_)
+    'hello world'
+
+    Now that this is an Adapter, it can be become part of a larger struct.
+    >>> spec = Struct(
+    ...     'magic' / Const('YUP'),
+    ...     'data' / Compressed(Bytes(26), lzma),
+    ...     'trailer' / Int32ul,
+    ... )
+    >>> spec.parse('YUP]\x00\x00\x80\x00\x004\x19I\xee\x8d\xe9\x17\x89:3`\x05\xf7\xcfd\xff\xfbx \x00\x03\x00\x00\x00')
+    Container(magic='YUP')(data='hello world')(trailer=3)
+    >>> spec.build(_)
+    'YUP]\x00\x00\x80\x00\x004\x19I\xee\x8d\xe9\x17\x89:3`\x05\xf7\xcfd\xff\xfbx \x00\x03\x00\x00\x00'
+    """
+    __slots__ = ["lib", "wrap_exception"]
+
+    def __init__(self, subcon, lib, wrap_exception=True):
+        super(Compressed, self).__init__(subcon)
+        self.wrap_exception = wrap_exception
+        if hasattr(lib, "compress") and hasattr(lib, "decompress"):
+            self.lib = lib
+        elif lib == "zlib":
+            import zlib
+            self.lib = zlib
+        elif lib == "gzip":
+            import gzip
+            self.lib = gzip
+        elif lib == "bzip2":
+            import bz2
+            self.lib = bz2
+        else:
+            raise ValueError('Invalid lib parameter: {}'.format(lib))
+
+    def _decode(self, data, context, path):
+        try:
+            return self.lib.decompress(data)
+        except Exception as e:
+            if self.wrap_exception:
+                raise ConstructError('Decompression failed with error: {}'.format(e))
+            else:
+                raise
+
+    def _encode(self, data, context, path):
+        try:
+            return self.lib.compress(data)
+        except Exception as e:
+            if self.wrap_exception:
+                raise ConstructError('Compression failed with error: {}'.format(e))
+            else:
+                raise
+
+
+class Union(construct.Union):
+    """
+    Patches the Union() Construct to not require the parsefrom parameter. (defaults to None)
+    """
+
+    def __init__(self, parsefrom_or_subcon, *subcons, **subconskw):
+        if isinstance(parsefrom_or_subcon, Construct):
+            parsefrom = None
+            subcons = (parsefrom_or_subcon,) + subcons
+        else:
+            parsefrom = parsefrom_or_subcon
+        super(Union, self).__init__(parsefrom, *subcons, **subconskw)
+
+
+# Map an integer in the inclusive range 0-255 to its string byte representation
+PRINTABLE = [bytes2str(int2byte(i)) if 32 <= i < 128 else '.' for i in range(256)]
+HEXPRINT = [format(i, '02X') for i in range(256)]
+
+# Copy of construct.lib.hex.hexdump but removes the "hexundump(" string.
+# Not sure why that was added....
+def hexdump(data, linesize):
+    r"""
+    Turns bytes into a unicode string of the format:
+
+    ::
+
+        >>> print(hexdump(b'0' * 100, 16))
+        hexundump(\"\"\"
+        0000   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
+        0010   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
+        0020   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
+        0030   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
+        0040   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
+        0050   30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30   0000000000000000
+        0060   30 30 30 30                                       0000
+        \"\"\")
+    """
+    if len(data) < 16**4:
+        fmt = "%%04X   %%-%ds   %%s" % (3*linesize-1,)
+    elif len(data) < 16**8:
+        fmt = "%%08X   %%-%ds   %%s" % (3*linesize-1,)
+    else:
+        raise ValueError("hexdump cannot process more than 16**8 or 4294967296 bytes")
+    prettylines = []
+    for i in range(0, len(data), linesize):
+        line = data[i:i+linesize]
+        hextext = " ".join(HEXPRINT[b] for b in iterateints(line))
+        rawtext = "".join(PRINTABLE[b] for b in iterateints(line))
+        prettylines.append(fmt % (i, str(hextext), str(rawtext)))
+    return "\n".join(prettylines)
+
+
+class Probe(construct.Probe):
+    """
+    Patches back some of the features of Probe() that were removed:
+
+        - The lookahead stream is enabled by default
+        - Use hexdump instead of hexlify to display lookahead stream
+        - Allows for setting a name
+    """
+    def __init__(self, into=None, lookahead=128, name=None):
+        self.print_name = name
+        super(Probe, self).__init__(into=into, lookahead=lookahead)
+
+    def printout(self, stream, context, path):
+        print("--------------------------------------------------")
+        print("Probe {}".format(self.print_name or ''))
+        print("Path: {}".format(path))
+        if self.into:
+            print("Into: {!r}".format(self.into))
+
+        if self.lookahead and stream is not None:
+            fallback = stream.tell()
+            stream_bytes = stream.read(self.lookahead)
+            stream.seek(fallback)
+            if stream_bytes:
+                print("Stream peek:\n{}".format(hexdump(stream_bytes, 32)))
+            else:
+                print("Stream peek: EOF reached")
+
+        if context is not None:
+            if self.into:
+                try:
+                    subcontext = self.into(context)
+                    print(subcontext)
+                except Exception:
+                    print("Failed to compute {!r} on the context {!r}".format(self.into, context))
+            else:
+                print(context)
+        print("--------------------------------------------------")
+
+
+class FocusedSeq(construct.FocusedSeq):
+    """
+    Patches FocusedSeq to add back support for supplying an index.
+
+    Also fixes the build and parse functions.
+    """
+
+    def _parse(self, stream, context, path):
+        context = Container(_ = context, _params = context._params, _root = None, _parsing = context._parsing, _building = context._building, _sizing = context._sizing, _subcons = self._subcons, _io = stream, _index = context.get("_index", None))
+        context._root = context._.get("_root", context)
+        parsebuildfrom = evaluate(self.parsebuildfrom, context)
+
+        found = False  # Must use separate flag because returning a parse result of None is valid.
+        finalret = None
+        for i, sc in enumerate(self.subcons):
+            parseret = sc._parsereport(stream, context, path)
+            context[i] = parseret  # PATCH: re-added ability to reference by index.
+            if sc.name:
+                context[sc.name] = parseret
+            if sc.name == parsebuildfrom or i == parsebuildfrom:
+                finalret = parseret
+                found = True
+
+        if not found:
+            raise ConstructError("Unable to find entry: {}".format(parsebuildfrom))
+
+        return finalret
+
+    def _build(self, obj, stream, context, path):
+        context = Container(_ = context, _params = context._params, _root = None, _parsing = context._parsing, _building = context._building, _sizing = context._sizing, _subcons = self._subcons, _io = stream, _index = context.get("_index", None))
+        context._root = context._.get("_root", context)
+        parsebuildfrom = evaluate(self.parsebuildfrom, context)
+
+        found = False
+        finalret = None
+        for i, sc in enumerate(self.subcons):
+            if sc.name == parsebuildfrom or i == parsebuildfrom:
+                sub_obj = obj
+            else:
+                sub_obj = context._.get(sc.name, context._.get(i, None))
+            try:
+                buildret = sc._build(sub_obj, stream, context, path)
+            except ConstructError as e:
+                raise ConstructError("Unable to build field at index: {}".format(i))
+
+            context[i] = buildret
+            if sc.name:
+                context[sc.name] = buildret
+
+            if sc.name == parsebuildfrom or i == parsebuildfrom:
+                finalret = buildret
+                found = True
+
+        if not found:
+            raise ConstructError("Unable to find entry: {}".format(parsebuildfrom))
+
+        return finalret
+
+
+class Mapping(construct.Mapping):
+    r"""
+    Patches Mapping to allow non-symmetric mappings by swapping the mapping
+    from encoding (building) to decoding (parsing) and allow for an optional mapping in the other direction.
+
+    :param subcon: Construct instance
+    :param mapping: dict, for decoding (parsing) mapping
+    :param enc_mapping: Optional mapping for encoding (building), otherwise the reversed decoding mapping it used
+
+    Example::
+        >>> spec = Mapping(Byte, {0: u'a', 1: u'b', 2: u'b'})
+        >>> spec.parse(b'\x02')
+        u'b'
+
+        # Reverse mapping is sorted so 1 will be used instead of 2.
+        >>> spec.build(u'b')
+        '\x01'
+    """
+
+    def __init__(self, subcon, dec_mapping, enc_mapping=None):
+        super(Mapping, self).__init__(subcon, {})
+        self.decmapping = dec_mapping
+        self.encmapping = enc_mapping or {v: k for k, v in sorted(dec_mapping.items(), reverse=True)}
+
+
+
+def _patch_pop():
+    """
+    Patches the pop() function in Container to allow for a default value.
+    """
+    def pop(self, key, *default):
+        try:
+            val = dict.pop(self, key, *default)
+            self.__keys_order__.remove(key)
+            return val
+        except ValueError:
+            if default:
+                return default[0]
+            else:
+                raise KeyError
+
+    Container.pop = pop
+
+
+def _patch_slice():
+    """Patches the slicing mechanism to use Range"""
+    orig_get_item = Construct.__getitem__
+
+    def __getitem__(self, count):
+        if isinstance(count, slice):
+            if count.step is not None:
+                raise ValueError("slice must not contain a step: %r" % count)
+            min = 0 if count.start is None else count.start
+            max = sys.maxsize if count.stop is None else count.stop
+            return Range(min, max, self)
+        else:
+            return orig_get_item(self, count)
+
+    Construct.__getitem__ = __getitem__
+
+
+def _patch_StringEncoded():
+    """
+    Patches StringEncoded to throw a ConstructError type exception if decoding fails.
+
+    Fixes: github.com/construct/construct/issues/743
+    """
+    orig_decode = construct.StringEncoded._decode
+
+    def _decode(self, obj, context, path):
+        try:
+            return orig_decode(self, obj, context, path)
+        except UnicodeDecodeError as e:
+            raise StringError("[{}] string decoding failed: {}".format(path, e))
+
+    construct.StringEncoded._decode = _decode
+
+
+def _patch_sizeof():
+    """
+    Patches the sizeof() function in Struct, Sequence, and FocusedSeq to properly provide context.
+
+    Fixes: github.com/construct/construct/issues/771
+    """
+    def _sizeof(self, context, path):
+        # Removed the context manipulation.
+        try:
+            # Added back dereferencing nested context that was incorrectly removed.
+            def isStruct(sc):
+                return isStruct(sc.subcon) if isinstance(sc, Renamed) else isinstance(sc, Struct)
+            def nest(context, sc):
+                if isStruct(sc) and not sc.flagembedded and sc.name in context:
+                    context2 = context[sc.name]
+                    context2["_"] = context
+                    return context2
+                else:
+                    return context
+            return sum(sc._sizeof(nest(context, sc), path) for sc in self.subcons)
+        except (KeyError, AttributeError):
+            raise SizeofError("cannot calculate size, key not found in context")
+
+    # Conveniently, all 3 Constructs are implemented in the same way.
+    construct.Struct._sizeof = _sizeof
+    construct.Sequence._sizeof = _sizeof
+    construct.FocusedSeq._sizeof = _sizeof
+
+
+def _patch_encodingunit():
+    """
+    Patches the encodingunit() function that is used to calculate
+    sizes for null terminated strings.
+
+    This fixes the limitation of having a hardcoded set of supported encodings found in the original
+    implementation.
+    """
+    # must be ordered largest to smallest
+    _BOM_BYTES = (
+        codecs.BOM_UTF32_LE,
+        codecs.BOM_UTF32_BE,
+        codecs.BOM_UTF16_LE,
+        codecs.BOM_UTF16_BE,
+        codecs.BOM_UTF8,
+    )
+
+    # NOTE: We can't patch in our version of encodingunit() so we are going to have to reimplement
+    # the functions that use it (seen below)
+    def encodingunit(encoding):
+        r"""
+        >>> encodingunit('utf-8')
+        b'\x00'
+        >>> encodingunit('utf-16le')
+        b'\x00\x00'
+        >>> encodingunit('utf-16')
+        b'\x00\x00'
+        >>> encodingunit('utf-32')
+        b'\x00\x00\x00\x00'
+        >>> encodingunit('cp950')
+        b'\x00'
+        """
+        # Check "basic" byte size without BOM mark
+        encoding = encoding.lower()
+        encoded = u'\0'.encode(encoding)
+        for bom_bytes in _BOM_BYTES:
+            if encoded.startswith(bom_bytes) and len(bom_bytes) < len(encoded):
+                encoded = encoded[len(bom_bytes):]
+                break
+        return bytes(len(encoded))
+
+    construct.core.encodingunit = encodingunit
+
+
+def _patch_mergefields():
+    """
+    Patches the mergefields() function to remove the hardcoded list of embeddable classes.
+
+    This fixes the issue of trying to wrap Embedded around a Bitwise component.
+
+    Fixes: github.com/construct/construct/issues/TODO
+    """
+    def mergefields(*subcons):
+        def select(sc):
+            # If it quacks like a duck...
+            if hasattr(sc, 'subcons'):
+                return sc.subcons
+            elif hasattr(sc, 'subcon'):
+                return select(sc.subcon)
+            raise ConstructError(
+                "Embedding only works with: Struct Sequence FocusedSeq Union LazyStruct: {!r}".format(sc))
+
+        result = []
+        for sc in subcons:
+            if sc.flagembedded:
+                result.extend(select(sc))
+            else:
+                result.append(sc)
+        return result
+
+    construct.core.mergefields = mergefields
+
+
+def _patch():
+    """Patches 2.9 with 2.8 features and other general fixes."""
+    _patch_pop()
+    _patch_slice()
+    _patch_StringEncoded()
+    _patch_sizeof()
+    _patch_encodingunit()
+    _patch_mergefields()
+
+
+_patch()
```

### Comparing `mwcp-3.8.0/mwcp/utils/construct/windows_constants.py` & `mwcp-3.9.0/mwcp/utils/construct/windows_constants.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,133 +1,133 @@
-
-
-# IMAGE_SECTION_HEADER.Characteristics
-IMAGE_SCN_TYPE_NO_PAD = 'IMAGE_SCN_TYPE_NO_PAD'
-IMAGE_SCN_CNT_CODE = 'IMAGE_SCN_CNT_CODE'
-IMAGE_SCN_CNT_INITIALIZED_DATA = 'IMAGE_SCN_CNT_INITIALIZED_DATA'
-IMAGE_SCN_CNT_UNINITIALIZED_DATA = 'IMAGE_SCN_CNT_UNINITIALIZED_DATA'
-IMAGE_SCN_LNK_OTHER = 'IMAGE_SCN_LNK_OTHER'
-IMAGE_SCN_LNK_INFO = 'IMAGE_SCN_LNK_INFO'
-IMAGE_SCN_LNK_REMOVE = 'IMAGE_SCN_LNK_REMOVE'
-IMAGE_SCN_LNK_COMDAT = 'IMAGE_SCN_LNK_COMDAT'
-IMAGE_SCN_NO_DEFER_SPEC_EXC = 'IMAGE_SCN_NO_DEFER_SPEC_EXC'
-IMAGE_SCN_GPREL = 'IMAGE_SCN_GPREL'
-IMAGE_SCN_MEM_PURGEABLE = 'IMAGE_SCN_MEM_PURGEABLE'
-IMAGE_SCN_MEM_LOCKED = 'IMAGE_SCN_MEM_LOCKED'
-IMAGE_SCN_MEM_PRELOAD = 'IMAGE_SCN_MEM_PRELOAD'
-IMAGE_SCN_ALIGN_1BYTES = 'IMAGE_SCN_ALIGN_1BYTES'
-IMAGE_SCN_ALIGN_2BYTES = 'IMAGE_SCN_ALIGN_2BYTES'
-IMAGE_SCN_ALIGN_4BYTES = 'IMAGE_SCN_ALIGN_4BYTES'
-IMAGE_SCN_ALIGN_8BYTES = 'IMAGE_SCN_ALIGN_8BYTES'
-IMAGE_SCN_ALIGN_16BYTES = 'IMAGE_SCN_ALIGN_16BYTES'
-IMAGE_SCN_ALIGN_32BYTES = 'IMAGE_SCN_ALIGN_32BYTES'
-IMAGE_SCN_ALIGN_64BYTES = 'IMAGE_SCN_ALIGN_64BYTES'
-IMAGE_SCN_ALIGN_128BYTES = 'IMAGE_SCN_ALIGN_128BYTES'
-IMAGE_SCN_ALIGN_256BYTES = 'IMAGE_SCN_ALIGN_256BYTES'
-IMAGE_SCN_ALIGN_512BYTES = 'IMAGE_SCN_ALIGN_512BYTES'
-IMAGE_SCN_ALIGN_1024BYTES = 'IMAGE_SCN_ALIGN_1024BYTES'
-IMAGE_SCN_ALIGN_2048BYTES = 'IMAGE_SCN_ALIGN_2048BYTES'
-IMAGE_SCN_ALIGN_4096BYTES = 'IMAGE_SCN_ALIGN_4096BYTES'
-IMAGE_SCN_ALIGN_8192BYTES = 'IMAGE_SCN_ALIGN_8192BYTES'
-IMAGE_SCN_LNK_NRELOC_OVFL = 'IMAGE_SCN_LNK_NRELOC_OVFL'
-IMAGE_SCN_MEM_DISCARDABLE = 'IMAGE_SCN_MEM_DISCARDABLE'
-IMAGE_SCN_MEM_NOT_CACHED = 'IMAGE_SCN_MEM_NOT_CACHED'
-IMAGE_SCN_MEM_NOT_PAGED = 'IMAGE_SCN_MEM_NOT_PAGED'
-IMAGE_SCN_MEM_SHARED = 'IMAGE_SCN_MEM_SHARED'
-IMAGE_SCN_MEM_EXECUTE = 'IMAGE_SCN_MEM_EXECUTE'
-IMAGE_SCN_MEM_READ = 'IMAGE_SCN_MEM_READ'
-IMAGE_SCN_MEM_WRITE = 'IMAGE_SCN_MEM_WRITE'
-
-# IMAGE_OPTIONAL_HEADER.Magic
-IMAGE_NT_OPTIONAL_HDR32_MAGIC = 0x10b
-IMAGE_NT_OPTIONAL_HDR64_MAGIC = 0x20b
-IMAGE_ROM_OPTIONAL_HDR_MAGIC = 0x107
-
-# IMAGE_OPTIONAL_HEADER.Subsystem
-IMAGE_SUBSYSTEM_UNKNOWN = 0
-IMAGE_SUBSYSTEM_NATIVE = 1
-IMAGE_SUBSYSTEM_WINDOWS_GUI = 2
-IMAGE_SUBSYSTEM_WINDOWS_CUI = 3
-IMAGE_SUBSYSTEM_OS2_CUI = 5
-IMAGE_SUBSYSTEM_POSIX_CUI = 7
-IMAGE_SUBSYSTEM_WINDOWS_CE_GUI = 9
-IMAGE_SUBSYSTEM_EFI_APPLICATION = 10
-IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER = 11
-IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER = 12
-IMAGE_SUBSYSTEM_EFI_ROM = 13
-IMAGE_SUBSYSTEM_XBOX = 14
-IMAGE_SUBSYSTEM_WINDOWS_BOOT_APPLICATION = 16
-
-
-# Make default DataDirectory and standard indexes available for convenience.
-# WARNING: Make sure you make a copy of DEFAULT_DATA_DIRECTORIES!!
-DATA_DIR_INDEX_EXPORTS = 0
-DATA_DIR_INDEX_IMPORTS = 1
-DATA_DIR_INDEX_RESOURCE = 2
-DATA_DIR_INDEX_EXCEPTION = 3
-DATA_DIR_INDEX_CERTIFICATE = 4
-DATA_DIR_INDEX_BASE_RELOC = 5
-DATA_DIR_INDEX_DEBUG = 6
-DATA_DIR_INDEX_ARCHITECTURE = 7
-DATA_DIR_INDEX_GLOBAL_PTR = 8
-DATA_DIR_INDEX_TLS = 9
-DATA_DIR_INDEX_LOAD_CONFIG = 10
-DATA_DIR_INDEX_BOUND_IMPORT = 11
-DATA_DIR_INDEX_IMPORT_ADDRESS = 12
-DATA_DIR_INDEX_DELAY_IMPORT_DESCRIPTOR = 13
-DATA_DIR_INDEX_CLR_HEADER = 14
-DEFAULT_DATA_DIRECTORIES = [dict(VirtualAddress=0, Size=0)] * 16
-
-# IMAGE_OPTIONAL_HEADER.DllCharacteristics
-IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE = 'IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE'
-IMAGE_DLLCHARACTERISTICS_FORCE_INTEGRITY = 'IMAGE_DLLCHARACTERISTICS_FORCE_INTEGRITY'
-IMAGE_DLLCHARACTERISTICS_NX_COMPAT = 'IMAGE_DLLCHARACTERISTICS_NX_COMPAT'
-IMAGE_DLLCHARACTERISTICS_NO_ISOLATION = 'IMAGE_DLLCHARACTERISTICS_NO_ISOLATION'
-IMAGE_DLLCHARACTERISTICS_NO_SEH = 'IMAGE_DLLCHARACTERISTICS_NO_SEH'
-IMAGE_DLLCHARACTERISTICS_NO_BIND = 'IMAGE_DLLCHARACTERISTICS_NO_BIND'
-IMAGE_DLLCHARACTERISTICS_WDM_DRIVER = 'IMAGE_DLLCHARACTERISTICS_WDM_DRIVER'
-IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE = 'IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE'
-
-# IMAGE_FILE_HEADER.Machine
-IMAGE_FILE_MACHINE_UNKNOWN = 0x0
-IMAGE_FILE_MACHINE_AM33 = 0x1d3
-IMAGE_FILE_MACHINE_AMD64 = 0x8664
-IMAGE_FILE_MACHINE_ARM = 0x1c0
-IMAGE_FILE_MACHINE_ARM64 = 0xaa64
-IMAGE_FILE_MACHINE_ARMNT = 0x1c4
-IMAGE_FILE_MACHINE_EBC = 0xebc
-IMAGE_FILE_MACHINE_I386 = 0x14c
-IMAGE_FILE_MACHINE_IA64 = 0x200
-IMAGE_FILE_MACHINE_M32R = 0x9041
-IMAGE_FILE_MACHINE_MIPS16 = 0x266
-IMAGE_FILE_MACHINE_MIPSFPU = 0x366
-IMAGE_FILE_MACHINE_MIPSFPU16 = 0x466
-IMAGE_FILE_MACHINE_POWERPC = 0x1f0
-IMAGE_FILE_MACHINE_POWERPCFP = 0x1f1
-IMAGE_FILE_MACHINE_R4000 = 0x166
-IMAGE_FILE_MACHINE_RISCV32 = 0x5032
-IMAGE_FILE_MACHINE_RISCV64 = 0x5064
-IMAGE_FILE_MACHINE_RISCV128 = 0x5128
-IMAGE_FILE_MACHINE_SH3 = 0x1a2
-IMAGE_FILE_MACHINE_SH3DSP = 0x1a3
-IMAGE_FILE_MACHINE_SH4 = 0x1a6
-IMAGE_FILE_MACHINE_SH5 = 0x1a8
-IMAGE_FILE_MACHINE_THUMB = 0x1c2
-IMAGE_FILE_MACHINE_WCEMIPSV2 = 0x169
-
-
-# IMAGE_FILE_HEADER characterstics.
-IMAGE_FILE_RELOCS_STRIPPED = 'IMAGE_FILE_RELOCS_STRIPPED'
-IMAGE_FILE_EXECUTABLE_IMAGE = 'IMAGE_FILE_EXECUTABLE_IMAGE'
-IMAGE_FILE_LINE_NUMS_STRIPPED = 'IMAGE_FILE_LINE_NUMS_STRIPPED'
-IMAGE_FILE_LOCAL_SYMS_STRIPPED = 'IMAGE_FILE_LOCAL_SYMS_STRIPPED'
-IMAGE_FILE_AGGRESIVE_WS_TRIM = 'IMAGE_FILE_AGGRESIVE_WS_TRIM'
-IMAGE_FILE_LARGE_ADDRESS_AWARE = 'IMAGE_FILE_LARGE_ADDRESS_AWARE'
-IMAGE_FILE_BYTES_REVERSED_LO = 'IMAGE_FILE_BYTES_REVERSED_LO'
-IMAGE_FILE_32BIT_MACHINE = 'IMAGE_FILE_32BIT_MACHINE'
-IMAGE_FILE_DEBUG_STRIPPED = 'IMAGE_FILE_DEBUG_STRIPPED'
-IMAGE_FILE_REMOVABLE_RUN_FROM_SWAP = 'IMAGE_FILE_REMOVABLE_RUN_FROM_SWAP'
-IMAGE_FILE_NET_RUN_FROM_SWAP = 'IMAGE_FILE_NET_RUN_FROM_SWAP'
-IMAGE_FILE_SYSTEM = 'IMAGE_FILE_SYSTEM'
-IMAGE_FILE_DLL = 'IMAGE_FILE_DLL'
-IMAGE_FILE_UP_SYSTEM_ONLY = 'IMAGE_FILE_UP_SYSTEM_ONLY'
+
+
+# IMAGE_SECTION_HEADER.Characteristics
+IMAGE_SCN_TYPE_NO_PAD = 'IMAGE_SCN_TYPE_NO_PAD'
+IMAGE_SCN_CNT_CODE = 'IMAGE_SCN_CNT_CODE'
+IMAGE_SCN_CNT_INITIALIZED_DATA = 'IMAGE_SCN_CNT_INITIALIZED_DATA'
+IMAGE_SCN_CNT_UNINITIALIZED_DATA = 'IMAGE_SCN_CNT_UNINITIALIZED_DATA'
+IMAGE_SCN_LNK_OTHER = 'IMAGE_SCN_LNK_OTHER'
+IMAGE_SCN_LNK_INFO = 'IMAGE_SCN_LNK_INFO'
+IMAGE_SCN_LNK_REMOVE = 'IMAGE_SCN_LNK_REMOVE'
+IMAGE_SCN_LNK_COMDAT = 'IMAGE_SCN_LNK_COMDAT'
+IMAGE_SCN_NO_DEFER_SPEC_EXC = 'IMAGE_SCN_NO_DEFER_SPEC_EXC'
+IMAGE_SCN_GPREL = 'IMAGE_SCN_GPREL'
+IMAGE_SCN_MEM_PURGEABLE = 'IMAGE_SCN_MEM_PURGEABLE'
+IMAGE_SCN_MEM_LOCKED = 'IMAGE_SCN_MEM_LOCKED'
+IMAGE_SCN_MEM_PRELOAD = 'IMAGE_SCN_MEM_PRELOAD'
+IMAGE_SCN_ALIGN_1BYTES = 'IMAGE_SCN_ALIGN_1BYTES'
+IMAGE_SCN_ALIGN_2BYTES = 'IMAGE_SCN_ALIGN_2BYTES'
+IMAGE_SCN_ALIGN_4BYTES = 'IMAGE_SCN_ALIGN_4BYTES'
+IMAGE_SCN_ALIGN_8BYTES = 'IMAGE_SCN_ALIGN_8BYTES'
+IMAGE_SCN_ALIGN_16BYTES = 'IMAGE_SCN_ALIGN_16BYTES'
+IMAGE_SCN_ALIGN_32BYTES = 'IMAGE_SCN_ALIGN_32BYTES'
+IMAGE_SCN_ALIGN_64BYTES = 'IMAGE_SCN_ALIGN_64BYTES'
+IMAGE_SCN_ALIGN_128BYTES = 'IMAGE_SCN_ALIGN_128BYTES'
+IMAGE_SCN_ALIGN_256BYTES = 'IMAGE_SCN_ALIGN_256BYTES'
+IMAGE_SCN_ALIGN_512BYTES = 'IMAGE_SCN_ALIGN_512BYTES'
+IMAGE_SCN_ALIGN_1024BYTES = 'IMAGE_SCN_ALIGN_1024BYTES'
+IMAGE_SCN_ALIGN_2048BYTES = 'IMAGE_SCN_ALIGN_2048BYTES'
+IMAGE_SCN_ALIGN_4096BYTES = 'IMAGE_SCN_ALIGN_4096BYTES'
+IMAGE_SCN_ALIGN_8192BYTES = 'IMAGE_SCN_ALIGN_8192BYTES'
+IMAGE_SCN_LNK_NRELOC_OVFL = 'IMAGE_SCN_LNK_NRELOC_OVFL'
+IMAGE_SCN_MEM_DISCARDABLE = 'IMAGE_SCN_MEM_DISCARDABLE'
+IMAGE_SCN_MEM_NOT_CACHED = 'IMAGE_SCN_MEM_NOT_CACHED'
+IMAGE_SCN_MEM_NOT_PAGED = 'IMAGE_SCN_MEM_NOT_PAGED'
+IMAGE_SCN_MEM_SHARED = 'IMAGE_SCN_MEM_SHARED'
+IMAGE_SCN_MEM_EXECUTE = 'IMAGE_SCN_MEM_EXECUTE'
+IMAGE_SCN_MEM_READ = 'IMAGE_SCN_MEM_READ'
+IMAGE_SCN_MEM_WRITE = 'IMAGE_SCN_MEM_WRITE'
+
+# IMAGE_OPTIONAL_HEADER.Magic
+IMAGE_NT_OPTIONAL_HDR32_MAGIC = 0x10b
+IMAGE_NT_OPTIONAL_HDR64_MAGIC = 0x20b
+IMAGE_ROM_OPTIONAL_HDR_MAGIC = 0x107
+
+# IMAGE_OPTIONAL_HEADER.Subsystem
+IMAGE_SUBSYSTEM_UNKNOWN = 0
+IMAGE_SUBSYSTEM_NATIVE = 1
+IMAGE_SUBSYSTEM_WINDOWS_GUI = 2
+IMAGE_SUBSYSTEM_WINDOWS_CUI = 3
+IMAGE_SUBSYSTEM_OS2_CUI = 5
+IMAGE_SUBSYSTEM_POSIX_CUI = 7
+IMAGE_SUBSYSTEM_WINDOWS_CE_GUI = 9
+IMAGE_SUBSYSTEM_EFI_APPLICATION = 10
+IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER = 11
+IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER = 12
+IMAGE_SUBSYSTEM_EFI_ROM = 13
+IMAGE_SUBSYSTEM_XBOX = 14
+IMAGE_SUBSYSTEM_WINDOWS_BOOT_APPLICATION = 16
+
+
+# Make default DataDirectory and standard indexes available for convenience.
+# WARNING: Make sure you make a copy of DEFAULT_DATA_DIRECTORIES!!
+DATA_DIR_INDEX_EXPORTS = 0
+DATA_DIR_INDEX_IMPORTS = 1
+DATA_DIR_INDEX_RESOURCE = 2
+DATA_DIR_INDEX_EXCEPTION = 3
+DATA_DIR_INDEX_CERTIFICATE = 4
+DATA_DIR_INDEX_BASE_RELOC = 5
+DATA_DIR_INDEX_DEBUG = 6
+DATA_DIR_INDEX_ARCHITECTURE = 7
+DATA_DIR_INDEX_GLOBAL_PTR = 8
+DATA_DIR_INDEX_TLS = 9
+DATA_DIR_INDEX_LOAD_CONFIG = 10
+DATA_DIR_INDEX_BOUND_IMPORT = 11
+DATA_DIR_INDEX_IMPORT_ADDRESS = 12
+DATA_DIR_INDEX_DELAY_IMPORT_DESCRIPTOR = 13
+DATA_DIR_INDEX_CLR_HEADER = 14
+DEFAULT_DATA_DIRECTORIES = [dict(VirtualAddress=0, Size=0)] * 16
+
+# IMAGE_OPTIONAL_HEADER.DllCharacteristics
+IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE = 'IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE'
+IMAGE_DLLCHARACTERISTICS_FORCE_INTEGRITY = 'IMAGE_DLLCHARACTERISTICS_FORCE_INTEGRITY'
+IMAGE_DLLCHARACTERISTICS_NX_COMPAT = 'IMAGE_DLLCHARACTERISTICS_NX_COMPAT'
+IMAGE_DLLCHARACTERISTICS_NO_ISOLATION = 'IMAGE_DLLCHARACTERISTICS_NO_ISOLATION'
+IMAGE_DLLCHARACTERISTICS_NO_SEH = 'IMAGE_DLLCHARACTERISTICS_NO_SEH'
+IMAGE_DLLCHARACTERISTICS_NO_BIND = 'IMAGE_DLLCHARACTERISTICS_NO_BIND'
+IMAGE_DLLCHARACTERISTICS_WDM_DRIVER = 'IMAGE_DLLCHARACTERISTICS_WDM_DRIVER'
+IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE = 'IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE'
+
+# IMAGE_FILE_HEADER.Machine
+IMAGE_FILE_MACHINE_UNKNOWN = 0x0
+IMAGE_FILE_MACHINE_AM33 = 0x1d3
+IMAGE_FILE_MACHINE_AMD64 = 0x8664
+IMAGE_FILE_MACHINE_ARM = 0x1c0
+IMAGE_FILE_MACHINE_ARM64 = 0xaa64
+IMAGE_FILE_MACHINE_ARMNT = 0x1c4
+IMAGE_FILE_MACHINE_EBC = 0xebc
+IMAGE_FILE_MACHINE_I386 = 0x14c
+IMAGE_FILE_MACHINE_IA64 = 0x200
+IMAGE_FILE_MACHINE_M32R = 0x9041
+IMAGE_FILE_MACHINE_MIPS16 = 0x266
+IMAGE_FILE_MACHINE_MIPSFPU = 0x366
+IMAGE_FILE_MACHINE_MIPSFPU16 = 0x466
+IMAGE_FILE_MACHINE_POWERPC = 0x1f0
+IMAGE_FILE_MACHINE_POWERPCFP = 0x1f1
+IMAGE_FILE_MACHINE_R4000 = 0x166
+IMAGE_FILE_MACHINE_RISCV32 = 0x5032
+IMAGE_FILE_MACHINE_RISCV64 = 0x5064
+IMAGE_FILE_MACHINE_RISCV128 = 0x5128
+IMAGE_FILE_MACHINE_SH3 = 0x1a2
+IMAGE_FILE_MACHINE_SH3DSP = 0x1a3
+IMAGE_FILE_MACHINE_SH4 = 0x1a6
+IMAGE_FILE_MACHINE_SH5 = 0x1a8
+IMAGE_FILE_MACHINE_THUMB = 0x1c2
+IMAGE_FILE_MACHINE_WCEMIPSV2 = 0x169
+
+
+# IMAGE_FILE_HEADER characterstics.
+IMAGE_FILE_RELOCS_STRIPPED = 'IMAGE_FILE_RELOCS_STRIPPED'
+IMAGE_FILE_EXECUTABLE_IMAGE = 'IMAGE_FILE_EXECUTABLE_IMAGE'
+IMAGE_FILE_LINE_NUMS_STRIPPED = 'IMAGE_FILE_LINE_NUMS_STRIPPED'
+IMAGE_FILE_LOCAL_SYMS_STRIPPED = 'IMAGE_FILE_LOCAL_SYMS_STRIPPED'
+IMAGE_FILE_AGGRESIVE_WS_TRIM = 'IMAGE_FILE_AGGRESIVE_WS_TRIM'
+IMAGE_FILE_LARGE_ADDRESS_AWARE = 'IMAGE_FILE_LARGE_ADDRESS_AWARE'
+IMAGE_FILE_BYTES_REVERSED_LO = 'IMAGE_FILE_BYTES_REVERSED_LO'
+IMAGE_FILE_32BIT_MACHINE = 'IMAGE_FILE_32BIT_MACHINE'
+IMAGE_FILE_DEBUG_STRIPPED = 'IMAGE_FILE_DEBUG_STRIPPED'
+IMAGE_FILE_REMOVABLE_RUN_FROM_SWAP = 'IMAGE_FILE_REMOVABLE_RUN_FROM_SWAP'
+IMAGE_FILE_NET_RUN_FROM_SWAP = 'IMAGE_FILE_NET_RUN_FROM_SWAP'
+IMAGE_FILE_SYSTEM = 'IMAGE_FILE_SYSTEM'
+IMAGE_FILE_DLL = 'IMAGE_FILE_DLL'
+IMAGE_FILE_UP_SYSTEM_ONLY = 'IMAGE_FILE_UP_SYSTEM_ONLY'
 IMAGE_FILE_BYTES_REVERSED_HI = 'IMAGE_FILE_BYTES_REVERSED_HI'
```

### Comparing `mwcp-3.8.0/mwcp/utils/construct/windows_enums.py` & `mwcp-3.9.0/mwcp/utils/construct/windows_enums.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,177 +1,177 @@
-"""
-A central location to store common windows enumerations.
-This module will be imported along with 'from mwcp.utils import construct'
-"""
-
-from .version28 import *
-
-# Visible interface. Add the classes and functions you would like to be available for users of construct
-# library here.
-__all__ = ['RegHive', 'LanguageIdentifier', 'KnownFolderID', 'AlgorithmID']
-
-
-REGHIVES = {
-    "HKCR": 0x80000000,
-    "HKCU": 0x80000001,
-    "HKLM": 0x80000002,
-    "HKU":  0x80000003,
-    "HKPD": 0x80000004,
-    "HKCC": 0x80000005,
-    "HKDD": 0x80000006,
-}
-
-
-def RegHive(subcon):
-    r"""
-    Converts an integer to registry hive enum.
-
-    >>> RegHive(Int32ul).build("HKCU")
-    '\x01\x00\x00\x80'
-    >>> str(RegHive(Int32ul).parse('\x01\x00\x00\x80'))
-    'HKCU'
-    """
-    return Enum(subcon, **REGHIVES)
-
-
-# TODO: Extend dictionary to incorporate more languages
-LANGUAGEIDENTIFIERS = {
-    "English (United States)": 0x409,
-    "Korean": 0x412,
-    "Chinese (PRC)": 0x804,
-}
-
-
-def LanguageIdentifier(subcon):
-    r"""
-    Converts an integer to language identifer enum
-
-    >>> LanguageIdentifier(Int32ul).build("English (United States)")
-    '\t\x04\x00\x00'
-    >>> str(LanguageIdentifier(Int32ul).parse("\x04\x08\x00\x00"))
-    'Chinese (PRC)'
-    """
-    return Enum(subcon, **LANGUAGEIDENTIFIERS)
-
-
-CSIDL = {
-    'CSIDL_SYSTEM': 37,
-    'CSIDL_COMMON_PROGRAMS': 23,
-    'CSIDL_PROFILE': 40,
-    'CSIDL_ALTSTARTUP': 29,
-    'CSIDL_LOCAL_APPDATA': 28,
-    'CSIDL_PRINTHOOD': 27,
-    'CSIDL_FONTS': 20,
-    'CSIDL_PROGRAM_FILES_COMMON': 43,
-    'CSIDL_PROGRAM_FILESX86': 42,
-    'CSIDL_MYDOCUMENTS': 5,
-    'CSIDL_MYVIDEO': 14,
-    'CSIDL_PROGRAM_FILES': 38,
-    'CSIDL_ADMINTOOLS': 48,
-    'CSIDL_COMMON_DOCUMENTS': 46,
-    'CSIDL_CONNECTIONS': 49,
-    'CSIDL_COMMON_ALTSTARTUP': 30,
-    'CSIDL_DRIVES': 17,
-    'CSIDL_RESOURCES_LOCALIZED': 57,
-    'CSIDL_HISTORY': 34,
-    'CSIDL_NETHOOD': 19,
-    'CSIDL_CDBURN_AREA': 59,
-    'CSIDL_COMMON_DESKTOPDIRECTORY': 25,
-    'CSIDL_SYSTEMX86': 41,
-    'CSIDL_COMMON_TEMPLATES': 45,
-    'CSIDL_MYPICTURES': 39,
-    'CSIDL_COMMON_VIDEO': 55,
-    'CSIDL_COMMON_STARTMENU': 22,
-    'CSIDL_COMMON_FAVORITES': 31,
-    'CSIDL_INTERNET_CACHE': 32,
-    'CSIDL_WINDOWS': 36,
-    'CSIDL_COMMON_PICTURES': 54,
-    'CSIDL_COMMON_APPDATA': 35,
-    'CSIDL_DESKTOPDIRECTORY': 16,
-    'CSIDL_RESOURCES': 56,
-    'CSIDL_COMMON_MUSIC': 53,
-    'CSIDL_COMMON_OEM_LINKS': 58,
-    'CSIDL_NETWORK': 18,
-    'CSIDL_COOKIES': 33,
-    'CSIDL_COMPUTERSNEARME': 61,
-    'CSIDL_COMMON_ADMINTOOLS': 47,
-    'CSIDL_APPDATA': 26,
-    'CSIDL_TEMPLATES': 21,
-    'CSIDL_COMMON_STARTUP': 24,
-    'CSIDL_MYMUSIC': 13,
-    'CSIDL_PROGRAM_FILES_COMMONX86': 44
-}
-
-
-def KnownFolderID(subcon):
-    r"""
-    Converts an integer to a CSIDL (KNownFolderID) value
-
-    >>> KnownFolderID(Int32ul).build("CSIDL_SYSTEM")
-    '%\x00\x00\x00'
-    >>> str(KnownFolderID(Int32ul).parse("\x18\x00\x00\x00"))
-    'CSIDL_COMMON_STARTUP'
-    """
-    return Enum(subcon, **CSIDL)
-
-
-ALGIDS = {
-    'CALG_DSS_SIGN': 0x00002200,
-    'CALG_DES': 0x00006601,
-    'CALG_DH_EPHEM': 0x0000aa02,
-    'CALG_3DES': 0x00006603,
-    'CALG_DESX': 0x00006604,
-    'CALG_ECDH': 0x0000aa05,
-    'CALG_NO_SIGN': 0x00002000,
-    'CALG_DH_SF': 0x0000aa01,
-    'CALC_SSL3_SHAMD5': 0x00008008,
-    'CALG_3DES_112': 0x00006609,
-    'CALG_SKIPJACK': 0x0000660a,
-    'CALG_HASH_REPLACE_OWF': 0x0000800b,
-    'CALG_CYLINK_MEK': 0x0000660c,
-    'CALG_MD4': 0x00008002,
-    'CALG_AES_128': 0x0000660e,
-    'CALG_AES_192': 0x0000660f,
-    'CALG_AES_256': 0x00006610,
-    'CALG_AES': 0x00006611,
-    'CALG_AGREEDKEY_ANY': 0x0000aa03,
-    'CALG_SHA1': 0x00008004,
-    'CALG_MAC': 0x00008005,
-    'CALG_MD2': 0x00008001,
-    'CALG_TLS1_MASTER': 0x00004c06,
-    'CALG_RSA_SIGN': 0x00002400,
-    'CALG_SCHANNEL_ENC_KEY': 0x00004c07,
-    'CALG_HMAC': 0x00008009,
-    'CALG_TLS1PRF': 0x0000800a,
-    'CALG_TEK': 0x0000660b,
-    'CALG_SHA_256': 0x0000800c,
-    'CALG_SHA_384': 0x0000800d,
-    'CALG_SHA_512': 0x0000800e,
-    'CALG_HUGHES_MD5': 0x0000a003,
-    'CALG_RC4': 0x00006801,
-    'CALG_ECDSA': 0x00002203,
-    'CALG_RC2': 0x00006602,
-    'CALG_SEAL': 0x00006802,
-    'CALG_SSL3_MASTER': 0x00004c01,
-    'CALG_SCHANNEL_MASTER_HASH': 0x00004c02,
-    'CALG_MD5': 0x00008003,
-    'CALG_SCHANNEL_MAC_KEY': 0x00004c03,
-    'CALG_KEY_KEYX': 0x0000aa04,
-    'CALG_ECMQV': 0x0000a001,
-    'CALG_PCT1_MASTER': 0x00004c04,
-    'CALG_RSA_KEYX': 0x0000a400,
-    'CALG_OID_INFO_CNG_ONLY': 0xffffffff,
-    'CALG_SSL2_MASTER': 0x00004c05,
-    'CALG_OID_INFO_PARAMETERS': 0xfffffffe,
-}
-
-
-def AlgorithmID(subcon):
-    r"""
-    Converts an integer to an AlgorithmID value
-
-    >>> str(AlgorithmID(Int16ul).parse("\x00\xa4"))
-    'CALG_RSA_KEYX'
-    >>> AlgorithmID(Int16ul).build("CALG_RC4")
-    '\x01h'
-    """
+"""
+A central location to store common windows enumerations.
+This module will be imported along with 'from mwcp.utils import construct'
+"""
+
+from .version28 import *
+
+# Visible interface. Add the classes and functions you would like to be available for users of construct
+# library here.
+__all__ = ['RegHive', 'LanguageIdentifier', 'KnownFolderID', 'AlgorithmID']
+
+
+REGHIVES = {
+    "HKCR": 0x80000000,
+    "HKCU": 0x80000001,
+    "HKLM": 0x80000002,
+    "HKU":  0x80000003,
+    "HKPD": 0x80000004,
+    "HKCC": 0x80000005,
+    "HKDD": 0x80000006,
+}
+
+
+def RegHive(subcon):
+    r"""
+    Converts an integer to registry hive enum.
+
+    >>> RegHive(Int32ul).build("HKCU")
+    '\x01\x00\x00\x80'
+    >>> str(RegHive(Int32ul).parse('\x01\x00\x00\x80'))
+    'HKCU'
+    """
+    return Enum(subcon, **REGHIVES)
+
+
+# TODO: Extend dictionary to incorporate more languages
+LANGUAGEIDENTIFIERS = {
+    "English (United States)": 0x409,
+    "Korean": 0x412,
+    "Chinese (PRC)": 0x804,
+}
+
+
+def LanguageIdentifier(subcon):
+    r"""
+    Converts an integer to language identifer enum
+
+    >>> LanguageIdentifier(Int32ul).build("English (United States)")
+    '\t\x04\x00\x00'
+    >>> str(LanguageIdentifier(Int32ul).parse("\x04\x08\x00\x00"))
+    'Chinese (PRC)'
+    """
+    return Enum(subcon, **LANGUAGEIDENTIFIERS)
+
+
+CSIDL = {
+    'CSIDL_SYSTEM': 37,
+    'CSIDL_COMMON_PROGRAMS': 23,
+    'CSIDL_PROFILE': 40,
+    'CSIDL_ALTSTARTUP': 29,
+    'CSIDL_LOCAL_APPDATA': 28,
+    'CSIDL_PRINTHOOD': 27,
+    'CSIDL_FONTS': 20,
+    'CSIDL_PROGRAM_FILES_COMMON': 43,
+    'CSIDL_PROGRAM_FILESX86': 42,
+    'CSIDL_MYDOCUMENTS': 5,
+    'CSIDL_MYVIDEO': 14,
+    'CSIDL_PROGRAM_FILES': 38,
+    'CSIDL_ADMINTOOLS': 48,
+    'CSIDL_COMMON_DOCUMENTS': 46,
+    'CSIDL_CONNECTIONS': 49,
+    'CSIDL_COMMON_ALTSTARTUP': 30,
+    'CSIDL_DRIVES': 17,
+    'CSIDL_RESOURCES_LOCALIZED': 57,
+    'CSIDL_HISTORY': 34,
+    'CSIDL_NETHOOD': 19,
+    'CSIDL_CDBURN_AREA': 59,
+    'CSIDL_COMMON_DESKTOPDIRECTORY': 25,
+    'CSIDL_SYSTEMX86': 41,
+    'CSIDL_COMMON_TEMPLATES': 45,
+    'CSIDL_MYPICTURES': 39,
+    'CSIDL_COMMON_VIDEO': 55,
+    'CSIDL_COMMON_STARTMENU': 22,
+    'CSIDL_COMMON_FAVORITES': 31,
+    'CSIDL_INTERNET_CACHE': 32,
+    'CSIDL_WINDOWS': 36,
+    'CSIDL_COMMON_PICTURES': 54,
+    'CSIDL_COMMON_APPDATA': 35,
+    'CSIDL_DESKTOPDIRECTORY': 16,
+    'CSIDL_RESOURCES': 56,
+    'CSIDL_COMMON_MUSIC': 53,
+    'CSIDL_COMMON_OEM_LINKS': 58,
+    'CSIDL_NETWORK': 18,
+    'CSIDL_COOKIES': 33,
+    'CSIDL_COMPUTERSNEARME': 61,
+    'CSIDL_COMMON_ADMINTOOLS': 47,
+    'CSIDL_APPDATA': 26,
+    'CSIDL_TEMPLATES': 21,
+    'CSIDL_COMMON_STARTUP': 24,
+    'CSIDL_MYMUSIC': 13,
+    'CSIDL_PROGRAM_FILES_COMMONX86': 44
+}
+
+
+def KnownFolderID(subcon):
+    r"""
+    Converts an integer to a CSIDL (KNownFolderID) value
+
+    >>> KnownFolderID(Int32ul).build("CSIDL_SYSTEM")
+    '%\x00\x00\x00'
+    >>> str(KnownFolderID(Int32ul).parse("\x18\x00\x00\x00"))
+    'CSIDL_COMMON_STARTUP'
+    """
+    return Enum(subcon, **CSIDL)
+
+
+ALGIDS = {
+    'CALG_DSS_SIGN': 0x00002200,
+    'CALG_DES': 0x00006601,
+    'CALG_DH_EPHEM': 0x0000aa02,
+    'CALG_3DES': 0x00006603,
+    'CALG_DESX': 0x00006604,
+    'CALG_ECDH': 0x0000aa05,
+    'CALG_NO_SIGN': 0x00002000,
+    'CALG_DH_SF': 0x0000aa01,
+    'CALC_SSL3_SHAMD5': 0x00008008,
+    'CALG_3DES_112': 0x00006609,
+    'CALG_SKIPJACK': 0x0000660a,
+    'CALG_HASH_REPLACE_OWF': 0x0000800b,
+    'CALG_CYLINK_MEK': 0x0000660c,
+    'CALG_MD4': 0x00008002,
+    'CALG_AES_128': 0x0000660e,
+    'CALG_AES_192': 0x0000660f,
+    'CALG_AES_256': 0x00006610,
+    'CALG_AES': 0x00006611,
+    'CALG_AGREEDKEY_ANY': 0x0000aa03,
+    'CALG_SHA1': 0x00008004,
+    'CALG_MAC': 0x00008005,
+    'CALG_MD2': 0x00008001,
+    'CALG_TLS1_MASTER': 0x00004c06,
+    'CALG_RSA_SIGN': 0x00002400,
+    'CALG_SCHANNEL_ENC_KEY': 0x00004c07,
+    'CALG_HMAC': 0x00008009,
+    'CALG_TLS1PRF': 0x0000800a,
+    'CALG_TEK': 0x0000660b,
+    'CALG_SHA_256': 0x0000800c,
+    'CALG_SHA_384': 0x0000800d,
+    'CALG_SHA_512': 0x0000800e,
+    'CALG_HUGHES_MD5': 0x0000a003,
+    'CALG_RC4': 0x00006801,
+    'CALG_ECDSA': 0x00002203,
+    'CALG_RC2': 0x00006602,
+    'CALG_SEAL': 0x00006802,
+    'CALG_SSL3_MASTER': 0x00004c01,
+    'CALG_SCHANNEL_MASTER_HASH': 0x00004c02,
+    'CALG_MD5': 0x00008003,
+    'CALG_SCHANNEL_MAC_KEY': 0x00004c03,
+    'CALG_KEY_KEYX': 0x0000aa04,
+    'CALG_ECMQV': 0x0000a001,
+    'CALG_PCT1_MASTER': 0x00004c04,
+    'CALG_RSA_KEYX': 0x0000a400,
+    'CALG_OID_INFO_CNG_ONLY': 0xffffffff,
+    'CALG_SSL2_MASTER': 0x00004c05,
+    'CALG_OID_INFO_PARAMETERS': 0xfffffffe,
+}
+
+
+def AlgorithmID(subcon):
+    r"""
+    Converts an integer to an AlgorithmID value
+
+    >>> str(AlgorithmID(Int16ul).parse("\x00\xa4"))
+    'CALG_RSA_KEYX'
+    >>> AlgorithmID(Int16ul).build("CALG_RC4")
+    '\x01h'
+    """
     return Enum(subcon, **ALGIDS)
```

### Comparing `mwcp-3.8.0/mwcp/utils/construct/windows_structures.py` & `mwcp-3.9.0/mwcp/utils/construct/windows_structures.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,366 +1,366 @@
-"""
-A central location to store common windows enumerations.
-This module will be imported along with 'from mwcp.utils import construct'
-"""
-
-from __future__ import absolute_import, division
-
-import datetime
-
-from . import version28 as construct
-from .version28 import this, len_
-
-from . import network, datetime_, windows_enums
-from .windows_constants import *
-
-
-"""PEFILE STRUCTURES"""
-
-IMAGE_DOS_HEADER = construct.Struct(
-    "e_magic" / construct.Default(construct.Bytes(2), b"MZ"),
-    "e_cblp" / construct.Int16ul,
-    "e_cp" / construct.Int16ul,
-    "e_crlc" / construct.Int16ul,
-    "e_cparhdr" / construct.Int16ul,
-    "e_mimalloc" / construct.Int16ul,
-    "e_maxalloc" / construct.Int16ul,
-    "e_ss" / construct.Int16ul,
-    "e_sp" / construct.Int16ul,
-    "e_csum" / construct.Int16ul,
-    "e_ip" / construct.Int16ul,
-    "e_cs" / construct.Int16ul,
-    "e_lfarlc" / construct.Int16ul,
-    "e_ovno" / construct.Int16ul,
-    "e_res1" / construct.Bytes(8),
-    "e_oemid" / construct.Int16ul,
-    "e_oeminfo" / construct.Int16ul,
-    "e_res2" / construct.Bytes(20),
-    "e_lfanew" / construct.Int32ul
-)
-
-
-IMAGE_SECTION_HEADER = construct.Struct(
-    "Name" / construct.String(8),
-    "VirtualSize" / construct.Int32ul,  # alias "PhysicalAddress"
-    "VirtualAddress" / construct.Int32ul,
-    "SizeOfRawData" / construct.Int32ul,
-    "PointerToRawData" / construct.Int32ul,
-    "PointerToRelocations" / construct.Default(construct.Int32ul, 0),
-    "PointerToLinenumbers" / construct.Default(construct.Int32ul, 0),
-    "NumberOfRelocations" / construct.Default(construct.Int16ul, 0),
-    "NumberOfLinenumbers" / construct.Default(construct.Int16ul, 0),
-    "Characteristics" / construct.FlagsEnum(
-        construct.Int32ul,
-        IMAGE_SCN_TYPE_NO_PAD=0x00000008,
-        IMAGE_SCN_CNT_CODE=0x00000020,
-        IMAGE_SCN_CNT_INITIALIZED_DATA=0x00000040,
-        IMAGE_SCN_CNT_UNINITIALIZED_DATA=0x00000080,
-        IMAGE_SCN_LNK_OTHER=0x00000100,
-        IMAGE_SCN_LNK_INFO=0x00000200,
-        IMAGE_SCN_LNK_REMOVE=0x00000800,
-        IMAGE_SCN_LNK_COMDAT=0x00001000,
-        IMAGE_SCN_NO_DEFER_SPEC_EXC=0x00004000,
-        IMAGE_SCN_GPREL=0x00008000,
-        IMAGE_SCN_MEM_PURGEABLE=0x00020000,
-        IMAGE_SCN_MEM_LOCKED=0x00040000,
-        IMAGE_SCN_MEM_PRELOAD=0x00080000,
-        IMAGE_SCN_ALIGN_1BYTES=0x00100000,
-        IMAGE_SCN_ALIGN_2BYTES=0x00200000,
-        IMAGE_SCN_ALIGN_4BYTES=0x00300000,
-        IMAGE_SCN_ALIGN_8BYTES=0x00400000,
-        IMAGE_SCN_ALIGN_16BYTES=0x00500000,
-        IMAGE_SCN_ALIGN_32BYTES=0x00600000,
-        IMAGE_SCN_ALIGN_64BYTES=0x00700000,
-        IMAGE_SCN_ALIGN_128BYTES=0x00800000,
-        IMAGE_SCN_ALIGN_256BYTES=0x00900000,
-        IMAGE_SCN_ALIGN_512BYTES=0x00A00000,
-        IMAGE_SCN_ALIGN_1024BYTES=0x00B00000,
-        IMAGE_SCN_ALIGN_2048BYTES=0x00C00000,
-        IMAGE_SCN_ALIGN_4096BYTES=0x00D00000,
-        IMAGE_SCN_ALIGN_8192BYTES=0x00E00000,
-        IMAGE_SCN_LNK_NRELOC_OVFL=0x01000000,
-        IMAGE_SCN_MEM_DISCARDABLE=0x02000000,
-        IMAGE_SCN_MEM_NOT_CACHED=0x04000000,
-        IMAGE_SCN_MEM_NOT_PAGED=0x08000000,
-        IMAGE_SCN_MEM_SHARED=0x10000000,
-        IMAGE_SCN_MEM_EXECUTE=0x20000000,
-        IMAGE_SCN_MEM_READ=0x40000000,
-        IMAGE_SCN_MEM_WRITE=0x80000000,
-    )
-)
-
-IMAGE_DATA_DIRECTORY = construct.Struct(
-    "VirtualAddress" / construct.Int32ul,
-    "Size" / construct.Int32ul,
-)
-
-IMAGE_EXPORT_DIRECTORY = construct.Struct(
-    "Characteristics" / construct.Default(construct.Int32ul, 0),
-    "TimeDateStamp" / datetime_.EpochTime,
-    "MajorVersion" / construct.Int16ul,
-    "MinorVersion" / construct.Int16ul,
-    "Name" / construct.Int32ul,  # rva pointer to the name
-    "Base" / construct.Int32ul,
-    "NumberOfFunctions" / construct.Int32ul,
-    "NumberOfNames" / construct.Int32ul,
-    "AddressOfFunctions" / construct.Int32ul,
-    "AddressOfNames" / construct.Int32ul,
-    "AddressOfNameOrdinals" / construct.Int32ul,
-)
-
-IMAGE_IMPORT_DESCRIPTOR = construct.Struct(
-    "Characteristics" / construct.Int32ul,
-    "TimeDateStamp" / construct.Int32ul,
-    "ForwarderChain" / construct.Int32ul,
-    "Name" / construct.Int32ul,  # rva pointer to the name
-    "FirstThunk" / construct.Int32ul,
-)
-
-IMAGE_OPTIONAL_HEADER = construct.Struct(
-    "Magic" / construct.OneOf(construct.Int16ul, [
-        IMAGE_NT_OPTIONAL_HDR32_MAGIC, IMAGE_NT_OPTIONAL_HDR64_MAGIC, IMAGE_ROM_OPTIONAL_HDR_MAGIC]),
-    "MajorLinkerVersion" / construct.Byte,
-    "MinorLinkerVersion" / construct.Byte,
-    "SizeOfCode" / construct.Int32ul,
-    "SizeOfInitializedData" / construct.Int32ul,
-    "SizeOfUninitializedData" / construct.Int32ul,
-    "AddressOfEntryPoint" / construct.Int32ul,
-    "BaseOfCode" / construct.Int32ul,
-    "BaseOfData" / construct.If(this.Magic != IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int32ul),
-    "ImageBase" / construct.IfThenElse(
-        this.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int64ul, construct.Int32ul
-    ),
-    "SectionAlignment" / construct.Int32ul,
-    "FileAlignment" / construct.Int32ul,
-    "MajorOperatingSystemVersion" / construct.Int16ul,
-    "MinorOperatingSystemVersion" / construct.Int16ul,
-    "MajorImageVersion" / construct.Int16ul,
-    "MinorImageVersion" / construct.Int16ul,
-    "MajorSubsystemVersion" / construct.Int16ul,
-    "MinorSubsystemVersion" / construct.Int16ul,
-    "Win32VersionValue" / construct.Default(construct.Int32ul, 0),  # must be 0
-    "SizeOfImage" / construct.Int32ul,
-    "SizeOfHeaders" / construct.Int32ul,
-    "CheckSum" / construct.Int32ul,
-    # TODO: Use enums instead?
-    "Subsystem" / construct.OneOf(construct.Int16ul, [
-        IMAGE_SUBSYSTEM_UNKNOWN,
-        IMAGE_SUBSYSTEM_NATIVE,
-        IMAGE_SUBSYSTEM_WINDOWS_GUI,
-        IMAGE_SUBSYSTEM_WINDOWS_CUI,
-        IMAGE_SUBSYSTEM_OS2_CUI,
-        IMAGE_SUBSYSTEM_POSIX_CUI,
-        IMAGE_SUBSYSTEM_WINDOWS_CE_GUI,
-        IMAGE_SUBSYSTEM_EFI_APPLICATION,
-        IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER,
-        IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER,
-        IMAGE_SUBSYSTEM_EFI_ROM,
-        IMAGE_SUBSYSTEM_XBOX,
-        IMAGE_SUBSYSTEM_WINDOWS_BOOT_APPLICATION,
-    ]),
-    "DllCharacteristics" / construct.FlagsEnum(
-        construct.Int16ul,
-        IMAGE_DLLCHARACTERISTICS_HIGH_ENTROPY_VA=0x0020,
-        IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE=0x0040,
-        IMAGE_DLLCHARACTERISTICS_FORCE_INTEGRITY=0x0080,
-        IMAGE_DLLCHARACTERISTICS_NX_COMPAT=0x0100,
-        IMAGE_DLLCHARACTERISTICS_NO_ISOLATION=0x0200,
-        IMAGE_DLLCHARACTERISTICS_NO_SEH=0x0400,
-        IMAGE_DLLCHARACTERISTICS_NO_BIND=0x0800,
-        IMAGE_DLLCHARACTERISTICS_APPCONTAINER=0x1000,
-        IMAGE_DLLCHARACTERISTICS_WDM_DRIVER=0x2000,
-        IMAGE_DLLCHARACTERISTICS_GUARD_CF=0x4000,
-        IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE=0x8000,
-    ),
-    "SizeOfStackReserve" / construct.IfThenElse(
-        this.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int64ul, construct.Int32ul
-    ),
-    "SizeOfStackCommit" / construct.IfThenElse(
-        this.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int64ul, construct.Int32ul
-    ),
-    "SizeOfHeapReserve" / construct.IfThenElse(
-        this.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int64ul, construct.Int32ul
-    ),
-    "SizeOfHeapCommit" / construct.IfThenElse(
-        this.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int64ul, construct.Int32ul
-    ),
-    "LoaderFlags" / construct.Int32ul,
-    "NumberOfRvaAndSizes" / construct.Rebuild(construct.Int32ul, construct.len_(this.DataDirectory)),
-    "DataDirectory" / construct.Default(IMAGE_DATA_DIRECTORY[this.NumberOfRvaAndSizes], DEFAULT_DATA_DIRECTORIES[:]),
-)
-
-IMAGE_FILE_HEADER = construct.Struct(
-    "Machine" / construct.Int16ul,  # IMAGE_FILE_MACHINE_*
-    "NumberOfSections" / construct.Int16ul,
-    "TimeDateStamp" / construct.Int32ul,
-    "PointerToSymbolTable" / construct.Default(construct.Int32ul, 0),
-    "NumberOfSymbols" / construct.Default(construct.Int32ul, 0),
-    # NOTE: This defaults to assuming a 32-bit PE when building if the SizeOfOptionalHeader isn't provided in the context.
-    "SizeOfOptionalHeader" / construct.Default(
-        construct.Int16ul, IMAGE_OPTIONAL_HEADER.sizeof(Magic=IMAGE_NT_OPTIONAL_HDR32_MAGIC, NumberOfRvaAndSizes=16)),
-    "Characteristics" / construct.FlagsEnum(
-        construct.Int16ul,
-        IMAGE_FILE_RELOCS_STRIPPED=0x0001,
-        IMAGE_FILE_EXECUTABLE_IMAGE=0x0002,
-        IMAGE_FILE_LINE_NUMS_STRIPPED=0x0004,
-        IMAGE_FILE_LOCAL_SYMS_STRIPPED=0x0008,
-        IMAGE_FILE_AGGRESIVE_WS_TRIM=0x0010,
-        IMAGE_FILE_LARGE_ADDRESS_AWARE=0x0020,
-        IMAGE_FILE_BYTES_REVERSED_LO=0x0080,
-        IMAGE_FILE_32BIT_MACHINE=0x0100,
-        IMAGE_FILE_DEBUG_STRIPPED=0x0200,
-        IMAGE_FILE_REMOVABLE_RUN_FROM_SWAP=0x0400,
-        IMAGE_FILE_NET_RUN_FROM_SWAP=0x0800,
-        IMAGE_FILE_SYSTEM=0x1000,
-        IMAGE_FILE_DLL=0x2000,
-        IMAGE_FILE_UP_SYSTEM_ONLY=0x4000,
-        IMAGE_FILE_BYTES_REVERSED_HI=0x8000,
-    ),
-)
-
-IMAGE_NT_HEADERS = construct.Struct(
-    "Signature" / construct.Default(construct.Int32ul, 0x4550),  # b'PE\x00\x00'
-    "FileHeader" / IMAGE_FILE_HEADER,
-    "OptionalHeader" / IMAGE_OPTIONAL_HEADER
-)
-
-PEFILE_HEADER = construct.Struct(
-    "DosHeader" / IMAGE_DOS_HEADER,
-    # TODO: Use construct.FixedSized() if we ever update construct.
-    "DosStub" / construct.Bytes(this.DosHeader.e_lfanew - IMAGE_DOS_HEADER.sizeof()),
-    "NTHeaders" / IMAGE_NT_HEADERS,
-    "SectionTable" / IMAGE_SECTION_HEADER[this.NTHeaders.FileHeader.NumberOfSections],
-)
-
-"""WINSOCK STRUCTURES"""
-
-SOCKADDR_IN = construct.Struct(
-    "sin_family" / construct.Int16ul,
-    "sin_port" / construct.Int16ub,  # in network byte order
-    "sin_addr" / network.IP4Address,
-    "sin_zero" / construct.Bytes(8)
-)
-
-# Same as SOCKADDR_IN but with the port as little endian.
-SOCKADDR_IN_L = construct.Struct(
-    "sin_family" / construct.Int16ul,
-    "sin_port" / construct.Int16ul,
-    "sin_addr" / network.IP4Address,
-    "sin_zero" / construct.Bytes(8)
-)
-
-"""CRYPTO STRUCTURES"""
-
-PUBLICKEYSTRUC = construct.Struct(
-    "type" / construct.Byte,
-    "version" / construct.Byte,
-    "reserved" / construct.Int16ul,
-    "algid" / windows_enums.AlgorithmID(construct.Int32ul),
-)
-
-PUBLICKEYBLOB = construct.Struct(
-    "publickeystruc" / PUBLICKEYSTRUC,
-    construct.Check(this.publickeystruc.algid == "CALG_RSA_KEYX"),
-    construct.Const(b"RSA1"),
-    "bitlen" / construct.Int32ul,
-    construct.Check((this.bitlen % 8) == 0),
-    "pubexponent" / construct.Int32ul,
-    "modulus" / construct.BytesInteger(this.bitlen // 8, swapped=True)
-)
-
-PRIVATEKEYBLOB = construct.Struct(
-    "publickeystruc" / PUBLICKEYSTRUC,
-    construct.Check(this.publickeystruc.algid == "CALG_RSA_KEYX"),
-    construct.Const(b"RSA2"),
-    "bitlen" / construct.Int32ul,
-    construct.Check((this.bitlen % 8) == 0),
-    "pubexponent" / construct.Int32ul,
-    "modulus" / construct.BytesInteger(this.bitlen // 8, swapped=True),
-    "P" / construct.BytesInteger(this.bitlen // 16, swapped=True),
-    "Q" / construct.BytesInteger(this.bitlen // 16, swapped=True),
-    # d % (p - 1)
-    "Dp" / construct.BytesInteger(this.bitlen // 16, swapped=True),
-    # d % (q - 1)
-    "Dq" / construct.BytesInteger(this.bitlen // 16, swapped=True),
-    # ~(q % p)
-    "Iq" / construct.BytesInteger(this.bitlen // 16, swapped=True),
-    # Private Exponent
-    "D" / construct.BytesInteger(this.bitlen // 8, swapped=True)
-)
-
-"""TIME STRUCTURES"""
-
-SYSTEMTIME = construct.Struct(
-    "wYear" / construct.Int16ul,
-    "wMonth" / construct.Int16ul,
-    "wDayOfWeek" / construct.Int16ul,
-    "wDay" / construct.Int16ul,
-    "wHour" / construct.Int16ul,
-    "wMinute" / construct.Int16ul,
-    "wSecond" / construct.Int16ul,
-    "wMilliseconds" / construct.Int16ul,
-)
-
-
-# TODO: Implement _encode
-class SystemTimeAdapter(construct.Adapter):
-    r"""
-    Adapter to convert SYSTEMTIME structured data to datetime.datetime ISO format.
-
-    >>> SystemTimeAdapter(SYSTEMTIME).parse(b'\xdd\x07\t\x00\x03\x00\x12\x00\t\x00.\x00\x15\x00\xf2\x02')
-    '2013-09-18T09:46:21.754000'
-    >>> SystemTimeAdapter(SYSTEMTIME, tzinfo=datetime.timezone.utc).parse(b'\xdd\x07\t\x00\x03\x00\x12\x00\t\x00.\x00\x15\x00\xf2\x02')
-    '2013-09-18T09:46:21.754000+00:00
-    """
-    def __init__(self, subcon, tzinfo=None):
-        """
-        :param tzinfo: Optional timezone object, default is localtime
-        :param subcon: subcon to parse SystemTime
-        """
-        super(SystemTimeAdapter, self).__init__(subcon)
-        self._tzinfo = tzinfo
-
-    def _decode(self, obj, context, path):
-        return datetime.datetime(
-            obj.wYear, obj.wMonth, obj.wDay, obj.wHour, obj.wMinute, obj.wSecond, obj.wMilliseconds * 1000,
-            tzinfo=self._tzinfo
-        ).isoformat()
-
-
-# Add common helpers
-SystemTime = SystemTimeAdapter(SYSTEMTIME)
-SystemTimeUTC = SystemTimeAdapter(SYSTEMTIME, tzinfo=datetime.timezone.utc)
-
-
-EPOCH_AS_FILETIME = 116444736000000000
-HUNDREDS_OF_NANOSECONDS = 10000000
-
-
-# TODO: Implement _encode
-class FileTimeAdapter(construct.Adapter):
-    r"""
-    Adapter to convert FILETIME structured data to datetime.datetime ISO format.
-    Technically FILETIME is two 32-bit integers as dwLowDateTime and dwHighDateTime, but there is no need to do that
-
-    >>> FileTimeAdapter(construct.Int64ul).parse(b'\x00\x93\xcc\x11\xa7\x88\xd0\x01')
-    '2015-05-07T05:20:33'
-    >>> FileTimeAdapter(construct.Int64ul, tz=datetime.timezone.utc).parse(b'\x00\x93\xcc\x11\xa7\x88\xd0\x01')
-    '2015-05-07T09:20:33.328000+00:00'
-    """
-    def __init__(self, subcon, tz=None):
-        """
-        :param tz: Optional timezone object, default is localtime
-        :param subcon: subcon to parse FileTime
-        """
-        super(FileTimeAdapter, self).__init__(subcon)
-        self._tz = tz
-
-    def _decode(self, obj, context, path):
-        return datetime.datetime.fromtimestamp(
-            (obj - EPOCH_AS_FILETIME) / HUNDREDS_OF_NANOSECONDS, tz=self._tz
-        ).isoformat()
-
-
-# Add common helpers
-FileTime = FileTimeAdapter(construct.Int64ul)
-FileTimeUTC = FileTimeAdapter(construct.Int64ul, tz=datetime.timezone.utc)
+"""
+A central location to store common windows enumerations.
+This module will be imported along with 'from mwcp.utils import construct'
+"""
+
+from __future__ import absolute_import, division
+
+import datetime
+
+from . import version28 as construct
+from .version28 import this, len_
+
+from . import network, datetime_, windows_enums
+from .windows_constants import *
+
+
+"""PEFILE STRUCTURES"""
+
+IMAGE_DOS_HEADER = construct.Struct(
+    "e_magic" / construct.Default(construct.Bytes(2), b"MZ"),
+    "e_cblp" / construct.Int16ul,
+    "e_cp" / construct.Int16ul,
+    "e_crlc" / construct.Int16ul,
+    "e_cparhdr" / construct.Int16ul,
+    "e_mimalloc" / construct.Int16ul,
+    "e_maxalloc" / construct.Int16ul,
+    "e_ss" / construct.Int16ul,
+    "e_sp" / construct.Int16ul,
+    "e_csum" / construct.Int16ul,
+    "e_ip" / construct.Int16ul,
+    "e_cs" / construct.Int16ul,
+    "e_lfarlc" / construct.Int16ul,
+    "e_ovno" / construct.Int16ul,
+    "e_res1" / construct.Bytes(8),
+    "e_oemid" / construct.Int16ul,
+    "e_oeminfo" / construct.Int16ul,
+    "e_res2" / construct.Bytes(20),
+    "e_lfanew" / construct.Int32ul
+)
+
+
+IMAGE_SECTION_HEADER = construct.Struct(
+    "Name" / construct.String(8),
+    "VirtualSize" / construct.Int32ul,  # alias "PhysicalAddress"
+    "VirtualAddress" / construct.Int32ul,
+    "SizeOfRawData" / construct.Int32ul,
+    "PointerToRawData" / construct.Int32ul,
+    "PointerToRelocations" / construct.Default(construct.Int32ul, 0),
+    "PointerToLinenumbers" / construct.Default(construct.Int32ul, 0),
+    "NumberOfRelocations" / construct.Default(construct.Int16ul, 0),
+    "NumberOfLinenumbers" / construct.Default(construct.Int16ul, 0),
+    "Characteristics" / construct.FlagsEnum(
+        construct.Int32ul,
+        IMAGE_SCN_TYPE_NO_PAD=0x00000008,
+        IMAGE_SCN_CNT_CODE=0x00000020,
+        IMAGE_SCN_CNT_INITIALIZED_DATA=0x00000040,
+        IMAGE_SCN_CNT_UNINITIALIZED_DATA=0x00000080,
+        IMAGE_SCN_LNK_OTHER=0x00000100,
+        IMAGE_SCN_LNK_INFO=0x00000200,
+        IMAGE_SCN_LNK_REMOVE=0x00000800,
+        IMAGE_SCN_LNK_COMDAT=0x00001000,
+        IMAGE_SCN_NO_DEFER_SPEC_EXC=0x00004000,
+        IMAGE_SCN_GPREL=0x00008000,
+        IMAGE_SCN_MEM_PURGEABLE=0x00020000,
+        IMAGE_SCN_MEM_LOCKED=0x00040000,
+        IMAGE_SCN_MEM_PRELOAD=0x00080000,
+        IMAGE_SCN_ALIGN_1BYTES=0x00100000,
+        IMAGE_SCN_ALIGN_2BYTES=0x00200000,
+        IMAGE_SCN_ALIGN_4BYTES=0x00300000,
+        IMAGE_SCN_ALIGN_8BYTES=0x00400000,
+        IMAGE_SCN_ALIGN_16BYTES=0x00500000,
+        IMAGE_SCN_ALIGN_32BYTES=0x00600000,
+        IMAGE_SCN_ALIGN_64BYTES=0x00700000,
+        IMAGE_SCN_ALIGN_128BYTES=0x00800000,
+        IMAGE_SCN_ALIGN_256BYTES=0x00900000,
+        IMAGE_SCN_ALIGN_512BYTES=0x00A00000,
+        IMAGE_SCN_ALIGN_1024BYTES=0x00B00000,
+        IMAGE_SCN_ALIGN_2048BYTES=0x00C00000,
+        IMAGE_SCN_ALIGN_4096BYTES=0x00D00000,
+        IMAGE_SCN_ALIGN_8192BYTES=0x00E00000,
+        IMAGE_SCN_LNK_NRELOC_OVFL=0x01000000,
+        IMAGE_SCN_MEM_DISCARDABLE=0x02000000,
+        IMAGE_SCN_MEM_NOT_CACHED=0x04000000,
+        IMAGE_SCN_MEM_NOT_PAGED=0x08000000,
+        IMAGE_SCN_MEM_SHARED=0x10000000,
+        IMAGE_SCN_MEM_EXECUTE=0x20000000,
+        IMAGE_SCN_MEM_READ=0x40000000,
+        IMAGE_SCN_MEM_WRITE=0x80000000,
+    )
+)
+
+IMAGE_DATA_DIRECTORY = construct.Struct(
+    "VirtualAddress" / construct.Int32ul,
+    "Size" / construct.Int32ul,
+)
+
+IMAGE_EXPORT_DIRECTORY = construct.Struct(
+    "Characteristics" / construct.Default(construct.Int32ul, 0),
+    "TimeDateStamp" / datetime_.EpochTime,
+    "MajorVersion" / construct.Int16ul,
+    "MinorVersion" / construct.Int16ul,
+    "Name" / construct.Int32ul,  # rva pointer to the name
+    "Base" / construct.Int32ul,
+    "NumberOfFunctions" / construct.Int32ul,
+    "NumberOfNames" / construct.Int32ul,
+    "AddressOfFunctions" / construct.Int32ul,
+    "AddressOfNames" / construct.Int32ul,
+    "AddressOfNameOrdinals" / construct.Int32ul,
+)
+
+IMAGE_IMPORT_DESCRIPTOR = construct.Struct(
+    "Characteristics" / construct.Int32ul,
+    "TimeDateStamp" / construct.Int32ul,
+    "ForwarderChain" / construct.Int32ul,
+    "Name" / construct.Int32ul,  # rva pointer to the name
+    "FirstThunk" / construct.Int32ul,
+)
+
+IMAGE_OPTIONAL_HEADER = construct.Struct(
+    "Magic" / construct.OneOf(construct.Int16ul, [
+        IMAGE_NT_OPTIONAL_HDR32_MAGIC, IMAGE_NT_OPTIONAL_HDR64_MAGIC, IMAGE_ROM_OPTIONAL_HDR_MAGIC]),
+    "MajorLinkerVersion" / construct.Byte,
+    "MinorLinkerVersion" / construct.Byte,
+    "SizeOfCode" / construct.Int32ul,
+    "SizeOfInitializedData" / construct.Int32ul,
+    "SizeOfUninitializedData" / construct.Int32ul,
+    "AddressOfEntryPoint" / construct.Int32ul,
+    "BaseOfCode" / construct.Int32ul,
+    "BaseOfData" / construct.If(this.Magic != IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int32ul),
+    "ImageBase" / construct.IfThenElse(
+        this.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int64ul, construct.Int32ul
+    ),
+    "SectionAlignment" / construct.Int32ul,
+    "FileAlignment" / construct.Int32ul,
+    "MajorOperatingSystemVersion" / construct.Int16ul,
+    "MinorOperatingSystemVersion" / construct.Int16ul,
+    "MajorImageVersion" / construct.Int16ul,
+    "MinorImageVersion" / construct.Int16ul,
+    "MajorSubsystemVersion" / construct.Int16ul,
+    "MinorSubsystemVersion" / construct.Int16ul,
+    "Win32VersionValue" / construct.Default(construct.Int32ul, 0),  # must be 0
+    "SizeOfImage" / construct.Int32ul,
+    "SizeOfHeaders" / construct.Int32ul,
+    "CheckSum" / construct.Int32ul,
+    # TODO: Use enums instead?
+    "Subsystem" / construct.OneOf(construct.Int16ul, [
+        IMAGE_SUBSYSTEM_UNKNOWN,
+        IMAGE_SUBSYSTEM_NATIVE,
+        IMAGE_SUBSYSTEM_WINDOWS_GUI,
+        IMAGE_SUBSYSTEM_WINDOWS_CUI,
+        IMAGE_SUBSYSTEM_OS2_CUI,
+        IMAGE_SUBSYSTEM_POSIX_CUI,
+        IMAGE_SUBSYSTEM_WINDOWS_CE_GUI,
+        IMAGE_SUBSYSTEM_EFI_APPLICATION,
+        IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER,
+        IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER,
+        IMAGE_SUBSYSTEM_EFI_ROM,
+        IMAGE_SUBSYSTEM_XBOX,
+        IMAGE_SUBSYSTEM_WINDOWS_BOOT_APPLICATION,
+    ]),
+    "DllCharacteristics" / construct.FlagsEnum(
+        construct.Int16ul,
+        IMAGE_DLLCHARACTERISTICS_HIGH_ENTROPY_VA=0x0020,
+        IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE=0x0040,
+        IMAGE_DLLCHARACTERISTICS_FORCE_INTEGRITY=0x0080,
+        IMAGE_DLLCHARACTERISTICS_NX_COMPAT=0x0100,
+        IMAGE_DLLCHARACTERISTICS_NO_ISOLATION=0x0200,
+        IMAGE_DLLCHARACTERISTICS_NO_SEH=0x0400,
+        IMAGE_DLLCHARACTERISTICS_NO_BIND=0x0800,
+        IMAGE_DLLCHARACTERISTICS_APPCONTAINER=0x1000,
+        IMAGE_DLLCHARACTERISTICS_WDM_DRIVER=0x2000,
+        IMAGE_DLLCHARACTERISTICS_GUARD_CF=0x4000,
+        IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE=0x8000,
+    ),
+    "SizeOfStackReserve" / construct.IfThenElse(
+        this.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int64ul, construct.Int32ul
+    ),
+    "SizeOfStackCommit" / construct.IfThenElse(
+        this.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int64ul, construct.Int32ul
+    ),
+    "SizeOfHeapReserve" / construct.IfThenElse(
+        this.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int64ul, construct.Int32ul
+    ),
+    "SizeOfHeapCommit" / construct.IfThenElse(
+        this.Magic == IMAGE_NT_OPTIONAL_HDR64_MAGIC, construct.Int64ul, construct.Int32ul
+    ),
+    "LoaderFlags" / construct.Int32ul,
+    "NumberOfRvaAndSizes" / construct.Rebuild(construct.Int32ul, construct.len_(this.DataDirectory)),
+    "DataDirectory" / construct.Default(IMAGE_DATA_DIRECTORY[this.NumberOfRvaAndSizes], DEFAULT_DATA_DIRECTORIES[:]),
+)
+
+IMAGE_FILE_HEADER = construct.Struct(
+    "Machine" / construct.Int16ul,  # IMAGE_FILE_MACHINE_*
+    "NumberOfSections" / construct.Int16ul,
+    "TimeDateStamp" / construct.Int32ul,
+    "PointerToSymbolTable" / construct.Default(construct.Int32ul, 0),
+    "NumberOfSymbols" / construct.Default(construct.Int32ul, 0),
+    # NOTE: This defaults to assuming a 32-bit PE when building if the SizeOfOptionalHeader isn't provided in the context.
+    "SizeOfOptionalHeader" / construct.Default(
+        construct.Int16ul, IMAGE_OPTIONAL_HEADER.sizeof(Magic=IMAGE_NT_OPTIONAL_HDR32_MAGIC, NumberOfRvaAndSizes=16)),
+    "Characteristics" / construct.FlagsEnum(
+        construct.Int16ul,
+        IMAGE_FILE_RELOCS_STRIPPED=0x0001,
+        IMAGE_FILE_EXECUTABLE_IMAGE=0x0002,
+        IMAGE_FILE_LINE_NUMS_STRIPPED=0x0004,
+        IMAGE_FILE_LOCAL_SYMS_STRIPPED=0x0008,
+        IMAGE_FILE_AGGRESIVE_WS_TRIM=0x0010,
+        IMAGE_FILE_LARGE_ADDRESS_AWARE=0x0020,
+        IMAGE_FILE_BYTES_REVERSED_LO=0x0080,
+        IMAGE_FILE_32BIT_MACHINE=0x0100,
+        IMAGE_FILE_DEBUG_STRIPPED=0x0200,
+        IMAGE_FILE_REMOVABLE_RUN_FROM_SWAP=0x0400,
+        IMAGE_FILE_NET_RUN_FROM_SWAP=0x0800,
+        IMAGE_FILE_SYSTEM=0x1000,
+        IMAGE_FILE_DLL=0x2000,
+        IMAGE_FILE_UP_SYSTEM_ONLY=0x4000,
+        IMAGE_FILE_BYTES_REVERSED_HI=0x8000,
+    ),
+)
+
+IMAGE_NT_HEADERS = construct.Struct(
+    "Signature" / construct.Default(construct.Int32ul, 0x4550),  # b'PE\x00\x00'
+    "FileHeader" / IMAGE_FILE_HEADER,
+    "OptionalHeader" / IMAGE_OPTIONAL_HEADER
+)
+
+PEFILE_HEADER = construct.Struct(
+    "DosHeader" / IMAGE_DOS_HEADER,
+    # TODO: Use construct.FixedSized() if we ever update construct.
+    "DosStub" / construct.Bytes(this.DosHeader.e_lfanew - IMAGE_DOS_HEADER.sizeof()),
+    "NTHeaders" / IMAGE_NT_HEADERS,
+    "SectionTable" / IMAGE_SECTION_HEADER[this.NTHeaders.FileHeader.NumberOfSections],
+)
+
+"""WINSOCK STRUCTURES"""
+
+SOCKADDR_IN = construct.Struct(
+    "sin_family" / construct.Int16ul,
+    "sin_port" / construct.Int16ub,  # in network byte order
+    "sin_addr" / network.IP4Address,
+    "sin_zero" / construct.Bytes(8)
+)
+
+# Same as SOCKADDR_IN but with the port as little endian.
+SOCKADDR_IN_L = construct.Struct(
+    "sin_family" / construct.Int16ul,
+    "sin_port" / construct.Int16ul,
+    "sin_addr" / network.IP4Address,
+    "sin_zero" / construct.Bytes(8)
+)
+
+"""CRYPTO STRUCTURES"""
+
+PUBLICKEYSTRUC = construct.Struct(
+    "type" / construct.Byte,
+    "version" / construct.Byte,
+    "reserved" / construct.Int16ul,
+    "algid" / windows_enums.AlgorithmID(construct.Int32ul),
+)
+
+PUBLICKEYBLOB = construct.Struct(
+    "publickeystruc" / PUBLICKEYSTRUC,
+    construct.Check(this.publickeystruc.algid == "CALG_RSA_KEYX"),
+    construct.Const(b"RSA1"),
+    "bitlen" / construct.Int32ul,
+    construct.Check((this.bitlen % 8) == 0),
+    "pubexponent" / construct.Int32ul,
+    "modulus" / construct.BytesInteger(this.bitlen // 8, swapped=True)
+)
+
+PRIVATEKEYBLOB = construct.Struct(
+    "publickeystruc" / PUBLICKEYSTRUC,
+    construct.Check(this.publickeystruc.algid == "CALG_RSA_KEYX"),
+    construct.Const(b"RSA2"),
+    "bitlen" / construct.Int32ul,
+    construct.Check((this.bitlen % 8) == 0),
+    "pubexponent" / construct.Int32ul,
+    "modulus" / construct.BytesInteger(this.bitlen // 8, swapped=True),
+    "P" / construct.BytesInteger(this.bitlen // 16, swapped=True),
+    "Q" / construct.BytesInteger(this.bitlen // 16, swapped=True),
+    # d % (p - 1)
+    "Dp" / construct.BytesInteger(this.bitlen // 16, swapped=True),
+    # d % (q - 1)
+    "Dq" / construct.BytesInteger(this.bitlen // 16, swapped=True),
+    # ~(q % p)
+    "Iq" / construct.BytesInteger(this.bitlen // 16, swapped=True),
+    # Private Exponent
+    "D" / construct.BytesInteger(this.bitlen // 8, swapped=True)
+)
+
+"""TIME STRUCTURES"""
+
+SYSTEMTIME = construct.Struct(
+    "wYear" / construct.Int16ul,
+    "wMonth" / construct.Int16ul,
+    "wDayOfWeek" / construct.Int16ul,
+    "wDay" / construct.Int16ul,
+    "wHour" / construct.Int16ul,
+    "wMinute" / construct.Int16ul,
+    "wSecond" / construct.Int16ul,
+    "wMilliseconds" / construct.Int16ul,
+)
+
+
+# TODO: Implement _encode
+class SystemTimeAdapter(construct.Adapter):
+    r"""
+    Adapter to convert SYSTEMTIME structured data to datetime.datetime ISO format.
+
+    >>> SystemTimeAdapter(SYSTEMTIME).parse(b'\xdd\x07\t\x00\x03\x00\x12\x00\t\x00.\x00\x15\x00\xf2\x02')
+    '2013-09-18T09:46:21.754000'
+    >>> SystemTimeAdapter(SYSTEMTIME, tzinfo=datetime.timezone.utc).parse(b'\xdd\x07\t\x00\x03\x00\x12\x00\t\x00.\x00\x15\x00\xf2\x02')
+    '2013-09-18T09:46:21.754000+00:00
+    """
+    def __init__(self, subcon, tzinfo=None):
+        """
+        :param tzinfo: Optional timezone object, default is localtime
+        :param subcon: subcon to parse SystemTime
+        """
+        super(SystemTimeAdapter, self).__init__(subcon)
+        self._tzinfo = tzinfo
+
+    def _decode(self, obj, context, path):
+        return datetime.datetime(
+            obj.wYear, obj.wMonth, obj.wDay, obj.wHour, obj.wMinute, obj.wSecond, obj.wMilliseconds * 1000,
+            tzinfo=self._tzinfo
+        ).isoformat()
+
+
+# Add common helpers
+SystemTime = SystemTimeAdapter(SYSTEMTIME)
+SystemTimeUTC = SystemTimeAdapter(SYSTEMTIME, tzinfo=datetime.timezone.utc)
+
+
+EPOCH_AS_FILETIME = 116444736000000000
+HUNDREDS_OF_NANOSECONDS = 10000000
+
+
+# TODO: Implement _encode
+class FileTimeAdapter(construct.Adapter):
+    r"""
+    Adapter to convert FILETIME structured data to datetime.datetime ISO format.
+    Technically FILETIME is two 32-bit integers as dwLowDateTime and dwHighDateTime, but there is no need to do that
+
+    >>> FileTimeAdapter(construct.Int64ul).parse(b'\x00\x93\xcc\x11\xa7\x88\xd0\x01')
+    '2015-05-07T05:20:33'
+    >>> FileTimeAdapter(construct.Int64ul, tz=datetime.timezone.utc).parse(b'\x00\x93\xcc\x11\xa7\x88\xd0\x01')
+    '2015-05-07T09:20:33.328000+00:00'
+    """
+    def __init__(self, subcon, tz=None):
+        """
+        :param tz: Optional timezone object, default is localtime
+        :param subcon: subcon to parse FileTime
+        """
+        super(FileTimeAdapter, self).__init__(subcon)
+        self._tz = tz
+
+    def _decode(self, obj, context, path):
+        return datetime.datetime.fromtimestamp(
+            (obj - EPOCH_AS_FILETIME) / HUNDREDS_OF_NANOSECONDS, tz=self._tz
+        ).isoformat()
+
+
+# Add common helpers
+FileTime = FileTimeAdapter(construct.Int64ul)
+FileTimeUTC = FileTimeAdapter(construct.Int64ul, tz=datetime.timezone.utc)
```

### Comparing `mwcp-3.8.0/mwcp/utils/custombase64.py` & `mwcp-3.9.0/mwcp/utils/custombase64.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,185 +1,185 @@
-"""
-Custom Base64 related utility
-"""
-
-import base64
-import logging
-import sys
-
-
-logger = logging.getLogger(__name__)
-
-
-# Standard alphabet base on size.
-_STD_ALPHA = {
-    16: b'0123456789ABCDEF',
-    32: b'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
-    64: b'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
-}
-
-
-def _validate_alphabet(alphabet, type):
-    """
-    validate the custom alphabet
-        - 64 or 65 characters
-        - mappings are unique
-    """
-    if len(alphabet) not in (type, type+1):
-        raise ValueError('invalid alphabet provided')
-
-    if len(alphabet) != len(set(alphabet)):
-        raise ValueError('mapping must be unique')
-
-    return
-
-
-def _adjust_pad(alphabet, data, decode):
-    logger.warning('The padding character has not been specified in the custom alphabet')
-
-    if not (len(data) * 8) % 6:
-        logger.info('The data does not require the padding character.  continuing')
-        return alphabet
-
-    if decode:
-        for char in data:
-            if char not in alphabet:
-                logger.info(
-                    'The character "{}" does not appear in the alphabet, '
-                    'but was found in the encoded data.  it will be used as the padding char'.format(char))
-                return alphabet + bytes([char]) if isinstance(char, int) else char  # support for python 2 or 3
-        raise ValueError('please provide a padding character to the custom alphabet')
-    else:
-        if b'=' not in alphabet:
-            return alphabet + b'='
-        else:
-            raise ValueError('ERROR: please provide a padding character to the custom alphabet')
-
-
-def _code(data, custom_alpha, size, decode, code_func):
-    if isinstance(custom_alpha, str):
-        custom_alpha = custom_alpha.encode()
-    if isinstance(data, str):
-        data = data.encode()
-    _validate_alphabet(custom_alpha, size)
-    if size != 16 and len(custom_alpha) == size:
-        _adjust_pad(custom_alpha, data, decode)
-    std_alpha = _STD_ALPHA[size]
-
-    if decode:
-        table = bytes.maketrans(custom_alpha, std_alpha)
-        data = data.translate(table)
-        return code_func(data)
-    else:
-        table = bytes.maketrans(std_alpha, custom_alpha)
-        data = code_func(data)
-        return data.translate(table)
-
-
-def b64encode(data, alphabet=None):
-    """
-    Base64 encode
-    :param data: data.
-    :param alphabet: custom alphabet or standard alphabet.
-    :return: base64 encoded data.
-
-    >>> b64encode('hello world')
-    'aGVsbG8gd29ybGQ='
-    >>> custom_alphabet = b'EFGHQRSTUVWefghijklmnopIJKLMNOPABCDqrstuvwxyXYZabcdz0123456789+/='
-    >>> b64encode('hello world', alphabet=custom_alphabet)
-    'LSoXMS8BO29dMSj='
-    """
-    alphabet = alphabet or _STD_ALPHA[64]
-    return _code(data, alphabet, 64, False, base64.b64encode)
-
-
-def b64decode(data, alphabet=None):
-    """
-    Base64 decode (pads characters if necessary)
-    :param data: base64 encoded data.
-    :param alphabet: custom alphabet or standard alphabet.
-    :return: base64 decoded data.
-
-    >>> b64decode('aGVsbG8gd29ybGQ=')
-    'hello world'
-    >>> custom_alphabet = b'EFGHQRSTUVWefghijklmnopIJKLMNOPABCDqrstuvwxyXYZabcdz0123456789+/='
-    >>> b64decode('LSoXMS8BO29dMSj=', alphabet=custom_alphabet)
-    'hello world'
-    >>> b64decode('LSoXMS8BO29dMSj', alphabet=custom_alphabet)
-    'hello world'
-    """
-    alphabet = alphabet or _STD_ALPHA[64]
-    # Pad the data, if necessary
-    data += alphabet[len(alphabet)-1:] * ((-len(data)) % 4)
-    return _code(data, alphabet, 64, True, base64.b64decode)
-
-
-def b32encode(data, alphabet=None):
-    """
-    Base32 encodes
-    :param data: data
-    :param alphabet: custom alphabet or standard alphabet.
-    :return: base32 encoded data.
-
-    >>> b32encode('hello world')
-    'NBSWY3DPEB3W64TMMQ======'
-    >>> custom_alphabet = 'FGHIJQ345RSTUVWXYKLMABCDENOPZ267='
-    >>> b32encode('hello world', alphabet=custom_alphabet)
-    'VGLCEPIXJGPC6ZMUUY======'
-    """
-    alphabet = alphabet or _STD_ALPHA[32]
-    return _code(data, alphabet, 32, False, base64.b32encode)
-
-
-def b32decode(data, alphabet=None):
-    """
-    Base32 decode (pads characters if necessary)
-    :param data: base32 encoded data.
-    :param alphabet: custom alphabet or standard alphabet.
-    :return: base32 decoded data.
-
-    >>> b32decode('NBSWY3DPEB3W64TMMQ======')
-    'hello world'
-    >>> custom_alphabet = 'FGHIJQ345RSTUVWXYKLMABCDENOPZ267='
-    >>> b32decode('VGLCEPIXJGPC6ZMUUY======', alphabet=custom_alphabet)
-    'hello world'
-    >>> b32decode('VGLCEPIXJGPC6ZMUUY', alphabet=custom_alphabet)
-    'hello world'
-    """
-    alphabet = alphabet or _STD_ALPHA[32]
-    # Pad the data, if necessary
-    data += alphabet[len(alphabet)-1:] * ((-len(data)) % 8)
-    return _code(data, alphabet, 32, True, base64.b32decode)
-
-
-def b16encode(data, alphabet=None):
-    """
-    Base16 encodes
-    :param data: data
-    :param alphabet: custom alphabet or standard alphabet.
-    :return: base16 encoded data.
-
-    >>> b16encode('hello world')
-    '68656C6C6F20776F726C64'
-    >>> custom_alphabet = '78BDE0123F459A6C'
-    >>> b16encode('hello world', alphabet=custom_alphabet)
-    '131019191CB7221C2B191E'
-    """
-    alphabet = alphabet or _STD_ALPHA[16]
-    return _code(data, alphabet, 16, False, base64.b16encode)
-
-
-def b16decode(data, alphabet=None):
-    """
-    Base16 decode
-    :param data: base16 encoded data.
-    :param alphabet: custom alphabet or standard alphabet.
-    :return: base16 decoded data.
-
-    >>> b16decode('68656C6C6F20776F726C64')
-    'hello world'
-    >>> custom_alphabet = '78BDE0123F459A6C'
-    >>> b16decode('131019191CB7221C2B191E', alphabet=custom_alphabet)
-    'hello world'
-    """
-    alphabet = alphabet or _STD_ALPHA[16]
-    return _code(data, alphabet, 16, True, base64.b16decode)
+"""
+Custom Base64 related utility
+"""
+
+import base64
+import logging
+import sys
+
+
+logger = logging.getLogger(__name__)
+
+
+# Standard alphabet base on size.
+_STD_ALPHA = {
+    16: b'0123456789ABCDEF',
+    32: b'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
+    64: b'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
+}
+
+
+def _validate_alphabet(alphabet, type):
+    """
+    validate the custom alphabet
+        - 64 or 65 characters
+        - mappings are unique
+    """
+    if len(alphabet) not in (type, type+1):
+        raise ValueError('invalid alphabet provided')
+
+    if len(alphabet) != len(set(alphabet)):
+        raise ValueError('mapping must be unique')
+
+    return
+
+
+def _adjust_pad(alphabet, data, decode):
+    logger.warning('The padding character has not been specified in the custom alphabet')
+
+    if not (len(data) * 8) % 6:
+        logger.info('The data does not require the padding character.  continuing')
+        return alphabet
+
+    if decode:
+        for char in data:
+            if char not in alphabet:
+                logger.info(
+                    'The character "{}" does not appear in the alphabet, '
+                    'but was found in the encoded data.  it will be used as the padding char'.format(char))
+                return alphabet + bytes([char]) if isinstance(char, int) else char  # support for python 2 or 3
+        raise ValueError('please provide a padding character to the custom alphabet')
+    else:
+        if b'=' not in alphabet:
+            return alphabet + b'='
+        else:
+            raise ValueError('ERROR: please provide a padding character to the custom alphabet')
+
+
+def _code(data, custom_alpha, size, decode, code_func):
+    if isinstance(custom_alpha, str):
+        custom_alpha = custom_alpha.encode()
+    if isinstance(data, str):
+        data = data.encode()
+    _validate_alphabet(custom_alpha, size)
+    if size != 16 and len(custom_alpha) == size:
+        _adjust_pad(custom_alpha, data, decode)
+    std_alpha = _STD_ALPHA[size]
+
+    if decode:
+        table = bytes.maketrans(custom_alpha, std_alpha)
+        data = data.translate(table)
+        return code_func(data)
+    else:
+        table = bytes.maketrans(std_alpha, custom_alpha)
+        data = code_func(data)
+        return data.translate(table)
+
+
+def b64encode(data, alphabet=None):
+    """
+    Base64 encode
+    :param data: data.
+    :param alphabet: custom alphabet or standard alphabet.
+    :return: base64 encoded data.
+
+    >>> b64encode('hello world')
+    'aGVsbG8gd29ybGQ='
+    >>> custom_alphabet = b'EFGHQRSTUVWefghijklmnopIJKLMNOPABCDqrstuvwxyXYZabcdz0123456789+/='
+    >>> b64encode('hello world', alphabet=custom_alphabet)
+    'LSoXMS8BO29dMSj='
+    """
+    alphabet = alphabet or _STD_ALPHA[64]
+    return _code(data, alphabet, 64, False, base64.b64encode)
+
+
+def b64decode(data, alphabet=None):
+    """
+    Base64 decode (pads characters if necessary)
+    :param data: base64 encoded data.
+    :param alphabet: custom alphabet or standard alphabet.
+    :return: base64 decoded data.
+
+    >>> b64decode('aGVsbG8gd29ybGQ=')
+    'hello world'
+    >>> custom_alphabet = b'EFGHQRSTUVWefghijklmnopIJKLMNOPABCDqrstuvwxyXYZabcdz0123456789+/='
+    >>> b64decode('LSoXMS8BO29dMSj=', alphabet=custom_alphabet)
+    'hello world'
+    >>> b64decode('LSoXMS8BO29dMSj', alphabet=custom_alphabet)
+    'hello world'
+    """
+    alphabet = alphabet or _STD_ALPHA[64]
+    # Pad the data, if necessary
+    data += alphabet[len(alphabet)-1:] * ((-len(data)) % 4)
+    return _code(data, alphabet, 64, True, base64.b64decode)
+
+
+def b32encode(data, alphabet=None):
+    """
+    Base32 encodes
+    :param data: data
+    :param alphabet: custom alphabet or standard alphabet.
+    :return: base32 encoded data.
+
+    >>> b32encode('hello world')
+    'NBSWY3DPEB3W64TMMQ======'
+    >>> custom_alphabet = 'FGHIJQ345RSTUVWXYKLMABCDENOPZ267='
+    >>> b32encode('hello world', alphabet=custom_alphabet)
+    'VGLCEPIXJGPC6ZMUUY======'
+    """
+    alphabet = alphabet or _STD_ALPHA[32]
+    return _code(data, alphabet, 32, False, base64.b32encode)
+
+
+def b32decode(data, alphabet=None):
+    """
+    Base32 decode (pads characters if necessary)
+    :param data: base32 encoded data.
+    :param alphabet: custom alphabet or standard alphabet.
+    :return: base32 decoded data.
+
+    >>> b32decode('NBSWY3DPEB3W64TMMQ======')
+    'hello world'
+    >>> custom_alphabet = 'FGHIJQ345RSTUVWXYKLMABCDENOPZ267='
+    >>> b32decode('VGLCEPIXJGPC6ZMUUY======', alphabet=custom_alphabet)
+    'hello world'
+    >>> b32decode('VGLCEPIXJGPC6ZMUUY', alphabet=custom_alphabet)
+    'hello world'
+    """
+    alphabet = alphabet or _STD_ALPHA[32]
+    # Pad the data, if necessary
+    data += alphabet[len(alphabet)-1:] * ((-len(data)) % 8)
+    return _code(data, alphabet, 32, True, base64.b32decode)
+
+
+def b16encode(data, alphabet=None):
+    """
+    Base16 encodes
+    :param data: data
+    :param alphabet: custom alphabet or standard alphabet.
+    :return: base16 encoded data.
+
+    >>> b16encode('hello world')
+    '68656C6C6F20776F726C64'
+    >>> custom_alphabet = '78BDE0123F459A6C'
+    >>> b16encode('hello world', alphabet=custom_alphabet)
+    '131019191CB7221C2B191E'
+    """
+    alphabet = alphabet or _STD_ALPHA[16]
+    return _code(data, alphabet, 16, False, base64.b16encode)
+
+
+def b16decode(data, alphabet=None):
+    """
+    Base16 decode
+    :param data: base16 encoded data.
+    :param alphabet: custom alphabet or standard alphabet.
+    :return: base16 decoded data.
+
+    >>> b16decode('68656C6C6F20776F726C64')
+    'hello world'
+    >>> custom_alphabet = '78BDE0123F459A6C'
+    >>> b16decode('131019191CB7221C2B191E', alphabet=custom_alphabet)
+    'hello world'
+    """
+    alphabet = alphabet or _STD_ALPHA[16]
+    return _code(data, alphabet, 16, True, base64.b16decode)
```

### Comparing `mwcp-3.8.0/mwcp/utils/elffileutils.py` & `mwcp-3.9.0/mwcp/utils/elffileutils.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,128 +1,128 @@
-"""
-Description: Utility for elftools python library.
-"""
-
-import logging
-
-logger = logging.getLogger(__name__)
-
-import elftools.elf.elffile as elffile
-import io
-
-
-def obtain_elf(file_data):
-    """
-    Given file data, create an elftools.ELFFile object from the data.
-
-    :param file_data: Input ELF file data
-
-    :return: An elftools.ELFFile object or None
-    """
-    try:
-        elf = elffile.ELFFile(io.BytesIO(file_data))
-        return elf
-    except elffile.ELFError:
-        logger.debug('An elftools.ELFFile object on the file data could not be created.')
-        return None
-
-
-def obtain_section(section_name, elf=None, file_data=None):
-    """
-    Obtain the section obtain for a specficied ELF section of a file.
-
-    :param section_name: The name of the section to obtain
-    :param elf: elftools.ELFFile object
-    :param file_data: Input file data
-
-    :return: The elftools.Section object, or None.
-    """
-    if file_data:
-        elf = obtain_elf(file_data)
-    if elf:
-        for section in elf.iter_sections():
-            if section.name == section_name:
-                    return section
-        return None
-    else:
-        return None
-
-
-def obtain_section_data(section_name, elf=None, file_data=None, min_size=0):
-    """
-    Obtain the data in a specified ELF section of a file.
-
-    :param section_name: The name of the section from which to extract data.
-    :param elf: elftools.ELFFile object
-    :param file_data: Input file data
-    :param min_size: The minimum acceptable size for the section_data
-
-    :return: The PE section data, or None.
-    """
-    if file_data:
-        elf = obtain_elf(file_data)
-    if elf:
-        section = obtain_section(section_name, elf)
-        if section:
-            section_data = section.data()
-            if len(section_data) > min_size:
-                return section_data
-            return None
-        return None
-    else:
-        return None
-
-
-def check_section(section_name, elf=None, file_data=None):
-    """
-    Check if a specified ELF section exists in a file.
-
-    :param section_name: The name of the section from which to extract data.
-    :param elf: elftools.ELFFile object
-    :param file_data: Input file data
-
-    :return: True if the section name is observed, False if it is not.
-    """
-    if file_data:
-        elf = obtain_elf(file_data)
-    if elf and obtain_section(section_name, elf):
-        return True
-    return False
-
-
-def obtain_physical_offset(mem_offset, elf=None, file_data=None):
-    """
-    For an ELF file (in x86), convert a provided memory offset to a raw offset.
-
-    :param mem_offset: The memory offset to convert to a raw offset
-    :param elf: elftools.ELFFile object
-    :param file_data: Input file data
-
-    :return: Raw offset, or None.
-    """
-    if file_data:
-        elf = obtain_elf(file_data)
-    if elf:
-        for phy_offset in elf.address_offsets(mem_offset):
-            return phy_offset
-    return None
-
-
-def obtain_memory_offset(phy_offset, elf=None, file_data=None):
-    """
-    For an ELF file, convert a provided raw offset to a memory offset.
-
-    :param phy_offset: The raw offset to convert to a memory offset
-    :param elf: elftools.ELFFile object
-    :param file_data: Input file data
-
-    :return: Memory offset, or None.
-    """
-    if file_data:
-        elf = obtain_elf(file_data)
-    if elf:
-        for seg in elf.iter_segments():
-            if seg['p_offset'] <= phy_offset < (seg['p_offset'] + seg['p_filesz']):
-                return phy_offset - seg['p_offset'] + seg['p_vaddr']
-        return None
-    else:
-        return None
+"""
+Description: Utility for elftools python library.
+"""
+
+import logging
+
+logger = logging.getLogger(__name__)
+
+import elftools.elf.elffile as elffile
+import io
+
+
+def obtain_elf(file_data):
+    """
+    Given file data, create an elftools.ELFFile object from the data.
+
+    :param file_data: Input ELF file data
+
+    :return: An elftools.ELFFile object or None
+    """
+    try:
+        elf = elffile.ELFFile(io.BytesIO(file_data))
+        return elf
+    except elffile.ELFError:
+        logger.debug('An elftools.ELFFile object on the file data could not be created.')
+        return None
+
+
+def obtain_section(section_name, elf=None, file_data=None):
+    """
+    Obtain the section obtain for a specficied ELF section of a file.
+
+    :param section_name: The name of the section to obtain
+    :param elf: elftools.ELFFile object
+    :param file_data: Input file data
+
+    :return: The elftools.Section object, or None.
+    """
+    if file_data:
+        elf = obtain_elf(file_data)
+    if elf:
+        for section in elf.iter_sections():
+            if section.name == section_name:
+                    return section
+        return None
+    else:
+        return None
+
+
+def obtain_section_data(section_name, elf=None, file_data=None, min_size=0):
+    """
+    Obtain the data in a specified ELF section of a file.
+
+    :param section_name: The name of the section from which to extract data.
+    :param elf: elftools.ELFFile object
+    :param file_data: Input file data
+    :param min_size: The minimum acceptable size for the section_data
+
+    :return: The PE section data, or None.
+    """
+    if file_data:
+        elf = obtain_elf(file_data)
+    if elf:
+        section = obtain_section(section_name, elf)
+        if section:
+            section_data = section.data()
+            if len(section_data) > min_size:
+                return section_data
+            return None
+        return None
+    else:
+        return None
+
+
+def check_section(section_name, elf=None, file_data=None):
+    """
+    Check if a specified ELF section exists in a file.
+
+    :param section_name: The name of the section from which to extract data.
+    :param elf: elftools.ELFFile object
+    :param file_data: Input file data
+
+    :return: True if the section name is observed, False if it is not.
+    """
+    if file_data:
+        elf = obtain_elf(file_data)
+    if elf and obtain_section(section_name, elf):
+        return True
+    return False
+
+
+def obtain_physical_offset(mem_offset, elf=None, file_data=None):
+    """
+    For an ELF file (in x86), convert a provided memory offset to a raw offset.
+
+    :param mem_offset: The memory offset to convert to a raw offset
+    :param elf: elftools.ELFFile object
+    :param file_data: Input file data
+
+    :return: Raw offset, or None.
+    """
+    if file_data:
+        elf = obtain_elf(file_data)
+    if elf:
+        for phy_offset in elf.address_offsets(mem_offset):
+            return phy_offset
+    return None
+
+
+def obtain_memory_offset(phy_offset, elf=None, file_data=None):
+    """
+    For an ELF file, convert a provided raw offset to a memory offset.
+
+    :param phy_offset: The raw offset to convert to a memory offset
+    :param elf: elftools.ELFFile object
+    :param file_data: Input file data
+
+    :return: Memory offset, or None.
+    """
+    if file_data:
+        elf = obtain_elf(file_data)
+    if elf:
+        for seg in elf.iter_segments():
+            if seg['p_offset'] <= phy_offset < (seg['p_offset'] + seg['p_filesz']):
+                return phy_offset - seg['p_offset'] + seg['p_vaddr']
+        return None
+    else:
+        return None
```

### Comparing `mwcp-3.8.0/mwcp/utils/logutil.py` & `mwcp-3.9.0/mwcp/utils/logutil.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,203 +1,203 @@
-"""Utilities for setting up logging."""
-import copy
-import errno
-import logging.config
-import logging.handlers
-import multiprocessing as mp
-import os
-import platform
-import sys
-import threading
-import traceback
-import warnings
-from collections import deque
-
-import appdirs
-import yaml
-
-import mwcp
-
-# Queue used to send over log messages from child to main process.
-# (See mwcp.utils.multi_proc for its use.)
-mp_queue = mp.Queue()
-
-
-class LevelCharFilter(logging.Filter):
-    """Logging filter used to add a 'level_char' format variable."""
-
-    def filter(self, record):
-        if record.levelno >= logging.ERROR:
-            record.level_char = "!"
-        elif record.levelno >= logging.WARN:
-            record.level_char = "-"
-        elif record.levelno >= logging.INFO:
-            record.level_char = "+"
-        elif record.levelno >= logging.DEBUG:
-            record.level_char = "*"
-        else:
-            record.level_char = " "
-        return True
-
-
-class MPRotatingFileHandler(logging.handlers.RotatingFileHandler):
-    """
-    Handle the uncommon case of the log attempting to roll over when
-    another process has the log open. This only happens on Windows, and
-    the log ends up being a handful of KBs greater than 1024. Entries
-    are still written, and the rollover happens if/when the MainProcess is
-    the only process with the log file open.
-    """
-
-    def __init__(self, filename, **kwargs):
-        # Expand and variables and home directories and make path if it doesn't exist.
-        filename = os.path.expandvars(os.path.expanduser(filename))
-
-        # If path is relative, add to standard log directory.
-        if not os.path.isabs(filename):
-            filename = os.path.join(appdirs.user_log_dir("mwcp", appauthor=False), filename)
-
-        directory = os.path.dirname(filename)
-        if not os.path.exists(directory):
-            os.makedirs(directory)
-        super(MPRotatingFileHandler, self).__init__(filename, **kwargs)
-
-    def doRollover(self):
-        """
-        Attempt to roll over to the next log file. If the current file
-        is locked (Windows issue), keep writing to the original file until
-        it is unlocked.
-
-        :return:
-        """
-        try:
-            super(MPRotatingFileHandler, self).doRollover()
-        except OSError as e:
-            if not (sys.platform == "win32" and e.errno == errno.EACCES):
-                raise
-
-
-class MPChildHandler(logging.Handler):
-    """
-    Simple handler for child processes.
-
-    Ensures pickle-ability and sends the record entry to the queue.
-    """
-
-    def __init__(self, log_queue):
-        super(MPChildHandler, self).__init__()
-        self.queue = log_queue
-
-    def emit(self, record):
-        if record.exc_info:
-            record.exc_text = "".join(traceback.format_exception(*record.exc_info))
-            record.exc_info = None
-
-        self.queue.put(record)
-
-
-class ListHandler(logging.Handler):
-    """
-    Log to a list, with an optional maximum number of records to store.
-
-    Full records are available with the `records` property, and messages (i.e.
-    the text of the log entry) at available with the `messages` property.
-    """
-
-    def __init__(self, entries=None):
-        """
-        Behaves essentially identical to any other handler.
-
-        The only option is max_entries, to specify the max number of log
-        entries kept. By default, no limit.
-
-        :param int entries: Maximum number of records to store.
-        """
-        super(ListHandler, self).__init__()
-
-        self._deque = deque(maxlen=entries)
-
-    def __copy__(self):
-        new_handler = ListHandler()
-        # Actually copy the deque, otherwise we'll get double entries
-        new_handler._deque = copy.copy(self._deque)
-        return new_handler
-
-    def emit(self, record):
-        msg = self.format(record)
-        record.formatted_msg = msg
-        self._deque.append(record)
-
-    def clear(self):
-        return self._deque.clear()
-
-    @property
-    def records(self):
-        """
-        List of the last `max_entries` records logged.
-        """
-        return list(self._deque)
-
-    @property
-    def messages(self):
-        """
-        List of the last `max_entries` formatted messages logged.
-        """
-        return [record.formatted_msg for record in self._deque]
-
-
-def start_listener():
-    """Start the listener thread for multi-process logging."""
-    if mp.current_process().name != "MainProcess":
-        return
-
-    def _mp_log_listener(log_queue):
-        while True:
-            record = log_queue.get()
-            _logger = logging.getLogger(record.name)
-            if _logger.isEnabledFor(record.levelno):
-                _logger.handle(record)
-
-    listener_thread = threading.Thread(target=_mp_log_listener, args=(mp_queue,))
-    listener_thread.daemon = True
-    listener_thread.start()
-
-
-def setup_logging(default_level=logging.INFO, queue=None):
-    """
-    Sets up logging using default log config file or log config file set by 'MWCP_LOG_CFG'
-
-    :param default_level: Default log level to set to if config file fails.
-    :param queue: Queue used to pass logs to.
-    """
-    if queue:
-        assert mp.current_process().name != "MainProcess"
-        logging.root.addHandler(MPChildHandler(queue))
-        # If on Windows, allow all records to pass through, this is necessary because Windows
-        # subprocesses don't duplicate the global state like posix systems.
-        # Therefore, we have to pass all log messages through since effective
-        # log level is unknown.
-        if "Windows" in platform.platform():
-            logging.root.setLevel(logging.DEBUG)
-    else:
-        # Allow setting log configuration using 'MWCP_LOG_CFG' environment variable.
-        log_config = os.getenv("MWCP_LOG_CFG", None)
-        if log_config is None:
-            log_config = mwcp.config.get("LOG_CONFIG_PATH", None)
-        else:
-            warnings.warn(
-                "Using MWCP_LOG_CFG to set log configuration is deprecated. "
-                "Please specify path in the configuration file instead."
-            )
-        if log_config:
-            try:
-                with open(log_config, "rt") as f:
-                    config = yaml.safe_load(f.read())
-                logging.config.dictConfig(config)
-            except IOError as e:
-                warnings.warn("Unable to set log config file: {} with error: {}".format(log_config, e))
-                logging.basicConfig(level=default_level)
-        else:
-            logging.basicConfig(level=default_level)
-
-        # Startup queue listener if we are in the main process.
-        start_listener()
+"""Utilities for setting up logging."""
+import copy
+import errno
+import logging.config
+import logging.handlers
+import multiprocessing as mp
+import os
+import platform
+import sys
+import threading
+import traceback
+import warnings
+from collections import deque
+
+import appdirs
+import yaml
+
+import mwcp
+
+# Queue used to send over log messages from child to main process.
+# (See mwcp.utils.multi_proc for its use.)
+mp_queue = mp.Queue()
+
+
+class LevelCharFilter(logging.Filter):
+    """Logging filter used to add a 'level_char' format variable."""
+
+    def filter(self, record):
+        if record.levelno >= logging.ERROR:
+            record.level_char = "!"
+        elif record.levelno >= logging.WARN:
+            record.level_char = "-"
+        elif record.levelno >= logging.INFO:
+            record.level_char = "+"
+        elif record.levelno >= logging.DEBUG:
+            record.level_char = "*"
+        else:
+            record.level_char = " "
+        return True
+
+
+class MPRotatingFileHandler(logging.handlers.RotatingFileHandler):
+    """
+    Handle the uncommon case of the log attempting to roll over when
+    another process has the log open. This only happens on Windows, and
+    the log ends up being a handful of KBs greater than 1024. Entries
+    are still written, and the rollover happens if/when the MainProcess is
+    the only process with the log file open.
+    """
+
+    def __init__(self, filename, **kwargs):
+        # Expand and variables and home directories and make path if it doesn't exist.
+        filename = os.path.expandvars(os.path.expanduser(filename))
+
+        # If path is relative, add to standard log directory.
+        if not os.path.isabs(filename):
+            filename = os.path.join(appdirs.user_log_dir("mwcp", appauthor=False), filename)
+
+        directory = os.path.dirname(filename)
+        if not os.path.exists(directory):
+            os.makedirs(directory)
+        super(MPRotatingFileHandler, self).__init__(filename, **kwargs)
+
+    def doRollover(self):
+        """
+        Attempt to roll over to the next log file. If the current file
+        is locked (Windows issue), keep writing to the original file until
+        it is unlocked.
+
+        :return:
+        """
+        try:
+            super(MPRotatingFileHandler, self).doRollover()
+        except OSError as e:
+            if not (sys.platform == "win32" and e.errno == errno.EACCES):
+                raise
+
+
+class MPChildHandler(logging.Handler):
+    """
+    Simple handler for child processes.
+
+    Ensures pickle-ability and sends the record entry to the queue.
+    """
+
+    def __init__(self, log_queue):
+        super(MPChildHandler, self).__init__()
+        self.queue = log_queue
+
+    def emit(self, record):
+        if record.exc_info:
+            record.exc_text = "".join(traceback.format_exception(*record.exc_info))
+            record.exc_info = None
+
+        self.queue.put(record)
+
+
+class ListHandler(logging.Handler):
+    """
+    Log to a list, with an optional maximum number of records to store.
+
+    Full records are available with the `records` property, and messages (i.e.
+    the text of the log entry) at available with the `messages` property.
+    """
+
+    def __init__(self, entries=None):
+        """
+        Behaves essentially identical to any other handler.
+
+        The only option is max_entries, to specify the max number of log
+        entries kept. By default, no limit.
+
+        :param int entries: Maximum number of records to store.
+        """
+        super(ListHandler, self).__init__()
+
+        self._deque = deque(maxlen=entries)
+
+    def __copy__(self):
+        new_handler = ListHandler()
+        # Actually copy the deque, otherwise we'll get double entries
+        new_handler._deque = copy.copy(self._deque)
+        return new_handler
+
+    def emit(self, record):
+        msg = self.format(record)
+        record.formatted_msg = msg
+        self._deque.append(record)
+
+    def clear(self):
+        return self._deque.clear()
+
+    @property
+    def records(self):
+        """
+        List of the last `max_entries` records logged.
+        """
+        return list(self._deque)
+
+    @property
+    def messages(self):
+        """
+        List of the last `max_entries` formatted messages logged.
+        """
+        return [record.formatted_msg for record in self._deque]
+
+
+def start_listener():
+    """Start the listener thread for multi-process logging."""
+    if mp.current_process().name != "MainProcess":
+        return
+
+    def _mp_log_listener(log_queue):
+        while True:
+            record = log_queue.get()
+            _logger = logging.getLogger(record.name)
+            if _logger.isEnabledFor(record.levelno):
+                _logger.handle(record)
+
+    listener_thread = threading.Thread(target=_mp_log_listener, args=(mp_queue,))
+    listener_thread.daemon = True
+    listener_thread.start()
+
+
+def setup_logging(default_level=logging.INFO, queue=None):
+    """
+    Sets up logging using default log config file or log config file set by 'MWCP_LOG_CFG'
+
+    :param default_level: Default log level to set to if config file fails.
+    :param queue: Queue used to pass logs to.
+    """
+    if queue:
+        assert mp.current_process().name != "MainProcess"
+        logging.root.addHandler(MPChildHandler(queue))
+        # If on Windows, allow all records to pass through, this is necessary because Windows
+        # subprocesses don't duplicate the global state like posix systems.
+        # Therefore, we have to pass all log messages through since effective
+        # log level is unknown.
+        if "Windows" in platform.platform():
+            logging.root.setLevel(logging.DEBUG)
+    else:
+        # Allow setting log configuration using 'MWCP_LOG_CFG' environment variable.
+        log_config = os.getenv("MWCP_LOG_CFG", None)
+        if log_config is None:
+            log_config = mwcp.config.get("LOG_CONFIG_PATH", None)
+        else:
+            warnings.warn(
+                "Using MWCP_LOG_CFG to set log configuration is deprecated. "
+                "Please specify path in the configuration file instead."
+            )
+        if log_config:
+            try:
+                with open(log_config, "rt") as f:
+                    config = yaml.safe_load(f.read())
+                logging.config.dictConfig(config)
+            except IOError as e:
+                warnings.warn("Unable to set log config file: {} with error: {}".format(log_config, e))
+                logging.basicConfig(level=default_level)
+        else:
+            logging.basicConfig(level=default_level)
+
+        # Startup queue listener if we are in the main process.
+        start_listener()
```

### Comparing `mwcp-3.8.0/mwcp/utils/multi_proc.py` & `mwcp-3.9.0/mwcp/utils/multi_proc.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,54 +1,54 @@
-"""
-Helper methods for setting up multiprocessing workers with logging capabilities
-"""
-
-import logging
-import multiprocessing as mp
-import multiprocessing.pool
-
-logger = logging.getLogger(__name__)
-
-from mwcp import registry
-from mwcp.utils import logutil
-
-
-def initializer(parser_sources, default_source):
-    """Initializer function that runs at the beginning of each process creation."""
-    registry._sources = parser_sources  # Propagate registered parser information.
-    registry._default_source = default_source
-
-
-class TProcess(mp.Process):
-    """
-    Slighted modified subclass of :class:`multiprocessing.Process`.
-
-    Use this in place of ``Process`` to enable logging in the spawned process.
-    """
-
-    def __init__(self, group=None, target=None, name=None, args=(), kwargs=None):
-        kwargs = kwargs or {}
-        # NOTE: Forcing group to be None since BaseProcess asserts it to be None.
-        super(TProcess, self).__init__(group=None, target=target, name=name, args=args, kwargs=kwargs)
-        self.queue = logutil.mp_queue
-
-    def run(self):
-        logutil.setup_logging(queue=self.queue)
-        logger.debug("Setup logger in {}".format(mp.current_process().name))
-        super(TProcess, self).run()
-
-
-class TPool(mp.pool.Pool):
-    """
-    Version of :class:`multiprocessing.pool.Pool` that uses :class:`TProcess`.
-    """
-
-    Process = TProcess
-
-    def __init__(self, processes=None, maxtasksperchild=None):
-        """Overwrite to add initializer."""
-        super(TPool, self).__init__(
-            processes=processes,
-            maxtasksperchild=maxtasksperchild,
-            initializer=initializer,
-            initargs=(registry._sources, registry._default_source),
-        )
+"""
+Helper methods for setting up multiprocessing workers with logging capabilities
+"""
+
+import logging
+import multiprocessing as mp
+import multiprocessing.pool
+
+logger = logging.getLogger(__name__)
+
+from mwcp import registry
+from mwcp.utils import logutil
+
+
+def initializer(parser_sources, default_source):
+    """Initializer function that runs at the beginning of each process creation."""
+    registry._sources = parser_sources  # Propagate registered parser information.
+    registry._default_source = default_source
+
+
+class TProcess(mp.Process):
+    """
+    Slighted modified subclass of :class:`multiprocessing.Process`.
+
+    Use this in place of ``Process`` to enable logging in the spawned process.
+    """
+
+    def __init__(self, group=None, target=None, name=None, args=(), kwargs=None):
+        kwargs = kwargs or {}
+        # NOTE: Forcing group to be None since BaseProcess asserts it to be None.
+        super(TProcess, self).__init__(group=None, target=target, name=name, args=args, kwargs=kwargs)
+        self.queue = logutil.mp_queue
+
+    def run(self):
+        logutil.setup_logging(queue=self.queue)
+        logger.debug("Setup logger in {}".format(mp.current_process().name))
+        super(TProcess, self).run()
+
+
+class TPool(mp.pool.Pool):
+    """
+    Version of :class:`multiprocessing.pool.Pool` that uses :class:`TProcess`.
+    """
+
+    Process = TProcess
+
+    def __init__(self, processes=None, maxtasksperchild=None):
+        """Overwrite to add initializer."""
+        super(TPool, self).__init__(
+            processes=processes,
+            maxtasksperchild=maxtasksperchild,
+            initializer=initializer,
+            initargs=(registry._sources, registry._default_source),
+        )
```

### Comparing `mwcp-3.8.0/mwcp/utils/pecon.py` & `mwcp-3.9.0/mwcp/utils/pecon.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,495 +1,495 @@
-"""
-pecon - PE file reCONstructor
-
-Usage:
-    >>> from mwcp.utils import pecon
-
-    # Create a PE object
-    >>> pe = pecon.PE()
-
-    # Fill in pe with known information (fields not provided will contain a default as defined in the PE constructor)
-    >>> pe.DosHeader.e_lfanew = 0x3211
-    >>> pe.OptionalHeader.SizeOfCode = 0x3141241
-    >>> pe.OptionalHeader.AddressOfEntryPoint = 0x43222
-    >>> pe.OptionalHeader.Subsystem = pecon.IMAGE_SUBSYSTEM_WINDOWS_GUI
-    # DataDirectory is a list of IMAGE_DATA_DIRECTORY structs.
-    # By default it contains the standard 16, which can be accessed with indexes or though helper attributes
-    # ("imports", "exports", etc)
-    # NOTE: While it would make more sense to call it "DataDirectories", we are trying to be
-    #       consistent with Microsoft's names.
-    >>> pe.OptionalHeader.DataDirectory.imports.VirtualAddress = 0x101
-    >>> pe.OptionalHeader.DataDirectory.imports.Size = 20
-    # Create pecon.Section() objects to fill in section information.
-    # (By default there are no sections.)
-    >>> pe.SectionTable.append(pecon.Section(Name='.text', VirtualSize=4, VirtualAddress=0x3422, data=b'blah'))
-
-    # Generate file data.
-    >>> pe_data = pe.build()
-    # To only build the header, you can tell it to avoid writing the section data.
-    >>> pe_data = pe.build(write_section_data=False)
-
-    # You can also modifiy fields in an already existing exe file.
-    >>> pe = pecon.PE(exe_data)
-    >>> pe.OptionalHeader.SizeOfCode = 0x3422
-    >>> pe_data = pe.build()
-
-
-"""
-
-import copy
-import io
-import logging
-
-logger = logging.getLogger(__name__)
-
-from mwcp.utils import construct
-from construct import this
-
-# Expose the constants users will need.
-from mwcp.utils.construct.windows_constants import *
-
-
-# Overwrite Container class to provide deepcopy functionality.
-class Container(construct.Container):
-
-    @classmethod
-    def from_container(cls, container_object):
-        """Factory method for converting an already existing Container object."""
-        _dict = {}
-        for key, value in container_object.items():
-            if isinstance(value, dict):
-                value = cls.from_container(value)
-            if isinstance(value, list):
-                for i in range(len(value)):
-                    # one level is all that is necessary for what we are doing.
-                    if isinstance(value[i], dict):
-                        value[i] = cls.from_container(value[i])
-            _dict[key] = value
-        return cls(_dict)
-
-    def __deepcopy__(self, memo):
-        _copy = Container()
-        for key, value in self.items():
-            _copy[key] = copy.deepcopy(value, memo)
-        return _copy
-
-
-class DataDirectories(construct.ListContainer):
-    """
-    A list of IMAGE_DATA_DIRECTORY entries
-
-    Provides convenience properties for accessing standard directories by name.
-
-    :param int size: Number of directory entries. defaults to the standard size of 16
-    """
-
-    def __init__(self, size=16):
-        super(DataDirectories, self).__init__()
-        for _ in range(size):
-            self.append(Container(VirtualAddress=0, Size=0))
-
-    def sizeof(self):
-        return construct.IMAGE_DATA_DIRECTORY.sizeof() * len(self)
-
-    # Provide convenience properties for accessing standard data directories.
-
-    @property
-    def exports(self):
-        return self[construct.DATA_DIR_INDEX_EXPORTS]
-
-    @exports.setter
-    def exports(self, value):
-        self[construct.DATA_DIR_INDEX_EXPORTS] = value
-
-    @property
-    def imports(self):
-        return self[construct.DATA_DIR_INDEX_IMPORTS]
-
-    @imports.setter
-    def imports(self, value):
-        self[construct.DATA_DIR_INDEX_IMPORTS] = value
-
-    @property
-    def resource(self):
-        return self[construct.DATA_DIR_INDEX_RESOURCE]
-
-    @resource.setter
-    def resource(self, value):
-        self[construct.DATA_DIR_INDEX_RESOURCE] = value
-
-    @property
-    def exception(self):
-        return self[construct.DATA_DIR_INDEX_EXCEPTION]
-
-    @exception.setter
-    def exception(self, value):
-        self[construct.DATA_DIR_INDEX_EXCEPTION] = value
-
-    @property
-    def certificate(self):
-        return self[construct.DATA_DIR_INDEX_CERTIFICATE]
-
-    @certificate.setter
-    def certificate(self, value):
-        self[construct.DATA_DIR_INDEX_CERTIFICATE] = value
-
-    @property
-    def base_reloc(self):
-        return self[construct.DATA_DIR_INDEX_BASE_RELOC]
-
-    @base_reloc.setter
-    def base_reloc(self, value):
-        self[construct.DATA_DIR_INDEX_BASE_RELOC] = value
-
-    @property
-    def debug(self):
-        return self[construct.DATA_DIR_INDEX_DEBUG]
-
-    @debug.setter
-    def debug(self, value):
-        self[construct.DATA_DIR_INDEX_DEBUG] = value
-
-    @property
-    def architecture(self):
-        return self[construct.DATA_DIR_INDEX_ARCHITECTURE]
-
-    @architecture.setter
-    def architecture(self, value):
-        self[construct.DATA_DIR_INDEX_ARCHITECTURE] = value
-
-    @property
-    def global_ptr(self):
-        return self[construct.DATA_DIR_INDEX_GLOBAL_PTR]
-
-    @global_ptr.setter
-    def global_ptr(self, value):
-        self[construct.DATA_DIR_INDEX_GLOBAL_PTR] = value
-
-    @property
-    def tls(self):
-        return self[construct.DATA_DIR_INDEX_TLS]
-
-    @tls.setter
-    def tls(self, value):
-        self[construct.DATA_DIR_INDEX_TLS] = value
-
-    @property
-    def load_config(self):
-        return self[construct.DATA_DIR_INDEX_LOAD_CONFIG]
-
-    @load_config.setter
-    def load_config(self, value):
-        self[construct.DATA_DIR_INDEX_LOAD_CONFIG] = value
-
-    @property
-    def bound_import(self):
-        return self[construct.DATA_DIR_INDEX_BOUND_IMPORT]
-
-    @bound_import.setter
-    def bound_import(self, value):
-        self[construct.DATA_DIR_INDEX_BOUND_IMPORT] = value
-
-    @property
-    def import_address(self):
-        return self[construct.DATA_DIR_INDEX_IMPORT_ADDRESS]
-
-    @import_address.setter
-    def import_address(self, value):
-        self[construct.DATA_DIR_INDEX_IMPORT_ADDRESS] = value
-
-    @property
-    def dely_import_descriptor(self):
-        return self[construct.DATA_DIR_INDEX_DELAY_IMPORT_DESCRIPTOR]
-
-    @dely_import_descriptor.setter
-    def dely_import_descriptor(self, value):
-        self[construct.DATA_DIR_INDEX_DELAY_IMPORT_DESCRIPTOR] = value
-
-    @property
-    def clr_header(self):
-        return self[construct.DATA_DIR_INDEX_CLR_HEADER]
-
-    @clr_header.setter
-    def clr_header(self, value):
-        self[construct.DATA_DIR_INDEX_CLR_HEADER] = value
-
-
-class Section(Container):
-    """
-    Container for IMAGE_SECTION_HEADER
-
-    (Provides defaults for non-filled values.)
-    """
-
-    def __init__(self, *args, **kw):
-        _section_header = {
-            'Name': '',
-            'VirtualSize': 0,
-            'VirtualAddress': 0,
-            'SizeOfRawData': 0,
-            'PointerToRawData': 0,
-            'PointerToRelocations': 0,
-            'PointerToLinenumbers': 0,
-            'NumberOfrelocations': 0,
-            'NumberOfLinenumbers': 0,
-            'Characteristics': [],
-            'data': '',
-        }
-        super(Section, self).__init__(_section_header)
-        for arg in args:
-            self.update(arg)
-        self.update(kw)
-
-
-class PE(Container):
-
-    def __init__(self, data=None, is_64bit=False):
-        """
-
-        :param data: Data from an existing PE file, if provided, this will be used as the base line.
-        :param is_64bit: Whether to make a 64 bit or 32 bit PE file. Defaults to 32 bit.
-            (NOTE: This is only applicable if not passing in data.)
-        """
-
-        super(PE, self).__init__()
-
-        if data:
-            # If user provided data, parse it and use it as a base point.
-            self._parse(data)
-            return
-
-        # Otherwise create a default pe.
-
-        _characteristics = [
-            construct.IMAGE_FILE_RELOCS_STRIPPED,
-            construct.IMAGE_FILE_EXECUTABLE_IMAGE,
-            construct.IMAGE_FILE_LINE_NUMS_STRIPPED,
-            construct.IMAGE_FILE_LOCAL_SYMS_STRIPPED,
-        ]
-
-        if is_64bit:
-            _magic = construct.IMAGE_NT_OPTIONAL_HDR64_MAGIC
-            _machine = construct.IMAGE_FILE_MACHINE_AMD64
-        else:
-            _magic = construct.IMAGE_NT_OPTIONAL_HDR32_MAGIC
-            _machine = construct.IMAGE_FILE_MACHINE_I386
-            _characteristics.append(construct.IMAGE_FILE_32BIT_MACHINE)
-
-        _dos_header = Container({
-            'e_magic': b'MZ',
-            'e_cblp': 0x90,
-            'e_cp': 0x03,
-            'e_crlc': 0,
-            'e_cparhdr': 4,
-            'e_mimalloc': 0,
-            'e_maxalloc': 0xffff,
-            'e_ss': 0,
-            'e_sp': 184,
-            'e_csum': 0,
-            'e_ip': 0,
-            'e_cs': 0,
-            'e_lfarlc': 64,
-            'e_ovno': 0,
-            'e_res1': b'\x00\x00\x00\x00\x00\x00\x00\x00',
-            'e_oemid': 0,
-            'e_oeminfo': 0,
-            'e_res2': b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00',
-            'e_lfanew': 224,
-        })
-
-        _data_directories = DataDirectories()
-
-        _optional_header = Container({
-            'Magic': _magic,
-            'MajorLinkerVersion': 1,
-            'MinorLinkerVersion': 71,
-            'SizeOfCode': 0,
-            'SizeOfInitializedData': 0,
-            'SizeOfUninitializedData': 0,
-            'AddressOfEntryPoint': 0,
-            'BaseOfCode': 0,
-            'BaseOfData': 0,
-            'ImageBase': 0,
-            'SectionAlignment': 4096,
-            'FileAlignment': 512,
-            'MajorOperatingSystemVersion': 1,
-            'MinorOperatingSystemVersion': 0,
-            'MajorImageVersion': 0,
-            'MinorImageVersion': 0,
-            'MajorSubsystemVersion': 5,
-            'MinorSubsystemVersion': 1,
-            'Win32VersionValue': 0,  # must be 0 (but I guess still allow them to change it)
-            'SizeOfImage': 0,
-            'SizeOfHeaders': 0,
-            'CheckSum': 0,
-            'Subsystem': construct.IMAGE_SUBSYSTEM_WINDOWS_CUI,
-            'DllCharacteristics': [],
-            'SizeOfStackReserve': 1048576,
-            'SizeOfStackCommit': 4096,
-            'SizeOfHeapReserve': 1048576,
-            'SizeOfHeapCommit': 4096,
-            'LoaderFlags': 0,
-            'NumberOfRvaAndSizes': _data_directories.sizeof(),
-            'DataDirectory': _data_directories,
-        })
-
-        _file_header = Container({
-            'Machine': _machine,
-            'NumberOfSections': 0,
-            'TimeDateStamp': 0,
-            'PointerToSymbolTable': 0,
-            'NumberOfSymbols': 0,
-            'SizeOfOptionalHeader': construct.IMAGE_OPTIONAL_HEADER.sizeof(**_optional_header),
-            'Characteristics': _characteristics,
-        })
-
-        self.DosHeader = Container(_dos_header)
-
-        # Default to "ret" opcode.
-        self.DosStub = b'\xc3'
-
-        self.NTHeaders = Container(
-            Signature=0x4550,   # b'PE\x00\x00'
-            FileHeader=Container(_file_header),
-            OptionalHeader=Container(_optional_header)
-        )
-
-        self.SectionTable = construct.ListContainer()
-
-    def _parse(self, data):
-        """
-        Parses data containing PE file and updates dictionary to reflect results.
-
-        :raises ConstructError: If provided data could not be parsed (ie. not a pe)
-        """
-        pe = construct.PEFILE_HEADER.parse(data)
-
-        # Convert Container classes to use ours, so we can deepcopy.
-        pe = Container.from_container(pe)
-
-        # Convert the FlagEnums into list of constants.
-        for section in pe.SectionTable:
-            if isinstance(section.Characteristics, dict):
-                section.Characteristics = [flag for flag, value in section.Characteristics.items() if value]
-            section.data = data[section.PointerToRawData:section.PointerToRawData + section.SizeOfRawData]
-        file_header = pe.NTHeaders.FileHeader
-        if isinstance(file_header.Characteristics, dict):
-            file_header.Characteristics = [
-                flag for flag, value in file_header.Characteristics.items() if value]
-        optional_header = pe.NTHeaders.OptionalHeader
-        if isinstance(optional_header.DllCharacteristics, dict):
-            optional_header.DllCharacteristics = [
-                flag for flag, value in optional_header.DllCharacteristics.items() if value]
-
-        self.update(pe)
-
-    def _fix_section(self, section):
-        """Fixes up section container for building."""
-        section_copy = copy.deepcopy(section)
-
-        # Formulate characteristics based on name if they weren't provided.
-        if not section_copy.Characteristics:
-            _characteristics = [construct.IMAGE_SCN_MEM_READ]
-            if section_copy.Name == u'.text':
-                _characteristics += [construct.IMAGE_SCN_CNT_CODE, construct.IMAGE_SCN_MEM_EXECUTE]
-            else:
-                _characteristics += [construct.IMAGE_SCN_CNT_INITIALIZED_DATA]
-            if section_copy.Name == u'.data':
-                _characteristics += [construct.IMAGE_SCN_MEM_WRITE]
-            if section_copy.Name == u'.reloc':
-                _characteristics += [construct.IMAGE_SCN_MEM_DISCARDABLE]
-            section_copy.Characteristics = _characteristics
-
-        # FlagEnums must be a dictionary.
-        if isinstance(section_copy.Characteristics, list):
-            section_copy.Characteristics = {flag: True for flag in section_copy.Characteristics}
-
-        # Fix up data to be consistent.
-        data_size = max(section_copy.SizeOfRawData, len(section_copy.data))
-        section_copy.SizeOfRawData = data_size
-        section_copy.data = section_copy.data.ljust(data_size, b'\x00')[:data_size]
-
-        return section_copy
-
-    def build(self, write_section_data=True):
-        """
-        Generate PE file.
-
-        :param write_section_data: Whether to include section data (otherwise only the headers are written)
-
-        :returns bytes: PE file data.
-
-        :raises ValueError: If set attributes contains contradicting data.
-        """
-        pe = copy.deepcopy(self)
-
-        # Pad dos stub to match e_lfanew. (Warn if dos stub is too large.)
-        dos_stub_size = pe.DosHeader.e_lfanew - construct.IMAGE_DOS_HEADER.sizeof()
-        if len(pe.DosStub) > dos_stub_size:
-            raise ValueError(
-                'Provided DOS stub is too large for provided DosHeader.e_lfanew: {}'.format(pe.DosHeader.e_lfanew))
-        pe.DosStub = pe.DosStub.ljust(dos_stub_size, b'\x00')
-
-        # Fix file header.
-        file_header = pe.NTHeaders.FileHeader
-        if file_header.NumberOfSections and file_header.NumberOfSections != len(pe.SectionTable):
-            logger.debug(
-                'NTHeaders.FileHeader.NumberOfSections does not equal the number of sections provided. Auto-adjusting.')
-        file_header.NumberOfSections = len(pe.SectionTable)
-        if isinstance(file_header.Characteristics, list):
-            file_header.Characteristics = {flag: True for flag in file_header.Characteristics}
-
-        # Fix sections.
-        pe.SectionTable = list(map(self._fix_section, pe.SectionTable))
-
-        # Fix optional header.
-        optional_header = pe.NTHeaders.OptionalHeader
-        number_of_rva_and_sizes = len(optional_header.DataDirectory)
-        optional_header.NumberOfRvaAndSizes = number_of_rva_and_sizes
-        file_header.SizeOfOptionalHeader = construct.IMAGE_OPTIONAL_HEADER.sizeof(**optional_header)
-        if isinstance(optional_header.DllCharacteristics, list):
-            optional_header.DllCharacteristics = {flag: True for flag in optional_header.DllCharacteristics}
-
-        # SizeOfHeaders is the sum of the headers rounded by FileAlignment.
-        headers_size = construct.PEFILE_HEADER.sizeof(**pe)
-        file_alignment = optional_header.FileAlignment - 1
-        headers_size = (headers_size + file_alignment) & 0xffffffff - file_alignment
-        optional_header.SizeOfHeaders = headers_size
-
-        pe_data = construct.PEFILE_HEADER.build(pe)
-
-        # Add section data.
-        if write_section_data:
-            stream = io.BytesIO(pe_data)
-            spec = construct.Pointer(this.PointerToRawData, construct.Bytes(this.SizeOfRawData))
-            for section in pe.SectionTable:
-                spec.build_stream(section.data, stream, **section)
-            pe_data = stream.getvalue()
-
-        return pe_data
-
-    # Provide convenience properties for accessing NTHeader components.
-
-    @property
-    def OptionalHeader(self):
-        return self.NTHeaders.OptionalHeader
-
-    @OptionalHeader.setter
-    def OptionalHeader(self, value):
-        self.NTHeaders.OptionalHeader = value
-
-    @property
-    def FileHeader(self):
-        return self.NTHeaders.FileHeader
-
-    @FileHeader.setter
-    def FileHeader(self, value):
-        self.NTHeaders.FileHeader = value
-
-    @property
-    def Signature(self):
-        return self.NTHeaders.Signature
-
-    @Signature.setter
-    def Signature(self, value):
-        self.NTHeaders.Signature = value
+"""
+pecon - PE file reCONstructor
+
+Usage:
+    >>> from mwcp.utils import pecon
+
+    # Create a PE object
+    >>> pe = pecon.PE()
+
+    # Fill in pe with known information (fields not provided will contain a default as defined in the PE constructor)
+    >>> pe.DosHeader.e_lfanew = 0x3211
+    >>> pe.OptionalHeader.SizeOfCode = 0x3141241
+    >>> pe.OptionalHeader.AddressOfEntryPoint = 0x43222
+    >>> pe.OptionalHeader.Subsystem = pecon.IMAGE_SUBSYSTEM_WINDOWS_GUI
+    # DataDirectory is a list of IMAGE_DATA_DIRECTORY structs.
+    # By default it contains the standard 16, which can be accessed with indexes or though helper attributes
+    # ("imports", "exports", etc)
+    # NOTE: While it would make more sense to call it "DataDirectories", we are trying to be
+    #       consistent with Microsoft's names.
+    >>> pe.OptionalHeader.DataDirectory.imports.VirtualAddress = 0x101
+    >>> pe.OptionalHeader.DataDirectory.imports.Size = 20
+    # Create pecon.Section() objects to fill in section information.
+    # (By default there are no sections.)
+    >>> pe.SectionTable.append(pecon.Section(Name='.text', VirtualSize=4, VirtualAddress=0x3422, data=b'blah'))
+
+    # Generate file data.
+    >>> pe_data = pe.build()
+    # To only build the header, you can tell it to avoid writing the section data.
+    >>> pe_data = pe.build(write_section_data=False)
+
+    # You can also modifiy fields in an already existing exe file.
+    >>> pe = pecon.PE(exe_data)
+    >>> pe.OptionalHeader.SizeOfCode = 0x3422
+    >>> pe_data = pe.build()
+
+
+"""
+
+import copy
+import io
+import logging
+
+logger = logging.getLogger(__name__)
+
+from mwcp.utils import construct
+from construct import this
+
+# Expose the constants users will need.
+from mwcp.utils.construct.windows_constants import *
+
+
+# Overwrite Container class to provide deepcopy functionality.
+class Container(construct.Container):
+
+    @classmethod
+    def from_container(cls, container_object):
+        """Factory method for converting an already existing Container object."""
+        _dict = {}
+        for key, value in container_object.items():
+            if isinstance(value, dict):
+                value = cls.from_container(value)
+            if isinstance(value, list):
+                for i in range(len(value)):
+                    # one level is all that is necessary for what we are doing.
+                    if isinstance(value[i], dict):
+                        value[i] = cls.from_container(value[i])
+            _dict[key] = value
+        return cls(_dict)
+
+    def __deepcopy__(self, memo):
+        _copy = Container()
+        for key, value in self.items():
+            _copy[key] = copy.deepcopy(value, memo)
+        return _copy
+
+
+class DataDirectories(construct.ListContainer):
+    """
+    A list of IMAGE_DATA_DIRECTORY entries
+
+    Provides convenience properties for accessing standard directories by name.
+
+    :param int size: Number of directory entries. defaults to the standard size of 16
+    """
+
+    def __init__(self, size=16):
+        super(DataDirectories, self).__init__()
+        for _ in range(size):
+            self.append(Container(VirtualAddress=0, Size=0))
+
+    def sizeof(self):
+        return construct.IMAGE_DATA_DIRECTORY.sizeof() * len(self)
+
+    # Provide convenience properties for accessing standard data directories.
+
+    @property
+    def exports(self):
+        return self[construct.DATA_DIR_INDEX_EXPORTS]
+
+    @exports.setter
+    def exports(self, value):
+        self[construct.DATA_DIR_INDEX_EXPORTS] = value
+
+    @property
+    def imports(self):
+        return self[construct.DATA_DIR_INDEX_IMPORTS]
+
+    @imports.setter
+    def imports(self, value):
+        self[construct.DATA_DIR_INDEX_IMPORTS] = value
+
+    @property
+    def resource(self):
+        return self[construct.DATA_DIR_INDEX_RESOURCE]
+
+    @resource.setter
+    def resource(self, value):
+        self[construct.DATA_DIR_INDEX_RESOURCE] = value
+
+    @property
+    def exception(self):
+        return self[construct.DATA_DIR_INDEX_EXCEPTION]
+
+    @exception.setter
+    def exception(self, value):
+        self[construct.DATA_DIR_INDEX_EXCEPTION] = value
+
+    @property
+    def certificate(self):
+        return self[construct.DATA_DIR_INDEX_CERTIFICATE]
+
+    @certificate.setter
+    def certificate(self, value):
+        self[construct.DATA_DIR_INDEX_CERTIFICATE] = value
+
+    @property
+    def base_reloc(self):
+        return self[construct.DATA_DIR_INDEX_BASE_RELOC]
+
+    @base_reloc.setter
+    def base_reloc(self, value):
+        self[construct.DATA_DIR_INDEX_BASE_RELOC] = value
+
+    @property
+    def debug(self):
+        return self[construct.DATA_DIR_INDEX_DEBUG]
+
+    @debug.setter
+    def debug(self, value):
+        self[construct.DATA_DIR_INDEX_DEBUG] = value
+
+    @property
+    def architecture(self):
+        return self[construct.DATA_DIR_INDEX_ARCHITECTURE]
+
+    @architecture.setter
+    def architecture(self, value):
+        self[construct.DATA_DIR_INDEX_ARCHITECTURE] = value
+
+    @property
+    def global_ptr(self):
+        return self[construct.DATA_DIR_INDEX_GLOBAL_PTR]
+
+    @global_ptr.setter
+    def global_ptr(self, value):
+        self[construct.DATA_DIR_INDEX_GLOBAL_PTR] = value
+
+    @property
+    def tls(self):
+        return self[construct.DATA_DIR_INDEX_TLS]
+
+    @tls.setter
+    def tls(self, value):
+        self[construct.DATA_DIR_INDEX_TLS] = value
+
+    @property
+    def load_config(self):
+        return self[construct.DATA_DIR_INDEX_LOAD_CONFIG]
+
+    @load_config.setter
+    def load_config(self, value):
+        self[construct.DATA_DIR_INDEX_LOAD_CONFIG] = value
+
+    @property
+    def bound_import(self):
+        return self[construct.DATA_DIR_INDEX_BOUND_IMPORT]
+
+    @bound_import.setter
+    def bound_import(self, value):
+        self[construct.DATA_DIR_INDEX_BOUND_IMPORT] = value
+
+    @property
+    def import_address(self):
+        return self[construct.DATA_DIR_INDEX_IMPORT_ADDRESS]
+
+    @import_address.setter
+    def import_address(self, value):
+        self[construct.DATA_DIR_INDEX_IMPORT_ADDRESS] = value
+
+    @property
+    def dely_import_descriptor(self):
+        return self[construct.DATA_DIR_INDEX_DELAY_IMPORT_DESCRIPTOR]
+
+    @dely_import_descriptor.setter
+    def dely_import_descriptor(self, value):
+        self[construct.DATA_DIR_INDEX_DELAY_IMPORT_DESCRIPTOR] = value
+
+    @property
+    def clr_header(self):
+        return self[construct.DATA_DIR_INDEX_CLR_HEADER]
+
+    @clr_header.setter
+    def clr_header(self, value):
+        self[construct.DATA_DIR_INDEX_CLR_HEADER] = value
+
+
+class Section(Container):
+    """
+    Container for IMAGE_SECTION_HEADER
+
+    (Provides defaults for non-filled values.)
+    """
+
+    def __init__(self, *args, **kw):
+        _section_header = {
+            'Name': '',
+            'VirtualSize': 0,
+            'VirtualAddress': 0,
+            'SizeOfRawData': 0,
+            'PointerToRawData': 0,
+            'PointerToRelocations': 0,
+            'PointerToLinenumbers': 0,
+            'NumberOfrelocations': 0,
+            'NumberOfLinenumbers': 0,
+            'Characteristics': [],
+            'data': '',
+        }
+        super(Section, self).__init__(_section_header)
+        for arg in args:
+            self.update(arg)
+        self.update(kw)
+
+
+class PE(Container):
+
+    def __init__(self, data=None, is_64bit=False):
+        """
+
+        :param data: Data from an existing PE file, if provided, this will be used as the base line.
+        :param is_64bit: Whether to make a 64 bit or 32 bit PE file. Defaults to 32 bit.
+            (NOTE: This is only applicable if not passing in data.)
+        """
+
+        super(PE, self).__init__()
+
+        if data:
+            # If user provided data, parse it and use it as a base point.
+            self._parse(data)
+            return
+
+        # Otherwise create a default pe.
+
+        _characteristics = [
+            construct.IMAGE_FILE_RELOCS_STRIPPED,
+            construct.IMAGE_FILE_EXECUTABLE_IMAGE,
+            construct.IMAGE_FILE_LINE_NUMS_STRIPPED,
+            construct.IMAGE_FILE_LOCAL_SYMS_STRIPPED,
+        ]
+
+        if is_64bit:
+            _magic = construct.IMAGE_NT_OPTIONAL_HDR64_MAGIC
+            _machine = construct.IMAGE_FILE_MACHINE_AMD64
+        else:
+            _magic = construct.IMAGE_NT_OPTIONAL_HDR32_MAGIC
+            _machine = construct.IMAGE_FILE_MACHINE_I386
+            _characteristics.append(construct.IMAGE_FILE_32BIT_MACHINE)
+
+        _dos_header = Container({
+            'e_magic': b'MZ',
+            'e_cblp': 0x90,
+            'e_cp': 0x03,
+            'e_crlc': 0,
+            'e_cparhdr': 4,
+            'e_mimalloc': 0,
+            'e_maxalloc': 0xffff,
+            'e_ss': 0,
+            'e_sp': 184,
+            'e_csum': 0,
+            'e_ip': 0,
+            'e_cs': 0,
+            'e_lfarlc': 64,
+            'e_ovno': 0,
+            'e_res1': b'\x00\x00\x00\x00\x00\x00\x00\x00',
+            'e_oemid': 0,
+            'e_oeminfo': 0,
+            'e_res2': b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00',
+            'e_lfanew': 224,
+        })
+
+        _data_directories = DataDirectories()
+
+        _optional_header = Container({
+            'Magic': _magic,
+            'MajorLinkerVersion': 1,
+            'MinorLinkerVersion': 71,
+            'SizeOfCode': 0,
+            'SizeOfInitializedData': 0,
+            'SizeOfUninitializedData': 0,
+            'AddressOfEntryPoint': 0,
+            'BaseOfCode': 0,
+            'BaseOfData': 0,
+            'ImageBase': 0,
+            'SectionAlignment': 4096,
+            'FileAlignment': 512,
+            'MajorOperatingSystemVersion': 1,
+            'MinorOperatingSystemVersion': 0,
+            'MajorImageVersion': 0,
+            'MinorImageVersion': 0,
+            'MajorSubsystemVersion': 5,
+            'MinorSubsystemVersion': 1,
+            'Win32VersionValue': 0,  # must be 0 (but I guess still allow them to change it)
+            'SizeOfImage': 0,
+            'SizeOfHeaders': 0,
+            'CheckSum': 0,
+            'Subsystem': construct.IMAGE_SUBSYSTEM_WINDOWS_CUI,
+            'DllCharacteristics': [],
+            'SizeOfStackReserve': 1048576,
+            'SizeOfStackCommit': 4096,
+            'SizeOfHeapReserve': 1048576,
+            'SizeOfHeapCommit': 4096,
+            'LoaderFlags': 0,
+            'NumberOfRvaAndSizes': _data_directories.sizeof(),
+            'DataDirectory': _data_directories,
+        })
+
+        _file_header = Container({
+            'Machine': _machine,
+            'NumberOfSections': 0,
+            'TimeDateStamp': 0,
+            'PointerToSymbolTable': 0,
+            'NumberOfSymbols': 0,
+            'SizeOfOptionalHeader': construct.IMAGE_OPTIONAL_HEADER.sizeof(**_optional_header),
+            'Characteristics': _characteristics,
+        })
+
+        self.DosHeader = Container(_dos_header)
+
+        # Default to "ret" opcode.
+        self.DosStub = b'\xc3'
+
+        self.NTHeaders = Container(
+            Signature=0x4550,   # b'PE\x00\x00'
+            FileHeader=Container(_file_header),
+            OptionalHeader=Container(_optional_header)
+        )
+
+        self.SectionTable = construct.ListContainer()
+
+    def _parse(self, data):
+        """
+        Parses data containing PE file and updates dictionary to reflect results.
+
+        :raises ConstructError: If provided data could not be parsed (ie. not a pe)
+        """
+        pe = construct.PEFILE_HEADER.parse(data)
+
+        # Convert Container classes to use ours, so we can deepcopy.
+        pe = Container.from_container(pe)
+
+        # Convert the FlagEnums into list of constants.
+        for section in pe.SectionTable:
+            if isinstance(section.Characteristics, dict):
+                section.Characteristics = [flag for flag, value in section.Characteristics.items() if value]
+            section.data = data[section.PointerToRawData:section.PointerToRawData + section.SizeOfRawData]
+        file_header = pe.NTHeaders.FileHeader
+        if isinstance(file_header.Characteristics, dict):
+            file_header.Characteristics = [
+                flag for flag, value in file_header.Characteristics.items() if value]
+        optional_header = pe.NTHeaders.OptionalHeader
+        if isinstance(optional_header.DllCharacteristics, dict):
+            optional_header.DllCharacteristics = [
+                flag for flag, value in optional_header.DllCharacteristics.items() if value]
+
+        self.update(pe)
+
+    def _fix_section(self, section):
+        """Fixes up section container for building."""
+        section_copy = copy.deepcopy(section)
+
+        # Formulate characteristics based on name if they weren't provided.
+        if not section_copy.Characteristics:
+            _characteristics = [construct.IMAGE_SCN_MEM_READ]
+            if section_copy.Name == u'.text':
+                _characteristics += [construct.IMAGE_SCN_CNT_CODE, construct.IMAGE_SCN_MEM_EXECUTE]
+            else:
+                _characteristics += [construct.IMAGE_SCN_CNT_INITIALIZED_DATA]
+            if section_copy.Name == u'.data':
+                _characteristics += [construct.IMAGE_SCN_MEM_WRITE]
+            if section_copy.Name == u'.reloc':
+                _characteristics += [construct.IMAGE_SCN_MEM_DISCARDABLE]
+            section_copy.Characteristics = _characteristics
+
+        # FlagEnums must be a dictionary.
+        if isinstance(section_copy.Characteristics, list):
+            section_copy.Characteristics = {flag: True for flag in section_copy.Characteristics}
+
+        # Fix up data to be consistent.
+        data_size = max(section_copy.SizeOfRawData, len(section_copy.data))
+        section_copy.SizeOfRawData = data_size
+        section_copy.data = section_copy.data.ljust(data_size, b'\x00')[:data_size]
+
+        return section_copy
+
+    def build(self, write_section_data=True):
+        """
+        Generate PE file.
+
+        :param write_section_data: Whether to include section data (otherwise only the headers are written)
+
+        :returns bytes: PE file data.
+
+        :raises ValueError: If set attributes contains contradicting data.
+        """
+        pe = copy.deepcopy(self)
+
+        # Pad dos stub to match e_lfanew. (Warn if dos stub is too large.)
+        dos_stub_size = pe.DosHeader.e_lfanew - construct.IMAGE_DOS_HEADER.sizeof()
+        if len(pe.DosStub) > dos_stub_size:
+            raise ValueError(
+                'Provided DOS stub is too large for provided DosHeader.e_lfanew: {}'.format(pe.DosHeader.e_lfanew))
+        pe.DosStub = pe.DosStub.ljust(dos_stub_size, b'\x00')
+
+        # Fix file header.
+        file_header = pe.NTHeaders.FileHeader
+        if file_header.NumberOfSections and file_header.NumberOfSections != len(pe.SectionTable):
+            logger.debug(
+                'NTHeaders.FileHeader.NumberOfSections does not equal the number of sections provided. Auto-adjusting.')
+        file_header.NumberOfSections = len(pe.SectionTable)
+        if isinstance(file_header.Characteristics, list):
+            file_header.Characteristics = {flag: True for flag in file_header.Characteristics}
+
+        # Fix sections.
+        pe.SectionTable = list(map(self._fix_section, pe.SectionTable))
+
+        # Fix optional header.
+        optional_header = pe.NTHeaders.OptionalHeader
+        number_of_rva_and_sizes = len(optional_header.DataDirectory)
+        optional_header.NumberOfRvaAndSizes = number_of_rva_and_sizes
+        file_header.SizeOfOptionalHeader = construct.IMAGE_OPTIONAL_HEADER.sizeof(**optional_header)
+        if isinstance(optional_header.DllCharacteristics, list):
+            optional_header.DllCharacteristics = {flag: True for flag in optional_header.DllCharacteristics}
+
+        # SizeOfHeaders is the sum of the headers rounded by FileAlignment.
+        headers_size = construct.PEFILE_HEADER.sizeof(**pe)
+        file_alignment = optional_header.FileAlignment - 1
+        headers_size = (headers_size + file_alignment) & 0xffffffff - file_alignment
+        optional_header.SizeOfHeaders = headers_size
+
+        pe_data = construct.PEFILE_HEADER.build(pe)
+
+        # Add section data.
+        if write_section_data:
+            stream = io.BytesIO(pe_data)
+            spec = construct.Pointer(this.PointerToRawData, construct.Bytes(this.SizeOfRawData))
+            for section in pe.SectionTable:
+                spec.build_stream(section.data, stream, **section)
+            pe_data = stream.getvalue()
+
+        return pe_data
+
+    # Provide convenience properties for accessing NTHeader components.
+
+    @property
+    def OptionalHeader(self):
+        return self.NTHeaders.OptionalHeader
+
+    @OptionalHeader.setter
+    def OptionalHeader(self, value):
+        self.NTHeaders.OptionalHeader = value
+
+    @property
+    def FileHeader(self):
+        return self.NTHeaders.FileHeader
+
+    @FileHeader.setter
+    def FileHeader(self, value):
+        self.NTHeaders.FileHeader = value
+
+    @property
+    def Signature(self):
+        return self.NTHeaders.Signature
+
+    @Signature.setter
+    def Signature(self, value):
+        self.NTHeaders.Signature = value
```

### Comparing `mwcp-3.8.0/mwcp/utils/pefileutils.py` & `mwcp-3.9.0/mwcp/utils/pefileutils.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,742 +1,742 @@
-"""
-Description: Utility for generic, repeated functions. Expandable as needed
-python version: 2.7.8
-"""
-
-import logging
-from pathlib import Path
-from typing import List, Optional
-
-import pefile
-
-logger = logging.getLogger(__name__)
-
-
-def obtain_pe(file_data):
-    """
-    Given file data, create a pefile.PE object from the data.
-
-    :param file_data: Input PE file data
-
-    :return: A pefile.PE object or None
-    """
-    if not file_data:
-        return None
-    try:
-        return pefile.PE(data=file_data)
-    except pefile.PEFormatError as e:
-        logger.debug("A pefile.PE object on the file data could not be created: {}".format(e))
-        return None
-
-
-def obtain_section(section_name, pe=None, file_data=None):
-    """
-    Obtain the section obtain for a specficied PE section of a file.
-
-    :param section_name: The name of the section from which to extract data.
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: The PE secton object, or None.
-    """
-    if isinstance(section_name, str):
-        section_name = section_name.encode()
-
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        for section in pe.sections:
-            if section.Name.rstrip(b"\0") == section_name:
-                return section
-        return None
-    else:
-        return None
-
-
-def obtain_section_data(section_name, pe=None, file_data=None, min_size=0) -> Optional[bytes]:
-    """
-    Obtain the data in a specified PE section of a file.
-
-    :param section_name: The name of the section from which to extract data.
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-    :param min_size: The minimum acceptable size for the section_data
-
-    :return: The PE section data, or None.
-    """
-
-    if isinstance(section_name, str):
-        section_name = section_name.encode()
-
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        section = obtain_section(section_name, pe)
-        if section:
-            section_data = section.get_data()
-            if len(section_data) > min_size:
-                return section_data
-            return None
-        return None
-    else:
-        return None
-
-
-def check_section(section_name, pe=None, file_data=None):
-    """
-    Check if a specified PE section exists in a file.
-
-    :param section_name: The name of the section from which to extract data.
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: True if the section name is observed, False if it is not.
-    """
-    if isinstance(section_name, str):
-        section_name = section_name.encode()
-
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        for section in pe.sections:
-            if section.Name.rstrip(b"\0") == section_name:
-                return True
-        return False
-    return False
-
-
-def obtain_physical_offset(mem_offset, pe=None, file_data=None):
-    """
-    For an PE file, convert a provided memory offset to a raw offset.
-
-    :param mem_offset: The memory offset to convert to a raw offset
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: Raw offset, or None.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        rva = mem_offset - pe.OPTIONAL_HEADER.ImageBase
-        return pe.get_physical_by_rva(rva)
-    else:
-        return None
-
-
-def obtain_memory_offset(raw_offset, pe=None, file_data=None):
-    """
-    For an PE file, convert a provided raw offset to a memory offset.
-
-    :param raw_offset: The raw offset to convert to a memory offset
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: Memory offset, or None.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        return pe.OPTIONAL_HEADER.ImageBase + pe.get_rva_from_offset(raw_offset)
-    else:
-        return None
-
-
-def obtain_physical_offset_x64(rel_loc, inst_end_raw, pe=None, file_data=None):
-    """
-    For a 64-bit PE file, pointers to data elements are relative to the end of the assembly instruction. Therefore,
-    given a location (rel_loc) relative to the end of an instruction (inst_end_raw), convert the end instruction
-    address to a memory offset, add that value to the relative location of the data, and convert that to a raw
-    offset.
-
-    :param rel_loc: Location of data element relative to the end of the instruction address in inst_end_raw
-    :param inst_end_raw: End of an instruction address referencing the data for rel_loc
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: Raw offset for the data, or None.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        inst_end_mem = obtain_memory_offset(inst_end_raw, pe=pe)
-        # Obtain the memory location of the data and convert it to a physical offset
-        mem_loc = rel_loc + inst_end_mem
-        return obtain_physical_offset(mem_loc, pe=pe)
-    else:
-        return None
-
-
-def obtain_exports_list(pe=None, file_data=None) -> List[bytes]:
-    """
-    Obtain a list of export names for the input PE file.
-
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: A list of export names, or None.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        try:
-            return [export.name for export in pe.DIRECTORY_ENTRY_EXPORT.symbols]
-        except AttributeError:
-            return []
-    else:
-        return []
-
-
-def check_export(export_name, pe=None, file_data=None):
-    """
-    Check if the provided export name is in the list of exports for the file.
-
-    :param export_name: Target export name
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return bool: Indicating if provided export name is in file exports
-    """
-    if isinstance(export_name, str):
-        export_name = export_name.encode()
-    exports = obtain_exports_list(pe, file_data)
-    return export_name in exports
-
-
-def obtain_imported_dlls(pe=None, file_data=None) -> Optional[List[bytes]]:
-    """
-    Obtain a list of imported DLL names for the input PE file.
-
-    :param pe: pefile.PE object, or None by default
-    :param file_data: file data from which to create a pefile.PE object, or None by default
-
-    :return: List of imported DLLs, or None
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        try:
-            return [imp.dll for imp in pe.DIRECTORY_ENTRY_IMPORT]
-        except AttributeError:
-            return None
-    else:
-        return None
-
-
-def obtain_imports_list(dll_name, pe=None, file_data=None):
-    """
-    Obtain a list of imports from a specified DLL for the input PE file.
-
-    :param dll_name: Name of the DLL to obtain imports from
-    :param pe: pefile.PE object, or None by default
-    :param file_data: file data from which to create a pefile.PE object, or None by default
-
-    :return: List of imports from the specified DLL, or None
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        try:
-            for imp in pe.DIRECTORY_ENTRY_IMPORT:
-                if imp.dll.lower() == dll_name.lower():
-                    return [imp_func.name for imp_func in imp.imports]
-        except AttributeError:
-            return None
-    else:
-        return None
-
-
-def is_imported(dll_name, func_name, pe=None, file_data=None):
-    """
-    Determines if a specified function is imported by the file.
-
-    :param dll_name: Name of the DLL containing the imported function in question
-    :param func_name: Name of the imported function within dll_name
-    :param pe: pefile.PE object, or None by default
-    :param file_data: file data from which to create a pefile.PE object, or None by default
-
-    :return: True if function is imported
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        imported_funcs = obtain_imports_list(dll_name, pe=pe)
-        if imported_funcs:
-            for func in imported_funcs:
-                if func.lower() == func_name.lower():
-                    return True
-    else:
-        return None
-
-
-def obtain_file_ext(pe=None, file_data=None):
-    """
-    Attempt to return the appropriate file extension for the input PE file. Use .bin as the default if it cannot be
-    recovered or None if the file is not a PE file.
-
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: The appropriate file extension for the PE file, .bin, or None.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        if pe.is_driver():
-            return ".sys"
-        elif pe.is_exe():
-            return ".exe"
-        elif pe.is_dll():
-            return ".dll"
-        else:
-            return ".bin"
-    else:
-        return None
-
-
-def is_64bit(pe=None, file_data=None):
-    """
-    Evaluate whether an input pefile.PE object or file data is 64-bit.
-
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: True if 64-bit, False if 32-bit, None if could not be determined.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        if pe.PE_TYPE == pefile.OPTIONAL_HEADER_MAGIC_PE_PLUS:
-            return True
-        elif pe.PE_TYPE == pefile.OPTIONAL_HEADER_MAGIC_PE:
-            return False
-        else:
-            logger.debug("The architecture type for the file could not be determined.")
-    return None
-
-
-def obtain_architecture_string(pe=None, file_data=None, bitterm=True):
-    """
-    Obtain an architecture type string for the input PE file. Allow the bitterm variable to determine if the string
-    should be in the format of "32-bit" (default) or "x86" (must specify False). Return "Undetermined" if neither.
-
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-    :param bitterm: Flag to determine return string type
-
-    :return: A string representing the architecture for the input PE file.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        is64 = is_64bit(pe=pe)
-        if is64:
-            if bitterm:
-                return "64-bit"
-            else:
-                return "x64"
-        # Specfically check if the return value is False, because that indicates 32-bit, None indicates undetermined.
-        elif is64 is False:
-            if bitterm:
-                return "32-bit"
-            else:
-                return "x86"
-        else:
-            return "Undetermined"
-    else:
-        return None
-
-
-def _obtain_exif_fname(pe):
-    """
-    Obtain the filename from the pe.FileInfo listing of exif metadata.
-
-    :param pe: pefile.PE object
-
-    :return:
-    """
-    try:
-        for file_info in pe.FileInfo:
-            for entry in file_info:
-                if entry.Key == b"StringFileInfo":
-                    for string_table in entry.StringTable:
-                        try:
-                            return string_table.entries[b"OriginalFilename"]
-                        except KeyError:
-                            continue
-    except AttributeError:
-        return None
-
-
-def _obtain_exportdir_fname(pe):
-    """
-    Obtain the filename from the export directory of the pefile.PE object.
-
-    :param pe: pefile.PE object
-
-    :return: The filename from the export directory, or None.
-    """
-    try:
-        filename = pe.get_string_at_rva(pe.DIRECTORY_ENTRY_EXPORT.struct.Name)
-        return filename
-    except AttributeError:
-        return None
-
-
-def obtain_original_filename(def_stub, pe=None, file_data=None, use_arch=False, ext=".bin"):
-    """
-    Attempt to obtain the original filename, either from the export directory or the pe.FileInfo, of the input file.
-    If the filename cannot be recovered from either of those locations, append the applicable architecture string and
-    file extension to the default stub and return that value. If no pefile.PE object is provided or can be created
-    from the provided file data, return the default stub appended with ".bin".
-
-    :param def_stub: Default filename stub, sans extension, to utilize if the filename cannot be recovered.
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-    :param use_arch: Flag indicating if the file architecture should be included in the name, False by default.
-    :param ext: Extension to default to if it could not be determined. (defaults to ".bin")
-
-    :return: The recovered filename from the pe metadata or a generated filename using def_stub.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        ext = obtain_file_ext(pe=pe)
-        arch = obtain_architecture_string(pe=pe, bitterm=False)
-        filename = _obtain_exportdir_fname(pe) or _obtain_exif_fname(pe)
-        if isinstance(filename, bytes):
-            filename = filename.decode("ascii", "backslashreplace")
-        if filename:
-            filename = Path(filename)
-            if use_arch:
-                base, ext = filename.stem, filename.suffix
-                filename = base + "_" + arch + ext
-            return str(filename)
-        else:
-            return def_stub + "_" + arch + ext
-    else:
-        return def_stub + ext
-
-
-def get_overlay_data_start_offset(pe, include_data_directories=True):
-    """
-    Get the offset of data appended to the file and not contained within
-    the area described in the headers.
-
-    MODIFICATIONS:
-        - Use include_data_directories parameter to allow user to specify if they
-          want to include the data directories in the calculation.
-        - Include SECURITY table.
-    """
-
-    largest_offset_and_size = (0, 0)
-
-    def update_if_sum_is_larger_and_within_file(offset_and_size, file_size=len(pe.__data__)):
-        if sum(offset_and_size) <= file_size and sum(offset_and_size) > sum(largest_offset_and_size):
-            return offset_and_size
-        return largest_offset_and_size
-
-    if hasattr(pe, "OPTIONAL_HEADER"):
-        largest_offset_and_size = update_if_sum_is_larger_and_within_file(
-            (pe.OPTIONAL_HEADER.get_file_offset(), pe.FILE_HEADER.SizeOfOptionalHeader)
-        )
-
-    for section in pe.sections:
-        largest_offset_and_size = update_if_sum_is_larger_and_within_file(
-            (section.PointerToRawData, section.SizeOfRawData)
-        )
-
-    if include_data_directories:
-        for idx, directory in enumerate(pe.OPTIONAL_HEADER.DATA_DIRECTORY):
-            try:
-                # Security directory is special in that its VirtualAddress is actually a file offset.
-                if idx == pefile.DIRECTORY_ENTRY["IMAGE_DIRECTORY_ENTRY_SECURITY"]:
-                    largest_offset_and_size = update_if_sum_is_larger_and_within_file(
-                        (directory.VirtualAddress, directory.Size)
-                    )
-                else:
-                    largest_offset_and_size = update_if_sum_is_larger_and_within_file(
-                        (pe.get_offset_from_rva(directory.VirtualAddress), directory.Size)
-                    )
-            # Ignore directories with RVA out of file
-            except pefile.PEFormatError:
-                continue
-
-    if len(pe.__data__) > sum(largest_offset_and_size):
-        return sum(largest_offset_and_size)
-
-    return None
-
-
-def get_overlay(pe, include_data_directories=True):
-    """
-    Get the data appended to the file and not contained within the area described in the headers.
-
-    MODIFICATIONS:
-        - Use include_data_directories parameter to allow user to specify if they
-          want to include the data directories in the calculation.
-    """
-
-    overlay_data_offset = get_overlay_data_start_offset(pe, include_data_directories=include_data_directories)
-
-    if overlay_data_offset is not None:
-        return pe.__data__[overlay_data_offset:]
-
-    return None
-
-
-def trim(pe, include_data_directories=True):
-    """
-    Return the just data defined by the PE headers, removing any overlayed data.
-
-    MODIFICATIONS:
-        - Use include_data_directories parameter to allow user to specify if they
-          want to include the data directories in the calculation.
-    """
-
-    overlay_data_offset = get_overlay_data_start_offset(pe, include_data_directories=include_data_directories)
-
-    if overlay_data_offset is not None:
-        return pe.__data__[:overlay_data_offset]
-
-    return pe.__data__[:]
-
-
-def is_memory_mapped(file_data):
-    """
-    Takes file data and tries to determine if it's a memory-mapped image (which can be squashed)
-    or a normal executable file
-
-    :param file_data: The executable file to determine whether it's a memory-mapped image
-
-    :return True if it's a memory-mapped image, false otherwise
-    """
-    pe = obtain_pe(file_data)
-    if pe:
-        for i in range(len(pe.sections) - 1):
-            if i == len(pe.sections) - 1:
-                section_end = pe.OPTIONAL_HEADER.SizeOfImage
-            else:
-                section_end = pe.sections[i + 1].VirtualAddress
-            section_start = pe.sections[i].VirtualAddress + pe.sections[i].SizeOfRawData
-            if file_data[section_start:section_end] != b"\x00" * (section_end - section_start):
-                return False
-        return True
-    return False
-
-
-def squash_flat_executable(memory_mapped, pe=None):
-    """
-    Takes a memory mapped executable image and squashes it back down to a file that IDA can load or that can be
-    executed. Note that hashes for files output by this function cannot be relied upon as valid.
-
-    :param memory_mapped: Memory-mapped input file data
-    :param pe: pefile.PE object
-
-    :return The squashed image or None
-    """
-    if not pe:
-        pe = obtain_pe(memory_mapped)
-    if pe:
-        squashed = pe.header
-        for section in pe.sections:
-            squashed += b"\x00" * (section.PointerToRawData - len(squashed))
-            squashed += memory_mapped[section.VirtualAddress : section.VirtualAddress + section.SizeOfRawData]
-        squashed += b"\x00" * (-len(squashed) & 0x1FF)
-        squashed += memory_mapped[pe.OPTIONAL_HEADER.SizeOfImage :]
-        return squashed
-    return None
-
-
-def obtain_raw_file_size(pe=None, file_data=None):
-    """
-    Obtain the raw file size based on the image header information. Specifically the SizeOfHeaders parameter from the
-    IMAGE_OPTIONAL_HEADER, and the SizeOfRawData parameter for each PE section.
-
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: The raw calculated size of the file from the PE headers.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        size = pe.OPTIONAL_HEADER.SizeOfHeaders
-        for section in pe.sections:
-            size += section.SizeOfRawData
-        return size
-    return None
-
-
-def has_resources(pe):
-    """
-    Determine if the pefile.PE object contains resources.
-
-    :param pe: pefile.PE object to check
-
-    :return: Boolean value on whether the pefile.PE object has a DIRECTORY_ENTRY_RESOURCE.
-    """
-    return hasattr(pe, "DIRECTORY_ENTRY_RESOURCE")
-
-
-class Resource(object):
-    """
-    Object for encapsulating resource information in a simplistic format.
-
-    :param pe: pefile.PE object
-    :param entry: pe.DIRECTORY_ENTRY_RESOURCE.entries[i].directory.entries[j] resource object.
-    :param dirtype: Directory name / type string
-    :param data: Data for the resource
-    :param offset: Starting offset to resource data.
-    :param idname: ID or name string for the resource (note: always a string)
-    :param rsrc_entry: String of the dirtype\idname
-    """
-
-    def __init__(self, pe, entry, dirtype):
-        self._data = None
-        self._pe = pe
-        self._entry = entry
-        self._offset = None
-        self.dirtype = dirtype
-        if entry.name:
-            self.idname = str(entry.name)
-        else:
-            self.idname = str(entry.id)
-        self.rsrc_entry = "%s\\%s" % (self.dirtype, self.idname)
-        self.fname_stub = "%s_%s" % (self.dirtype, self.idname)
-
-    @property
-    def data(self):
-        """
-        Obtain the data corresponding to the resource.
-
-        :return: Data extracted for the specified resource.
-        """
-        if not self._data:
-            rva = self._entry.directory.entries[0].data.struct.OffsetToData
-            size = self._entry.directory.entries[0].data.struct.Size
-            self._data = self._pe.get_memory_mapped_image()[rva : rva + size]
-            if not self._data:
-                # Sometimes the get_memory_mapped_image() method failed for an unknown reason.
-                # Resort to using get_data() if this happens.
-                # We can't just use get_data() to start with because this method fails to pull
-                # all the data for large resources.
-                self._data = self._pe.get_data(rva, size)
-        return self._data
-
-    @data.setter
-    def data(self, value):
-        """
-        Sets the data for given resource.
-        """
-        self._data = value
-
-    @property
-    def offset(self):
-        if not self._offset:
-            rva = self._entry.directory.entries[0].data.struct.OffsetToData
-            self._offset = self._pe.get_physical_by_rva(rva)
-        return self._offset
-
-
-def iter_rsrc(pe, dirtype=None):
-    """
-    Iterates through resources for given pe file.
-
-    :param pe: pefile.PE object
-    :param dirtype: Optional resource directory type or name to iterate.
-        defaults to iterating all directories.
-
-    :yield: pefileutils.Resources objects
-    """
-    if has_resources(pe):
-        for dir_entry in pe.DIRECTORY_ENTRY_RESOURCE.entries:
-            # Generate dirtype
-            if dir_entry.name:
-                extracted_dirtype = str(dir_entry.name)
-            else:
-                for key, id in pefile.RESOURCE_TYPE.items():
-                    if id == dir_entry.id:
-                        extracted_dirtype = key
-                        break
-                else:
-                    extracted_dirtype = str(dir_entry.id)
-
-            # Extract entries.
-            if not dirtype or str(dirtype) == extracted_dirtype:
-                for entry in dir_entry.directory.entries:
-                    yield Resource(pe, entry, extracted_dirtype)
-
-
-def extract_all_rsrc(pe=None, file_data=None):
-    """
-    For a specified file, extract all resources to a list of pefileutils.Resource objects.
-
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: List of pefileutils.Resource objects, or an empty list.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        return list(iter_rsrc(pe))
-    return []
-
-
-def extract_rsrc_dir(dirtype, pe=None, file_data=None):
-    """
-    For a specified file, extract all resources of in a specific directory (by name or type) to a list of
-    pefileutils.Resource objects.
-
-    :param dirtype: The resource directory type or name
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: List of pefileutils.Resource objects matching the dirtype, or an empty list.
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        return list(iter_rsrc(pe, dirtype=dirtype))
-    return []
-
-
-def extract_target_rsrc(dirtype, idname, pe=None, file_data=None):
-    """
-    For a specified file, extract a specific resource by name/id from a specific directory (by name or type) as a
-    pefileutils.Resource object.
-
-    :param dirtype: The resource directory type or name
-    :param idname: The resource name or id, must be a string
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-
-    :return: A pefileutils.Resource object matching the dirtype/idname
-    """
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        for rsrc in iter_rsrc(pe, dirtype=dirtype):
-            assert type(rsrc.idname) == type(idname), f"{type(rsrc.idname)} != {type(idname)}"
-            if rsrc.idname == idname:
-                return rsrc
-    return None
-
-
-def check_rsrc_dir(dirtype, pe=None, file_data=None):
-    """
-    For a specified file, check if a specific resource directory (by name or type) exists
-
-    :param dirtype: The resource directory type or name
-    :param pe: pefile.PE object
-    :param file_data: Input file data
-    :return: Boolean value indicating if resource directory exists
-    """
-
-    if file_data:
-        pe = obtain_pe(file_data)
-    if pe:
-        for _ in iter_rsrc(pe, dirtype=dirtype):
-            return True
-    return False
+"""
+Description: Utility for generic, repeated functions. Expandable as needed
+python version: 2.7.8
+"""
+
+import logging
+from pathlib import Path
+from typing import List, Optional
+
+import pefile
+
+logger = logging.getLogger(__name__)
+
+
+def obtain_pe(file_data):
+    """
+    Given file data, create a pefile.PE object from the data.
+
+    :param file_data: Input PE file data
+
+    :return: A pefile.PE object or None
+    """
+    if not file_data:
+        return None
+    try:
+        return pefile.PE(data=file_data)
+    except pefile.PEFormatError as e:
+        logger.debug("A pefile.PE object on the file data could not be created: {}".format(e))
+        return None
+
+
+def obtain_section(section_name, pe=None, file_data=None):
+    """
+    Obtain the section obtain for a specficied PE section of a file.
+
+    :param section_name: The name of the section from which to extract data.
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: The PE secton object, or None.
+    """
+    if isinstance(section_name, str):
+        section_name = section_name.encode()
+
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        for section in pe.sections:
+            if section.Name.rstrip(b"\0") == section_name:
+                return section
+        return None
+    else:
+        return None
+
+
+def obtain_section_data(section_name, pe=None, file_data=None, min_size=0) -> Optional[bytes]:
+    """
+    Obtain the data in a specified PE section of a file.
+
+    :param section_name: The name of the section from which to extract data.
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+    :param min_size: The minimum acceptable size for the section_data
+
+    :return: The PE section data, or None.
+    """
+
+    if isinstance(section_name, str):
+        section_name = section_name.encode()
+
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        section = obtain_section(section_name, pe)
+        if section:
+            section_data = section.get_data()
+            if len(section_data) > min_size:
+                return section_data
+            return None
+        return None
+    else:
+        return None
+
+
+def check_section(section_name, pe=None, file_data=None):
+    """
+    Check if a specified PE section exists in a file.
+
+    :param section_name: The name of the section from which to extract data.
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: True if the section name is observed, False if it is not.
+    """
+    if isinstance(section_name, str):
+        section_name = section_name.encode()
+
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        for section in pe.sections:
+            if section.Name.rstrip(b"\0") == section_name:
+                return True
+        return False
+    return False
+
+
+def obtain_physical_offset(mem_offset, pe=None, file_data=None):
+    """
+    For an PE file, convert a provided memory offset to a raw offset.
+
+    :param mem_offset: The memory offset to convert to a raw offset
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: Raw offset, or None.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        rva = mem_offset - pe.OPTIONAL_HEADER.ImageBase
+        return pe.get_physical_by_rva(rva)
+    else:
+        return None
+
+
+def obtain_memory_offset(raw_offset, pe=None, file_data=None):
+    """
+    For an PE file, convert a provided raw offset to a memory offset.
+
+    :param raw_offset: The raw offset to convert to a memory offset
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: Memory offset, or None.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        return pe.OPTIONAL_HEADER.ImageBase + pe.get_rva_from_offset(raw_offset)
+    else:
+        return None
+
+
+def obtain_physical_offset_x64(rel_loc, inst_end_raw, pe=None, file_data=None):
+    """
+    For a 64-bit PE file, pointers to data elements are relative to the end of the assembly instruction. Therefore,
+    given a location (rel_loc) relative to the end of an instruction (inst_end_raw), convert the end instruction
+    address to a memory offset, add that value to the relative location of the data, and convert that to a raw
+    offset.
+
+    :param rel_loc: Location of data element relative to the end of the instruction address in inst_end_raw
+    :param inst_end_raw: End of an instruction address referencing the data for rel_loc
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: Raw offset for the data, or None.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        inst_end_mem = obtain_memory_offset(inst_end_raw, pe=pe)
+        # Obtain the memory location of the data and convert it to a physical offset
+        mem_loc = rel_loc + inst_end_mem
+        return obtain_physical_offset(mem_loc, pe=pe)
+    else:
+        return None
+
+
+def obtain_exports_list(pe=None, file_data=None) -> List[bytes]:
+    """
+    Obtain a list of export names for the input PE file.
+
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: A list of export names, or None.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        try:
+            return [export.name for export in pe.DIRECTORY_ENTRY_EXPORT.symbols]
+        except AttributeError:
+            return []
+    else:
+        return []
+
+
+def check_export(export_name, pe=None, file_data=None):
+    """
+    Check if the provided export name is in the list of exports for the file.
+
+    :param export_name: Target export name
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return bool: Indicating if provided export name is in file exports
+    """
+    if isinstance(export_name, str):
+        export_name = export_name.encode()
+    exports = obtain_exports_list(pe, file_data)
+    return export_name in exports
+
+
+def obtain_imported_dlls(pe=None, file_data=None) -> Optional[List[bytes]]:
+    """
+    Obtain a list of imported DLL names for the input PE file.
+
+    :param pe: pefile.PE object, or None by default
+    :param file_data: file data from which to create a pefile.PE object, or None by default
+
+    :return: List of imported DLLs, or None
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        try:
+            return [imp.dll for imp in pe.DIRECTORY_ENTRY_IMPORT]
+        except AttributeError:
+            return None
+    else:
+        return None
+
+
+def obtain_imports_list(dll_name, pe=None, file_data=None):
+    """
+    Obtain a list of imports from a specified DLL for the input PE file.
+
+    :param dll_name: Name of the DLL to obtain imports from
+    :param pe: pefile.PE object, or None by default
+    :param file_data: file data from which to create a pefile.PE object, or None by default
+
+    :return: List of imports from the specified DLL, or None
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        try:
+            for imp in pe.DIRECTORY_ENTRY_IMPORT:
+                if imp.dll.lower() == dll_name.lower():
+                    return [imp_func.name for imp_func in imp.imports]
+        except AttributeError:
+            return None
+    else:
+        return None
+
+
+def is_imported(dll_name, func_name, pe=None, file_data=None):
+    """
+    Determines if a specified function is imported by the file.
+
+    :param dll_name: Name of the DLL containing the imported function in question
+    :param func_name: Name of the imported function within dll_name
+    :param pe: pefile.PE object, or None by default
+    :param file_data: file data from which to create a pefile.PE object, or None by default
+
+    :return: True if function is imported
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        imported_funcs = obtain_imports_list(dll_name, pe=pe)
+        if imported_funcs:
+            for func in imported_funcs:
+                if func.lower() == func_name.lower():
+                    return True
+    else:
+        return None
+
+
+def obtain_file_ext(pe=None, file_data=None):
+    """
+    Attempt to return the appropriate file extension for the input PE file. Use .bin as the default if it cannot be
+    recovered or None if the file is not a PE file.
+
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: The appropriate file extension for the PE file, .bin, or None.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        if pe.is_driver():
+            return ".sys"
+        elif pe.is_exe():
+            return ".exe"
+        elif pe.is_dll():
+            return ".dll"
+        else:
+            return ".bin"
+    else:
+        return None
+
+
+def is_64bit(pe=None, file_data=None):
+    """
+    Evaluate whether an input pefile.PE object or file data is 64-bit.
+
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: True if 64-bit, False if 32-bit, None if could not be determined.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        if pe.PE_TYPE == pefile.OPTIONAL_HEADER_MAGIC_PE_PLUS:
+            return True
+        elif pe.PE_TYPE == pefile.OPTIONAL_HEADER_MAGIC_PE:
+            return False
+        else:
+            logger.debug("The architecture type for the file could not be determined.")
+    return None
+
+
+def obtain_architecture_string(pe=None, file_data=None, bitterm=True):
+    """
+    Obtain an architecture type string for the input PE file. Allow the bitterm variable to determine if the string
+    should be in the format of "32-bit" (default) or "x86" (must specify False). Return "Undetermined" if neither.
+
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+    :param bitterm: Flag to determine return string type
+
+    :return: A string representing the architecture for the input PE file.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        is64 = is_64bit(pe=pe)
+        if is64:
+            if bitterm:
+                return "64-bit"
+            else:
+                return "x64"
+        # Specfically check if the return value is False, because that indicates 32-bit, None indicates undetermined.
+        elif is64 is False:
+            if bitterm:
+                return "32-bit"
+            else:
+                return "x86"
+        else:
+            return "Undetermined"
+    else:
+        return None
+
+
+def _obtain_exif_fname(pe):
+    """
+    Obtain the filename from the pe.FileInfo listing of exif metadata.
+
+    :param pe: pefile.PE object
+
+    :return:
+    """
+    try:
+        for file_info in pe.FileInfo:
+            for entry in file_info:
+                if entry.Key == b"StringFileInfo":
+                    for string_table in entry.StringTable:
+                        try:
+                            return string_table.entries[b"OriginalFilename"]
+                        except KeyError:
+                            continue
+    except AttributeError:
+        return None
+
+
+def _obtain_exportdir_fname(pe):
+    """
+    Obtain the filename from the export directory of the pefile.PE object.
+
+    :param pe: pefile.PE object
+
+    :return: The filename from the export directory, or None.
+    """
+    try:
+        filename = pe.get_string_at_rva(pe.DIRECTORY_ENTRY_EXPORT.struct.Name)
+        return filename
+    except AttributeError:
+        return None
+
+
+def obtain_original_filename(def_stub, pe=None, file_data=None, use_arch=False, ext=".bin"):
+    """
+    Attempt to obtain the original filename, either from the export directory or the pe.FileInfo, of the input file.
+    If the filename cannot be recovered from either of those locations, append the applicable architecture string and
+    file extension to the default stub and return that value. If no pefile.PE object is provided or can be created
+    from the provided file data, return the default stub appended with ".bin".
+
+    :param def_stub: Default filename stub, sans extension, to utilize if the filename cannot be recovered.
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+    :param use_arch: Flag indicating if the file architecture should be included in the name, False by default.
+    :param ext: Extension to default to if it could not be determined. (defaults to ".bin")
+
+    :return: The recovered filename from the pe metadata or a generated filename using def_stub.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        ext = obtain_file_ext(pe=pe)
+        arch = obtain_architecture_string(pe=pe, bitterm=False)
+        filename = _obtain_exportdir_fname(pe) or _obtain_exif_fname(pe)
+        if isinstance(filename, bytes):
+            filename = filename.decode("ascii", "backslashreplace")
+        if filename:
+            filename = Path(filename)
+            if use_arch:
+                base, ext = filename.stem, filename.suffix
+                filename = base + "_" + arch + ext
+            return str(filename)
+        else:
+            return def_stub + "_" + arch + ext
+    else:
+        return def_stub + ext
+
+
+def get_overlay_data_start_offset(pe, include_data_directories=True):
+    """
+    Get the offset of data appended to the file and not contained within
+    the area described in the headers.
+
+    MODIFICATIONS:
+        - Use include_data_directories parameter to allow user to specify if they
+          want to include the data directories in the calculation.
+        - Include SECURITY table.
+    """
+
+    largest_offset_and_size = (0, 0)
+
+    def update_if_sum_is_larger_and_within_file(offset_and_size, file_size=len(pe.__data__)):
+        if sum(offset_and_size) <= file_size and sum(offset_and_size) > sum(largest_offset_and_size):
+            return offset_and_size
+        return largest_offset_and_size
+
+    if hasattr(pe, "OPTIONAL_HEADER"):
+        largest_offset_and_size = update_if_sum_is_larger_and_within_file(
+            (pe.OPTIONAL_HEADER.get_file_offset(), pe.FILE_HEADER.SizeOfOptionalHeader)
+        )
+
+    for section in pe.sections:
+        largest_offset_and_size = update_if_sum_is_larger_and_within_file(
+            (section.PointerToRawData, section.SizeOfRawData)
+        )
+
+    if include_data_directories:
+        for idx, directory in enumerate(pe.OPTIONAL_HEADER.DATA_DIRECTORY):
+            try:
+                # Security directory is special in that its VirtualAddress is actually a file offset.
+                if idx == pefile.DIRECTORY_ENTRY["IMAGE_DIRECTORY_ENTRY_SECURITY"]:
+                    largest_offset_and_size = update_if_sum_is_larger_and_within_file(
+                        (directory.VirtualAddress, directory.Size)
+                    )
+                else:
+                    largest_offset_and_size = update_if_sum_is_larger_and_within_file(
+                        (pe.get_offset_from_rva(directory.VirtualAddress), directory.Size)
+                    )
+            # Ignore directories with RVA out of file
+            except pefile.PEFormatError:
+                continue
+
+    if len(pe.__data__) > sum(largest_offset_and_size):
+        return sum(largest_offset_and_size)
+
+    return None
+
+
+def get_overlay(pe, include_data_directories=True):
+    """
+    Get the data appended to the file and not contained within the area described in the headers.
+
+    MODIFICATIONS:
+        - Use include_data_directories parameter to allow user to specify if they
+          want to include the data directories in the calculation.
+    """
+
+    overlay_data_offset = get_overlay_data_start_offset(pe, include_data_directories=include_data_directories)
+
+    if overlay_data_offset is not None:
+        return pe.__data__[overlay_data_offset:]
+
+    return None
+
+
+def trim(pe, include_data_directories=True):
+    """
+    Return the just data defined by the PE headers, removing any overlayed data.
+
+    MODIFICATIONS:
+        - Use include_data_directories parameter to allow user to specify if they
+          want to include the data directories in the calculation.
+    """
+
+    overlay_data_offset = get_overlay_data_start_offset(pe, include_data_directories=include_data_directories)
+
+    if overlay_data_offset is not None:
+        return pe.__data__[:overlay_data_offset]
+
+    return pe.__data__[:]
+
+
+def is_memory_mapped(file_data):
+    """
+    Takes file data and tries to determine if it's a memory-mapped image (which can be squashed)
+    or a normal executable file
+
+    :param file_data: The executable file to determine whether it's a memory-mapped image
+
+    :return True if it's a memory-mapped image, false otherwise
+    """
+    pe = obtain_pe(file_data)
+    if pe:
+        for i in range(len(pe.sections) - 1):
+            if i == len(pe.sections) - 1:
+                section_end = pe.OPTIONAL_HEADER.SizeOfImage
+            else:
+                section_end = pe.sections[i + 1].VirtualAddress
+            section_start = pe.sections[i].VirtualAddress + pe.sections[i].SizeOfRawData
+            if file_data[section_start:section_end] != b"\x00" * (section_end - section_start):
+                return False
+        return True
+    return False
+
+
+def squash_flat_executable(memory_mapped, pe=None):
+    """
+    Takes a memory mapped executable image and squashes it back down to a file that IDA can load or that can be
+    executed. Note that hashes for files output by this function cannot be relied upon as valid.
+
+    :param memory_mapped: Memory-mapped input file data
+    :param pe: pefile.PE object
+
+    :return The squashed image or None
+    """
+    if not pe:
+        pe = obtain_pe(memory_mapped)
+    if pe:
+        squashed = pe.header
+        for section in pe.sections:
+            squashed += b"\x00" * (section.PointerToRawData - len(squashed))
+            squashed += memory_mapped[section.VirtualAddress : section.VirtualAddress + section.SizeOfRawData]
+        squashed += b"\x00" * (-len(squashed) & 0x1FF)
+        squashed += memory_mapped[pe.OPTIONAL_HEADER.SizeOfImage :]
+        return squashed
+    return None
+
+
+def obtain_raw_file_size(pe=None, file_data=None):
+    """
+    Obtain the raw file size based on the image header information. Specifically the SizeOfHeaders parameter from the
+    IMAGE_OPTIONAL_HEADER, and the SizeOfRawData parameter for each PE section.
+
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: The raw calculated size of the file from the PE headers.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        size = pe.OPTIONAL_HEADER.SizeOfHeaders
+        for section in pe.sections:
+            size += section.SizeOfRawData
+        return size
+    return None
+
+
+def has_resources(pe):
+    """
+    Determine if the pefile.PE object contains resources.
+
+    :param pe: pefile.PE object to check
+
+    :return: Boolean value on whether the pefile.PE object has a DIRECTORY_ENTRY_RESOURCE.
+    """
+    return hasattr(pe, "DIRECTORY_ENTRY_RESOURCE")
+
+
+class Resource(object):
+    """
+    Object for encapsulating resource information in a simplistic format.
+
+    :param pe: pefile.PE object
+    :param entry: pe.DIRECTORY_ENTRY_RESOURCE.entries[i].directory.entries[j] resource object.
+    :param dirtype: Directory name / type string
+    :param data: Data for the resource
+    :param offset: Starting offset to resource data.
+    :param idname: ID or name string for the resource (note: always a string)
+    :param rsrc_entry: String of the dirtype\idname
+    """
+
+    def __init__(self, pe, entry, dirtype):
+        self._data = None
+        self._pe = pe
+        self._entry = entry
+        self._offset = None
+        self.dirtype = dirtype
+        if entry.name:
+            self.idname = str(entry.name)
+        else:
+            self.idname = str(entry.id)
+        self.rsrc_entry = "%s\\%s" % (self.dirtype, self.idname)
+        self.fname_stub = "%s_%s" % (self.dirtype, self.idname)
+
+    @property
+    def data(self):
+        """
+        Obtain the data corresponding to the resource.
+
+        :return: Data extracted for the specified resource.
+        """
+        if not self._data:
+            rva = self._entry.directory.entries[0].data.struct.OffsetToData
+            size = self._entry.directory.entries[0].data.struct.Size
+            self._data = self._pe.get_memory_mapped_image()[rva : rva + size]
+            if not self._data:
+                # Sometimes the get_memory_mapped_image() method failed for an unknown reason.
+                # Resort to using get_data() if this happens.
+                # We can't just use get_data() to start with because this method fails to pull
+                # all the data for large resources.
+                self._data = self._pe.get_data(rva, size)
+        return self._data
+
+    @data.setter
+    def data(self, value):
+        """
+        Sets the data for given resource.
+        """
+        self._data = value
+
+    @property
+    def offset(self):
+        if not self._offset:
+            rva = self._entry.directory.entries[0].data.struct.OffsetToData
+            self._offset = self._pe.get_physical_by_rva(rva)
+        return self._offset
+
+
+def iter_rsrc(pe, dirtype=None):
+    """
+    Iterates through resources for given pe file.
+
+    :param pe: pefile.PE object
+    :param dirtype: Optional resource directory type or name to iterate.
+        defaults to iterating all directories.
+
+    :yield: pefileutils.Resources objects
+    """
+    if has_resources(pe):
+        for dir_entry in pe.DIRECTORY_ENTRY_RESOURCE.entries:
+            # Generate dirtype
+            if dir_entry.name:
+                extracted_dirtype = str(dir_entry.name)
+            else:
+                for key, id in pefile.RESOURCE_TYPE.items():
+                    if id == dir_entry.id:
+                        extracted_dirtype = key
+                        break
+                else:
+                    extracted_dirtype = str(dir_entry.id)
+
+            # Extract entries.
+            if not dirtype or str(dirtype) == extracted_dirtype:
+                for entry in dir_entry.directory.entries:
+                    yield Resource(pe, entry, extracted_dirtype)
+
+
+def extract_all_rsrc(pe=None, file_data=None):
+    """
+    For a specified file, extract all resources to a list of pefileutils.Resource objects.
+
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: List of pefileutils.Resource objects, or an empty list.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        return list(iter_rsrc(pe))
+    return []
+
+
+def extract_rsrc_dir(dirtype, pe=None, file_data=None):
+    """
+    For a specified file, extract all resources of in a specific directory (by name or type) to a list of
+    pefileutils.Resource objects.
+
+    :param dirtype: The resource directory type or name
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: List of pefileutils.Resource objects matching the dirtype, or an empty list.
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        return list(iter_rsrc(pe, dirtype=dirtype))
+    return []
+
+
+def extract_target_rsrc(dirtype, idname, pe=None, file_data=None):
+    """
+    For a specified file, extract a specific resource by name/id from a specific directory (by name or type) as a
+    pefileutils.Resource object.
+
+    :param dirtype: The resource directory type or name
+    :param idname: The resource name or id, must be a string
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+
+    :return: A pefileutils.Resource object matching the dirtype/idname
+    """
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        for rsrc in iter_rsrc(pe, dirtype=dirtype):
+            assert type(rsrc.idname) == type(idname), f"{type(rsrc.idname)} != {type(idname)}"
+            if rsrc.idname == idname:
+                return rsrc
+    return None
+
+
+def check_rsrc_dir(dirtype, pe=None, file_data=None):
+    """
+    For a specified file, check if a specific resource directory (by name or type) exists
+
+    :param dirtype: The resource directory type or name
+    :param pe: pefile.PE object
+    :param file_data: Input file data
+    :return: Boolean value indicating if resource directory exists
+    """
+
+    if file_data:
+        pe = obtain_pe(file_data)
+    if pe:
+        for _ in iter_rsrc(pe, dirtype=dirtype):
+            return True
+    return False
```

### Comparing `mwcp-3.8.0/mwcp/utils/poshdeob.py` & `mwcp-3.9.0/mwcp/utils/poshdeob.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,313 +1,313 @@
-r"""
-poshdeob - Powershell Deobfuscator
-
-This utility is used for converting obfuscated code and pulling strings along the way.
-
-WARNING: This is a very rudimentary parser that doesn't support a lot of things.
- It makes no promises in deobfuscating all your code.
-
-Usage:
-    from mwcp.utils import poshdeob
-
-    deobfuscated_code, found_strings = poshdeob.debofuscate(obfuscated_code)
-"""
-
-import argparse
-from typing import Tuple, List
-
-import pyparsing as pp
-import re
-import sys
-
-
-_PARSER = None
-
-
-# region PARSING HOOKS
-
-
-# Some variables found to be used in obfuscated code with the most probable values.
-# TODO: Fill this up!
-_VARIABLE_LOOKUP = {
-    "pshome": r"C:\Windows\System32\WindowsPowerShell\v1.0",
-    "shellid": "Microsoft.PowerShell",
-    "env:public": r"C:\Users\Public",
-    "env:comspec": r"C:\Windows\system32\cmd.exe",
-    "verbosepreference.tostring()": "SilentlyContinue",
-}
-
-
-def _indexing(tokens):
-    indices = tokens.indices
-    if len(indices) == 1:
-        return tokens.data[int(indices[0])]
-    else:
-        return [tokens.data[int(i)] for i in indices]
-
-
-def _string_format(tokens):
-    format_string = tokens.format_string
-    for format in tokens.format:
-        format_string = format_string.format(*format.params)
-    return format_string
-
-
-def _string_replace(tokens):
-    data = tokens.data
-    for replace in tokens.replace:
-        # Only escape "\" otherwise regex complains if it trailing.
-        old = replace.old.replace("\\", "\\\\")
-        new = replace.new.replace("\\", "\\\\")
-        data = re.sub(old, new, data, flags=re.IGNORECASE if replace.command != "creplace" else 0)
-    return data
-
-
-def _split(tokens):
-    split_data = [tokens.data]
-    for split in tokens.split:
-        for delimiter in split.delimiters:
-            new_split_data = []
-            for data in split_data:
-                new_split_data.extend(re.split(delimiter, data))
-            split_data = new_split_data
-    return split_data
-
-
-# endregion
-
-
-# region PARSING GRAMMER
-
-
-def OptionalParen(expr, parenthesis="()"):
-    """
-    Wraps pyparsing expression to add optional parenthesis.
-
-    >>> hello = OptionalParen(pp.Literal('hello'))
-    >>> hello.parseString('hello')
-    (['hello'], {})
-    >>> hello.parseString('((hello))')
-    (['hello'], {})
-    >>> goodbye = OptionalParen(pp.Literal('goodbye'), parenthesis='{}')
-    >>> goodbye.parseString('goodbye')
-    (['goodbye'], {})
-    >>> goodbye.parseString('{goodbye}')
-    (['goodbye'], {})
-    """
-    lpar, rpar = map(pp.Suppress, parenthesis)
-    term = pp.Forward()
-    term <<= expr | (lpar + term + rpar)
-    return term
-
-
-def _gen_parser():
-    r"""
-    Generates PyParsing grammar for parsing common powershell operations.
-
-    Tests:
-    >>> parser = _gen_parser()
-    >>> parser.parseString("'{1} {0}'-f 'world','hello'")
-    (['hello world'], {})
-    >>> parser.parseString('''
-    ...     'fGshellolNRfGs'-rEplaCE  ((([cHaR]108+[cHaR]78+[cHaR]82))),'!' .rePLace('fGs',[cHaR]96)''')
-    (['`hello!`'], {})
-    >>> parser.parseString("'ATBZCFD'-spLIT 'Z'-SPLIT'T'  -spLiT 'F'")
-    (['A', 'B', 'C', 'D'], {})
-    >>> parser.parseString("$ENv:PuBlIc[13]")
-    (['i'], {})
-    >>> parser.parseString("('h', 'e', 'l', 'lo')-JOIn ''")
-    (['hello'], {})
-    >>> parser.parseString("'he`llo'")
-    (['hello'], {})
-    >>> parser.parseString("'FOtestingFO'.RePLaCE('FO','`')")
-    (['`testing`'], {})
-    """
-    char = ("[" + pp.CaselessKeyword("char") + "]" + pp.Word(pp.nums)("num")).setParseAction(lambda t: chr(int(t.num)))
-    string = (
-        (pp.Suppress("'") + "`" + pp.Suppress("'"))
-        | (pp.Suppress('"') + "`" + pp.Suppress('"'))
-        | pp.QuotedString("'", escChar="`", escQuote="''", multiline=True, convertWhitespaceEscapes=False)
-        | pp.QuotedString('"', escChar="`", escQuote='""', multiline=True, convertWhitespaceEscapes=False)
-    )
-    variable = ("$" + pp.oneOf(_VARIABLE_LOOKUP.keys(), caseless=True)("var")).setParseAction(
-        lambda t: _VARIABLE_LOOKUP[t.var.lower()]
-    )
-
-    _string = pp.Suppress(pp.Optional("[" + pp.CaselessKeyword("string") + "]")) + OptionalParen(
-        pp.Suppress(pp.Optional("[" + pp.CaselessKeyword("string") + "]")) + string | char | variable
-    )
-    concat_string = OptionalParen(
-        pp.delimitedList(OptionalParen(_string), delim="+").setParseAction(lambda t: "".join(t))
-    )
-
-    # TODO: Support ranges and other fancy indexing.
-    indexing = (concat_string("data") + "[" + pp.delimitedList(pp.Word(pp.nums))("indices") + "]").setParseAction(
-        _indexing
-    )
-
-    # Combine used to enforce there is no space between "c" and "replace"
-    _replace_command = pp.Combine(pp.Optional(pp.CaselessLiteral("c")) + pp.CaselessLiteral("replace"))("command")
-    string_replace = (
-        concat_string("data")
-        + pp.OneOrMore(
-            pp.Group(
-                (pp.Combine("-" + _replace_command) + concat_string("old") + "," + concat_string("new"))
-                | (
-                    "."
-                    + ("'" + _replace_command + "'" | '"' + _replace_command + '"' | _replace_command)
-                    + ("(" + concat_string("old") + "," + concat_string("new") + ")")
-                )
-            )
-        )("replace")
-    ).setParseAction(_string_replace)
-
-    string_format = (
-        concat_string("format_string")
-        + pp.OneOrMore(pp.Group(pp.CaselessKeyword("-f") + pp.delimitedList(concat_string)("params")))("format")
-    ).setParseAction(_string_format)
-
-    split = (
-        concat_string("data")
-        + pp.OneOrMore(
-            pp.Group(
-                (pp.CaselessKeyword("-split") + concat_string("delimiters"))
-                | ("." + pp.CaselessKeyword("split") + "(" + concat_string("delimiters") + ")")
-            )
-        )("split")
-    ).setParseAction(_split)
-
-    join = (
-        OptionalParen(pp.delimitedList(concat_string)("string_list"))
-        + pp.CaselessKeyword("-join")
-        + concat_string("join_string")
-    ).setParseAction(lambda t: t.join_string.join(t.string_list))
-
-    join_unary = (
-        (pp.CaselessKeyword("-join") | pp.CaselessKeyword("[string]::join"))
-        + "("
-        + OptionalParen(pp.delimitedList(concat_string)("string_list"))
-        + ")"
-    ).setParseAction(lambda t: "".join(t.string_list))
-
-    # fmt: off
-    poss_elements = OptionalParen(
-        string_format
-        | string_replace
-        | split
-        | join_unary
-        | join
-        | indexing
-        | concat_string
-    )
-    # fmt: on
-
-    return poss_elements
-
-
-# endregion
-
-
-def _format_code_string(string):
-    """Formats string into user readable string that can be placed into powershell code."""
-    # Use least used quotes for best readability.
-    if string.count("'") > string.count('"'):
-        code_string = '"' + string.replace('"', '""') + '"'
-    else:
-        code_string = "'" + string.replace("'", "''") + "'"
-    return code_string
-
-
-def deobfuscate(code, depth=32, recursive=False) -> Tuple[str, List[str]]:
-    """
-    Deobfuscates strings found in powershell code.
-
-    :param code: obfuscated powershell code
-    :param depth: Number of levels of deobfuscation to run. (defaults to 32)
-    :param recursive: Whether to recursively deobfuscate found strings.
-                      (be careful, this can be very slow!!)
-
-    returns: tuple containing -- (deobfuscate code, list of strings found)
-    """
-    if depth <= 0:
-        raise ValueError("Depth must be a positive number.")
-    orig_depth = depth
-
-    if isinstance(code, bytes):
-        code = code.decode("latin1")
-
-    # Generate parser on first run.
-    global _PARSER
-    if not _PARSER:
-        _PARSER = _gen_parser()
-        _PARSER.keepTabs = True  # start/end offsets get screwy if we don't enable this.
-
-    # Continuously run code through string deobfuscation until we don't get anything new.
-    # (This is necessary because pyparsing is not a true recursive descent parser)
-    prev_code = ""
-    strings = []
-    while depth and prev_code != code:
-        depth -= 1
-        prev_code = code
-        strings = []
-        code_replacements = []
-        for result, start, end in _PARSER.scanString(code):
-            if recursive:
-                new_result = []
-                for string in result:
-                    deob_code, sub_strings = deobfuscate(string, depth=orig_depth, recursive=True)
-                    new_result.append(deob_code)
-                    strings.extend(sub_strings or [deob_code])
-                result = new_result
-            else:
-                strings.extend(result)
-
-            # replace obfuscated code with less obfuscated code.
-            code_string = ", ".join(map(_format_code_string, result))
-            # Only wrap parenthesis if more than one string.
-            if len(result) > 1:
-                code_string = "({})".format(code_string)
-
-            code_replacements.append((start, end, code_string))
-
-        # Replace code with new code.
-        new_code = ""
-        index = 0
-        for start, end, code_string in code_replacements:
-            # Sometimes pyparsing includes whitespace at the end of the parsed string for some reason...
-            try:
-                while code[end - 1] in ("\r", "\n", " "):
-                    end -= 1
-            except IndexError:
-                pass
-            new_code += code[index:start] + code_string
-            index = end
-        new_code += code[index:]
-        code = new_code
-
-    return code, strings
-
-
-def main():
-    """CLI interface"""
-    arg_parser = argparse.ArgumentParser("Powershell Deobfuscator")
-    arg_parser.add_argument("INPUT", help="Input file (or code) to deobfuscate")
-    arg_parser.add_argument("OUTPUT", nargs="?", help="Deobfuscated file (default: stdout)")
-
-    args = arg_parser.parse_args()
-
-    if args.OUTPUT:
-        output = open(args.OUTPUT, "w")
-    else:
-        output = sys.stdout
-
-    try:
-        with open(args.INPUT, "r") as fo:
-            deob_code, _ = deobfuscate(fo.read())
-            output.write(deob_code)
-    finally:
-        if args.OUTPUT:
-            output.close()
-
-
-if __name__ == "__main__":
-    main()
+r"""
+poshdeob - Powershell Deobfuscator
+
+This utility is used for converting obfuscated code and pulling strings along the way.
+
+WARNING: This is a very rudimentary parser that doesn't support a lot of things.
+ It makes no promises in deobfuscating all your code.
+
+Usage:
+    from mwcp.utils import poshdeob
+
+    deobfuscated_code, found_strings = poshdeob.debofuscate(obfuscated_code)
+"""
+
+import argparse
+from typing import Tuple, List
+
+import pyparsing as pp
+import re
+import sys
+
+
+_PARSER = None
+
+
+# region PARSING HOOKS
+
+
+# Some variables found to be used in obfuscated code with the most probable values.
+# TODO: Fill this up!
+_VARIABLE_LOOKUP = {
+    "pshome": r"C:\Windows\System32\WindowsPowerShell\v1.0",
+    "shellid": "Microsoft.PowerShell",
+    "env:public": r"C:\Users\Public",
+    "env:comspec": r"C:\Windows\system32\cmd.exe",
+    "verbosepreference.tostring()": "SilentlyContinue",
+}
+
+
+def _indexing(tokens):
+    indices = tokens.indices
+    if len(indices) == 1:
+        return tokens.data[int(indices[0])]
+    else:
+        return [tokens.data[int(i)] for i in indices]
+
+
+def _string_format(tokens):
+    format_string = tokens.format_string
+    for format in tokens.format:
+        format_string = format_string.format(*format.params)
+    return format_string
+
+
+def _string_replace(tokens):
+    data = tokens.data
+    for replace in tokens.replace:
+        # Only escape "\" otherwise regex complains if it trailing.
+        old = replace.old.replace("\\", "\\\\")
+        new = replace.new.replace("\\", "\\\\")
+        data = re.sub(old, new, data, flags=re.IGNORECASE if replace.command != "creplace" else 0)
+    return data
+
+
+def _split(tokens):
+    split_data = [tokens.data]
+    for split in tokens.split:
+        for delimiter in split.delimiters:
+            new_split_data = []
+            for data in split_data:
+                new_split_data.extend(re.split(delimiter, data))
+            split_data = new_split_data
+    return split_data
+
+
+# endregion
+
+
+# region PARSING GRAMMER
+
+
+def OptionalParen(expr, parenthesis="()"):
+    """
+    Wraps pyparsing expression to add optional parenthesis.
+
+    >>> hello = OptionalParen(pp.Literal('hello'))
+    >>> hello.parseString('hello')
+    (['hello'], {})
+    >>> hello.parseString('((hello))')
+    (['hello'], {})
+    >>> goodbye = OptionalParen(pp.Literal('goodbye'), parenthesis='{}')
+    >>> goodbye.parseString('goodbye')
+    (['goodbye'], {})
+    >>> goodbye.parseString('{goodbye}')
+    (['goodbye'], {})
+    """
+    lpar, rpar = map(pp.Suppress, parenthesis)
+    term = pp.Forward()
+    term <<= expr | (lpar + term + rpar)
+    return term
+
+
+def _gen_parser():
+    r"""
+    Generates PyParsing grammar for parsing common powershell operations.
+
+    Tests:
+    >>> parser = _gen_parser()
+    >>> parser.parseString("'{1} {0}'-f 'world','hello'")
+    (['hello world'], {})
+    >>> parser.parseString('''
+    ...     'fGshellolNRfGs'-rEplaCE  ((([cHaR]108+[cHaR]78+[cHaR]82))),'!' .rePLace('fGs',[cHaR]96)''')
+    (['`hello!`'], {})
+    >>> parser.parseString("'ATBZCFD'-spLIT 'Z'-SPLIT'T'  -spLiT 'F'")
+    (['A', 'B', 'C', 'D'], {})
+    >>> parser.parseString("$ENv:PuBlIc[13]")
+    (['i'], {})
+    >>> parser.parseString("('h', 'e', 'l', 'lo')-JOIn ''")
+    (['hello'], {})
+    >>> parser.parseString("'he`llo'")
+    (['hello'], {})
+    >>> parser.parseString("'FOtestingFO'.RePLaCE('FO','`')")
+    (['`testing`'], {})
+    """
+    char = ("[" + pp.CaselessKeyword("char") + "]" + pp.Word(pp.nums)("num")).setParseAction(lambda t: chr(int(t.num)))
+    string = (
+        (pp.Suppress("'") + "`" + pp.Suppress("'"))
+        | (pp.Suppress('"') + "`" + pp.Suppress('"'))
+        | pp.QuotedString("'", escChar="`", escQuote="''", multiline=True, convertWhitespaceEscapes=False)
+        | pp.QuotedString('"', escChar="`", escQuote='""', multiline=True, convertWhitespaceEscapes=False)
+    )
+    variable = ("$" + pp.oneOf(_VARIABLE_LOOKUP.keys(), caseless=True)("var")).setParseAction(
+        lambda t: _VARIABLE_LOOKUP[t.var.lower()]
+    )
+
+    _string = pp.Suppress(pp.Optional("[" + pp.CaselessKeyword("string") + "]")) + OptionalParen(
+        pp.Suppress(pp.Optional("[" + pp.CaselessKeyword("string") + "]")) + string | char | variable
+    )
+    concat_string = OptionalParen(
+        pp.delimitedList(OptionalParen(_string), delim="+").setParseAction(lambda t: "".join(t))
+    )
+
+    # TODO: Support ranges and other fancy indexing.
+    indexing = (concat_string("data") + "[" + pp.delimitedList(pp.Word(pp.nums))("indices") + "]").setParseAction(
+        _indexing
+    )
+
+    # Combine used to enforce there is no space between "c" and "replace"
+    _replace_command = pp.Combine(pp.Optional(pp.CaselessLiteral("c")) + pp.CaselessLiteral("replace"))("command")
+    string_replace = (
+        concat_string("data")
+        + pp.OneOrMore(
+            pp.Group(
+                (pp.Combine("-" + _replace_command) + concat_string("old") + "," + concat_string("new"))
+                | (
+                    "."
+                    + ("'" + _replace_command + "'" | '"' + _replace_command + '"' | _replace_command)
+                    + ("(" + concat_string("old") + "," + concat_string("new") + ")")
+                )
+            )
+        )("replace")
+    ).setParseAction(_string_replace)
+
+    string_format = (
+        concat_string("format_string")
+        + pp.OneOrMore(pp.Group(pp.CaselessKeyword("-f") + pp.delimitedList(concat_string)("params")))("format")
+    ).setParseAction(_string_format)
+
+    split = (
+        concat_string("data")
+        + pp.OneOrMore(
+            pp.Group(
+                (pp.CaselessKeyword("-split") + concat_string("delimiters"))
+                | ("." + pp.CaselessKeyword("split") + "(" + concat_string("delimiters") + ")")
+            )
+        )("split")
+    ).setParseAction(_split)
+
+    join = (
+        OptionalParen(pp.delimitedList(concat_string)("string_list"))
+        + pp.CaselessKeyword("-join")
+        + concat_string("join_string")
+    ).setParseAction(lambda t: t.join_string.join(t.string_list))
+
+    join_unary = (
+        (pp.CaselessKeyword("-join") | pp.CaselessKeyword("[string]::join"))
+        + "("
+        + OptionalParen(pp.delimitedList(concat_string)("string_list"))
+        + ")"
+    ).setParseAction(lambda t: "".join(t.string_list))
+
+    # fmt: off
+    poss_elements = OptionalParen(
+        string_format
+        | string_replace
+        | split
+        | join_unary
+        | join
+        | indexing
+        | concat_string
+    )
+    # fmt: on
+
+    return poss_elements
+
+
+# endregion
+
+
+def _format_code_string(string):
+    """Formats string into user readable string that can be placed into powershell code."""
+    # Use least used quotes for best readability.
+    if string.count("'") > string.count('"'):
+        code_string = '"' + string.replace('"', '""') + '"'
+    else:
+        code_string = "'" + string.replace("'", "''") + "'"
+    return code_string
+
+
+def deobfuscate(code, depth=32, recursive=False) -> Tuple[str, List[str]]:
+    """
+    Deobfuscates strings found in powershell code.
+
+    :param code: obfuscated powershell code
+    :param depth: Number of levels of deobfuscation to run. (defaults to 32)
+    :param recursive: Whether to recursively deobfuscate found strings.
+                      (be careful, this can be very slow!!)
+
+    returns: tuple containing -- (deobfuscate code, list of strings found)
+    """
+    if depth <= 0:
+        raise ValueError("Depth must be a positive number.")
+    orig_depth = depth
+
+    if isinstance(code, bytes):
+        code = code.decode("latin1")
+
+    # Generate parser on first run.
+    global _PARSER
+    if not _PARSER:
+        _PARSER = _gen_parser()
+        _PARSER.keepTabs = True  # start/end offsets get screwy if we don't enable this.
+
+    # Continuously run code through string deobfuscation until we don't get anything new.
+    # (This is necessary because pyparsing is not a true recursive descent parser)
+    prev_code = ""
+    strings = []
+    while depth and prev_code != code:
+        depth -= 1
+        prev_code = code
+        strings = []
+        code_replacements = []
+        for result, start, end in _PARSER.scanString(code):
+            if recursive:
+                new_result = []
+                for string in result:
+                    deob_code, sub_strings = deobfuscate(string, depth=orig_depth, recursive=True)
+                    new_result.append(deob_code)
+                    strings.extend(sub_strings or [deob_code])
+                result = new_result
+            else:
+                strings.extend(result)
+
+            # replace obfuscated code with less obfuscated code.
+            code_string = ", ".join(map(_format_code_string, result))
+            # Only wrap parenthesis if more than one string.
+            if len(result) > 1:
+                code_string = "({})".format(code_string)
+
+            code_replacements.append((start, end, code_string))
+
+        # Replace code with new code.
+        new_code = ""
+        index = 0
+        for start, end, code_string in code_replacements:
+            # Sometimes pyparsing includes whitespace at the end of the parsed string for some reason...
+            try:
+                while code[end - 1] in ("\r", "\n", " "):
+                    end -= 1
+            except IndexError:
+                pass
+            new_code += code[index:start] + code_string
+            index = end
+        new_code += code[index:]
+        code = new_code
+
+    return code, strings
+
+
+def main():
+    """CLI interface"""
+    arg_parser = argparse.ArgumentParser("Powershell Deobfuscator")
+    arg_parser.add_argument("INPUT", help="Input file (or code) to deobfuscate")
+    arg_parser.add_argument("OUTPUT", nargs="?", help="Deobfuscated file (default: stdout)")
+
+    args = arg_parser.parse_args()
+
+    if args.OUTPUT:
+        output = open(args.OUTPUT, "w")
+    else:
+        output = sys.stdout
+
+    try:
+        with open(args.INPUT, "r") as fo:
+            deob_code, _ = deobfuscate(fo.read())
+            output.write(deob_code)
+    finally:
+        if args.OUTPUT:
+            output.close()
+
+
+if __name__ == "__main__":
+    main()
```

### Comparing `mwcp-3.8.0/mwcp/utils/stringutils.py` & `mwcp-3.9.0/mwcp/utils/stringutils.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,26 +1,26 @@
-"""
-Utility used for string conversions.
-"""
-
-import string
-import unicodedata
-
-
-def convert_to_unicode(input_value):
-    if isinstance(input_value, str):
-        return input_value
-    elif isinstance(input_value, bytes):
-        return str(input_value, encoding="latin1", errors="replace")
-    else:
-        return convert_to_unicode(str(input_value))
-
-
-VALID_FILENAME_CHARS = "-_.() {}{}".format(string.ascii_letters, string.digits).encode("ascii")
-
-
-def sanitize_filename(filename):
-    """Convert given filename to sanitized version."""
-    filename = convert_to_unicode(filename)
-    filename = unicodedata.normalize("NFKD", filename)  # convert accented characters
-
-    return convert_to_unicode(bytes(c for c in filename.encode("ascii", "ignore") if c in VALID_FILENAME_CHARS))
+"""
+Utility used for string conversions.
+"""
+
+import string
+import unicodedata
+
+
+def convert_to_unicode(input_value):
+    if isinstance(input_value, str):
+        return input_value
+    elif isinstance(input_value, bytes):
+        return str(input_value, encoding="latin1", errors="replace")
+    else:
+        return convert_to_unicode(str(input_value))
+
+
+VALID_FILENAME_CHARS = "-_.() {}{}".format(string.ascii_letters, string.digits).encode("ascii")
+
+
+def sanitize_filename(filename):
+    """Convert given filename to sanitized version."""
+    filename = convert_to_unicode(filename)
+    filename = unicodedata.normalize("NFKD", filename)  # convert accented characters
+
+    return convert_to_unicode(bytes(c for c in filename.encode("ascii", "ignore") if c in VALID_FILENAME_CHARS))
```

### Comparing `mwcp-3.8.0/mwcp.egg-info/PKG-INFO` & `mwcp-3.9.0/mwcp.egg-info/PKG-INFO`

 * *Files 20% similar despite different names*

```diff
@@ -1,585 +1,658 @@
-Metadata-Version: 2.1
-Name: mwcp
-Version: 3.8.0
-Summary: A framework for malware configuration parsers.
-Home-page: http://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/
-Author: DC3
-Author-email: dcci@dc3.mil
-License: MIT
-Description: # DC3-MWCP
-        [Changelog](CHANGELOG.md) | [Releases](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/releases)
-        
-        DC3 Malware Configuration Parser (DC3-MWCP) is a framework for parsing configuration information from malware.
-        The information extracted from malware includes items such as addresses, passwords, filenames, and
-        mutex names. A parser module is usually created per malware family.
-        DC3-MWCP is designed to help ensure consistency in parser function and output, ease parser development,
-        and facilitate parser sharing. DC3-MWCP supports both analyst directed analysis and
-        large-scale automated execution, utilizing either the native python API, a REST API, or a provided
-        command line tool. DC3-MWCP is authored by the Defense Cyber Crime Center (DC3).
-        
-        - [Install](#install)
-        - [Dragodis Support](#dragodis-support)
-        - [DC3-Kordesii Support](#dc3-kordesii-support)
-        - [Usage](#usage)
-            - [CLI Tool](#cli-tool)
-            - [REST API](#rest-api)
-            - [Python API](#python-api)
-        - [Schema](#schema)
-        - [STIX Output](#stix-output)
-        - [Helper Utilities](#helper-utilities)
-        
-        ### Guides
-        - [Parser Development](docs/ParserDevelopment.md)
-        - [Parser Components](docs/ParserComponents.md)
-        - [Parser Installation](docs/ParserInstallation.md)
-        - [Parser Testing](docs/ParserTesting.md)
-        - [Python Style Guide](docs/PythonStyleGuide.md)
-        - [Construct Tutorial](docs/construct.ipynb)
-        - [Style Guide](docs/PythonStyleGuide.md)
-        - [Testing](docs/Testing.md)
-        
-        
-        ## Install
-        ```console
-        > pip install mwcp
-        ```
-        
-        Alternatively you can clone this repo and install locally.
-        ```console
-        > git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
-        > pip install ./DC3-MWCP
-        ```
-        
-        For a development mode use the `-e` flag to install in editable mode:
-        
-        ```console
-        > git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
-        > pip install -e ./DC3-MWCP
-        ```
-        
-        ## Dragodis Support
-        DC3-MWCP optionally supports [Dragodis](https://github.com/Defense-Cyber-Crime-Center/Dragodis)
-        if it is installed. This allows you to obtain a disassembler agnostic interface for parsing
-        the file's disassembly from the `mwcp.FileObject` object with the `.disassembly()` function.
-        
-        You can install Dragodis along with DC3-MWCP by adding `[dragodis]` to your appropriate install command:
-        ```
-        pip install mwcp[dragodis]
-        pip install ./DC3-MWCP[dragodis]
-        pip install -e ./DC3-MWCP[dragodis]
-        ```
-        
-        After installation make sure to follow Dragodis's [installation instructions](https://github.com/Defense-Cyber-Crime-Center/Dragodis/blob/master/docs/install.rst) to setup
-        a backend disassembler.
-        
-        *It is recommended to also install [Rugosa](https://github.com/Defense-Cyber-Crime-Center/rugosa) 
-        for emulation and regex/yara matching capabilities using Dragodis.*
-        
-        
-        ## DC3-Kordesii Support
-        DC3-MWCP optionally supports [DC3-Kordesii](https://github.com/Defense-Cyber-Crime-Center/kordesii)
-        if it is installed. This will allow you to run any DC3-Kordesii decoder from the
-        `mwcp.FileObject` object with the `run_kordesii_decoder` function.
-        
-        You can install DC3-Kordesii along with DC3-MWCP by adding `[kordesii]` to your appropriate install command:
-        ```
-        pip install mwcp[kordesii]
-        pip install ./DC3-MWCP[kordesii]
-        pip install -e ./DC3-MWCP[kordesii]
-        ```
-        
-        
-        ## Usage
-        DC3-MWCP is designed to allow easy development and use of malware config parsers. DC3-MWCP is also designed to ensure
-        that these parsers are scalable and that DC3-MWCP can be integrated in other systems.
-        
-        Most automated processing systems will use a condition, such as a yara signature match, to trigger execution
-        of an DC3-MWCP parser.
-        
-        There are 3 options for integration of DC3-MWCP:
-        - CLI: `mwcp`
-        - REST API: `mwcp serve`
-        - Python API
-        
-        DC3-MWCP also includes a utility for test case generation and execution.
-        
-        ### CLI tool
-        
-        DC3-MWCP can be used directly from the command line using the `mwcp` command.
-        
-        ```console
-        > mwcp parse foo ./README.md
-        ----- File: README.md -----
-        Field         Value
-        ------------  ----------------------------------------------------------------
-        Parser        foo
-        File Path     README.md
-        Description   Foo
-        Architecture
-        MD5           b21df2332fe87c0fae95bdda00b5a3c0
-        SHA1          8841a1fff55687ccddc587935b62667173b14bcd
-        SHA256        0097c13a3541a440d64155a7f4443d76597409e0f40ce3ae67f73f51f59f1930
-        Compile Time
-        Tags
-        
-        ---- Socket ----
-        Tags    Address    Network Protocol
-        ------  ---------  ------------------
-                127.0.0.1  tcp
-        
-        ---- URL ----
-        Tags    Url               Address    Network Protocol    Application Protocol
-        ------  ----------------  ---------  ------------------  ----------------------
-                http://127.0.0.1  127.0.0.1  tcp                 http
-        
-        ---- Residual Files ----
-        Tags    Filename           Description          MD5                               Arch    Compile Time
-        ------  -----------------  -------------------  --------------------------------  ------  --------------
-                fooconfigtest.txt  example output file  5eb63bbbe01eeed093cb22bb8f5acdc3
-        
-        ---- Logs ----
-        [+] File README.md identified as Foo.
-        [+] size of inputfile is 15560 bytes
-        [+] README.md dispatched residual file: fooconfigtest.txt
-        [+] File fooconfigtest.txt described as example output file
-        [+] operating on inputfile README.md
-        
-        ----- File Tree -----
-        <README.md (b21df2332fe87c0fae95bdda00b5a3c0) : Foo>
-         <fooconfigtest.txt (5eb63bbbe01eeed093cb22bb8f5acdc3) : example output file>
-        ```
-        
-        see ```mwcp parse -h``` for full set of options
-        
-        
-        ### REST API
-        
-        DC3-MWCP can be used as a web service. The web service provides a web application as
-        well as a REST API for some commonly used functions:
-        
-        * ```/run_parser/<parser>``` -- executes a parser on uploaded file
-        * ```/descriptions``` -- provides list of available parsers
-        * ```/schema.json``` -- provides the [schema](#schema) for report output
-        
-        To use, first start the server by running:
-        ```console
-        > mwcp serve
-        ```
-        
-        Then you can either use an HTTP client to create REST requests.
-        
-        Using cURL:
-        ```console
-        # Get JSON for processing README.md with foo parser
-        > curl --form data=@README.md http://localhost:8080/run_parser/foo
-        # Get STIX 2.1 JSON for processing README.md with foo parser
-        > curl --form data=@README.md --form output=stix http://localhost:8080/run_parser/foo
-        # Get STIX 2.1 JSON  without artifacts for processing README.md with foo parser
-        > curl --form data=@README.md --form output=stix --form no_file_data=1 http://localhost:8080/run_parser/foo
-        ```
-        
-        Using Python requests:
-        ```python
-        import requests
-        req = requests.post("http://localhost:8080/run_parser/foo", files={'data': open("README.md", 'rb')})
-        req.json()
-        ```
-        
-        Output:
-        ```json
-        {
-            "url": [
-                "http://127.0.0.1"
-            ],
-            "address": [
-                "127.0.0.1"
-            ],
-            "debug": [
-                "size of inputfile is 7128 bytes",
-                "outputfile: fooconfigtest.txt",
-                "operating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfile-n4mw7uw3"
-            ],
-            "outputfile": [
-                [
-                    "fooconfigtest.txt",
-                    "example output file",
-                    "5eb63bbbe01eeed093cb22bb8f5acdc3",
-                    "aGVsbG8gd29ybGQ="
-                ]
-            ],
-            "output_text": "\n----Standard Metadata----\n\nurl                  http://127.0.0.1\naddress              127.0.0.1\n\n----Debug----\n\nsize of inputfile
-        is 7128 bytes\noutputfile: fooconfigtest.txt\noperating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfi
-        le-n4mw7uw3\n\n----Output Files----\n\nfooconfigtest.txt    example output file\n                     5eb63bbbe01eeed093cb22bb8f5acdc3\n"
-        }
-        ```
-        
-        By default, the original legacy json schema will be provided upon request.
-        To use the new schema, you must set the `legacy` option in the query section to `False`.
-        
-        Eventually this new schema will replace the old one entirely. It is recommended to start using this flag
-        to help transition your automation platform to use the new schema.
-        
-        
-        ```console
-        > curl --form data=@README.md http://localhost:8080/run_parser/foo?legacy=False
-        ```
-        
-        ```json
-        [
-            {
-                "type": "report",
-                "tags": [],
-                "input_file": {
-                    "type": "input_file",
-                    "tags": [],
-                    "name": "README.md",
-                    "description": "Foo",
-                    "md5": "80a3d9b88c956c960d1fea265db0882e",
-                    "sha1": "994aa37fd26dd88272b8e661631eec8a5f425920",
-                    "sha256": "3bef8d5dc4cd94c0ee92c9b6d7ee47a4794e550d287ee1affde84c2b7bcdf3cb",
-                    "architecture": null,
-                    "compile_time": null,
-                    "file_path": "README.md",
-                    "data": null
-                },
-                "parser": "foo",
-                "errors": [],
-                "logs": [
-                    "[+] File README.md identified as Foo.",
-                    "[+] size of inputfile is 15887 bytes",
-                    "[+] README.md dispatched residual file: fooconfigtest.txt",
-                    "[+] File fooconfigtest.txt described as example output file",
-                    "[+] operating on inputfile README.md"
-                ],
-                "metadata": [
-                    {
-                        "type": "url",
-                        "tags": [],
-                        "url": "http://127.0.0.1",
-                        "socket": {
-                            "type": "socket",
-                            "tags": [],
-                            "address": "127.0.0.1",
-                            "port": null,
-                            "network_protocol": "tcp",
-                            "c2": null,
-                            "listen": null
-                        },
-                        "path": null,
-                        "query": "",
-                        "application_protocol": "http",
-                        "credential": null
-                    },
-                    {
-                        "type": "socket",
-                        "tags": [],
-                        "address": "127.0.0.1",
-                        "port": null,
-                        "network_protocol": "tcp",
-                        "c2": null,
-                        "listen": null
-                    },
-                    {
-                        "type": "residual_file",
-                        "tags": [],
-                        "name": "fooconfigtest.txt",
-                        "description": "example output file",
-                        "md5": "5eb63bbbe01eeed093cb22bb8f5acdc3",
-                        "sha1": "2aae6c35c94fcfb415dbe95f408b9ce91ee846ed",
-                        "sha256": "b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9",
-                        "architecture": null,
-                        "compile_time": null,
-                        "file_path": "README.md_mwcp_output\\5eb63_fooconfigtest.txt",
-                        "data": null
-                    }
-                ]
-            }
-        ]
-        ```
-        
-        A simple HTML interface is also available at the same address. By default this
-        is `http://localhost:8080/`. Individual samples can be submitted and results
-        saved as JSON, plain text, or ZIP archives.
-        
-        
-        ### Python API
-        DC3-MWCP can be run directly from Python.
-        
-        ```python
-        #!/usr/bin/env python
-        """
-        Simple example to demonstrate use of the API provided by DC3-MWCP framework.
-        """
-        
-        # first, import mwcp
-        import mwcp
-        
-        # register the builtin MWCP parsers and any other parser packages installed on the system
-        mwcp.register_entry_points()
-        
-        # register a directory containing parsers
-        mwcp.register_parser_directory(r'C:\my_parsers')
-        
-        # view all available parsers
-        print(mwcp.get_parser_descriptions(config_only=False))
-        
-        # call the run() function to to generate a mwcp.Report object.
-        report = mwcp.run("FooParser", "C:\\README.md")
-        # alternate, run on provided buffer:
-        report = mwcp.run("FooParser", data=b"lorem ipsum")
-        
-        # Display report results in a variety of formats:
-        print(report.as_dict())
-        print(report.as_json())
-        print(report.as_text())
-        
-        # The metadata schema has changed recently. To get the legacy format use the following:
-        print(report.as_dict_legacy())
-        print(report.as_json_legacy())
-        
-        # You can also programmatically view results of report:
-        from mwcp import metadata
-        
-        # display errors that may occur
-        for log in report.errors:
-          print(log)
-        
-        # display data about original input file
-        print(report.input_file)
-        
-        # get all url's using ftp protocol or has a query
-        for url in report.get(metadata.URL):
-          if url.application_protocol == "ftp" or url.query:
-            print(url.url)
-        
-        # get residual files
-        for residual_file in report.get(metadata.File):
-          print(residual_file.name)
-          print(residual_file.description)
-          print(residual_file.md5)
-        
-        # iterate through all metadata elements
-        for element in report:
-          print(element)
-        
-        ```
-        
-        ## Configuration
-        DC3-MWCP uses a configuration file which is located within the user's 
-        profile directory. (`%APPDATA%\Local\mwcp\config.yml` for Windows or `~/.config/mwcp/config.yml` for Linux)
-        
-        This configuration file is used to manage configurable parameters, such as the location
-        of the malware repository used for testing or the default parser source.
-        
-        To configure this file, run `mwcp config` to open up the file in your default text
-        editor.
-        
-        An alternative configuration file can also be temporarily set using the `--config` parameter.
-        ```console
-        > mwcp --config='new_config.yml' test Foo
-        ```
-        
-        Individual configuration parameters can be overwritten on the command line using the respective parameter.
-        
-        
-        ## Logging
-        DC3-MWCP uses Python's builtin in `logging` module to log all messages.
-        By default, logging is configured using the [log_config.yml](mwcp/config/log_config.yml) configuration
-        file. Which is currently set to log all messages to the console and error messages to `%LOCALAPPDATA%/mwcp/errors.log`. 
-        
-        You can provide your own custom log configuration file by adding the path
-        to the configuration parameter `LOG_CONFIG_PATH`. 
-        (Please see [Python's documentation](http://docs.python.org/dev/library/logging.config.html) for more information on how to write your own configuration file.)
-        
-        You may also use the `--verbose` or `--debug` flags to adjust the logging level when using the `mwcp` tool.
-        
-        
-        ## Schema
-        
-        One of the major goals of DC3-MWCP is to standardize output for malware configuration parsers, making the data
-        from one parser comparable with that of other parsers. This is achieved by establishing a schema of
-        standardized metadata elements that represent the common malware configuration items seen across malware families.
-        
-        A formal [JSON Schema](https://json-schema.org) can be found at [schema.json](/mwcp/config/schema.json), by calling `mwcp schema` in the command line, or programmatically by calling `mwcp.schema()`. 
-        This schema is versioned the same as DC3-MWCP. A change in the version may not necessarily
-        reflect a change in the actual schema. However, any major or minor changes to the schema will
-        be reflected in an appropriate change to the version and will be noted in the [changelog](/CHANGELOG.md).
-        Please ensure you pin DC3-MWCP appropriately.
-        
-        It is acknowledged that a set of generic elements will often not be adequate to capture the nuances of
-        individual malware families. To ensure that malware family specific attributes are appropriately captured
-        in parser output, the schema includes an "Other" element which supports arbitrary key-value pairs.
-        The keys and values are arbitrary to permit flexibility in describing the peculiarities of individual malware families.
-        Information
-        not captured in the abstract standardized elements is captured through this mechanism.
-        
-        The use of [tags](/docs/ParserComponents.md#tagging) is encouraged to provide additional context for the configuration items.
-        For example, if a specific url is used to download a second stage component, a tag of "download"
-        could be added to the reported URL element. Alternatively, if the URL is used for a proxy, 
-        a tag of "proxy" could be included.
-        There is no standard on what tags are available or when they should be included.
-        This should be determined by your organization.
-        
-        
-        ### Extending the Schema
-        
-        It is possible to extend the schema to include your own custom metadata elements.
-        This can be accomplished by creating a class that inherits from `mwcp.metadata.Metadata`. 
-        This class must be decorated with [attr](https://attrs.org) using the custom configuration `mwcp.metadata.config`. 
-        
-        *NOTE: The class name must be unique from other metadata elements.*
-        
-        ```python
-        from typing import List
-        
-        import attr
-        
-        import mwcp
-        from mwcp import metadata
-        
-        
-        @attr.s(**metadata.config)
-        class MyCustom(metadata.Metadata):
-            """
-            This is my custom metadata item.
-            """
-            field_a: str
-            field_b: int
-            field_c: List[str] = attr.ib(factory=list)
-        
-            
-        item = MyCustom(field_a="hello", field_b=42, field_c=["a", "b"])
-        
-        print(item)
-        print(item.as_dict())
-        
-        # Custom items can be included in the report like normal.
-        # MWCP will automatically format and display the custom element in the report.
-        report = mwcp.Report()
-        with report:
-            report.add(item)
-        
-        print(report.as_text())
-        ```
-        
-        ```
-        MyCustom(tags=set(), field_a='hello', field_b=42, field_c=['a', 'b'])
-        {'type': 'my_custom', 'tags': [], 'field_a': 'hello', 'field_b': 42, 'field_c': ['a', 'b']}
-        ---- My Custom ----
-        Tags    Field A      Field B  Field C
-        ------  ---------  ---------  ----------
-                hello             42  a, b
-        ```
-        
-        
-        Please note, that extending the schema will obviously cause the [schema.json](/mwcp/config/schema.json) file to be incorrect.
-        To regenerate the schema to also include the custom element run `mwcp.schema()` afterwards.
-        
-        ```python
-        import json
-        import mwcp
-        
-        with open("schema.json", "w") as fo:
-            json.dump(mwcp.schema(id="https://acme.org/0.1/schema.json"), fo, indent=4)
-        ```
-        
-        
-        ## STIX Output
-        
-        MWCP can generate a [STIX 2.1](https://www.oasis-open.org/standard/stix-version-2-1/) JSON output that is suitable for integration into many
-        systems that support the STIX standard. This output format makes use of three SCO 
-        extensions and one property extension in addition to the currently defined STIX
-        objects order to accurately convey MWCP's scan results.
-        
-        Some tools may not support these extensions yet which can result in the following data
-        being omitted when ingesting MWCP's STIX output.  The following provides a list of STIX
-        objects and extensions are used and what MWCP classes these are associated with:
-        
-        1. artifact (SCO)
-            1. File -- only used if the original binary is requested
-        2. crypto-currency-address (SCO Extension)
-            1. CryptoAddress
-        3. directory (SCO)
-            1. File
-            2. Path
-            3. Service
-        4. domain-name (SCO)
-            1. Socket
-            2. URL
-        5. email-address (SCO)
-            1. EmailAddress
-        6. file (SCO)
-            1. File
-            2. Path
-            3. Service
-        7. ipv4-address (SCO)
-            1. Socket
-            2. URL
-        8. ipv6-address (SCO)
-            1. Socket
-            2. URL
-        9. malware-analysis (SDO)
-            1. MWCP's scan results are tied together via a malware-analysis object showing the input object and the outputs
-        10. mutex (SCO)
-            1. Mutex
-        11. network-traffic (SCO)
-            1. Socket
-            2. URL
-        12. note (SDO)
-            1. Boolean and Integer values for Other.  These are added to the description of the Note.
-            2. Descriptions and other narrative text tied to SCOs
-            3. Tags for SCOs excluding files
-        13. observed-string (SCO Extension)
-            1. DecodedString
-            2. MissionID
-            3. Other
-            4. Pipe
-            5. User Agent
-            6. UUID
-        14. process (SCO)
-            1. Command
-            2. Service
-        15. relationship (SRO)
-            1. DecodedString
-            2. URL
-        16. RSA Private Key (Property Extension for x509-certificate)
-            1. RSAPrivateKey
-        17. symmetric-encryption (SCO)
-            1. EncryptionKey
-        18. user-account (SCO)
-            1. Credential
-        19. url (SCO)
-            1. URL
-        20. x509-certificate (SCO)
-            1. RSAPrivateKey
-            2. RSAPublicKey
-            3. SSLCertSHA1
-        21. windows-registry-key (SCO)
-            1. Registry2
-        
-        
-        ## Helper Utilities
-        MWCP comes with a few helper utilities (located in `mwcp.utils`) that may become useful for parsing malware files.
-        
-        - `pefileutils` - Provides helper functions for common routines done with the `pefile` library. (obtaining or checking for exports, imports, resources, sections, etc.)
-        - `elffileutils` - Provides helper functions for common routines done with the `elftools` library. Provides a consistent interface similar to `pefileutils`.
-        - `custombase64` - Provides functions for base64 encoding/decoding data with a custom alphabet.
-        - `construct` - Provides extended functionality to the [construct](https://construct.readthedocs.io) library and brings
-        back some lost features from version 2.8 into 2.9.
-            - This library has replaced the `enstructured` library originally found in the resources directory.
-            - Please follow [this tutorial](docs/construct.ipynb) for migrating from `enstructured` to `construct`.
-        - `pecon` - PE file reconstruction utility.
-            - Please see docstring in [pecon.py](mwcp/utils/pecon.py) for more information.
-        - `poshdeob` - An experimental powershell deobfuscator utility used to statically deobfuscate code and extract strings.
-         
-Keywords: malware
-Platform: UNKNOWN
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Intended Audience :: Developers
-Classifier: License :: OSI Approved :: MIT License
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.8
-Description-Content-Type: text/markdown
-Provides-Extra: dragodis
-Provides-Extra: kordesii
-Provides-Extra: testing
+Metadata-Version: 2.1
+Name: mwcp
+Version: 3.9.0
+Summary: A framework for malware configuration parsers.
+Home-page: http://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/
+Author: DC3
+Author-email: dcci@dc3.mil
+License: MIT
+Keywords: malware
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.8
+Description-Content-Type: text/markdown
+Provides-Extra: dragodis
+Provides-Extra: kordesii
+Provides-Extra: testing
+License-File: LICENSE.txt
+
+# DC3-MWCP
+[Changelog](CHANGELOG.md) | [Releases](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/releases)
+
+DC3 Malware Configuration Parser (DC3-MWCP) is a framework for parsing configuration information from malware.
+The information extracted from malware includes items such as addresses, passwords, filenames, and
+mutex names. A parser module is usually created per malware family.
+DC3-MWCP is designed to help ensure consistency in parser function and output, ease parser development,
+and facilitate parser sharing. DC3-MWCP supports both analyst directed analysis and
+large-scale automated execution, utilizing either the native python API, a REST API, or a provided
+command line tool. DC3-MWCP is authored by the Defense Cyber Crime Center (DC3).
+
+- [Install](#install)
+- [Builtin Parsers](#builtin-parsers)
+- [Dragodis Support](#dragodis-support)
+- [DC3-Kordesii Support](#dc3-kordesii-support)
+- [Usage](#usage)
+    - [CLI Tool](#cli-tool)
+    - [REST API](#rest-api)
+    - [Python API](#python-api)
+- [Schema](#schema)
+- [STIX Output](#stix-output)
+- [YARA Matching](#yara-matching)
+- [Helper Utilities](#helper-utilities)
+
+### Guides
+- [Parser Development](docs/ParserDevelopment.md)
+- [Parser Components](docs/ParserComponents.md)
+- [Parser Installation](docs/ParserInstallation.md)
+- [Parser Testing](docs/ParserTesting.md)
+- [Python Style Guide](docs/PythonStyleGuide.md)
+- [Construct Tutorial](docs/construct.ipynb)
+- [Style Guide](docs/PythonStyleGuide.md)
+- [Testing](docs/Testing.md)
+
+
+## Install
+```console
+> pip install mwcp
+```
+
+Alternatively you can clone this repo and install locally.
+```console
+> git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
+> pip install ./DC3-MWCP
+```
+
+For a development mode use the `-e` flag to install in editable mode:
+
+```console
+> git clone https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP.git
+> pip install -e ./DC3-MWCP
+```
+
+## Builtin Parsers
+DC3-MWCP includes a handful of builtin [parsers](./mwcp/parsers) to get you started.
+These can be used as-is, subclassed, or included in your own parser groups.
+
+To view the available parsers:
+```bash
+$ mwcp list
+```
+
+Parsers are installed under the `dc3` source name. To include them in a group simply add them with
+the `dc3:` prefix.
+
+```yml
+SuperMalware:
+    description: SuperMalware component
+    author: acme
+    parsers:
+      - dc3:Archive.Zip
+      - .Dropper
+      - .Implant
+      - dc3:Decoy
+```
+
+
+## Dragodis Support
+DC3-MWCP optionally supports [Dragodis](https://github.com/Defense-Cyber-Crime-Center/Dragodis)
+if it is installed. This allows you to obtain a disassembler agnostic interface for parsing
+the file's disassembly from the `mwcp.FileObject` object with the `.disassembly()` function.
+
+You can install Dragodis along with DC3-MWCP by adding `[dragodis]` to your appropriate install command:
+```
+pip install mwcp[dragodis]
+pip install ./DC3-MWCP[dragodis]
+pip install -e ./DC3-MWCP[dragodis]
+```
+
+After installation make sure to follow Dragodis's [installation instructions](https://github.com/Defense-Cyber-Crime-Center/Dragodis/blob/master/docs/install.rst) to setup
+a backend disassembler.
+
+*It is recommended to also install [Rugosa](https://github.com/Defense-Cyber-Crime-Center/rugosa) 
+for emulation and regex/yara matching capabilities using Dragodis.*
+
+
+## DC3-Kordesii Support
+DC3-MWCP optionally supports [DC3-Kordesii](https://github.com/Defense-Cyber-Crime-Center/kordesii)
+if it is installed. This will allow you to run any DC3-Kordesii decoder from the
+`mwcp.FileObject` object with the `run_kordesii_decoder` function.
+
+You can install DC3-Kordesii along with DC3-MWCP by adding `[kordesii]` to your appropriate install command:
+```
+pip install mwcp[kordesii]
+pip install ./DC3-MWCP[kordesii]
+pip install -e ./DC3-MWCP[kordesii]
+```
+
+
+## Usage
+DC3-MWCP is designed to allow easy development and use of malware config parsers. DC3-MWCP is also designed to ensure
+that these parsers are scalable and that DC3-MWCP can be integrated in other systems.
+
+Most automated processing systems will use a condition, such as a yara signature match, to trigger execution
+of an DC3-MWCP parser.
+
+There are 3 options for integration of DC3-MWCP:
+- CLI: `mwcp`
+- REST API: `mwcp serve`
+- Python API
+
+DC3-MWCP also includes a utility for test case generation and execution.
+
+### CLI tool
+
+DC3-MWCP can be used directly from the command line using the `mwcp` command.
+
+```console
+> mwcp parse foo ./README.md
+----- File: README.md -----
+Field         Value
+------------  ----------------------------------------------------------------
+Parser        foo
+File Path     README.md
+Description   Foo
+Architecture
+MD5           b21df2332fe87c0fae95bdda00b5a3c0
+SHA1          8841a1fff55687ccddc587935b62667173b14bcd
+SHA256        0097c13a3541a440d64155a7f4443d76597409e0f40ce3ae67f73f51f59f1930
+Compile Time
+Tags
+
+---- Socket ----
+Tags    Address    Network Protocol
+------  ---------  ------------------
+        127.0.0.1  tcp
+
+---- URL ----
+Tags    Url               Address    Network Protocol    Application Protocol
+------  ----------------  ---------  ------------------  ----------------------
+        http://127.0.0.1  127.0.0.1  tcp                 http
+
+---- Residual Files ----
+Tags    Filename           Description          MD5                               Arch    Compile Time
+------  -----------------  -------------------  --------------------------------  ------  --------------
+        fooconfigtest.txt  example output file  5eb63bbbe01eeed093cb22bb8f5acdc3
+
+---- Logs ----
+[+] File README.md identified as Foo.
+[+] size of inputfile is 15560 bytes
+[+] README.md dispatched residual file: fooconfigtest.txt
+[+] File fooconfigtest.txt described as example output file
+[+] operating on inputfile README.md
+
+----- File Tree -----
+<README.md (b21df2332fe87c0fae95bdda00b5a3c0) : Foo>
+ <fooconfigtest.txt (5eb63bbbe01eeed093cb22bb8f5acdc3) : example output file>
+```
+
+see ```mwcp parse -h``` for full set of options
+
+
+### REST API
+
+DC3-MWCP can be used as a web service. The web service provides a web application as
+well as a REST API for some commonly used functions:
+
+* ```/run_parser/<parser>``` -- executes a parser on uploaded file
+* ```/descriptions``` -- provides list of available parsers
+* ```/schema.json``` -- provides the [schema](#schema) for report output
+
+To use, first start the server by running:
+```console
+> mwcp serve
+```
+
+Then you can either use an HTTP client to create REST requests.
+
+Using cURL:
+```console
+# Get JSON for processing README.md with foo parser
+> curl --form data=@README.md http://localhost:8080/run_parser/foo
+# Get STIX 2.1 JSON for processing README.md with foo parser
+> curl --form data=@README.md --form output=stix http://localhost:8080/run_parser/foo
+# Get STIX 2.1 JSON  without artifacts for processing README.md with foo parser
+> curl --form data=@README.md --form output=stix --form no_file_data=1 http://localhost:8080/run_parser/foo
+```
+
+Using Python requests:
+```python
+import requests
+req = requests.post("http://localhost:8080/run_parser/foo", files={'data': open("README.md", 'rb')})
+req.json()
+```
+
+Output:
+```json
+{
+    "url": [
+        "http://127.0.0.1"
+    ],
+    "address": [
+        "127.0.0.1"
+    ],
+    "debug": [
+        "size of inputfile is 7128 bytes",
+        "outputfile: fooconfigtest.txt",
+        "operating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfile-n4mw7uw3"
+    ],
+    "outputfile": [
+        [
+            "fooconfigtest.txt",
+            "example output file",
+            "5eb63bbbe01eeed093cb22bb8f5acdc3",
+            "aGVsbG8gd29ybGQ="
+        ]
+    ],
+    "output_text": "\n----Standard Metadata----\n\nurl                  http://127.0.0.1\naddress              127.0.0.1\n\n----Debug----\n\nsize of inputfile is 7128 bytes\noutputfile: fooconfigtest.txt\noperating on inputfile C:\\Users\\JOHN.DOE\\AppData\\Local\\Temp\\mwcp-managed_tempdir-pk0f12oh\\mwcp-inputfile-n4mw7uw3\n\n----Output Files----\n\nfooconfigtest.txt    example output file\n                     5eb63bbbe01eeed093cb22bb8f5acdc3\n"
+}
+```
+
+By default, the original legacy json schema will be provided upon request.
+To use the new schema, you must set the `legacy` option in the query section to `False`.
+
+Eventually this new schema will replace the old one entirely. It is recommended to start using this flag
+to help transition your automation platform to use the new schema.
+
+
+```console
+> curl --form data=@README.md http://localhost:8080/run_parser/foo?legacy=False
+```
+
+```json
+[
+    {
+        "type": "report",
+        "tags": [],
+        "input_file": {
+            "type": "input_file",
+            "tags": [],
+            "name": "README.md",
+            "description": "Foo",
+            "md5": "80a3d9b88c956c960d1fea265db0882e",
+            "sha1": "994aa37fd26dd88272b8e661631eec8a5f425920",
+            "sha256": "3bef8d5dc4cd94c0ee92c9b6d7ee47a4794e550d287ee1affde84c2b7bcdf3cb",
+            "architecture": null,
+            "compile_time": null,
+            "file_path": "README.md",
+            "data": null
+        },
+        "parser": "foo",
+        "errors": [],
+        "logs": [
+            "[+] File README.md identified as Foo.",
+            "[+] size of inputfile is 15887 bytes",
+            "[+] README.md dispatched residual file: fooconfigtest.txt",
+            "[+] File fooconfigtest.txt described as example output file",
+            "[+] operating on inputfile README.md"
+        ],
+        "metadata": [
+            {
+                "type": "url",
+                "tags": [],
+                "url": "http://127.0.0.1",
+                "socket": {
+                    "type": "socket",
+                    "tags": [],
+                    "address": "127.0.0.1",
+                    "port": null,
+                    "network_protocol": "tcp",
+                    "c2": null,
+                    "listen": null
+                },
+                "path": null,
+                "query": "",
+                "application_protocol": "http",
+                "credential": null
+            },
+            {
+                "type": "socket",
+                "tags": [],
+                "address": "127.0.0.1",
+                "port": null,
+                "network_protocol": "tcp",
+                "c2": null,
+                "listen": null
+            },
+            {
+                "type": "residual_file",
+                "tags": [],
+                "name": "fooconfigtest.txt",
+                "description": "example output file",
+                "md5": "5eb63bbbe01eeed093cb22bb8f5acdc3",
+                "sha1": "2aae6c35c94fcfb415dbe95f408b9ce91ee846ed",
+                "sha256": "b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9",
+                "architecture": null,
+                "compile_time": null,
+                "file_path": "README.md_mwcp_output\\5eb63_fooconfigtest.txt",
+                "data": null
+            }
+        ]
+    }
+]
+```
+
+A simple HTML interface is also available at the same address. By default this
+is `http://localhost:8080/`. Individual samples can be submitted and results
+saved as JSON, plain text, or ZIP archives.
+
+
+### Python API
+DC3-MWCP can be run directly from Python.
+
+```python
+#!/usr/bin/env python
+"""
+Simple example to demonstrate use of the API provided by DC3-MWCP framework.
+"""
+
+# first, import mwcp
+import mwcp
+
+# register the builtin MWCP parsers and any other parser packages installed on the system
+mwcp.register_entry_points()
+
+# register a directory containing parsers
+mwcp.register_parser_directory(r'C:\my_parsers')
+
+# view all available parsers
+print(mwcp.get_parser_descriptions(config_only=False))
+
+# call the run() function to to generate a mwcp.Report object.
+report = mwcp.run("FooParser", "C:\\README.md")
+# alternate, run on provided buffer:
+report = mwcp.run("FooParser", data=b"lorem ipsum")
+
+# Display report results in a variety of formats:
+print(report.as_dict())
+print(report.as_json())
+print(report.as_text())
+
+# The metadata schema has changed recently. To get the legacy format use the following:
+print(report.as_dict_legacy())
+print(report.as_json_legacy())
+
+# You can also programmatically view results of report:
+from mwcp import metadata
+
+# display errors that may occur
+for log in report.errors:
+  print(log)
+
+# display data about original input file
+print(report.input_file)
+
+# get all url's using ftp protocol or has a query
+for url in report.get(metadata.URL):
+  if url.application_protocol == "ftp" or url.query:
+    print(url.url)
+
+# get residual files
+for residual_file in report.get(metadata.File):
+  print(residual_file.name)
+  print(residual_file.description)
+  print(residual_file.md5)
+
+# iterate through all metadata elements
+for element in report:
+  print(element)
+
+```
+
+## Configuration
+DC3-MWCP uses a configuration file which is located within the user's 
+profile directory. (`%APPDATA%\Local\mwcp\config.yml` for Windows or `~/.config/mwcp/config.yml` for Linux)
+
+This configuration file is used to manage configurable parameters, such as the location
+of the malware repository used for testing or the default parser source.
+
+To configure this file, run `mwcp config` to open up the file in your default text
+editor.
+
+An alternative configuration file can also be temporarily set using the `--config` parameter.
+```console
+> mwcp --config='new_config.yml' test Foo
+```
+
+Individual configuration parameters can be overwritten on the command line using the respective parameter.
+
+
+## Logging
+DC3-MWCP uses Python's builtin in `logging` module to log all messages.
+By default, logging is configured using the [log_config.yml](mwcp/config/log_config.yml) configuration
+file. Which is currently set to log all messages to the console and error messages to `%LOCALAPPDATA%/mwcp/errors.log`. 
+
+You can provide your own custom log configuration file by adding the path
+to the configuration parameter `LOG_CONFIG_PATH`. 
+(Please see [Python's documentation](http://docs.python.org/dev/library/logging.config.html) for more information on how to write your own configuration file.)
+
+You may also use the `--verbose` or `--debug` flags to adjust the logging level when using the `mwcp` tool.
+
+
+## Schema
+
+One of the major goals of DC3-MWCP is to standardize output for malware configuration parsers, making the data
+from one parser comparable with that of other parsers. This is achieved by establishing a schema of
+standardized metadata elements that represent the common malware configuration items seen across malware families.
+
+A formal [JSON Schema](https://json-schema.org) can be found at [schema.json](/mwcp/config/schema.json), by calling `mwcp schema` in the command line, or programmatically by calling `mwcp.schema()`. 
+This schema is versioned the same as DC3-MWCP. A change in the version may not necessarily
+reflect a change in the actual schema. However, any major or minor changes to the schema will
+be reflected in an appropriate change to the version and will be noted in the [changelog](/CHANGELOG.md).
+Please ensure you pin DC3-MWCP appropriately.
+
+It is acknowledged that a set of generic elements will often not be adequate to capture the nuances of
+individual malware families. To ensure that malware family specific attributes are appropriately captured
+in parser output, the schema includes an "Other" element which supports arbitrary key-value pairs.
+The keys and values are arbitrary to permit flexibility in describing the peculiarities of individual malware families.
+Information
+not captured in the abstract standardized elements is captured through this mechanism.
+
+The use of [tags](/docs/ParserComponents.md#tagging) is encouraged to provide additional context for the configuration items.
+For example, if a specific url is used to download a second stage component, a tag of "download"
+could be added to the reported URL element. Alternatively, if the URL is used for a proxy, 
+a tag of "proxy" could be included.
+There is no standard on what tags are available or when they should be included.
+This should be determined by your organization.
+
+
+### Extending the Schema
+
+It is possible to extend the schema to include your own custom metadata elements.
+This can be accomplished by creating a class that inherits from `mwcp.metadata.Metadata`. 
+This class must be decorated with [attr](https://attrs.org) using the custom configuration `mwcp.metadata.config`. 
+
+*NOTE: The class name must be unique from other metadata elements.*
+
+```python
+from typing import List
+
+import attr
+
+import mwcp
+from mwcp import metadata
+
+
+@attr.s(**metadata.config)
+class MyCustom(metadata.Metadata):
+    """
+    This is my custom metadata item.
+    """
+    field_a: str
+    field_b: int
+    field_c: List[str] = attr.ib(factory=list)
+
+    
+item = MyCustom(field_a="hello", field_b=42, field_c=["a", "b"])
+
+print(item)
+print(item.as_dict())
+
+# Custom items can be included in the report like normal.
+# MWCP will automatically format and display the custom element in the report.
+report = mwcp.Report()
+with report:
+    report.add(item)
+
+print(report.as_text())
+```
+
+```
+MyCustom(tags=set(), field_a='hello', field_b=42, field_c=['a', 'b'])
+{'type': 'my_custom', 'tags': [], 'field_a': 'hello', 'field_b': 42, 'field_c': ['a', 'b']}
+---- My Custom ----
+Tags    Field A      Field B  Field C
+------  ---------  ---------  ----------
+        hello             42  a, b
+```
+
+
+Please note, that extending the schema will obviously cause the [schema.json](/mwcp/config/schema.json) file to be incorrect.
+To regenerate the schema to also include the custom element run `mwcp.schema()` afterwards.
+
+```python
+import json
+import mwcp
+
+with open("schema.json", "w") as fo:
+    json.dump(mwcp.schema(id="https://acme.org/0.1/schema.json"), fo, indent=4)
+```
+
+
+## STIX Output
+
+MWCP can generate a [STIX 2.1](https://www.oasis-open.org/standard/stix-version-2-1/) JSON output that is suitable for integration into many
+systems that support the STIX standard. This output format makes use of three SCO 
+extensions and one property extension in addition to the currently defined STIX
+objects order to accurately convey MWCP's scan results.
+
+Some tools may not support these extensions yet which can result in the following data
+being omitted when ingesting MWCP's STIX output.  The following provides a list of STIX
+objects and extensions are used and what MWCP classes these are associated with:
+
+1. artifact (SCO)
+    1. File -- only used if the original binary is requested
+2. crypto-currency-address (SCO Extension)
+    1. CryptoAddress
+3. directory (SCO)
+    1. File
+    2. Path
+    3. Service
+4. domain-name (SCO)
+    1. Socket
+    2. URL
+5. email-address (SCO)
+    1. EmailAddress
+6. file (SCO)
+    1. File
+    2. Path
+    3. Service
+7. ipv4-address (SCO)
+    1. Socket
+    2. URL
+8. ipv6-address (SCO)
+    1. Socket
+    2. URL
+9. malware-analysis (SDO)
+    1. MWCP's scan results are tied together via a malware-analysis object showing the input object and the outputs
+10. mutex (SCO)
+    1. Mutex
+11. network-traffic (SCO)
+    1. Socket
+    2. URL
+12. note (SDO)
+    1. Boolean and Integer values for Other.  These are added to the description of the Note.
+    2. Descriptions and other narrative text tied to SCOs
+    3. Tags for SCOs excluding files
+13. observed-string (SCO Extension)
+    1. DecodedString
+    2. MissionID
+    3. Other
+    4. Pipe
+    5. User Agent
+    6. UUID
+14. process (SCO)
+    1. Command
+    2. Service
+15. relationship (SRO)
+    1. DecodedString
+    2. URL
+16. RSA Private Key (Property Extension for x509-certificate)
+    1. RSAPrivateKey
+17. symmetric-encryption (SCO)
+    1. EncryptionKey
+18. user-account (SCO)
+    1. Credential
+19. url (SCO)
+    1. URL
+20. x509-certificate (SCO)
+    1. RSAPrivateKey
+    2. RSAPublicKey
+    3. SSLCertSHA1
+21. windows-registry-key (SCO)
+    1. Registry2
+
+
+## YARA Matching
+
+MWCP includes a runner that can use YARA match results to determine which parser(s) to run on a given file.
+
+This will be used whenever you use `-` instead of specifying a parser on the command line,
+when a parser isn't specified in `mwcp.run()`, or when a parser isn't specified in a server request.
+
+```bash
+$ mwcp parse - input.exe
+$ curl --form data=@input.exe http://localhost:8080/run_parser
+```
+
+```python
+import mwcp 
+mwcp.register_entry_points()
+
+report = mwcp.run(data=b"file data")
+```
+
+As well, YARA matching will be recursively used on unidentified residual files.
+If you want to disable this, either set `--no-recursive` on the command line or set `recursive=False` on `mwcp.run()`.
+
+### Setup
+
+To enable YARA matching you'll need to specify a directory containing YARA signatures which use the `mwcp` 
+meta field to map a signature to a comma delimited list of parsers. Parsers can be specified in the same
+way as on the command line or Python API. That is, parser group names, `.` notation for specific parser components,
+and the use of `:` for specifying a parser source are all valid.
+
+Any signatures that don't have the `mwcp` meta field will be ignored.
+
+```yara
+rule SuperMalware {
+    meta:
+        mwcp = "SuperMalware"
+    ...
+}
+```
+
+To setup a YARA repo, set the `YARA_REPO` field to point to a directory containing YARA signatures (subdirectories allowed)
+in the configuration file that appears when you call `mwcp config`.
+If you have upgraded from an older version of MWCP, you may need to first backup and remove the original configuration file and
+then run `mwcp config` again to have MWCP recreate the file.
+
+Alternatively, the yara repo can be specified in the command line with `--yara-repo`. But the former method
+is necessary to use YARA matching with the server.
+
+
+## Helper Utilities
+MWCP comes with a few helper utilities (located in `mwcp.utils`) that may become useful for parsing malware files.
+
+- `pefileutils` - Provides helper functions for common routines done with the `pefile` library. (obtaining or checking for exports, imports, resources, sections, etc.)
+- `elffileutils` - Provides helper functions for common routines done with the `elftools` library. Provides a consistent interface similar to `pefileutils`.
+- `custombase64` - Provides functions for base64 encoding/decoding data with a custom alphabet.
+- `construct` - Provides extended functionality to the [construct](https://construct.readthedocs.io) library and brings
+back some lost features from version 2.8 into 2.9.
+    - This library has replaced the `enstructured` library originally found in the resources directory.
+    - Please follow [this tutorial](docs/construct.ipynb) for migrating from `enstructured` to `construct`.
+- `pecon` - PE file reconstruction utility.
+    - Please see docstring in [pecon.py](mwcp/utils/pecon.py) for more information.
+- `poshdeob` - An experimental powershell deobfuscator utility used to statically deobfuscate code and extract strings.
+
```

### Comparing `mwcp-3.8.0/mwcp.egg-info/SOURCES.txt` & `mwcp-3.9.0/mwcp.egg-info/SOURCES.txt`

 * *Files 4% similar despite different names*

```diff
@@ -12,15 +12,14 @@
 mwcp/file_object.py
 mwcp/metadata.py
 mwcp/parser.py
 mwcp/parser_config.yml
 mwcp/registry.py
 mwcp/report.py
 mwcp/report_writers.py
-mwcp/reporter.py
 mwcp/runner.py
 mwcp/tester.py
 mwcp/testing.py
 mwcp.egg-info/PKG-INFO
 mwcp.egg-info/SOURCES.txt
 mwcp.egg-info/dependency_links.txt
 mwcp.egg-info/entry_points.txt
@@ -28,17 +27,26 @@
 mwcp.egg-info/top_level.txt
 mwcp/config/__init__.py
 mwcp/config/config.yml
 mwcp/config/fields.json
 mwcp/config/fields.txt
 mwcp/config/log_config.yml
 mwcp/config/schema.json
+mwcp/parsers/Archive.py
+mwcp/parsers/Decoy.py
+mwcp/parsers/GenericDropper.py
+mwcp/parsers/ISO.py
+mwcp/parsers/PDF.py
+mwcp/parsers/PowerShell.py
+mwcp/parsers/Python.py
+mwcp/parsers/Quarantined.py
+mwcp/parsers/RSA.py
 mwcp/parsers/TA.py
+mwcp/parsers/VisualBasic.py
 mwcp/parsers/__init__.py
-mwcp/parsers/bar.py
 mwcp/parsers/foo.py
 mwcp/parsers/tests/foo/f144899b86766688991c5d0d10902f4a.json
 mwcp/resources/__init__.py
 mwcp/resources/techanarchy_bridge.py
 mwcp/resources/RATDecoders/PLACE_PARSERS_HERE
 mwcp/resources/RATDecoders/__init__.py
 mwcp/stix/__init__.py
@@ -85,14 +93,17 @@
 mwcp/tests/test_report_writer/report.txt
 mwcp/tests/test_report_writer/report_foreign.html
 mwcp/tests/test_report_writer/report_foreign.md
 mwcp/tests/test_report_writer/report_foreign.txt
 mwcp/tests/test_report_writer/report_wordwrap.html
 mwcp/tests/test_report_writer/report_wordwrap.md
 mwcp/tests/test_report_writer/report_wordwrap.txt
+mwcp/tests/test_runner/Sample.py
+mwcp/tests/test_runner/yara_repo/rule_a.yara
+mwcp/tests/test_runner/yara_repo/rule_b.yara
 mwcp/tests/test_server/DecodedStringTestParser.py
 mwcp/tests/test_stix/report.json
 mwcp/tests/test_string_report/strings.json
 mwcp/tests/test_string_report/strings.txt
 mwcp/tools/__init__.py
 mwcp/tools/update_legacy_tests.py
 mwcp/tools/update_schema.py
```

### Comparing `mwcp-3.8.0/setup.py` & `mwcp-3.9.0/setup.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,75 +1,81 @@
-#!/usr/bin/env python
-"""
-A framework for malware configuration parsers.
-"""
-
-from setuptools import setup, find_packages
-
-setup(
-    name="mwcp",
-    author="DC3",
-    author_email="dcci@dc3.mil",
-    keywords="malware",
-    url="http://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/",
-    packages=find_packages(),
-    include_package_data=True,
-    license='MIT',
-    classifiers=[
-        'Development Status :: 5 - Production/Stable',
-        'Intended Audience :: Developers',
-        'License :: OSI Approved :: MIT License',
-        'Programming Language :: Python :: 3',
-        'Programming Language :: Python :: 3.8',
-    ],
-    entry_points={
-        'console_scripts': [
-            'mwcp = mwcp.cli:main',
-            'poshdeob = mwcp.utils.poshdeob:main',
-            'mwcp_update_legacy_tests = mwcp.tools.update_legacy_tests:main',
-        ],
-        'mwcp.parsers': [
-            'mwcp = mwcp.parsers',
-        ]
-    },
-    install_requires=[
-        'anytree',
-        'appdirs',
-        'attrs>=20.3.0',
-        'bitarray',
-        'cattrs',
-        'click>=8.0.1',
-        'construct==2.9.45',  # pin because parsers are very dependent on this.
-        'defusedxml',
-        'future',
-        'jinja2',  # For construct.html_hex()
-        'jsonschema_extractor>=1.0',
-        'pandas',
-        'pefile>=2019.4.18',
-        'pyasn1',
-        'pyasn1_modules',
-        'pyelftools',
-        'pyparsing',
-        'pytest>=6.0.0',
-        'pytest-datadir',
-        'pytest-xdist',
-        'pytest-mock',
-        'pyyaml',
-        'requests',
-        'ruamel.yaml',
-        'six',
-        'tabulate[widechars]<1.0.0',
-        'stix2',
-        # For the server and API
-        'flask',
-        'pygments',
-    ],
-    extras_require={
-        'dragodis': ['dragodis>=0.2.0'],
-        'kordesii': ['kordesii>=2.0.0'],
-        'testing': [
-            'jsonschema',
-            'dragodis',
-            'rugosa',
-        ],
-    }
-)
+#!/usr/bin/env python
+"""
+A framework for malware configuration parsers.
+"""
+
+from setuptools import setup, find_packages
+
+setup(
+    name="mwcp",
+    author="DC3",
+    author_email="dcci@dc3.mil",
+    keywords="malware",
+    url="http://github.com/Defense-Cyber-Crime-Center/DC3-MWCP/",
+    packages=find_packages(),
+    include_package_data=True,
+    license='MIT',
+    classifiers=[
+        'Development Status :: 5 - Production/Stable',
+        'Intended Audience :: Developers',
+        'License :: OSI Approved :: MIT License',
+        'Programming Language :: Python :: 3',
+        'Programming Language :: Python :: 3.8',
+    ],
+    entry_points={
+        'console_scripts': [
+            'mwcp = mwcp.cli:main',
+            'poshdeob = mwcp.utils.poshdeob:main',
+            'mwcp_update_legacy_tests = mwcp.tools.update_legacy_tests:main',
+        ],
+        'mwcp.parsers': [
+            'dc3 = mwcp.parsers',
+        ]
+    },
+    install_requires=[
+        'anytree',
+        'appdirs',
+        'attrs>=20.3.0',
+        'bitarray',
+        'cattrs',
+        'click>=8.0.1',
+        'construct==2.9.45',  # pin because parsers are very dependent on this.
+        'defusedxml',
+        'future',
+        'jinja2',  # For construct.html_hex()
+        'jsonschema_extractor>=1.0',
+        'pandas',
+        'pefile>=2019.4.18',
+        'pyasn1',
+        'pyasn1_modules',
+        'pyelftools',
+        'pyparsing',
+        'pytest>=6.0.0',
+        'pytest-datadir',
+        'pytest-xdist',
+        'pytest-mock',
+        'pyyaml',
+        'requests',
+        'ruamel.yaml',
+        'six',
+        'tabulate[widechars]<1.0.0',
+        'stix2',
+        'yara-python',
+        # For the server and API
+        'flask',
+        'pygments',
+
+        # Dependencies for builtin parsers.
+        'isoparser',
+        'pycryptodome',
+        'olefile',
+    ],
+    extras_require={
+        'dragodis': ['dragodis>=0.2.0'],
+        'kordesii': ['kordesii>=2.0.0'],
+        'testing': [
+            'jsonschema',
+            'dragodis',
+            'rugosa',
+        ],
+    }
+)
```

